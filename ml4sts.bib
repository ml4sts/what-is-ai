@article{10.1145/3433949,
  title = {The ({{Im}}){{Possibility}} of Fairness: {{Different}} Value Systems Require Different Mechanisms for Fair Decision Making},
  author = {Friedler, Sorelle A. and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  year = {2021},
  month = mar,
  journal = {Communications of The Acm},
  volume = {64},
  number = {4},
  pages = {136--143},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {0001-0782},
  doi = {10.1145/3433949},
  abstract = {What does it mean to be fair?},
  issue_date = {April 2021}
}

@article{10.1145/3458723,
  title = {Datasheets for Datasets},
  author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and III, Hal Daum{\'e} and Crawford, Kate},
  year = {2021},
  month = nov,
  journal = {Communications of The Acm},
  volume = {64},
  number = {12},
  pages = {86--92},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {0001-0782},
  doi = {10.1145/3458723},
  abstract = {Documentation to facilitate communication between dataset creators and consumers.},
  issue_date = {December 2021}
}

@inproceedings{10.1145/3465416.3483302,
  title = {Opportunities for a More Interdisciplinary Approach to Measuring Perceptions of Fairness in Machine Learning},
  booktitle = {Equity and Access in Algorithms, Mechanisms, and Optimization},
  author = {Boykin, C. Malik and Dasch, Sophia T. and Rice Jr., Vincent and Lakshminarayanan, Venkat R. and Togun, Taiwo A. and Brown, Sarah M.},
  year = {2021},
  series = {{{EAAMO}} '21},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3465416.3483302},
  abstract = {As machine learning (ML) is deployed in high-stakes domains, such as disease diagnosis or prison sentencing, questions of fairness have become an area of concern in its development. This interest has produced a variety of statistical fairness definitions derived from classical performance metrics which further expand the decisions that ML practitioners must make in building a system. The need to choose between these definitions raises questions about what conditions influence people to perceive an algorithm as fair or not. Recent results highlight the heavily contextual nature of fairness perceptions, and the specific conditions under which psychological principles such as framing can reliably sway these perceptions. Additional interdisciplinary insights include lessons from the replication crisis within psychology, from which we can glean best-practices for reproducible empirical research. We survey key research at the intersection of ML and psychology, focusing on psychological mechanisms underlying fairness preferences. We conclude by stating the continued need for interdisciplinary research, and underscore best-practices that can inform the state-of-the-art practice. We consider this research to be of a descriptive nature, enabling a deeper understanding and a substantiated discussion.},
  articleno = {1},
  isbn = {978-1-4503-8553-4},
  keywords = {experiment design,fairness,machine learning}
}

@inproceedings{abebe2020roles,
  title = {Roles for Computing in Social Change},
  booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  author = {Abebe, Rediet and Barocas, Solon and Kleinberg, Jon and Levy, Karen and Raghavan, Manish and Robinson, David G},
  year = {2020},
  pages = {252--260}
}

@inproceedings{abebe2020Rolesa,
  title = {Roles for Computing in Social Change},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Abebe, Rediet and Barocas, Solon and Kleinberg, Jon and Levy, Karen and Raghavan, Manish and Robinson, David G.},
  year = {2020},
  month = jan,
  pages = {252--260},
  publisher = {ACM},
  address = {Barcelona Spain},
  doi = {10.1145/3351095.3372871},
  urldate = {2024-04-19},
  isbn = {978-1-4503-6936-7},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/F7C2N7TF/Abebe et al. - 2020 - Roles for computing in social change.pdf}
}

@misc{Acc,
  title = {Acc\_{{FPR}} - {{Jupyter Notebook}}},
  urldate = {2021-07-02},
  howpublished = {http://localhost:8888/notebooks/Acc\_FPR.ipynb\#Equal-Accuracy-and-FPR},
  file = {/Users/brownsarahm/Zotero/storage/GHVYWT7F/Acc_FPR.html}
}

@article{adebayo2018FairML,
  title = {{{FairML}}: {{Auditing}} Black-Box Predictive Models},
  author = {Adebayo, J},
  year = {2018}
}

@article{adler2017solving,
  title = {Solving Ill-Posed Inverse Problems Using Iterative Deep Neural Networks},
  author = {Adler, Jonas and {\"O}ktem, Ozan},
  year = {2017},
  journal = {Inverse Problems. An International Journal on the Theory and Practice of Inverse Problems, Inverse Methods and Computerized Inversion of Data},
  volume = {33},
  number = {12},
  pages = {124007},
  publisher = {IOP Publishing}
}

@article{adler2017Solving,
  title = {Solving Ill-Posed Inverse Problems Using Iterative Deep Neural Networks},
  author = {Adler, Jonas and {\"O}ktem, Ozan},
  year = {2017},
  journal = {Inverse Problems},
  volume = {33},
  number = {12},
  pages = {124007},
  publisher = {IOP Publishing}
}

@article{adolphs1997impaired,
  title = {Impaired Declarative Memory for Emotional Material Following Bilateral Amygdala Damage in Humans},
  author = {Adolphs, R and Cahill, L and Schul, R and Babinsky, R},
  year = {1997},
  journal = {Learning and Memory},
  volume = {4},
  number = {3},
  pages = {291--300}
}

@inproceedings{agrawal1998automatic,
  title = {Automatic Subspace Clustering of High Dimensional Data for Data Mining Applications},
  booktitle = {Proceedings {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Agrawal, R and Gehrke, J and Gunopulos, D and Raghavan, P},
  year = {1998},
  month = jun,
  pages = {94--105},
  publisher = {ACM Press},
  address = {Seattle, WA}
}

@article{agreCritical,
  title = {Toward a {{Critical Technical Practice}}},
  author = {Agre, Philip E},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/DXMXXBU6/Agre - Toward a Critical Technical Practice.pdf}
}

@article{ahissar2001figuring,
  title = {Figuring Space by Time},
  author = {Ahissar, Ehud and Arieli, Amos},
  year = {2001},
  journal = {Neuron},
  volume = {32},
  number = {2},
  pages = {185--201}
}

@article{ahn2019Fairsight,
  title = {Fairsight: {{Visual}} Analytics for Fairness in Decision Making},
  author = {Ahn, Yongsu and Lin, Yu-Ru},
  year = {2019},
  journal = {IEEE transactions on visualization and computer graphics},
  volume = {26},
  number = {1},
  pages = {1086--1095},
  publisher = {IEEE}
}

@inproceedings{ai_environment_primer,
  title = {The Environmental Impacts of {{AI}} -- Policy Primer},
  booktitle = {Hugging Face Blog},
  author = {Luccioni, Sasha and Trevelin, Bruna and Mitchell, Margaret},
  year = {2024},
  doi = {10.57967/hf/3004}
}

@article{aif3602018,
  title = {{{AI Fairness}} 360: {{An}} Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias},
  author = {Bellamy, Rachel K. E. and Dey, Kuntal and Hind, Michael and Hoffman, Samuel C. and Houde, Stephanie and Kannan, Kalapriya and Lohia, Pranay and Martino, Jacquelyn and Mehta, Sameep and Mojsilovic, Aleksandra and Nagar, Seema and Ramamurthy, Karthikeyan Natesan and Richards, John and Saha, Diptikalyan and Sattigeri, Prasanna and Singh, Moninder and Varshney, Kush R. and Zhang, Yunfeng},
  year = {2018},
  month = oct,
  journal = {arXiv preprint arXiv: {\textbackslash}ldots}
}

@article{aldous1983Exchangeability,
  title = {Exchangeability and Related Topics},
  author = {Aldous, David J},
  year = {1983},
  journal = {{\'E}cole d'{\'E}t{\'e} de Probabilit{\'e}s de Saint-Flour XIII --- 1983},
  pages = {1--198},
  issn = {10477047},
  doi = {10.1007/BFb0099421},
  abstract = {Page 1. EXCHANGEABILITY AND RELATED TOPICS PAR David J. ALDOUS Page 2. O. Introduction If you had asked a probabilist in 1970 what was known about exchangeability , you would likely have received the answer "There's de Finetti's ...},
  file = {/Users/brownsarahm/Zotero/storage/B2SKBBZJ/Aldous - 1983 - Exchangeability and related topics(3).pdf}
}

@inproceedings{alghamdi2020model,
  title = {Model Projection: {{Theory}} and Applications to Fair Machine Learning},
  booktitle = {2020 {{IEEE}} International Symposium on Information Theory ({{ISIT}})},
  author = {Alghamdi, Wael and Asoodeh, Shahab and Wang, Hao and Calmon, Flavio P and Wei, Dennis and Ramamurthy, Karthikeyan Natesan},
  year = {2020},
  pages = {2711--2716},
  publisher = {IEEE},
  address = {Los Angeles, CA, USA},
  organization = {IEEE}
}

@article{alin2010Simpson,
  title = {Simpson's Paradox},
  author = {Alin, Aylin},
  year = {2010},
  journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
  volume = {2},
  number = {2},
  pages = {247--250}
}

@inproceedings{alipourfard2018Can,
  title = {Can You {{Trust}} the {{Trend}}: {{Discovering Simpson}}'s {{Paradoxes}} in {{Social Data}}},
  booktitle = {e {{Eleventh ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {Alipourfard, Nazanin and Fennell, Peter G and Lerman, Kristina},
  year = {2018},
  file = {/Users/brownsarahm/Zotero/storage/6Y4RQ96N/Alipourfard, Fennell, Lerman - 2018 - Can you Trust the Trend Discovering Simpson's Paradoxes in Social Data.pdf}
}

@article{allen2014tracking,
  title = {Tracking Whole-Brain Connectivity Dynamics in the Resting State},
  author = {{\noopsort{allen}}a. Allen, Elena and Damaraju, Eswar and Plis, Sergey M. and Erhardt, Erik B. and Eichele, Tom and Calhoun, Vince D.},
  year = {2014},
  journal = {Cerebral Cortex},
  volume = {24},
  number = {March},
  pages = {663--676},
  issn = {10473211},
  doi = {10.1093/cercor/bhs352},
  abstract = {Spontaneous fluctuations are a hallmark of recordings of neural signals, emergent over time scales spanning milliseconds and tens of minutes. However, investigations of intrinsic brain organization based on resting-state functional magnetic resonance imaging have largely not taken into account the presence and potential of temporal variability, as most current approaches to examine functional connectivity (FC) implicitly assume that relationships are constant throughout the length of the recording. In this work, we describe an approach to assess whole-brain FC dynamics based on spatial independent component analysis, sliding time window correlation, and k-means clustering of windowed correlation matrices. The method is applied to resting-state data from a large sample (n = 405) of young adults. Our analysis of FC variability highlights particularly flexible connections between regions in lateral parietal and cingulate cortex, and argues against a labeling scheme where such regions are treated as separate and antagonistic entities. Additionally, clustering analysis reveals unanticipated FC states that in part diverge strongly from stationary connectivity patterns and challenge current descriptions of interactions between large-scale networks. Temporal trends in the occurrence of different FC states motivate theories regarding their functional roles and relationships with vigilance/arousal. Overall, we suggest that the study of time-varying aspects of FC can unveil flexibility in the functional coordination between different neural systems, and that the exploitation of these dynamics in further investigations may improve our understanding of behavioral shifts and adaptive processes.},
  pmid = {23146964},
  keywords = {dynamics,fMRI,functional connectivity,independent component analysis,intrinsic activity,resting state,state variability},
  file = {/Users/brownsarahm/Zotero/storage/NYKCCL77/Allen et al. - 2014 - Tracking whole-brain connectivity dynamics in the resting state(3).pdf}
}

@article{allman2009identifiability,
  title = {Identifiability of Parameters in Latent Structure Models with Many Observed Variables},
  author = {Allman, Elizabeth S. and Matias, Catherine and {\noopsort{rhodes}}a. Rhodes, John},
  year = {2009},
  month = dec,
  journal = {The Annals of Statistics},
  volume = {37},
  number = {6A},
  pages = {3099--3132},
  issn = {0090-5364},
  doi = {10.1214/09-AOS689},
  keywords = {62E10,62F99,62G99,finite mixtu,Identifiability},
  file = {/Users/brownsarahm/Zotero/storage/FFZJ4QK2/Allman, Matias, Rhodes - 2009 - Identifiability of parameters in latent structure models with many observed variables(3).pdf}
}

@article{aly2005survey,
  title = {Survey on {{Multiclass Classification Methods Extensible}} Algorithms},
  author = {Aly, Mohamed},
  year = {2005},
  journal = {Neural Networks},
  number = {November},
  pages = {1--9},
  file = {/Users/brownsarahm/Zotero/storage/46HPXYMU/Aly - 2005 - Survey on Multiclass Classification Methods Extensible algorithms(3).pdf}
}

@blog{Amal2022,
  title = {Ensuring Fairness and Bias in Machine Learning Models},
  author = {Salilan, Amal},
  year = {2022}
}

@article{amaral2003topographic,
  title = {Topographic Organization of Projections from the Amygdala to the Visual Cortex in the Macaque Monkey},
  author = {Amaral, D G and Behniea, H and Kelly, J L},
  year = {2003},
  journal = {Neuroscience},
  volume = {118},
  number = {4},
  pages = {1099--1120}
}

@book{ambrose2010How,
  title = {How Learning Works: {{Seven}} Research-Based Principles for Smart Teaching},
  author = {Ambrose, Susan A and Bridges, Michael W and DiPietro, Michele and Lovett, Marsha C and Norman, Marie K},
  year = {2010},
  publisher = {John Wiley \& Sons}
}

@book{ambrose2010Howa,
  title = {How Learning Works: {{Seven}} Research-Based Principles for Smart Teaching},
  author = {Ambrose, Susan A and Bridges, Michael W and DiPietro, Michele and Lovett, Marsha C and Norman, Marie K},
  year = {2010},
  publisher = {John Wiley \& Sons}
}

@techreport{americanpsychiatricassociation2013diagnostic,
  title = {The {{Diagnostic}} and {{Statistical Manual}} of {{Mental Disorders}}: {{DSM}} 5},
  author = {{American Psychiatric Association}},
  year = {2013},
  institution = {bookpointUS}
}

@article{an1998prefrontal,
  title = {Prefrontal Cortical Projections to Longitudinal Columns in the Midbrain Periaqueductal Grey of Macaque Monkeys},
  author = {An, X and Bandler, R and Ongur, D and Price, J L},
  year = {1998},
  journal = {Journal of Comparative Neurology},
  volume = {401},
  pages = {455--479}
}

@book{analysisgroupatfmribfsl,
  title = {{{FSL FLIRT FAQ}}},
  author = {{"Analysis Group at FMRIB"}},
  file = {/Users/brownsarahm/Zotero/storage/IJZNJW4C/Analysis Group at FMRIB - Unknown - FSL FLIRT FAQ(3).html}
}

@article{anandkumar2014spectral,
  title = {A {{Spectral Algorithm}} for {{Latent Dirichlet Allocation}}},
  author = {Anandkumar, Anima and Foster, Dean P. and Hsu, Daniel and Kakade, Sham M. and Liu, Yi Kai},
  year = {2014},
  journal = {Algorithmica},
  pages = {1--9},
  issn = {01784617},
  doi = {10.1007/s00453-014-9909-1},
  abstract = {Topic modeling is a generalization of clustering that posits that observations (words in a document) are generated by multiple latent factors (topics), as opposed to just one. This increased representational power comes at the cost of a more challenging unsupervised learning problem of estimating the topic-word distributions when only words are observed, and the topics are hidden. This work provides a simple and efficient learning procedure that is guaranteed to recover the parameters for a wide class of topic models, including Latent Dirichlet Allocation (LDA). For LDA, the procedure correctly recovers both the topic-word distributions and the parameters of the Dirichlet prior over the topic mixtures, using only trigram statistics (i.e., third order moments, which may be estimated with documents containing just three words). The method, called Excess Correlation Analysis, is based on a spectral decomposition of low-order moments via two singular value decompositions (SVDs). Moreover, the algorithm is scalable, since the SVDs are carried out only on k k matrices, where k is the number of latent factors (topics) and is typically much smaller than the dimension of the observation (word) space.},
  keywords = {Latent Dirichlet allocation,Method of moments,Mixture models,Topic models},
  file = {/Users/brownsarahm/Zotero/storage/5HQJU6Y8/Anandkumar et al. - 2014 - A Spectral Algorithm for Latent Dirichlet Allocation(3).pdf}
}

@article{anderson2006geometric,
  title = {Geometric Subspace Methods and Time-Delay Embedding for {{EEG}} Artifact Removal and Classification},
  author = {Anderson, Charles W. and Knight, James N. and O'Connor, Tim and Kirby, Michael J. and Sokolov, Artem},
  year = {2006},
  journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  volume = {14},
  number = {2},
  pages = {142--146},
  issn = {15344320},
  doi = {10.1109/TNSRE.2006.875527},
  abstract = {Generalized singular-value decomposition is used to separate multichannel electroencephalogram (EEG) into components found by optimizing a signal-to-noise quotient. These components are used to filter out artifacts. Short-time principal components analysis of time-delay embedded EEG is used to represent windowed EEG data to classify EEG according to which mental task is being performed. Examples are presented of the filtering of various artifacts and results are shown of classification of EEG from five mental tasks using committees of decision trees.},
  pmid = {16792280},
  keywords = {Artifact,Brain-computer interface (BCI),Classification,Electroencephalogram (EEG),Principal components analysis,Time-delay embedding},
  file = {/Users/brownsarahm/Zotero/storage/F7RD8RDN/Anderson et al. - 2006 - Geometric subspace methods and time-delay embedding for EEG artifact removal and classification(3).pdf}
}

@article{anderson2013allocating,
  title = {Allocating Structure to Function: The Strong Links between Neuroplasticity and Natural Selection},
  author = {Anderson, Michael L and Finlay, Barbara L},
  year = {2013},
  journal = {Frontiers in human neuroscience},
  volume = {7}
}

@book{anderson2014phrenology,
  title = {After Phrenology: {{Neural}} Reuse and the Interactive Brain},
  author = {Anderson, Michael L},
  year = {2014},
  publisher = {MIT Press}
}

@article{andrews-hanna2014default,
  title = {The Default Network and Self-Generated Thought: Component Processes, Dynamic Control, and Clinical Relevance},
  author = {{Andrews-Hanna}, Jessica R and Smallwood, Jonathan and Spreng, R Nathan},
  year = {2014},
  journal = {Annals of the New York Academy of Sciences},
  volume = {1316},
  number = {1},
  pages = {29--52}
}

@article{angelino2016patterns,
  title = {Patterns of {{Scalable Bayesian Inference}}},
  author = {Angelino, Elaine and Johnson, Matthew James and Adams, Ryan P.},
  year = {2016},
  volume = {9},
  number = {1},
  pages = {1--129},
  issn = {1935-8237},
  doi = {10.1561/2200000052},
  abstract = {Datasets are growing not just in size but in complexity, creating a demand for rich models and quantification of uncertainty. Bayesian methods are an excellent fit for this demand, but scaling Bayesian inference is a challenge. In response to this challenge, there has been considerable recent work based on varying assumptions about model structure, underlying computational resources, and the importance of asymptotic correctness. As a result, there is a zoo of ideas with few clear overarching principles. In this paper, we seek to identify unifying principles, patterns, and intuitions for scaling Bayesian inference. We review existing work on utilizing modern computing resources with both MCMC and variational approximation techniques. From this taxonomy of ideas, we characterize the general principles that have proven successful for designing scalable inference procedures and comment on the path forward.},
  file = {/Users/brownsarahm/Zotero/storage/4T5YDNAK/Angelino, Johnson, Adams - 2016 - Patterns of Scalable Bayesian Inference.pdf}
}

@article{angelino2017Learning,
  title = {Learning Certifiably Optimal Rule Lists for Categorical Data},
  author = {Angelino, Elaine and {Larus-Stone}, Nicholas and Alabi, Daniel and Seltzer, Margo and Rudin, Cynthia},
  year = {2017},
  journal = {Journal of Machine Learning Research},
  volume = {18},
  number = {234},
  pages = {1--78}
}

@inproceedings{angell2018themis,
  title = {Themis: {{Automatically}} Testing Software for Discrimination},
  booktitle = {Proceedings of the 2018 26th {{ACM}} Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  author = {Angell, Rico and Johnson, Brittany and Brun, Yuriy and Meliou, Alexandra},
  year = {2018},
  pages = {871--875}
}

@article{angluin1988queries,
  title = {Queries and Concept Learning},
  author = {Angluin, Dana},
  year = {1988},
  month = apr,
  journal = {Machine Learning},
  volume = {2},
  number = {4},
  pages = {319--342},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/BF00116828},
  urldate = {2019-11-20},
  abstract = {We consider the problem of using queries to learn an unknown concept. Several types of queries are described and studied: membership, equivalence, subset, superset, disjointness, and exhaustiveness queries. Examples are given of efficient learning methods using various subsets of these queries for formal domains, including the regular languages, restricted classes of context-free languages, the pattern languages, and restricted types of prepositional formulas. Some general lower bound techniques are given. Equivalence queries are compared with Valiant's criterion of probably approximately correct identification under random sampling.},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/DFZIY9RV/Angluin - 1988 - Queries and concept learning.pdf}
}

@article{angwin2016machine,
  title = {Machine Bias},
  author = {Angwin, Julia and Larson, Jeff and Mattu, Surya and Kirchner, Lauren},
  year = {2016},
  journal = {ProPublica, May},
  volume = {23},
  pages = {2016}
}

@article{aodha2014putting,
  title = {Putting the {{Scientist}} in the {{Loop}} - {{Accelerating Scientific Progress}} with {{Interactive Machine Learning}}},
  author = {Aodha, Oisin Mac and Terry, Michael and Girolami, Mark},
  year = {2014},
  journal = {Pattern Recognition (ICPR), 2014 22nd International Conference on},
  pages = {9--17},
  issn = {10514651},
  doi = {10.1109/ICPR.2014.12},
  keywords = {biodiver-,computer vision,data visualization,ecology,human-computer interaction,interactive machine learning},
  file = {/Users/brownsarahm/Zotero/storage/X8EHYF6I/Aodha, Terry, Girolami - 2014 - Putting the Scientist in the Loop - Accelerating Scientific Progress with Interactive Machine Learnin(3).pdf}
}

@book{aoki1990state,
  title = {State {{Space Modeling}} of {{Time Series}}},
  author = {Aoki, Masanao},
  year = {1990},
  edition = {2nd hard c},
  address = {Berlin, Heidelberg},
  isbn = {3387528695}
}

@article{apolloni1998sample,
  title = {Sample Size Lower Bounds in {{PAC}} Learning by Algorithmic Complexity Theory},
  author = {Apolloni, B. and Gentile, C.},
  year = {1998},
  month = dec,
  journal = {Theoretical Computer Science},
  volume = {209},
  number = {1-2},
  pages = {141--162},
  issn = {03043975},
  doi = {10.1016/S0304-3975(97)00102-3},
  file = {/Users/brownsarahm/Zotero/storage/IUPQCJM7/Apolloni, Gentile - 1998 - Sample size lower bounds in PAC learning by algorithmic complexity theory(3).pdf}
}

@article{arah2008role,
  title = {The Role of Causal Reasoning in Understanding {{Simpson}}'s Paradox, {{Lord}}'s Paradox, and the Suppression Effect: Covariate Selection in the Analysis of Observational Studies},
  author = {Arah, Onyebuchi A},
  year = {2008},
  journal = {Emerging Themes in Epidemiology},
  volume = {5},
  number = {1},
  pages = {5}
}

@article{ardizzone2018analyzing,
  title = {Analyzing Inverse Problems with Invertible Neural Networks},
  author = {Ardizzone, Lynton and Kruse, Jakob and Wirkert, Sebastian and Rahner, Daniel and Pellegrini, Eric W and Klessen, Ralf S and {Maier-Hein}, Lena and Rother, Carsten and K{\"o}the, Ullrich},
  year = {2018},
  journal = {arXiv preprint arXiv:1808.04730},
  eprint = {1808.04730},
  archiveprefix = {arXiv}
}

@article{ardizzone2018Analyzing,
  title = {Analyzing Inverse Problems with Invertible Neural Networks},
  author = {Ardizzone, Lynton and Kruse, Jakob and Wirkert, Sebastian and Rahner, Daniel and Pellegrini, Eric W and Klessen, Ralf S and {Maier-Hein}, Lena and Rother, Carsten and K{\"o}the, Ullrich},
  year = {2018},
  journal = {arXiv preprint arXiv:1808.04730},
  eprint = {1808.04730},
  archiveprefix = {arXiv}
}

@article{arlot2010survey,
  title = {A Survey of Cross-Validation Procedures for Model Selection},
  author = {Arlot, Sylvain and Celisse, Alain},
  year = {2010},
  volume = {4},
  pages = {40--79},
  issn = {1935-7516},
  doi = {10.1214/09-SS054},
  abstract = {Used to estimate the risk of an estimator or to perform model selection, cross-validation is a widespread strategy because of its simplicity and its apparent universality. Many results exist on the model selection performances of cross-validation procedures. This survey intends to relate these results to the most recent advances of model selection theory, with a particular emphasis on distinguishing empirical statements from rigorous theoretical results. As a conclusion, guidelines are provided for choosing the best cross-validation procedure according to the particular features of the problem in hand.},
  keywords = {Computational,Information-Theoretic Learning with,Learning/Statistics \& Optimisation,Theory \& Algorithms},
  file = {/Users/brownsarahm/Zotero/storage/IS5LQIDV/Arlot, Celisse - 2010 - A survey of cross-validation procedures for model selection(3).pdf}
}

@article{armstrong2014visualizing,
  title = {Visualizing {{Statistical Mix Effects}} and {{Simpson}}\&\#x0027\${\textbackslash}backslashmathsemicolon\$s {{Paradox}}},
  author = {Armstrong, Zan and Wattenberg, Martin},
  year = {2014},
  journal = {Ieee Tvcg},
  volume = {20},
  number = {12},
  pages = {2132--2141},
  doi = {10.1109/tvcg.2014.2346297}
}

@article{arnold2019factsheets,
  title = {{{FactSheets}}: {{Increasing Trust}} in {{AI Services}} through {{Supplier}}'s {{Declarations}} of {{Conformity}}},
  shorttitle = {{{FactSheets}}},
  author = {Arnold, Matthew and Bellamy, Rachel K. E. and Hind, Michael and Houde, Stephanie and Mehta, Sameep and Mojsilovic, Aleksandra and Nair, Ravi and Ramamurthy, Karthikeyan Natesan and Reimer, Darrell and Olteanu, Alexandra and Piorkowski, David and Tsay, Jason and Varshney, Kush R.},
  year = {2019},
  month = feb,
  journal = {arXiv:1808.07261 [cs]},
  eprint = {1808.07261},
  primaryclass = {cs},
  urldate = {2020-05-09},
  abstract = {Accuracy is an important concern for suppliers of artificial intelligence (AI) services, but considerations beyond accuracy, such as safety (which includes fairness and explainability), security, and provenance, are also critical elements to engender consumers' trust in a service. Many industries use transparent, standardized, but often not legally required documents called supplier's declarations of conformity (SDoCs) to describe the lineage of a product along with the safety and performance testing it has undergone. SDoCs may be considered multi-dimensional fact sheets that capture and quantify various aspects of the product and its development to make it worthy of consumers' trust. Inspired by this practice, we propose FactSheets to help increase trust in AI services. We envision such documents to contain purpose, performance, safety, security, and provenance information to be completed by AI service providers for examination by consumers. We suggest a comprehensive set of declaration items tailored to AI and provide examples for two fictitious AI services in the appendix of the paper.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society},
  file = {/Users/brownsarahm/Zotero/storage/FCDNGS6Z/Arnold et al. - 2019 - FactSheets Increasing Trust in AI Services throug.pdf;/Users/brownsarahm/Zotero/storage/7BIZM8T6/1808.html}
}

@article{article2008human,
  title = {Human {{Brain Mapping}}},
  author = {Article, Research and Article, Research and Biophysics, Medical and Biophysics, Medical and Anne, Jo and Anne, Jo and Ontario, Western and Ontario, Western},
  year = {2008},
  journal = {Human Brain Mapping},
  file = {/Users/brownsarahm/Zotero/storage/YV4JZG9V/Article et al. - 2008 - Human Brain Mapping(3).pdf}
}

@article{arulampalam2002tutorial,
  title = {A Tutorial on Particle Filters for Online Nonlinear/Non-{{Gaussian Bayesian}} Tracking},
  author = {Arulampalam, M S and Maskell, S and Gordon, N and Clapp, T},
  editor = {Djuri{\'c}, Petar M},
  year = {2002},
  journal = {IEEE Transactions on Signal Processing},
  volume = {50},
  number = {2},
  pages = {174--188},
  issn = {1053587X},
  doi = {10.1109/78.978374},
  abstract = {Increasingly, for many application areas, it is becoming important to include elements of nonlinearity and non-Gaussianity in order to model accurately the underlying dynamics of a physical system. Moreover, it is typically crucial to process data on-line as it arrives, both from the point of view of storage costs as well as for rapid adaptation to changing signal characteristics. In this paper, we review both optimal and suboptimal Bayesian algorithms for nonlinear/non-Gaussian tracking problems, with a focus on particle filters. Particle filters are sequential Monte Carlo methods based on point mass (or "particle") representations of probability densities, which can be applied to any state-space model and which generalize the traditional Kalman filtering methods. Several variants of the particle filter such as SIR, ASIR, and RPF are introduced within a generic framework of the sequential importance sampling (SIS) algorithm. These are discussed and compared with the standard EKF through an illustrative example},
  pmid = {978374}
}

@article{ascoli2013mindbrain,
  title = {The Mind-Brain Relationship as a Mathematical Problem.},
  author = {{\noopsort{ascoli}}a Ascoli, Giorgio},
  year = {2013},
  month = jan,
  journal = {ISRN neuroscience},
  volume = {2013},
  pages = {261364},
  issn = {2314-4661},
  doi = {10.1155/2013/261364},
  abstract = {This paper aims to frame certain fundamental aspects of the human mind (content and meaning of mental states) and foundational elements of brain computation (spatial and temporal patterns of neural activity) so as to enable at least in principle their integration within one and the same quantitative representation. Through the history of science, similar approaches have been instrumental to bridge other seemingly mysterious scientific phenomena, such as thermodynamics and statistical mechanics, optics and electromagnetism, or chemistry and quantum physics, among several other examples. Identifying the relevant levels of analysis is important to define proper mathematical formalisms for describing the brain and the mind, such that they could be mapped onto each other in order to explain their equivalence. Based on these premises, we overview the potential of neural connectivity to provide highly informative constraints on brain computational process. Moreover, we outline approaches for representing cognitive and emotional states geometrically with semantic maps. Next, we summarize leading theoretical framework that might serve as an explanatory bridge between neural connectivity and mental space. Furthermore, we discuss the implications of this framework for human communication and our view of reality. We conclude by analyzing the practical requirements to manage the necessary data for solving the mind-brain problem from this perspective.},
  pmid = {24967307},
  file = {/Users/brownsarahm/Zotero/storage/7AGYU23J/Ascoli - 2013 - The mind-brain relationship as a mathematical problem(3).pdf}
}

@inproceedings{ashurst2022Ai,
  title = {Ai Ethics Statements: Analysis and Lessons Learnt from Neurips Broader Impact Statements},
  booktitle = {2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Ashurst, Carolyn and Hine, Emmie and Sedille, Paul and Carlier, Alexis},
  year = {2022},
  pages = {2047--2056}
}

@inproceedings{ashurst2022Disentangling,
  title = {Disentangling the {{Components}} of {{Ethical Research}} in {{Machine Learning}}},
  booktitle = {2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Ashurst, Carolyn and Barocas, Solon and Campbell, Rosie and Raji, Deborah},
  year = {2022},
  pages = {2057--2068}
}

@inproceedings{ashurst2022Disentanglinga,
  title = {Disentangling the Components of Ethical Research in Machine Learning},
  booktitle = {Proceedings of the 2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Ashurst, Carolyn and Barocas, Solon and Campbell, Rosie and Raji, Deborah},
  year = {2022},
  pages = {2057--2068}
}

@inproceedings{assefa2020Generating,
  title = {Generating Synthetic Data in Finance: Opportunities, Challenges and Pitfalls},
  booktitle = {Proceedings of the {{First ACM International Conference}} on {{AI}} in {{Finance}}},
  author = {Assefa, Samuel A and Dervovic, Danial and Mahfouz, Mahmoud and Tillman, Robert E and Reddy, Prashant and Veloso, Manuela},
  year = {2020},
  pages = {1--8}
}

@book{association1978diagnostic,
  title = {Diagnostic and Statistical Manual of Mental Disorders: {{DSM-III}} Draft\${\textbackslash}backslash\$prepared by the {{Task Force}} on {{Nomenclature}} and {{Statistics}} of the {{American Psychiatric Association}}},
  author = {Association, American Psychiatric},
  year = {1978},
  publisher = {American Psychiatric Association}
}

@book{asuncion2007uci,
  title = {{{UCI}} Machine Learning Repository},
  author = {Asuncion, Arthur and Newman, David},
  year = {2007}
}

@book{atfmribfslutils,
  title = {Fslutils},
  author = {{\noopsort{fmrib"}}{at FMRIB"}, "Analysis Group}
}

@article{authordeveloping,
  title = {Developing a {{Physiological Alternative}} for {{Clinical PTSD Scores}}},
  author = {Author, Anonymous and Address, Affiliation},
  pages = {1--6},
  file = {/Users/brownsarahm/Zotero/storage/GMG86WP5/Author, Address - Unknown - Developing a Physiological Alternative for Clinical PTSD Scores(3).pdf}
}

@article{authorhuman,
  title = {Human {{Brain Mapping}}},
  author = {Author, Dear and Wiley, John and Checklist, Author Instructions and Information, Reprint Order and Form, Color Charge},
  file = {/Users/brownsarahm/Zotero/storage/A3HNHNBL/Article et al. - 2008 - Human Brain Mapping(3).pdf}
}

@article{babar2014Auditing,
  title = {Auditing {{Algorithms}} : {{Research Methods}} for {{Detecting Discrimination}} on {{Internet Platforms}}},
  author = {Babar, Sachin and Mahalle, Parikshit and Stango, Antonietta and Prasad, Neeli and Prasad, Ramjee and Gorkemli, Serkan and Sandvig, Christian and Hamilton, Kevin and Karahalios, Karrie and Langbort, Cedric and Hardy, Jean and Lindtner, Silvia and Ur, Blase and Jung, Jaeyeon and Schechter, Stuart and Klasnja, Predrag and Consolvo, Sunny and Choudhury, Tanzeem and Beckwith, Richard and Shneidman, Edwin and Hernandez, Javier and Hoque, Mohammed Ehsan and Picard, Rosalind W and Hoyle, Roberto and Templeman, Robert and Armes, Steven and Anthony, Denise and Crandall, David and Gray, Stacey and G{\"u}rses, Seda and Hoboken, Joris Van and Peppet, S. and K{\"o}nings, Bastian and Thoma, Sebastian and Schaub, Florian and Weber, Michael and Denning, Tamara and Kohno, Tadayoshi and Levy, Henry M. and Schaub, Florian and Balebako, Rebecca and Durity, Adam L and Cranor, Lorrie Faith and Zeng, Eric and Mare, Shrirang and Roesner, Franziska and Hong, Jason and Dougherty, Chad and Sayre, Kirk and Seacord, Robert C. and Svoboda, David and Togashi, Kazuya},
  year = {2014},
  journal = {Communications of the ACM},
  volume = {93},
  number = {1},
  pages = {1--23},
  issn = {00404411},
  doi = {10.1109/DEXA.2009.55},
  abstract = {Is your smart TV listening to your conversations? Are your children's toys spying on your family?},
  pmid = {84635968},
  keywords = {audit mechanisms,authentication,authorization,domestic technologies,Internet of Things,internet of things (IoT),mobile devices,monitoring,parents,privacy,Privacy,privacy preferences,privacy signaling,secure,secure design patterns,Security,smart homes,software security,teenagers,trust},
  file = {/Users/brownsarahm/Zotero/storage/PXEFTPQZ/Babar et al. - 2014 - Auditing Algorithms Research Methods for Detecting Discrimination on Internet Platforms.pdf}
}

@article{bach2009exploring,
  title = {Exploring {{Large Feature Spaces}} with {{Hierarchical Multiple Kernel Learning}}},
  author = {Bach, Francis},
  year = {2009},
  number = {2},
  abstract = {For supervised and unsupervised learning, positive definite kernels allow to use large and potentially infinite dimensional feature spaces with a computational cost that only depends on the number of observations. This is usually done through the penalization of predictor functions by Euclidean or Hilbertian norms. In this paper, we explore penalizing by sparsity-inducing norms such as the {$\ell$}1-norm or the block {$\ell$}1-norm. We assume that the kernel decomposes into a large sum of individual basis kernels which can be embedded in a directed acyclic graph; we show that it is then possible to perform kernel selection through a hierarchical multiple kernel learning framework, in polynomial time in the number of selected kernels. This framework is naturally applied to non linear variable selection; our extensive simulations on synthetic datasets and datasets from the UCI repository show that efficiently exploring the large feature space through sparsity-inducing norms leads to state-of-the-art predictive performance.},
  keywords = {Learning/Statistics \& Optimisation},
  file = {/Users/brownsarahm/Zotero/storage/GMF5GJHT/Bach - 2009 - Exploring Large Feature Spaces with Hierarchical Multiple Kernel Learning(3).pdf}
}

@article{bach2011convex,
  title = {Convex Optimization with Sparsity-Inducing Norms},
  author = {Bach, Francis and Jenatton, R},
  year = {2011},
  journal = {Optimization for Machine {\textbackslash}ldots},
  pages = {1--35},
  file = {/Users/brownsarahm/Zotero/storage/VUQJQHRJ/Bach, Jenatton - 2011 - Convex optimization with sparsity-inducing norms(3).pdf}
}

@article{bach2015impaired,
  title = {Impaired Threat Prioritisation after Selective Bilateral Amygdala Lesions},
  author = {Bach, Dominik R. and Hurlemann, Rene and Dolan, Raymond J.},
  year = {2015},
  journal = {Cortex},
  volume = {63},
  pages = {206--213},
  issn = {00109452},
  doi = {10.1016/j.cortex.2014.08.017},
  file = {/Users/brownsarahm/Zotero/storage/8KXVD9G3/Bach, Hurlemann, Dolan - 2015 - Impaired threat prioritisation after selective bilateral amygdala lesions(3).pdf}
}

@book{bache2013uci,
  title = {{{UCI}} Machine Learning Repository},
  author = {Bache, Kevin and Lichman, Moshe},
  year = {2013}
}

@article{bachem2017practical,
  title = {Practical {{Coreset Constructions}} for {{Machine Learning}}},
  author = {Bachem, Olivier and Lucic, Mario and Krause, Andreas},
  year = {2017},
  abstract = {We investigate coresets - succinct, small summaries of large data sets - so that solutions found on the summary are provably competitive with solution found on the full data set. We provide an overview over the state-of-the-art in coreset construction for machine learning. In Section 2, we present both the intuition behind and a theoretically sound framework to construct coresets for general problems and apply it to \$k\$-means clustering. In Section 3 we summarize existing coreset construction algorithms for a variety of machine learning problems such as maximum likelihood estimation of mixture models, Bayesian non-parametric models, principal component analysis, regression and general empirical risk minimization.},
  file = {/Users/brownsarahm/Zotero/storage/CKA37ZX2/Bachem, Lucic, Krause - 2017 - Practical Coreset Constructions for Machine Learning.pdf}
}

@article{baddeley2007spatial,
  title = {Spatial Point Processes and Their Applications},
  author = {Baddeley, A},
  year = {2007},
  journal = {Lecture Notes in Mathematics},
  volume = {1892},
  pages = {1--75}
}

@inproceedings{balayn2023Fairness,
  title = {``{$\CheckedBox$} {{Fairness Toolkits}}, {{A Checkbox Culture}}?'' {{On}} the {{Factors}} That {{Fragment Developer Practices}} in {{Handling Algorithmic Harms}}},
  booktitle = {Proceedings of the 2023 {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {Balayn, Agathe and Yurrita, Mireia and Yang, Jie and Gadiraju, Ujwal},
  year = {2023},
  pages = {482--495}
}

@inproceedings{balayn2023Fairnessa,
  title = {``{$\CheckedBox$} {{Fairness Toolkits}}, {{A Checkbox Culture}}?'' {{On}} the {{Factors}} That {{Fragment Developer Practices}} in {{Handling Algorithmic Harms}}},
  booktitle = {Proceedings of the 2023 {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {Balayn, Agathe and Yurrita, Mireia and Yang, Jie and Gadiraju, Ujwal},
  year = {2023},
  pages = {482--495}
}

@article{bandyoapdhyay2011logic,
  title = {The Logic of {{Simpson}}'s Paradox},
  author = {Bandyoapdhyay, Prasanta S and Nelson, Davin and Greenwood, Mark and Brittan, Gordon and Berwald, Jesse},
  year = {2011},
  journal = {Synthese},
  volume = {181},
  number = {2},
  pages = {185--208}
}

@article{bantilan2017Themisml,
  title = {Themis-Ml: {{A Fairness-aware Machine Learning Interface}} for {{End-to-end Discrimination Discovery}} and {{Mitigation}}},
  author = {Bantilan, Niels},
  year = {2017},
  journal = {arXiv preprint arXiv:1710.06921},
  eprint = {1710.06921},
  archiveprefix = {arXiv}
}

@inproceedings{bao2021s,
  title = {It's {{COMPASlicated}}: {{The}} Messy Relationship between {{RAI}} Datasets and Algorithmic Fairness Benchmarks},
  booktitle = {{{NeurIPS Dataset Track}}},
  author = {Bao, Michelle and Zhou, Angela and Zottola, Samantha and Brubach, Brian and Desmarais, Sarah and Horowitz, Aaron and Lum, Kristian and Venkatasubramanian, Suresh},
  year = {2021}
}

@article{barbas2015general,
  title = {General Cortical and Special Prefrontal Connections: Principles from Structure to Function},
  author = {Barbas, Helen},
  year = {2015},
  journal = {Annual Review of Neuroscience},
  volume = {38},
  pages = {269--289}
}

@book{barber2011bayesian,
  title = {Bayesian {{Reasoning}} and {{Machine Learning}}},
  author = {Barber, David},
  year = {2011},
  doi = {10.1017/CBO9780511804779},
  isbn = {978-0-521-51814-7},
  pmid = {16931139},
  keywords = {Computational,Information-Theoretic Learning with Statistics,Learning/Statistics \& Optimisation,Theory \& Algorithms},
  file = {/Users/brownsarahm/Zotero/storage/4462QFG7/Barber - 2011 - Bayesian Reasoning and Machine Learning(3).pdf}
}

@inproceedings{barker2008scientific,
  title = {Scientific {{Workflow}}: {{A Survey}} and {{Research Directions}}},
  booktitle = {Proceedings of the 7th {{International Conference}} on {{Parallel Processing}} and {{Applied Mathematics}}},
  author = {Barker, Adam and Van Hemert, Jano},
  year = {2008},
  pages = {746--753},
  doi = {10.1145/2213836.2213899},
  abstract = {Workflow technologies are emerging as the dominant approach to coordinate groups of distributed services. However with a space filled with competing specifications, standards and frameworks from multiple domains, choosing the right tool for the job is not always a straightforward task. Researchers are often unaware of the range of technology that already exists and focus on implementing yet another proprietary workflow system. As an antidote to this common problem, this paper presents a concise survey of existing workflow technology from the business and scientific domain and makes a number of key suggestions towards the future development of scientific workflow systems.},
  isbn = {3-540-68105-1 978-3-540-68105-2},
  file = {/Users/brownsarahm/Zotero/storage/Z9FBELWL/Barker, Van Hemert - 2008 - Scientific Workflow A Survey and Research Directions(3).pdf}
}

@book{barocas-hardt-narayanan,
  title = {Fairness and Machine Learning},
  author = {Barocas, Solon and Hardt, Moritz and Narayanan, Arvind},
  year = {2019},
  publisher = {fairmlbook.org}
}

@book{barocas-hardt-narayanan,
  title = {Fairness and Machine Learning},
  author = {Barocas, Solon and Hardt, Moritz and Narayanan, Arvind},
  year = {2019},
  publisher = {MIT Press},
  address = {Cambridge, MA}
}

@article{barocas2016big,
  title = {Big Data's Disparate Impact},
  author = {Barocas, Solon and Selbst, Andrew D},
  year = {2016},
  journal = {Calif. L. Rev.},
  volume = {104},
  pages = {671},
  publisher = {HeinOnline}
}

@article{barocas2017Problem,
  title = {The Problem with Bias: From Allocative to Representational Harms in Machine Learning. {{Special Interest Group}} for {{Computing}}},
  author = {Barocas, Solon and Crawford, Kate and Shapiro, Aaron and Wallach, Hanna},
  year = {2017},
  journal = {Information and Society (SIGCIS)},
  volume = {2}
}

@book{barocas2019Fairness,
  title = {Fairness and Machine Learning},
  author = {Barocas, Solon and Hardt, Moritz and Narayanan, Arvind},
  year = {2019},
  publisher = {fairmlbook.org}
}

@article{barrett2006are,
  title = {Are {{Emotions Natural Kinds}}?},
  author = {Barrett, Lisa Feldman},
  year = {2006},
  journal = {Perspectives on Psychological Science},
  pages = {28--58}
}

@book{barrett2009affect,
  title = {Affect as a {{Psychological Primitive}}.},
  author = {Barrett, Lisa Feldman and {Bliss-Moreau}, Eliza},
  year = {2009},
  month = jan,
  edition = {1},
  volume = {41},
  publisher = {Elsevier Inc.},
  doi = {10.1016/S0065-2601(08)00404-8},
  abstract = {In this article, we discuss the hypothesis that affect is a fundamental, psychologically irreducible property of the human mind. We begin by presenting historical perspectives on the nature of affect. Next, we proceed with a more contemporary discussion of core affect as a basic property of the mind that is realized within a broadly distributed neuronal workspace. We then present the affective circumplex, a mathematical formalization for representing core affective states, and show that this model can be used to represent individual differences in core affective feelings that are linked to meaningful variation in emotional experience. Finally, we conclude by suggesting that core affect has psychological consequences that reach beyond the boundaries of emotion, to influence learning and consciousness.},
  isbn = {978-0-12-374472-2},
  pmid = {20552040},
  file = {/Users/brownsarahm/Zotero/storage/7KX3ZSU4/Barrett, Bliss-Moreau - 2009 - Affect as a Psychological Primitive(3).pdf}
}

@article{barrett2009future,
  title = {The Future of Psychology: {{Connecting}} Mind to Brain},
  author = {Barrett, LF Lisa Feldman},
  year = {2009},
  journal = {Perspectives on Psychological Science},
  volume = {4},
  number = {4},
  pages = {326--339},
  doi = {10.1111/j.1745-6924.2009.01134.x.The},
  file = {/Users/brownsarahm/Zotero/storage/B2Q8KR4S/Barrett - 2009 - The future of psychology Connecting mind to brain(3).pdf}
}

@article{barrett2011bridging,
  title = {Bridging {{Token Identity Theory}} and {{Supervenience Theory Through Psychological Construction}}},
  author = {Barrett, Lisa Feldman},
  year = {2011},
  month = jan,
  journal = {Psychological Inquiry},
  volume = {22},
  number = {2},
  pages = {115--127},
  issn = {1047-840X},
  doi = {10.1080/1047840X.2011.555216},
  abstract = {A psychologist's task is to discover facts about the mind by measuring responses at the level of a person (e.g., reaction times, perceptions, eye or muscle movements, or bodily changes). A neuroscientist's task is to make similar discoveries by measuring responses from neurons in a brain (e.g., electrical,magnetic, blood flow or chemical measures related neurons firing).Both psychologists and neuroscientists use ideas (in the form of concepts, categories, and constructs) to transform their measurements into something meaningful. The relation between any set of numbers (reflecting a property of the person, or the activation in a set of neurons, a circuit, or a network) and a psychological construct is a psychometric issue that is formalized as a ``measurement model.'' The relation is also a philosophical act. Scientists (both neuroscientists and psychologists) who make such inferences, but don't explicitly declare their measurement models, are still doing philosophy, but they are doing it in stealth, enacting certain assumptions that are left unsaid. In ``Mind the Gap,'' Kievit and colleagues (this issue) take the admirable step of trying to unmask the measurement models that lurk within two well-defined traditions for linking the actions of neurons to the actions of people. They translate identity theory and supervenience theory into popular measurement models that exist in psychometric theory using the logic and language of structural equation modeling. By showing that both philosophical approaches can be represented as models that relate measurements to psychological constructs, Kievit et al. lay bare the fact that all measurement questions are also philosophical questions about how variation in numbers hint at or point to reality. They make the powerful point that translating philosophical assumptions into psychometric terms allows both identity theory and supervenience theory to be treated like hypotheses that can be empirically evaluated and compared in more or less a concrete way. The empirical example offered by Kievit et al. (linking intelligence to brain volume) is somewhat simplistic on both the neuroscience and psychological ends of the equation, and the nitty-gritty details of applying an explicit measurement approach to more complex data remains open, but this article represents a big step forward in negotiating the chasm between measures taken at the level of the brain and those taken at the level of the person. The overall approach is applauded, but a closer look at the details of how Kievit et al. operationalized identity and supervenience theory is in order. In science, as in philosophy, the devil is in the details. In the pages that follow, I highlight a few lurking demons that haunt the Kievit et al. approach. I don't point out every idea that I take issue with in the article, just as I don't congratulate every point of agreement. Instead, I focus in on a few key issues in formalizing identity and supervenience theory, with an eye to asking whether they are really all that different in measurement terms, as well as whether standard psychometric models can be used to operationalize each of them equally well. Like Kievit et al., I conclude that a supervenience theorymight win the day, but I try to get more specific about a version of supervenience that would successfully bridges the gap between the brain and the mind.},
  pmid = {21785534},
  file = {/Users/brownsarahm/Zotero/storage/E2A8FBTZ/Barrett - 2011 - Bridging Token Identity Theory and Supervenience Theory Through Psychological Construction(6).pdf}
}

@article{barrett2013firing,
  title = {Firing Rate Predictions in Optimal Balanced Networks},
  author = {Barrett, Dg and Deneve, S and Machens, Ck},
  year = {2013},
  journal = {Advances in Neural Information Processing (NIPS)},
  pages = {1--9},
  file = {/Users/brownsarahm/Zotero/storage/JSG55YEQ/Barrett, Deneve, Machens - 2013 - Firing rate predictions in optimal balanced networks(3).pdf}
}

@article{barrett2013largescale,
  title = {Large-Scale Brain Networks in Affective and Social Neuroscience: Towards an Integrative Functional Architecture of the Brain},
  author = {Barrett, LF Lisa Feldman and Satpute, Ajay Bhaskar AB},
  year = {2013},
  journal = {Current opinion in neurobiology},
  volume = {23},
  number = {3},
  pages = {361--372},
  file = {/Users/brownsarahm/Zotero/storage/3LJMGDXE/Barrett, Satpute - 2013 - Large-scale brain networks in affective and social neuroscience towards an integrative functional architect(3).pdf}
}

@article{barrett2014psychological,
  title = {A Psychological Construction Account of Emotion Regulation and Dysregulation: {{The}} Role of Situated Conceptualizations},
  author = {Barrett, Lisa Feldman and {Wilson-Mendenhall}, C. D. and Barsalou, L. W.},
  year = {2014},
  journal = {The Handbook of Emotion Regulation},
  pages = {447--465},
  file = {/Users/brownsarahm/Zotero/storage/QPL584PG/Barrett, Wilson-Mendenhall, Barsalou - 2014 - A psychological construction account of emotion regulation and dysregulation The role o(3).pdf}
}

@article{barrett2015inferring,
  title = {Inferring the {{Mind}} by {{Modelling}} the {{Brain}} : {{Beyond Faculty Psychology}}},
  author = {Barrett, Lisa Feldman and Brooks, Dana and Brown, Sarah M and {Clark-Polner}, Elizabeth and {Coll-Font}, Jaume and Dy, Jennifer G and Erdogmus, Deniz and Erem, Burak and Satpute, Ajay B and {Wilson-Mendenhall}, Christine D.},
  year = {2015},
  journal = {Manuscript in Progress},
  file = {/Users/brownsarahm/Zotero/storage/5MJ45MH4/Barrett et al. - 2015 - Inferring the Mind by Modelling the Brain Beyond Faculty Psychology(3).pdf}
}

@article{barrett2015interoceptive,
  title = {Interoceptive Predictions in the Brain},
  author = {Barrett, Lisa Feldman and Simmons, W Kyle},
  year = {2015},
  journal = {Nature Reviews Neuroscience},
  volume = {16},
  number = {7},
  pages = {419--429},
  issn = {1471-003X},
  doi = {10.1038/nrn3950},
  abstract = {Nature Reviews Neuroscience, (2015). doi:10.1038/nrn3950},
  pmid = {26016744},
  file = {/Users/brownsarahm/Zotero/storage/9M97K3I5/Barrett, Simmons - 2015 - Interoceptive predictions in the brain(6).pdf;/Users/brownsarahm/Zotero/storage/EL4BM9WC/Barrett, Simmons - 2015 - Interoceptive predictions in the brain(5).pdf}
}

@book{barrett2017how,
  title = {How Emotions Are Made: {{The}} Secret Life the Brain.},
  author = {Barrett, Lisa Feldman},
  year = {2017},
  publisher = {Houghton-Mifflin-Harcourt.},
  address = {New York, NY}
}

@article{barrett2017inferring,
  title = {Inferring the {{Mind}} by {{Modelling}} the {{Brain}}: {{A Framework}} for {{Computational Modeling}}},
  author = {Barrett, Lisa Feldman and Brooks, Dana and Brown, Sarah M and {Clark-Polner}, Elizabeth and {Coll-Font}, Jaume and Dy, Jennifer G and Erdogmus, Deniz and Erem, Burak and Satpute, Ajay B and {Wilson-Mendenhall}, Christine D.},
  year = {2017},
  journal = {Manuscript in Progress}
}

@article{barrettactive,
  title = {An Active Inference Theory of Allostasis and Interoception in Depression},
  author = {Barrett, Lisa Feldman and Quigley, Karen S and {\noopsort{hamilton}}{press)Hamilton}, P (in},
  journal = {Philosophical transactions of the Royal Society}
}

@article{barretttheory,
  title = {The Theory of Constructed Emotion: {{An}} Active Inference Account of Interoception and Categorization},
  author = {Barrett, Lisa Feldman},
  issn = {1098-6596},
  doi = {10.1017/CBO9781107415324.004},
  pmid = {25246403},
  keywords = {icle},
  file = {/Users/brownsarahm/Zotero/storage/RECBEI5J/Barrett - Unknown - The theory of constructed emotion An active inference account of interoception and categorization(3).pdf}
}

@article{barsalou2008grounded,
  title = {Grounded Cognition},
  author = {Barsalou, Lawrence W},
  year = {2008},
  journal = {Annual Review of Psychology},
  volume = {59},
  pages = {617--645}
}

@book{bartling2014opening,
  title = {Opening {{Science The Evolving Guide}} on {{How}} the {{Internet}} Is {{Changing Research}}, {{Collaboration}} and {{Scholarly Publishing}}},
  author = {Bartling, S{\"o}nke and Friesike, Sascha},
  year = {2014},
  doi = {10.1007/978-3-319-00026-8},
  abstract = {Modern information and communication technologies, together with a cultural upheaval within the research community, have profoundly changed research in nearly every aspect. Ranging from sharing and discussing ideas in social networks for scientists to new collaborative environments and novel publication formats, knowledge creation and dissemination as we know it is experiencing a vigorous shift towards increased transparency, collaboration and accessibility. Many assume that research workflows will change more in the next 20 years than they have in the last 200. This book provides researchers, decision makers, and other scientific stakeholders with a snapshot of the basics, the tools, and the underlying visions that drive the current scientific (r)evolution, often called `Open Science.'},
  isbn = {978-3-319-00026-8},
  pmid = {1855670631},
  file = {/Users/brownsarahm/Zotero/storage/CZIWZDHS/Bartling, Friesike - 2014 - Opening Science The Evolving Guide on How the Internet is Changing Research, Collaboration and Scholarly Pub.pdf}
}

@article{bassett2011dynamic,
  title = {Dynamic Reconfiguration of Human Brain Networks during Learning},
  author = {Bassett, Danielle S and Wymbs, Nicholas F and Porter, Mason A and Mucha, Peter J and Carlson, Jean M and Grafton, Scott T},
  year = {2011},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {108},
  number = {18},
  pages = {7641--7646}
}

@inproceedings{baumann2023Bias,
  title = {Bias on {{Demand}}: {{A Modelling Framework That Generates Synthetic Data With Bias}}},
  booktitle = {Proceedings of the 2023 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Baumann, Joachim and Castelnovo, Alessandro and Crupi, Riccardo and Inverardi, Nicole and Regoli, Daniele},
  year = {2023},
  pages = {1002--1013}
}

@article{bay2000uci,
  title = {The {{UCI KDD}} Archive of Large Data Sets for Data Mining Research and Experimentation},
  author = {Bay, Stephen D. and Kibler, Dennis and Pazzani, Michael J. and Smyth, Padhraic},
  year = {2000},
  journal = {ACM SIGKDD Explorations Newsletter},
  volume = {2},
  number = {2},
  pages = {81--85},
  issn = {19310145},
  doi = {10.1145/380995.381030},
  abstract = {Advances in data collection and storage have allowed organizations to create massive, complex and heterogeneous databases, which have stymied traditional methods of data analysis. This has led to the development of new analytical tools that often combine techniques from a variety of fields such as statistics, computer science, and mathematics to extract meaningful knowledge from the data. To support research in this area, UC Irvine has created the UCI Knowledge Discovery in Databases (KDD) Archive (http://kdd.ics.uci.edu/) which is a new online archive of large and complex datasets that encompasses a wide variety of data types, analysis tasks, and application areas. This article describes the objectives and philosophy of the UCI KDD Archive. We draw parallels with the development of the UCI Machine Learning Repository and its affect on the Machine Learning community.},
  keywords = {data archive,data mining},
  file = {/Users/brownsarahm/Zotero/storage/NHNL7SUF/Bay et al. - 2000 - The UCI KDD archive of large data sets for data mining research and experimentation.pdf}
}

@article{beall2014simpace,
  title = {{{SimPACE}}: {{Generating}} Simulated Motion Corrupted {{BOLD}} Data with Synthetic-Navigated Acquisition for the Development and Evaluation of {{SLOMOCO}}: {{A}} New, Highly Effective Slicewise Motion Correction.},
  author = {Beall, Erik B and Lowe, Mark J},
  year = {2014},
  month = jun,
  journal = {NeuroImage},
  volume = {14},
  eprint = {24969568},
  eprinttype = {pubmed},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2014.06.038},
  abstract = {Head motion in functional MRI and resting-state MRI is a major problem. Existing methods do not robustly reflect the true level of motion artifact for in vivo fMRI data. The primary issue is that current methods assume that motion is synchronized to the volume acquisition and thus ignore intra-volume motion. This manuscript covers three sections in the use of gold-standard motion-corrupted data to pursue an intra-volume motion correction. First, we present a way to get motion corrupted data with accurately known motion at the slice acquisition level. This technique simulates important data acquisition-related motion artifacts while acquiring real BOLD MRI data. It is based on a novel motion-injection pulse sequence that introduces known motion independently for every slice: Simulated Prospective Acquisition CorrEction (SimPACE). Secondly, with data acquired using SimPACE, we evaluate several motion correction and characterization techniques, including several commonly used BOLD signal- and motion parameter-based metrics. Finally, we introduce and evaluate a novel, slice-based motion correction technique. Our novel method, SLice-Oriented MOtion COrrection (SLOMOCO) performs better than the volumetric methods and, moreover, accurately detects the motion of independent slices, in this case equivalent to the known injected motion. We demonstrate that SLOMOCO can model and correct for nearly all effects of motion in BOLD data. Also, none of the commonly used motion metrics was observed to robustly identify motion corrupted events, especially in the most realistic scenario of sudden head movement. For some popular metrics, performance was poor even when using the ideal known slice motion instead of volumetric parameters. This has negative implications for methods relying on these metrics, such as recently proposed motion correction methods such as data censoring and global signal regression.},
  pmid = {24969568},
  keywords = {BOLD,Functional connectivity,Functional MRI,Motion correction,Spin history}
}

@article{beaver2012stochastic,
  title = {Stochastic {{Variational}} Inference},
  author = {{Beaver} and {Clark}},
  year = {2012},
  journal = {Journal of Machine Learning Research},
  volume = {14},
  pages = {1303--1347},
  issn = {1532-4435},
  doi = {citeulike-article-id:10852147},
  abstract = {Abstract: We develop stochastic variational inference , a scalable algorithm for approximating posterior distributions. We develop this technique for a large class of probabilistic models and we demonstrate it with two probabilistic topic models, latent Dirichlet allocation and ...},
  pmid = {19926898},
  file = {/Users/brownsarahm/Zotero/storage/7D5WUFZX/Beaver, Clark - 2012 - Stochastic Variational inference(2).pdf}
}

@article{becker2012fear,
  title = {Fear Processing and Social Networking in the Absence of a Functional Amygdala},
  author = {Becker, Benjamin and Mihov, Yoan and Scheele, Dirk and Kendrick, Keith M. and Feinstein, Justin S. and Matusch, Andreas and Aydin, Merve and Reich, Harald and Urbach, Horst and {Oros-Peusquens}, Ana Maria and Shah, Nadim J. and Kunz, Wolfram S. and Schlaepfer, Thomas E. and Zilles, Karl and Maier, Wolfgang and Hurlemann, Ren{\'e}},
  year = {2012},
  journal = {Biological Psychiatry},
  volume = {72},
  number = {1},
  pages = {70--77},
  issn = {00063223},
  doi = {10.1016/j.biopsych.2011.11.024},
  abstract = {Background: The human amygdala plays a crucial role in processing social signals, such as face expressions, particularly fearful ones, and facilitates responses to them in face-sensitive cortical regions. This contributes to social competence and individual amygdala size correlates with that of social networks. While rare patients with focal bilateral amygdala lesion typically show impaired recognition of fearful faces, this deficit is variable, and an intriguing possibility is that other brain regions can compensate to support fear and social signal processing. Methods: To investigate the brain's functional compensation of selective bilateral amygdala damage, we performed a series of behavioral, psychophysiological, and functional magnetic resonance imaging experiments in two adult female monozygotic twins (patient 1 and patient 2) with equivalent, extensive bilateral amygdala pathology as a sequela of lipoid proteinosis due to Urbach-Wiethe disease. Results: Patient 1, but not patient 2, showed preserved recognition of fearful faces, intact modulation of acoustic startle responses by fear-eliciting scenes, and a normal-sized social network. Functional magnetic resonance imaging revealed that patient 1 showed potentiated responses to fearful faces in her left premotor cortex face area and bilaterally in the inferior parietal lobule. Conclusions: The premotor cortex face area and inferior parietal lobule are both implicated in the cortical mirror-neuron system, which mediates learning of observed actions and may thereby promote both imitation and empathy. Taken together, our findings suggest that despite the pre-eminent role of the amygdala in processing social information, the cortical mirror-neuron system may sometimes adaptively compensate for its pathology. {\copyright} 2012 Society of Biological Psychiatry.},
  pmid = {22218285},
  keywords = {Acoustic startle reflex,amygdala lesion,compensation,emotion,face,fear,fMRI,mirror-neuron system,social network},
  file = {/Users/brownsarahm/Zotero/storage/7NDVBDCK/Becker et al. - 2012 - Fear processing and social networking in the absence of a functional amygdala(6).pdf;/Users/brownsarahm/Zotero/storage/Z76KUVCC/Becker et al. - 2012 - Fear processing and social networking in the absence of a functional amygdala(5).pdf}
}

@article{bellamy2018AI,
  title = {{{AI Fairness}} 360: {{An}} Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias},
  author = {Bellamy, Rachel K. E. and Dey, Kuntal and Hind, Michael and Hoffman, Samuel C. and Houde, Stephanie and Kannan, Kalapriya and Lohia, Pranay and Martino, Jacquelyn and Mehta, Sameep and Mojsilovic, Aleksandra and Nagar, Seema and Ramamurthy, Karthikeyan Natesan and Richards, John and Saha, Diptikalyan and Sattigeri, Prasanna and Singh, Moninder and Varshney, Kush R. and Zhang, Yunfeng},
  year = {2018},
  month = oct,
  journal = {arXiv preprint arXiv: {\textbackslash}ldots}
}

@book{bellamy2018AIa,
  title = {{{AI Fairness}} 360: {{An Extensible Toolkit}} for {{Detecting}}, {{Understanding}}, and {{Mitigating Unwanted Algorithmic Bias}}},
  author = {Bellamy, Rachel K. E. and Dey, Kuntal and Hind, Michael and Hoffman, Samuel C. and Houde, Stephanie and Kannan, Kalapriya and Lohia, Pranay and Martino, Jacquelyn and Mehta, Sameep and Mojsilovic, Aleksandra and Nagar, Seema and Ramamurthy, Karthikeyan Natesan and Richards, John and Saha, Diptikalyan and Sattigeri, Prasanna and Singh, Moninder and Varshney, Kush R. and Zhang, Yunfeng},
  year = {2018},
  month = oct
}

@article{bellamy2019AI,
  title = {{{AI Fairness}} 360: {{An}} Extensible Toolkit for Detecting and Mitigating Algorithmic Bias},
  author = {Bellamy, Rachel KE and Dey, Kuntal and Hind, Michael and Hoffman, Samuel C and Houde, Stephanie and Kannan, Kalapriya and Lohia, Pranay and Martino, Jacquelyn and Mehta, Sameep and Mojsilovi{\'c}, Aleksandra},
  year = {2019},
  journal = {IBM Journal of Research and Development},
  volume = {63},
  number = {4/5},
  pages = {4--1},
  publisher = {IBM},
  issn = {0018-8646}
}

@article{bellman1957markovian,
  title = {A {{Markovian Decision Process}}},
  author = {Bellman, Richard},
  year = {1957},
  journal = {Indiana Univ. Math. J.},
  volume = {6},
  number = {4},
  pages = {679--684},
  issn = {01650114},
  doi = {10.1007/BF02935461},
  abstract = {Bellman R. A markovian decision process. Journal of Mathematics and Mechanics, 6, 1957.}
}

@article{ben-david2006sober,
  title = {A {{Sober Look}} on {{Clustering Stability}}},
  author = {{Ben-David}, Shai and Pal, David and {\noopsort{luxburg}}{v. Luxburg}, Ulrike},
  year = {2006},
  number = {2002},
  issn = {03029743},
  doi = {10.1007/11776420_4},
  abstract = {Stability is a common tool to verify the validity of sample based algorithms. In clustering it is widely used to tune the parameters of the algorithm, such as the number k of clusters. In spite of the popularity of stability in practical applications, there has been very little theoreti- cal analysis of this notion. In this paper we provide a formal definition of stability and analyze some of its basic properties. Quite surprisingly, the conclusion of our analysis is that for large sample size, stability is fully determined by the behavior of the ob jective function which the clustering algorithm is aiming to minimize. If the ob jective function has a unique global minimizer, the algorithm is stable, otherwise it is un- stable. In particular we conclude that stability is not a well-suited tool to determine the number of clusters - it is determined by the symme- tries of the data which may be unrelated to clustering parameters. We prove our results for center-based clusterings and for spectral clustering, and support our conclusions by many examples in which the behavior of stability is counter-intuitive.},
  keywords = {Theory \& Algorithms},
  file = {/Users/brownsarahm/Zotero/storage/NEIG395X/Ben-David, Pal, v. Luxburg - 2006 - A Sober Look on Clustering Stability(3).pdf}
}

@inproceedings{ben-david2007stability,
  title = {Stability of k -{{Means Clustering}}},
  booktitle = {Conference on {{Learning Theory}}},
  author = {{Ben-david}, Shai and Simon, Hans Ulrich and Pal, David},
  year = {2007},
  pages = {20--34},
  file = {/Users/brownsarahm/Zotero/storage/XGE6JDTQ/Ben-david, Simon, Pal - 2007 - Stability of k -Means Clustering(3).pdf}
}

@article{bengio1995input,
  title = {An Input Output {{HMM}} Architecture},
  author = {Bengio, Yoshua and Frasconi, Paolo},
  year = {1995},
  journal = {Advances in neural information {\textbackslash}ldots},
  file = {/Users/brownsarahm/Zotero/storage/W8G3326R/Bengio, Frasconi - 1995 - An input output HMM architecture(3).pdf}
}

@article{bengio1996input,
  title = {Input/Output {{HMMs}} for Sequence Processing},
  author = {Bengio, Y and Frasconi, P},
  year = {1996},
  journal = {IEEE Transactions on Neural Networks},
  volume = {7},
  number = {5},
  pages = {1231--1249},
  keywords = {IOHMM},
  file = {/Users/brownsarahm/Zotero/storage/7L2S2LV5/Bengio, Frasconi - 1996 - Inputoutput HMMs for sequence processing(3).pdf}
}

@article{benner2004using,
  title = {Using the {{Dreyfus}} Model of Skill Acquisition to Describe and Interpret Skill Acquisition and Clinical Judgment in Nursing Practice and Education},
  author = {Benner, Patricia},
  year = {2004},
  journal = {Bulletin of science, technology \& society},
  volume = {24},
  number = {3},
  pages = {188--199},
  publisher = {SAGE Publications}
}

@inproceedings{benthall2019Racial,
  title = {Racial Categories in Machine Learning},
  booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
  author = {Benthall, Sebastian and Haynes, Bruce D.},
  year = {2019},
  series = {{{FAT}}* '19},
  pages = {289--298},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3287560.3287575},
  isbn = {978-1-4503-6125-5},
  keywords = {fairness,machine learning,racial classification,segregation}
}

@article{bertrand2018editions,
  title = {{\'E}ditions de La {{Maison}} Des Sciences de l ' Homme},
  author = {Bertrand, Monique},
  year = {2018},
  pages = {1--14}
}

@inproceedings{besserve2013statistical,
  title = {Statistical Analysis of Coupled Time Series with {{Kernel Cross-Spectral Density}} Operators.},
  booktitle = {Advances in {{Neural Information Processing Systems}} 26 ({{NIPS}} 2013)},
  author = {Besserve, Michel and Logothetis, Nikos K and Sch, Bernhard and Sch{\"o}lkopf, Bernhard},
  year = {2013},
  pages = {1--9},
  abstract = {Many applications require the analysis of complex interactions between time series. These interactions can be non-linear and involve vector valued as well as complex data structures such as graphs or strings. Here we provide a general framework for the statistical analysis of these dependencies when random variables are sampled from stationary time-series of arbitrary objects. To achieve this goal, we study the properties of the Kernel Cross-Spectral Density (KCSD) operator induced by positive definite kernels on arbitrary input domains. This framework enables us to develop an independence test between time series, as well as a similarity measure to compare different types of coupling. The performance of our test is compared to the HSIC test using i.i.d. assumptions, showing improvements in terms of detection errors, as well as the suitability of this approach for testing dependency in complex dynamical systems. This similarity measure enables us to identify different types of interactions in electrophysiological neural time series.},
  isbn = {78-1-63266-024-4},
  file = {/Users/brownsarahm/Zotero/storage/9LYLECBZ/Besserve, Logothetis, Sch - Unknown - Statistical analysis of coupled time series with Kernel Cross-Spectral Density operators (3).pdf;/Users/brownsarahm/Zotero/storage/SD5I8YBH/Besserve, Logothetis, Sch - Unknown - Statistical analysis of coupled time series with Kernel Cross-Spectral Density operators (4).pdf}
}

@inproceedings{beutel2019Puttinga,
  title = {Putting Fairness Principles into Practice: {{Challenges}}, Metrics, and Improvements},
  booktitle = {Proceedings of the 2019 {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {Beutel, Alex and Chen, Jilin and Doshi, Tulsee and Qian, Hai and Woodruff, Allison and Luu, Christine and Kreitmann, Pierre and Bischof, Jonathan and Chi, Ed H},
  year = {2019},
  pages = {453--459}
}

@article{bhaskar2006machine,
  title = {Machine Learning in Bioinformatics: A Brief Survey and Recommendations for Practitioners.},
  author = {Bhaskar, Harish and Hoyle, David C and Singh, Sameer},
  year = {2006},
  month = oct,
  journal = {Computers in biology and medicine},
  volume = {36},
  number = {10},
  eprint = {16226240},
  eprinttype = {pubmed},
  pages = {1104--25},
  issn = {0010-4825},
  doi = {10.1016/j.compbiomed.2005.09.002},
  abstract = {Machine learning is used in a large number of bioinformatics applications and studies. The application of machine learning techniques in other areas such as pattern recognition has resulted in accumulated experience as to correct and principled approaches for their use. The aim of this paper is to give an account of issues affecting the application of machine learning tools, focusing primarily on general aspects of feature and model parameter selection, rather than any single specific algorithm. These aspects are discussed in the context of published bioinformatics studies in leading journals over the last 5 years. We assess to what degree the experience gained by the pattern recognition research community pervades these bioinformatics studies. We finally discuss various critical issues relating to bioinformatic data sets and make a number of recommendations on the proper use of machine learning techniques for bioinformatics research based upon previously published research on machine learning.},
  pmid = {16226240},
  keywords = {Algorithms,Artificial Intelligence,Computational Biology,Humans,Mathematical Computing,Medical Informatics Applications,Neoplasms,Neoplasms: classification,Neoplasms: diagnosis,Neoplasms: genetics,Neural Networks (Computer),Oligonucleotide Array Sequence Analysis},
  file = {/Users/brownsarahm/Zotero/storage/NBZ8CVRK/Bhaskar, Hoyle, Singh - 2006 - Machine learning in bioinformatics a brief survey and recommendations for practitioners(3).pdf}
}

@article{bickart2012intrinsic,
  title = {Intrinsic {{Amygdala-Cortical Functional Connectivity Predicts Social Network Size}} in {{Humans}}},
  author = {Bickart, K. C. and Hollenbeck, M. C. and Barrett, L. F. and Dickerson, B. C.},
  year = {2012},
  journal = {Journal of Neuroscience},
  volume = {32},
  number = {42},
  pages = {14729--14741},
  issn = {0270-6474},
  abstract = {Using resting-state functional magnetic resonance imaging data from two independent samples of healthy adults, we parsed the amygdala's intrinsic connectivity into three partially distinct large-scale networks that strongly resemble the known anatomical organization of amygdala connectivity in rodents and monkeys. Moreover, in a third independent sample, we discovered that people who fostered and maintained larger and more complex social networks not only had larger amygdala volumes, but also amygdalae with stronger intrinsic connectivity within two of these networks: one putatively subserving perceptual abilities and one subserving affiliative behaviors. Our findings were anatomically specific to amygdalar circuitry in that individual differences in social network size and complexity could not be explained by the strength of intrinsic connectivity between nodes within two networks that do not typically involve the amygdala (i.e., the mentalizing and mirror networks), and were behaviorally specific in that amygdala connectivity did not correlate with other self-report measures of sociality.},
  pmid = {23077058},
  file = {/Users/brownsarahm/Zotero/storage/94CRBS5Q/Bickart et al. - 2012 - Intrinsic Amygdala-Cortical Functional Connectivity Predicts Social Network Size in Humans(5).pdf;/Users/brownsarahm/Zotero/storage/WFBTQPLZ/Bickart et al. - 2012 - Intrinsic Amygdala-Cortical Functional Connectivity Predicts Social Network Size in Humans(6).pdf}
}

@article{bickel1975Sex,
  title = {Sex Bias in Graduate Admissions: {{Data}} from {{Berkeley}}},
  author = {Bickel, Peter J and Hammel, Eugene A and O'Connell, J William and {Others}},
  year = {1975},
  journal = {Science},
  volume = {187},
  number = {4175},
  pages = {398--404}
}

@book{bickel2015mathematical,
  title = {Mathematical Statistics: Basic Ideas and Selected Topics, Volume {{I}}},
  author = {Bickel, Peter J and Doksum, Kjell A},
  year = {2015},
  volume = {117},
  publisher = {CRC Press}
}

@article{binder2009where,
  title = {Where Is the Semantic System? {{A}} Critical Review and Meta-Analysis of 120 Functional Neuroimaging Studies},
  author = {Binder, Jeffrey R and Desai, Rutvik H and Graves, William W and Conant, Lisa L},
  year = {2009},
  journal = {Cerebral Cortex},
  volume = {19},
  number = {12},
  pages = {2767--2796}
}

@article{bird2020Fairlearn,
  title = {Fairlearn: {{A}} Toolkit for Assessing and Improving Fairness in {{AI}}},
  author = {Bird, Sarah and Dud{\'i}k, Miro and Edgar, Richard and Horn, Brandon and Lutz, Roman and Milan, Vanessa and Sameki, Mehrnoosh and Wallach, Hanna and Walker, Kathleen},
  year = {2020},
  journal = {Microsoft, Tech. Rep. MSR-TR-2020-32}
}

@article{birhane2021Algorithmic,
  title = {Algorithmic Injustice: A Relational Ethics Approach},
  author = {Birhane, Abeba},
  year = {2021},
  journal = {Patterns},
  volume = {2},
  number = {2},
  publisher = {Elsevier}
}

@inproceedings{birhane2022Forgotten,
  title = {The Forgotten Margins of {{AI}} Ethics},
  booktitle = {2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Birhane, Abeba and Ruane, Elayne and Laurent, Thomas and S. Brown, Matthew and Flowers, Johnathan and Ventresque, Anthony and L. Dancy, Christopher},
  year = {2022},
  pages = {948--958}
}

@inproceedings{birhane2022Forgottena,
  title = {The Forgotten Margins of {{AI}} Ethics},
  booktitle = {2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Birhane, Abeba and Ruane, Elayne and Laurent, Thomas and S. Brown, Matthew and Flowers, Johnathan and Ventresque, Anthony and L. Dancy, Christopher},
  year = {2022},
  pages = {948--958}
}

@inproceedings{birhane2022Forgottenb,
  title = {The Forgotten Margins of {{AI}} Ethics},
  booktitle = {Proceedings of the 2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Birhane, Abeba and Ruane, Elayne and Laurent, Thomas and S. Brown, Matthew and Flowers, Johnathan and Ventresque, Anthony and L. Dancy, Christopher},
  year = {2022},
  pages = {948--958}
}

@book{bishop2006pattern,
  title = {Pattern {{Recognition}} and {{Machine Learning}}},
  author = {Bishop, Christopher M CM},
  year = {2006},
  edition = {1},
  volume = {4},
  publisher = {Springer-Verlag New York, Inc.},
  address = {Secaucus, NJ, USA},
  doi = {10.1641/B580519},
  isbn = {978-0-387-31073-2},
  pmid = {18292226},
  file = {/Users/brownsarahm/Zotero/storage/DTNHTD82/Bishop - 2006 - Pattern recognition and machine learning(2).pdf;/Users/brownsarahm/Zotero/storage/FDKKHB9Z/Bishop - Unknown - Pattern Recognition and machine learning(2).pdf;/Users/brownsarahm/Zotero/storage/Z5CRW2M6/Bishop - 2006 - Pattern Recognition and Machine Learning(5).pdf}
}

@article{bishop2013modelbased,
  title = {Model-Based Machine Learning.},
  author = {Bishop, Christopher M},
  year = {2013},
  month = feb,
  journal = {Philosophical transactions. Series A, Mathematical, physical, and engineering sciences},
  volume = {371},
  number = {1984},
  pages = {20120222},
  issn = {1364-503X},
  doi = {10.1098/rsta.2012.0222},
  abstract = {Several decades of research in the field of machine learning have resulted in a multitude of different algorithms for solving a broad range of problems. To tackle a new application, a researcher typically tries to map their problem onto one of these existing methods, often influenced by their familiarity with specific algorithms and by the availability of corresponding software implementations. In this study, we describe an alternative methodology for applying machine learning, in which a bespoke solution is formulated for each new application. The solution is expressed through a compact modelling language, and the corresponding custom machine learning code is then generated automatically. This model-based approach offers several major advantages, including the opportunity to create highly tailored models for specific scenarios, as well as rapid prototyping and comparison of a range of alternative models. Furthermore, newcomers to the field of machine learning do not have to learn about the huge range of traditional methods, but instead can focus their attention on understanding a single modelling environment. In this study, we show how probabilistic graphical models, coupled with efficient inference algorithms, provide a very flexible foundation for model-based machine learning, and we outline a large-scale commercial application of this framework involving tens of millions of users. We also describe the concept of probabilistic programming as a powerful software environment for model-based machine learning, and we discuss a specific probabilistic programming language called Infer.NET, which has been widely used in practical applications.},
  pmid = {23277612},
  file = {/Users/brownsarahm/Zotero/storage/BRHK3FLC/Bishop - 2013 - Model-based machine learning(3).pdf}
}

@article{blake1995development,
  title = {The Development of a Clinician-Administered {{PTSD}} Scale},
  author = {Blake, Dudley David and Weathers, Frank W and Nagy, Linda M and Kaloupek, Danny G and Gusman, Fred D and Charney, Dennis S and Keane, Terence M},
  year = {1995},
  journal = {Journal of traumatic stress},
  volume = {8},
  number = {1},
  pages = {75--90},
  file = {/Users/brownsarahm/Zotero/storage/QCMJBZ36/Unknown - 1995 - Development of CAPS(2).pdf}
}

@article{blanchard2011generalizing,
  title = {Generalizing from {{Several Related Classification Tasks}} to a {{New Unlabeled Sample}}},
  author = {Blanchard, Gilles and Lee, Gyemin and Scott, Clayton},
  year = {2011},
  journal = {Proceedings of NIPS},
  volume = {1},
  number = {i},
  pages = {1--9},
  abstract = {We consider the problem of assigning class labels to an unlabeled test data set, given several labeled training data sets drawn from similar distributions. This problem arises in several applications where data distributions fluctuate because of biological, technical, or other sources of variation. We develop a distribution- free, kernel-based approach to the problem. This approach involves identifying an appropriate reproducing kernel Hilbert space and optimizing a regularized em- pirical risk over the space. We present generalization error analysis, describe uni- versal kernels, and establish universal consistency of the proposed methodology. Experimental results on flow cytometry data are presented.},
  keywords = {covariate shift,kernel methods},
  file = {/Users/brownsarahm/Zotero/storage/H8CHPEG7/Blanchard, Lee, Scott - 2011 - Generalizing from Several Related Classification Tasks to a New Unlabeled Sample(3).pdf}
}

@article{blei2003latent,
  title = {Latent Dirichlet Allocation},
  author = {Blei, David M DM and Ng, Andrew Y AY and Jordan, Michael I},
  year = {2003},
  journal = {the Journal of machine Learning research},
  volume = {3},
  pages = {993--1022},
  issn = {15324435},
  doi = {10.1162/jmlr.2003.3.4-5.993},
  abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
  pmid = {21362469},
  keywords = {lda,topic model},
  file = {/Users/brownsarahm/Zotero/storage/QFC2BD8R/Blei, Ng, Jordan - 2003 - Latent dirichlet allocation(3).pdf}
}

@article{blei2004variational,
  title = {Variational Methods for the {{Dirichlet}} Process},
  author = {Blei, David M. and Jordan, Michael I.},
  year = {2004},
  journal = {International Conference on Machine Learning},
  pages = {12},
  issn = {1936-0975},
  doi = {10.1145/1015330.1015439},
  abstract = {Variational inference methods, including mean field methods and loopy\${\textbackslash}backslash\$nbelief propaga- tion, have been widely used for approximate probabilistic\${\textbackslash}backslash\$ninference in graphical models. While often less accurate than MCMC,\${\textbackslash}backslash\$nvari- ational methods provide a fast deterministic approximation\${\textbackslash}backslash\$nto marginal and conditional probabilities. Such approximations can\${\textbackslash}backslash\$nbe particularly useful in high dimensional prob- lems where sampling\${\textbackslash}backslash\$nmethods are too slow to be effective. A limitation of current methods,\${\textbackslash}backslash\$nhowever, is that they are restricted to para- metric probabilistic\${\textbackslash}backslash\$nmodels. MCMC does not have such a limitation; indeed, MCMC sam- plers\${\textbackslash}backslash\$nhave been developed for the Dirichlet process (DP), a nonparametric\${\textbackslash}backslash\$nmeasure on measures (Ferguson, 1973) that is the cor- nerstone of\${\textbackslash}backslash\$nBayesian nonparametric statis- tics (Escobar \& West, 1995; Neal,\${\textbackslash}backslash\$n2000). In this paper, we develop a mean-field varia- tional approach\${\textbackslash}backslash\$nto approximate inference for the Dirichlet process, where the approximate\${\textbackslash}backslash\$nposterior is based on the truncated stick- breaking construction\${\textbackslash}backslash\$n(Ishwaran \& James, 2001). We compare our approach to DP sam- plers\${\textbackslash}backslash\$nfor Gaussian DP mixture models.},
  file = {/Users/brownsarahm/Zotero/storage/AHDA56CL/Blei, Jordan - 2004 - Variational methods for the Dirichlet process(3).pdf}
}

@article{blei2006dynamic,
  title = {Dynamic Topic Models},
  author = {Blei, David M and Lafferty, John D},
  year = {2006},
  journal = {Proceedings of the 23rd international conference {\textbackslash}ldots},
  pages = {113--120},
  file = {/Users/brownsarahm/Zotero/storage/4SAQQJXD/Blei, Lafferty - 2006 - Dynamic topic models(3).pdf}
}

@article{blei2011posterior,
  title = {Posterior {{Predictive Checks}}},
  author = {Blei, David M},
  year = {2011},
  pages = {1--8},
  file = {/Users/brownsarahm/Zotero/storage/6697WDKV/Blei - 2011 - Posterior Predictive Checks(3).pdf}
}

@article{bliss-moreau2008individual,
  title = {Individual {{Differences}} in {{Learning}} the {{Affective Value}} of {{Others Under Minimal Conditions}}},
  author = {{Bliss-moreau}, Eliza and Barrett, Lisa Feldman and Wright, Christopher I},
  year = {2008},
  journal = {Emotion},
  volume = {8},
  number = {4},
  pages = {479--493},
  doi = {10.1037/1528-3542.8.4.479.Individual},
  keywords = {affect,and brussel sprouts bad,beautiful and,chocolate tastes good to,cockroaches as ugly,extraversion,humans,learning,people live in a,some,to others,we see sunsets as,with affective value,world that is saturated},
  file = {/Users/brownsarahm/Zotero/storage/QZCSK5T5/Bliss-moreau, Barrett, Wright - 2008 - Individual Differences in Learning the Affective Value of Others Under Minimal Conditions(3).pdf}
}

@incollection{bloch2010need,
  title = {On the Need for Conceptual and Definitional Clarity in Emotion Regulation Research on Psychopathology},
  booktitle = {Emotion {{Regulation}} and {{Psychopathology}}: A {{Transdiagnostic Approach}} to {{Etiology}} and {{Treatment}}},
  author = {Bloch, L and Moran, {\relax EK} and Kring, {\relax AM}},
  year = {2010},
  publisher = {The Guilford Press},
  isbn = {1-60623-451-X 978-1-60623-451-8},
  file = {/Users/brownsarahm/Zotero/storage/XNEXHLYV/Bloch, Moran, Kring - 2010 - On the need for conceptual and definitional clarity in emotion regulation research on psychopathology(3).pdf}
}

@inproceedings{blum2020Recovering,
  title = {Recovering from Biased Data: {{Can}} Fairness Constraints Improve Accuracy?},
  booktitle = {1st Symposium on Foundations of Responsible Computing ({{FORC}} 2020)},
  author = {Blum, Avrim and Stangl, Kevin},
  year = {2020},
  pages = {22},
  publisher = {CoRR},
  address = {Chicago, IL},
  organization = {Schloss Dagstuhl-Leibniz-Zentrum f{\"u}r Informatik}
}

@book{blum2020ungrading,
  title = {Ungrading: {{Why}} Rating Students Undermines Learning (and What to Do Instead)},
  author = {Blum, Susan D and Kohn, Alfie},
  year = {2020},
  publisher = {West Virginia University Press}
}

@article{blyth1972simpson,
  title = {On {{Simpson}}'s Paradox and the Sure-Thing Principle},
  author = {Blyth, Colin R},
  year = {1972},
  journal = {Journal of the American Statistical Association},
  volume = {67},
  number = {338},
  pages = {364--366}
}

@article{bockenholt2003structure,
  title = {The Structure of Self-Reported Emotional Experiences: A Mixed-Effects {{Poisson}} Factor Model.},
  author = {B{\"o}ckenholt, Ulf and {\noopsort{kamakura}}a Kamakura, Wagner and Wedel, Michel},
  year = {2003},
  month = nov,
  journal = {The British journal of mathematical and statistical psychology},
  volume = {56},
  number = {Pt 2},
  eprint = {14633333},
  eprinttype = {pubmed},
  pages = {215--29},
  issn = {0007-1102},
  doi = {10.1348/000711003770480011},
  abstract = {Multivariate count data are commonly analysed by using Poisson distributions with varying intensity parameters, resulting in a random-effects model. In the analysis of a data set on the frequency of different emotion experiences we find that a Poisson model with a single random effect does not yield an adequate fit. An alternative model that requires as many random effects as emotion categories requires high-dimensional integration and the estimation of a large number of parameters. As a solution to these computational problems, we propose a factor-analytic Poisson model and show that a two-dimensional factor model fits the reported data very well. Moreover, it yields a substantively satisfactory solution: one factor describing the degree of pleasantness and unpleasantness of emotions and the other factor describing the activation levels of the emotions. We discuss the incorporation of covariates to facilitate rigorous tests of the random-effects structure. Marginal maximum likelihood methods lead to straight-forward estimation of the model, for which goodness-of-fit tests are also presented.},
  pmid = {14633333},
  keywords = {Arousal,Emotions,Extraversion (Psychology),Humans,Individuality,Likelihood Functions,Models,Multivariate Analysis,Neurotic Disorders,Neurotic Disorders: diagnosis,Neurotic Disorders: psychology,Personality Inventory,Personality Inventory: statistics \& numerical data,Poisson Distribution,Psychometrics,Psychometrics: statistics \& numerical data,Self Disclosure,Statistical}
}

@article{boerlin2013predictive,
  title = {Predictive {{Coding}} of {{Dynamical Variables}} in {{Balanced Spiking Networks}}},
  author = {Boerlin, Martin and Machens, Christian K. and Den{\`e}ve, Sophie},
  year = {2013},
  journal = {PLoS Computational Biology},
  volume = {9},
  number = {11},
  issn = {1553734X},
  doi = {10.1371/journal.pcbi.1003258},
  abstract = {Author SummaryTwo observations about the cortex have puzzled and fascinated neuroscientists for a long time. First, neural responses are highly variable. Second, the level of excitation and inhibition received by each neuron is tightly balanced at all times. Here, we demonstrate that both properties are necessary consequences of neural networks representing information reliably and with a small number of spikes. To achieve such efficiency, spikes of individual neurons must communicate prediction errors about a common population-level signal, automatically resulting in balanced excitation and inhibition and highly variable neural responses. We illustrate our approach by focusing on the implementation of linear dynamical systems. Among other things, this allows us to construct a network of spiking neurons that can integrate input signals, yet is robust against many perturbations. Most importantly, our approach shows that neural variability cannot be equated to noise. Despite exhibiting the same single unit properties as other widely used network models, our balanced networks are orders of magnitudes more reliable. Our results suggest that the precision of cortical representations has been strongly underestimated.},
  pmid = {24244113}
}

@inproceedings{bolukbasi2016man,
  title = {Man Is to Computer Programmer as Woman Is to Homemaker? Debiasing Word Embeddings},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T},
  year = {2016},
  pages = {4349--4357}
}

@inproceedings{bond2019human,
  title = {Human Centered Artificial Intelligence: {{Weaving UX}} into Algorithmic Decision Making},
  booktitle = {{{RoCHI}} 2019: {{International}} Conference on Human-Computer Interaction},
  author = {Bond, Raymond R and Mulvenna, Maurice and Finlay, D and Wong, Alexander and Koene, Ansgar and Brisk, Rob and Boger, Jennifer and Adel, Tameem},
  year = {2019}
}

@article{borgwardt2006integrating,
  title = {Integrating Structured Biological Data by {{Kernel Maximum Mean Discrepancy}}.},
  author = {Borgwardt, Karsten M and Gretton, Arthur and Rasch, Malte J and Kriegel, Hans-Peter and Sch{\"o}lkopf, Bernhard and Smola, Alex J},
  year = {2006},
  month = jul,
  journal = {Bioinformatics (Oxford, England)},
  volume = {22},
  number = {14},
  eprint = {16873512},
  eprinttype = {pubmed},
  pages = {e49--57},
  issn = {1367-4811},
  doi = {10.1093/bioinformatics/btl242},
  abstract = {Many problems in data integration in bioinformatics can be posed as one common question: Are two sets of observations generated by the same distribution? We propose a kernel-based statistical test for this problem, based on the fact that two distributions are different if and only if there exists at least one function having different expectation on the two distributions. Consequently we use the maximum discrepancy between function means as the basis of a test statistic. The Maximum Mean Discrepancy (MMD) can take advantage of the kernel trick, which allows us to apply it not only to vectors, but strings, sequences, graphs, and other common structured data types arising in molecular biology.},
  pmid = {16873512},
  keywords = {Algorithms,Biological,Computational Biology,Computational Biology: methods,Computer Simulation,Data Interpretation,Databases,Factual,Information Storage and Retrieval,Information Storage and Retrieval: methods,Models,Sample Size,Statistical,Statistical Distributions,Systems Integration},
  file = {/Users/brownsarahm/Zotero/storage/EBUFWP8S/Borgwardt et al. - 2006 - Integrating structured biological data by Kernel Maximum Mean Discrepancy(3).pdf}
}

@inproceedings{boriah2008similarity,
  title = {Similarity Measures for Categorical Data: {{A}} Comparative Evaluation},
  booktitle = {{{SDM}}},
  author = {Boriah, Shyam and Chandola, V and Kumar, V},
  year = {2008},
  file = {/Users/brownsarahm/Zotero/storage/7FPMF3EH/Boriah, Chandola, Kumar - 2008 - Similarity measures for categorical data A comparative evaluation(3).pdf}
}

@article{bostock2011datadriven,
  title = {D\${\textasciicircum}3\$ Data-Driven Documents},
  author = {Bostock, Michael and Ogievetsky, Vadim and Heer, Jeffrey},
  year = {2011},
  journal = {IEEE transactions on visualization and computer graphics},
  volume = {17},
  number = {12},
  pages = {2301--2309}
}

@article{bouillautinput,
  title = {Input {{Output-HMM}} and Their {{Bayesian Network}} Extensions to Diagnose Rail Degradations},
  author = {Bouillaut, L and Salem, A Ben and Aknin, P and Weber, P},
  journal = {Networks},
  file = {/Users/brownsarahm/Zotero/storage/NBKZQHPC/Bouillaut et al. - Unknown - Input Output-HMM and their Bayesian Network extensions to diagnose rail degradations(3).pdf}
}

@article{boulesteix2013plea,
  title = {A Plea for Neutral Comparison Studies in Computational Sciences},
  author = {Boulesteix, Anne-Laure and Lauer, Sabine and {\noopsort{eugster}}a Eugster, Manuel J},
  year = {2013},
  journal = {PloS one},
  volume = {8},
  number = {4},
  pages = {e61562},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0061562},
  abstract = {In computational science literature including, e.g., bioinformatics, computational statistics or machine learning, most published articles are devoted to the development of "new methods", while comparison studies are generally appreciated by readers but surprisingly given poor consideration by many journals. This paper stresses the importance of neutral comparison studies for the objective evaluation of existing methods and the establishment of standards by drawing parallels with clinical research. The goal of the paper is twofold. Firstly, we present a survey of recent computational papers on supervised classification published in seven high-ranking computational science journals. The aim is to provide an up-to-date picture of current scientific practice with respect to the comparison of methods in both articles presenting new methods and articles focusing on the comparison study itself. Secondly, based on the results of our survey we critically discuss the necessity, impact and limitations of neutral comparison studies in computational sciences. We define three reasonable criteria a comparison study has to fulfill in order to be considered as neutral, and explicate general considerations on the individual components of a "tidy neutral comparison study". R codes for completely replicating our statistical analyses and figures are available from the companion website http://www.ibe.med.uni-muenchen.de/organisation/mitarbeiter/020\_professuren/boulesteix/plea2013.},
  pmid = {23637855},
  keywords = {Artificial Intelligence,Computational Biology,Computational Biology: methods,Humans},
  file = {/Users/brownsarahm/Zotero/storage/BRSRUDA4/Boulesteix, Lauer, Eugster - 2013 - A plea for neutral comparison studies in computational sciences(3).pdf}
}

@article{bourdoukan2012learning,
  title = {Learning Optimal Spike-Based Representations},
  author = {Bourdoukan, Ralph and Barrett, David Gt and Machens, Christian K and Den{\`e}ve, Sophie},
  year = {2012},
  journal = {Advances in Neural Information Processing Systems 25},
  number = {c},
  pages = {2294--2302},
  issn = {10495258},
  abstract = {How do neural networks learn to represent information optimally? We answer this question by deriving spiking dynamics and learning dynamics directly from a measure of network performance. We find that a network of integrate-and-fire neurons undergoing Hebbian plasticity can learn an optimal spike-based repre- sentation for a linear decoder. The learning rule acts to minimise the membrane potential magnitude, which can be interpreted as a representation error after learn- ing. In this way, learning reduces the representation error and drives the network into a robust, balanced regime. The network becomes balanced because small rep- resentation errors correspond to small membrane potentials, which in turn results from a balance of excitation and inhibition. The representation is robust because neurons become self-correcting, only spiking if the representation error exceeds a threshold. Altogether, these results suggest that many observed features of cor- tical dynamics, such as excitatory-inhibitory balance, integrate-and-fire dynamics and Hebbian plasticity, are signatures of a robust, optimal spike-based code.},
  keywords = {predictive coding},
  file = {/Users/brownsarahm/Zotero/storage/9GS6UUGU/Bourdoukan et al. - 2012 - Learning optimal spike-based representations(3).pdf}
}

@inproceedings{bousquet2001algorithmic,
  title = {Algorithmic {{Stability}} and {{Generalization Performance}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 13},
  author = {Bousquet, Olivier and Elisseeff, Andre},
  year = {2001},
  pages = {196--202},
  file = {/Users/brownsarahm/Zotero/storage/5E2CU2E6/Bousquet, Elisseeff - 2001 - Algorithmic Stability and Generalization Performance(3).pdf}
}

@article{bousquet2002stability,
  title = {Stability and {{Generalization}}},
  author = {Bousquet, Olivier and Elisseeff, Andre},
  year = {2002},
  journal = {The Journal of Machine Learning Research},
  volume = {2},
  pages = {499--526},
  issn = {15324435},
  doi = {10.1162/153244302760200704},
  abstract = {We define notions of stability for learning algorithms and derive bounds on their generalization error based on the empirical error and the leave-one-out error. We then study the stability properties of large classes of learning algorithms such as regularization based algorithms. In particular we focus on Hilbert space regularization and Kullback-Liebler regularization. We then apply the results to SVM for regression and classification and to maximum entropy discrimination.},
  file = {/Users/brownsarahm/Zotero/storage/IZ4WTPV4/Bousquet, Elisseeff - 2002 - Stability and generalization(2).pdf}
}

@article{bousquet2004introduction,
  title = {Introduction to Statistical Learning Theory},
  author = {Bousquet, Olivier and Boucheron, S and Lugosi, G},
  year = {2004},
  journal = {{\textbackslash}ldots Lectures on Machine Learning},
  file = {/Users/brownsarahm/Zotero/storage/J8P5Z6G3/Bousquet, Boucheron, Lugosi - 2004 - Introduction to statistical learning theory(3).pdf}
}

@article{box1980sampling,
  title = {Sampling and {{Bayes}}' Inference in Scientific Modelling and Robustness},
  author = {Box, {\relax GEP}},
  year = {1980},
  journal = {Journal of the Royal Statistical Society. Series A ( {\textbackslash}ldots},
  eprint = {10.2307/2982063},
  eprinttype = {jstor},
  file = {/Users/brownsarahm/Zotero/storage/WCGNICEU/Box - 1980 - Sampling and Bayes' inference in scientific modelling and robustness(3).pdf}
}

@article{boyce2016individual,
  title = {Individual Differences in Loss Aversion: {{Conscientiousness}} Predicts How Life Satisfaction Responds to Losses versus Gains in Income},
  author = {Boyce, Christopher J and Wood, Alex M and Ferguson, Eamonn},
  year = {2016},
  journal = {Personality and Social Psychology Bulletin},
  volume = {42},
  number = {4},
  pages = {471--484},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA}
}

@article{boyce2016individual,
  title = {Individual Differences in Loss Aversion: {{Conscientiousness}} Predicts How Life Satisfaction Responds to Losses versus Gains in Income},
  author = {Boyce, Christopher J and Wood, Alex M and Ferguson, Eamonn},
  year = {2016},
  journal = {Personality and Social Psychology Bulletin},
  volume = {42},
  number = {4},
  pages = {471--484},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA}
}

@book{boyd2010convex,
  title = {Convex {{Optimization}}},
  author = {Boyd, Stephen and Vandenberghe, Lieven and Optimization, Convex},
  editor = {Press, Cambridge University},
  year = {2010},
  volume = {25},
  publisher = {Cambridge University Press},
  doi = {10.1080/10556781003625177},
  abstract = {We are developing a dual panel breast-dedicated PET system using LSO scintillators coupled to position sensitive avalanche photodiodes (PSAPD). The charge output is amplified and read using NOVA RENA-3 ASICs. This paper shows that the coincidence timing resolution of the RENA-3 ASIC can be improved using certain list-mode calibrations. We treat the calibration problem as a convex optimization problem and use the RENA-3s analog-based timing system to correct the measured data for time dispersion effects from correlated noise, PSAPD signal delays and varying signal amplitudes. The direct solution to the optimization problem involves a matrix inversion that grows order (n3) with the number of parameters. An iterative method using single-coordinate descent to approximate the inversion grows order (n). The inversion does not need to run to convergence, since any gains at high iteration number will be low compared to noise amplification. The system calibration method is demonstrated with measured pulser data as well as with two LSO-PSAPD detectors in electronic coincidence. After applying the algorithm, the 511keV photopeak paired coincidence time resolution from the LSO-PSAPD detectors under study improved by 57\%, from the raw value of 16.30.07 ns FWHM to 6.920.02 ns FWHM (11.520.05 ns to 4.890.02 ns for unpaired photons).},
  isbn = {978-0-521-83378-3},
  pmid = {20876008},
  file = {/Users/brownsarahm/Zotero/storage/2VW2GJ6X/Optimization - Unknown - Convex Optimization(2).pdf}
}

@article{boyd2010distributed,
  title = {Distributed {{Optimization}} and {{Statistical Learning}} via the {{Alternating Direction Method}} of {{Multipliers}}},
  author = {Boyd, Stephen},
  year = {2010},
  journal = {Foundations and Trends{\textregistered} in Machine Learning},
  volume = {3},
  number = {1},
  pages = {1--122},
  issn = {1935-8237},
  doi = {10.1561/2200000016},
  file = {/Users/brownsarahm/Zotero/storage/DX6EW3UT/Boyd - 2010 - Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers(3).pdf}
}

@article{boyd2012critical,
  title = {Critical Questions for Big Data: {{Provocations}} for a Cultural, Technological, and Scholarly Phenomenon},
  author = {Boyd, Danah and Crawford, Kate},
  year = {2012},
  journal = {Information Communication and Society},
  volume = {15},
  number = {5},
  pages = {662--679},
  issn = {1369118X},
  doi = {10.1080/1369118X.2012.678878},
  abstract = {The era of Big Data has begun. Computer scientists, physicists, economists, mathemati-cians, political scientists, bio-informaticists, sociologists, and other scholars are clamoring for access to the massive quantities of information produced by and about people, things, and their interactions. Diverse groups argue about the potential benefits and costs of ana-lyzing genetic sequences, social media interactions, health records, phone logs, govern-ment records, and other digital traces left by people. Significant questions emerge. Will large-scale search data help us create better tools, services, and public goods? Or will it usher in a new wave of privacy incursions and invasive marketing? Will data ana-lytics help us understand online communities and political movements? Or will it be used to track protesters and suppress speech? Will it transform how we study human communi-cation and culture, or narrow the palette of research options and alter what 'research' means? Given the rise of Big Data as a socio-technical phenomenon, we argue that it is necessary to critically interrogate its assumptions and biases. In this article, we offer six provocations to spark conversations about the issues of Big Data: a cultural, techno-logical, and scholarly phenomenon that rests on the interplay of technology, analysis, and mythology that provokes extensive utopian and dystopian rhetoric. Technology is neither good nor bad; nor is it neutral . . . technology's inter-action with the social ecology is such that technical developments frequently have environmental, social, and human consequences that go far beyond the immediate purposes of the technical devices and practices themselves.},
  pmid = {199800104512001},
  keywords = {analytics,Big Data,communication studies,epistemology,ethics,philosophy of science,social media,social network sites,Twitter},
  file = {/Users/brownsarahm/Zotero/storage/RRLP3JPJ/Boyd, Crawford - 2012 - Critical questions for big data Provocations for a cultural, technological, and scholarly phenomenon.pdf}
}

@techreport{bradley2007international,
  title = {The {{International Affective Digitized Sounds Affective Ratings}} of {{Sounds}} and {{Instruction Manual}}},
  author = {Bradley, Margaret M and Lang, Peter J and Margaret, M and Peter, J},
  year = {2007},
  institution = {University of Florida},
  file = {/Users/brownsarahm/Zotero/storage/DTIVUCLL/Bradley et al. - 2007 - The International Affective Digitized Sounds Affective Ratings of Sounds and Instruction Manual(2).pdf}
}

@article{bradley2007internationala,
  title = {The {{International Affective Digitized Sounds}} (2nd {{Edition}}; {{IADS-2}}): {{Affective Ratings}} of {{Sounds}} and {{Instruction Manual The International Affective Digitized Sounds}} (2nd {{Edition}} ({{IADS-2}}): {{Affective Ratings}} of {{Sounds}} and {{Instruction Manual}}},
  author = {Bradley, Margaret M and Lang, Peter J and Bertron, Andy and Zack, Jason and Gintoli, Salvatore and Axelrad, Jana and Cason, John and Brollia, Trevor and Hayden, Sarah and Thorne, Brittany and Karlsson, Marie and Bittiker, Alisson},
  year = {2007},
  file = {/Users/brownsarahm/Zotero/storage/56VNLTRB/Bradley et al. - 2007 - The International Affective Digitized Sounds Affective Ratings of Sounds and Instruction Manual(2).pdf}
}

@article{braga2013echoes,
  title = {Echoes of the Brain within Default Mode, Association, and Heteromodal Cortices.},
  author = {Braga, Rodrigo M and Sharp, David J and Leeson, Clare and Wise, Richard J S and Leech, Robert},
  year = {2013},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  volume = {33},
  number = {35},
  pages = {14031--9},
  issn = {1529-2401},
  abstract = {Intrinsic connectivity networks (ICNs), such as the default mode, frontoparietal control, and salience networks, provide a useful large-scale description of the functional architecture of the brain. Although ICNs are functionally specialized, the information that they process needs to be integrated for coherent cognition, perception, and behavior. A region capable of performing this integration might be expected to contain traces, or "echoes," of the neural signals from multiple ICNs. Here, using fMRI in humans, we show the existence of specific "transmodal" regions containing echoes of multiple ICNs. These regions include core nodes of the default mode network, as well as multimodal association regions of the temporoparietal and temporo-occipito-parietal junction, right middle frontal gyrus, and dorsal anterior cingulate cortex. In contrast, "unimodal" regions such as the primary sensory and motor cortices show a much more singular pattern of activity, containing traces of few or even single ICNs. The presence of ICN echoes might explain how transmodal regions are involved in multiple different cognitive states. Our results suggest that these transmodal regions have a particular local spatial organization containing topographic maps that relate to multiple ICNs. This makes transmodal regions uniquely placed to be able to mediate the cross talk between the brain's functional networks through local modulation of adjacent regions that communicate with different ICNs.},
  pmid = {23986239},
  keywords = {Adult,Brain Mapping,Cerebral Cortex,Cerebral Cortex: physiology,Cognition,Cognition: physiology,Female,Humans,Male,Middle Aged,Nerve Net,Nerve Net: physiology},
  file = {/Users/brownsarahm/Zotero/storage/7W9BZJBL/Braga et al. - 2013 - Echoes of the brain within default mode, association, and heteromodal cortices(3).pdf}
}

@article{braga2015effects,
  title = {The Effects of Construal Level on Heuristic Reasoning: {{The}} Case of Representativeness and Availability.},
  author = {Braga, Jo{\~a}o N and Ferreira, M{\'a}rio B and Sherman, Steven J},
  year = {2015},
  journal = {Decision},
  volume = {2},
  number = {3},
  pages = {216},
  publisher = {Educational Publishing Foundation}
}

@article{braga2018disentangling,
  title = {What's next? {{Disentangling}} Availability from Representativeness Using Binary Decision Tasks},
  author = {Braga, Jo{\~a}o N and Ferreira, M{\'a}rio B and Sherman, Steven J and Mata, Andr{\'e} and Jacinto, Sofia and Ferreira, Marina},
  year = {2018},
  journal = {Journal of Experimental Social Psychology},
  volume = {76},
  pages = {307--319},
  publisher = {Elsevier}
}

@article{branchjr2017Reflectionbased,
  title = {Reflection-Based Learning for Professional Ethical Formation},
  author = {Branch Jr, William T and George, Maura},
  year = {2017},
  journal = {AMA Journal of Ethics},
  volume = {19},
  number = {4},
  pages = {349--356},
  publisher = {American Medical Association}
}

@article{bressler2010largescale,
  title = {Large-Scale Brain Networks in Cognition: Emerging Methods and Principles},
  author = {Bressler, Steven L. and Menon, Vinod},
  year = {2010},
  journal = {Trends in Cognitive Sciences},
  volume = {14},
  number = {6},
  pages = {277--290},
  issn = {13646613},
  doi = {10.1016/j.tics.2010.04.004},
  abstract = {An understanding of how the human brain produces cognition ultimately depends on knowledge of large-scale brain organization. Although it has long been assumed that cognitive functions are attributable to the isolated operations of single brain areas, we demonstrate that the weight of evidence has now shifted in support of the view that cognition results from the dynamic interactions of distributed brain areas operating in large-scale networks. We review current research on structural and functional brain organization, and argue that the emerging science of large-scale brain networks provides a coherent framework for understanding of cognition. Critically, this framework allows a principled exploration of how cognitive functions emerge from, and are constrained by, core structural and functional networks of the brain. {\copyright} 2010 Elsevier Ltd. All rights reserved.},
  pmid = {20493761}
}

@inproceedings{brewer1994guidelines,
  title = {Guidelines for Use of the Perceptual Dimensions of Color for Mapping and Visualization},
  booktitle = {Color Hard Copy and Graphic Arts {{III}}},
  author = {Brewer, Cynthia A},
  year = {1994},
  volume = {2171},
  pages = {54--64},
  publisher = {{International Society for Optics and Photonics}}
}

@article{bringle2009partnerships,
  title = {Partnerships in Service Learning and Civic Engagement},
  author = {Bringle, Robert G and Clayton, Patti H and Price, Mary F},
  year = {2009},
  journal = {Partnerships: A Journal of Service Learning \& Civic Engagement},
  volume = {1},
  number = {1},
  pages = {1--20},
  abstract = {Developing campus-community partnerships is a core element of well-designed and effective civic engagement, including service learning and participatory action research. A structural model, SOFAR, is presented that differentiates campus into administrators, faculty, and students, and that differentiates community into organizational staff and residents (or clients, consumers, advocates). Partnerships are presented as being a subset of relationships between persons. The quality of these dyadic relationships is analyzed in terms of the degree to which the interactions possess closeness, equity, and integrity, and the degree to which the outcomes of those interactions are exploitive, transactional, or transformational. Implications are then offered for how this analysis can improve practice and research.}
}

@article{broadwater2004hybrid,
  title = {A Hybrid Algorithm for Subpixel Detection in Hyperspectral Imagery},
  author = {Broadwater, Joshua},
  year = {2004},
  journal = {Geoscience and Remote {\textbackslash}ldots},
  volume = {1},
  number = {1},
  pages = {1601--1604},
  keywords = {-hyperspectral,1 vector that represents,column represents the,e is an l,image,l,m is the number,m matrix where each,of endmembers within the,of the current pixel,spectral unmixing,subpixel detection,the spectral signature,where x is an},
  file = {/Users/brownsarahm/Zotero/storage/APS7RW8A/Broadwater - 2004 - A hybrid algorithm for subpixel detection in hyperspectral imagery(3).pdf}
}

@article{broderick2012madbayes,
  title = {{{MAD-Bayes}}: {{MAP-based Asymptotic Derivations}} from {{Bayes}}},
  author = {Broderick, Tamara and Kulis, Brian and Jordan, Michael I.},
  year = {2012},
  pages = {13},
  abstract = {The classical mixture of Gaussians model is related to K-means via small-variance asymptotics: as the covariances of the Gaussians tend to zero, the negative log-likelihood of the mixture of Gaussians model approaches the K-means objective, and the EM algorithm approaches the K-means algorithm. Kulis \& Jordan (2012) used this observation to obtain a novel K-means-like algorithm from a Gibbs sampler for the Dirichlet process (DP) mixture. We instead consider applying small-variance asymptotics directly to the posterior in Bayesian nonparametric models. This framework is independent of any specific Bayesian inference algorithm, and it has the major advantage that it generalizes immediately to a range of models beyond the DP mixture. To illustrate, we apply our framework to the feature learning setting, where the beta process and Indian buffet process provide an appropriate Bayesian nonparametric prior. We obtain a novel objective function that goes beyond clustering to learn (and penalize new) groupings for which we relax the mutual exclusivity and exhaustivity assumptions of clustering. We demonstrate several other algorithms, all of which are scalable and simple to implement. Empirical results demonstrate the benefits of the new framework.},
  file = {/Users/brownsarahm/Zotero/storage/7S2T9XJM/Broderick, Kulis, Jordan - 2012 - MAD-Bayes MAP-based Asymptotic Derivations from Bayes(3).pdf}
}

@article{broderick2013feature,
  title = {Feature {{Allocations}}, {{Probability Functions}}, and {{Paintboxes}}},
  author = {Broderick, Tamara and Pitman, Jim and Jordan, Michael I.},
  year = {2013},
  journal = {Bayesian Analysis},
  volume = {8},
  number = {4},
  pages = {801--836},
  issn = {1936-0975},
  doi = {10.1214/13-BA823},
  keywords = {beta process,efpf,feature,feature allocation,feature frequency model,indian buffet process,paintbox},
  file = {/Users/brownsarahm/Zotero/storage/49KWEHSW/Broderick, Pitman, Jordan - 2013 - Feature Allocations, Probability Functions, and Paintboxes(3).pdf}
}

@book{brogan1991modern,
  title = {Modern {{Control Theory}}},
  author = {Brogan, William L},
  year = {1991},
  edition = {third},
  publisher = {Prentice-Hall},
  isbn = {0-13-589763-7}
}

@inproceedings{brook2012effective,
  title = {Effective {{Community Partnerships}} for {{Women}} in {{STEM}}},
  author = {Brook, Stony and Miller, Carrie-ann and Major, Living Learning and Murrah, Judy and {Founda-}, Motorola},
  year = {2012},
  isbn = {978-0-87823-241-3}
}

@inproceedings{brown2011technical,
  title = {Technical {{Outreach Community Help}} : {{Initial Results}}},
  booktitle = {American {{Society}} for {{Engineering Education}}},
  author = {Brown, S.M. Sarah M and Thomas, L.D. Lauren D},
  year = {2011},
  abstract = {The National Society of Black Engineers Technical Outreach Community Help (NSBE TORCH) Program aims to provide exposure, stimulate enthusiasm and promote the value of science, technology, engineering and math in Black communities by providing introductory training with the ultimate goal of increasing participation in these fields at all levels. The program originated in 2002, and over the 2008-2009 and 2009-2010 leadership years the program was revised and refined to have clear objectives and subcomponents consisting of both informal and formal educational components. The program is organized at a national level and administered locally in a grassroots fashion. Sample program models and resources are provided to local student leadership for selective implementation with the support of national and regional student leaders. In this paper we examine the program model and the ability to measure impact through the grassroots student run organization of the program. We present preliminary data from pilot programs and evaluations from volunteers and local level leaders of both the program model and the impact of the program. Data collected from participants includes demographics data, efficacy and learning assessments, and evaluations of the programs? content. This data is collected through survey templates provided to local student leaders, tabulated locally, and returned to the National leadership. Through the pilot studies the data collection and research methods are verified for their effectiveness in this unique program model. This paper will present the program assessment for internal development as well as address research questions about engineering students involved in STEM mentoring activities. Finally we present recommendations for developing the program further and a plan for a comprehensive study of the impact of the program. In short term for the students benefitting and longer term of the mentors and volunteers involved. A research plan and toolkit that accommodates for this and allows for sample size increases toward significance are derived from the pilot results. {\copyright} 2011 American Society for Engineering Education.},
  copyright = {All rights reserved}
}

@article{brown2012conditional,
  title = {Conditional Likelihood Maximisation: {{A}} Unifying Framework for Information Theoretic Feature Selection},
  author = {Brown, Gavin and Luj, Mikel and Pocock, A and Zhao, {\relax MJ} and Luj{\'a}n, M and Luj, Mikel},
  year = {2012},
  journal = {The Journal of Machine Learning Research},
  volume = {13},
  pages = {27--66},
  keywords = {conditional likelihood,feature selection,mutual information},
  file = {/Users/brownsarahm/Zotero/storage/BAGIE9DG/Brown, Luj - 2012 - Conditional Likelihood Maximisation A Unifying Framework for Information Theoretic Feature Selection(2).pdf}
}

@inproceedings{brown2013variety,
  title = {Variety of {{Community Partnerships}} in {{Related Programs}}},
  booktitle = {American {{Society}} for {{Engineering Education0}}},
  author = {Brown, S.M. Sarah M and Hulett, Mario M.A.},
  year = {2013},
  address = {Atlanta, GA},
  abstract = {The National Society of Black Engineers' Technical OutReach Community Help (TORCH) program aims to promote the value of Science, Technology, Engineering and Math (STEM) education at all levels by increasing exposure, enthusiasm, skills, and participation within the Black community. This initiative is accomplished through unique formal and informal experiences led by Black college student-leaders within the student-run national organization at local, regional and national scales. The program components include formal classroom-style training, informal activities, grassroots outreach, direct technical service and, for organizational reasons, traditional community service activities as well. The program was developed and is managed centrally, but the majority of program implementation is facilitated by host organization's chapters, operating independently. The success of the program is driven by the student chapters and the community partnerships they create in the implementation of its activities. Through their creativity and leadership the partnerships created have ranged from technology to education. Furthermore, frequent leadership changes annually at all levels pose an additional threat to sustaining these essential relationships. We present preliminary analysis of the formation and maintenance of community partnerships for each of the program components and their impact on the efforts. We take as examples several programs that have been active over varying lengths of time and examine the interactions between the types of partnerships, attendance at various program components and student volunteer participation. {\copyright} American Society of Engeneering Education, 2013.},
  copyright = {All rights reserved}
}

@mastersthesis{brown2014machine,
  title = {Machine {{Learning Analysis}} of {{Peripheral Physiology}} for {{Emotion Detection}}},
  author = {Brown, Sarah M},
  year = {2014},
  copyright = {All rights reserved},
  school = {Northeastern University}
}

@book{brown2015confirmatory,
  title = {Confirmatory Factor Analysis for Applied Research},
  author = {Brown, Timothy A},
  year = {2015},
  publisher = {Guilford publications}
}

@inproceedings{brown2015sparse,
  title = {A {{Sparse Combined Regression-Classification Formulation}} for {{Learning}} a {{Physiological Alternative}} to {{Clinical Post-Traumatic Stress Disorder Scores}}},
  booktitle = {Association for the {{Advancement}} of {{Artificial Intelleigence}} 2015},
  author = {Brown, Sarah M and Webb, Andrea and Mangoubi, Rami S and Dy, Jennifer G},
  year = {2015},
  address = {Austin, TX},
  copyright = {All rights reserved},
  file = {/Users/brownsarahm/Zotero/storage/VZREMWUT/Brown et al. - 2015 - A Sparse Combined Regression-Classification Formulation for Learning a Physiological Alternative to Clinical Po(3).pdf}
}

@inproceedings{brown2020Language,
  title = {Language Models Are Few-Shot Learners},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and {Herbert-Voss}, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  editor = {Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M.F. and Lin, H.},
  year = {2020},
  volume = {33},
  pages = {1877--1901},
  publisher = {Curran Associates, Inc.}
}

@article{brown2023Ml4sts,
  title = {Ml4sts/Ml-Sim: V0.2},
  author = {Brown, Sarah and Biancamano, Justin and Fasina, Opeyemi},
  year = {2023},
  month = jul,
  publisher = {Zenodo},
  doi = {10.5281/zenodo.8179025}
}

@article{brownstability,
  title = {Stability as a {{Metric}} for {{Applied Machine Learning}}},
  author = {Brown, Sarah M},
  number = {section 2},
  pages = {1--7},
  file = {/Users/brownsarahm/Zotero/storage/5ZCUBG8L/Author, Address - Unknown - Stability as a Metric for Applied Machine Learning(9).pdf;/Users/brownsarahm/Zotero/storage/G4F26C2N/Author, Address - Unknown - Stability as a Metric for Applied Machine Learning(7).pdf;/Users/brownsarahm/Zotero/storage/I95LJYEX/Author, Address - Unknown - Stability as a Metric for Applied Machine Learning(8).pdf;/Users/brownsarahm/Zotero/storage/XJVN3YJD/Author, Address - Unknown - Stability as a Metric for Applied Machine Learning(10).pdf;/Users/brownsarahm/Zotero/storage/YBR8N6IC/Author, Address - Unknown - Stability as a Metric for Applied Machine Learning(6).pdf}
}

@article{buja2005supplementary,
  title = {Supplementary {{Material}} for ``{{Statistical Inference}} for {{Exploratory Data Analysis}} and {{Model Diagnostics}}''},
  author = {Buja, A and Cook, Dianne and Hofmann, Heike and Lawrence, M},
  year = {2005},
  journal = {Www-Stat.Wharton.Upenn.Edu},
  pages = {1--11},
  keywords = {cognitive perception,mining,permutation tests,rotation tests,simulation,statistical graphics,visual analytics,visual data}
}

@article{buja2009statistical,
  title = {Statistical Inference for Exploratory Data Analysis and Model Diagnostics},
  author = {Buja, Andreas and Cook, Dianne and Hofmann, Heike and Lawrence, Michael and Lee, Eun-Kyung and Swayne, Deborah F and Wickham, Hadley},
  year = {2009},
  journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {367},
  number = {1906},
  pages = {4361--4383}
}

@article{bullmore2009complex,
  title = {Complex Brain Networks: Graph Theoretical Analysis of Structural and Functional Systems},
  author = {Bullmore, Ed and Bullmore, Ed and Sporns, Olaf and Sporns, Olaf},
  year = {2009},
  journal = {Nat Rev Neurosci},
  volume = {10},
  number = {maRcH},
  pages = {186--198},
  issn = {1471-0048},
  doi = {10.1038/nrn2575},
  abstract = {Recent developments in the quantitative analysis of complex networks, based largely on graph theory, have been rapidly translated to studies of brain network organization. The brain's structural and functional systems have features of complex networks--such as small-world topology, highly connected hubs and modularity--both at the whole-brain scale of human neuroimaging and at a cellular scale in non-human animals. In this article, we review studies investigating complex brain networks in diverse experimental modalities (including structural and functional MRI, diffusion tensor imaging, magnetoencephalography and electroencephalography in humans) and provide an accessible introduction to the basic principles of graph theory. We also highlight some of the technical challenges and key questions to be addressed by future developments in this rapidly moving field.},
  pmid = {19190637},
  keywords = {brain-functionalities,brain-models,circuitry,computational-neuroscience,graph-theory,hypergraphs,hypernetworks,neuronal-structures},
  file = {/Users/brownsarahm/Zotero/storage/B42U2DCE/Bullmore et al. - 2009 - Complex brain networks graph theoretical analysis of structural and functional systems(3).pdf}
}

@inproceedings{buolamwini2018Gender,
  ids = {buolamwini2018gender},
  title = {Gender Shades: {{Intersectional}} Accuracy Disparities in Commercial Gender Classification},
  booktitle = {Conference on Fairness, Accountability and Transparency},
  author = {Buolamwini, Joy and Gebru, Timnit},
  year = {2018},
  pages = {77--91},
  organization = {PMLR}
}

@article{burrell2015how,
  title = {How the {{Machine}} '{{Thinks}}:' {{Understanding Opacity}} in {{Machine Learning Algorithms}}},
  author = {Burrell, Jenna},
  year = {2015},
  journal = {Ssrn},
  number = {June},
  pages = {1--12},
  doi = {10.2139/ssrn.2660674},
  abstract = {This article considers the issue of opacity as a problem for socially consequential mechanisms of classification and ranking, such as spam filters, credit card fraud detection, search engines, news trends, market segmentation and advertising, insurance or loan qualification, and credit scoring. These mechanisms of classification all frequently rely on computational algorithms, and in many cases on machine learning algorithms to do this work. In this article, I draw a distinction between three forms of opacity: (1) opacity as intentional corporate or state secrecy (2) opacity as technical illiteracy, and (3) an opacity that arises from the characteristics of machine learning algorithms and the scale required to apply them usefully. The analysis in this article gets inside the algorithms themselves. I cite existing literatures in computer science, known industry practices (as they are publicly presented), and do some testing and manipulation of code as a form of lightweight code audit. I argue that recognizing the distinct forms of opacity that may be coming into play in a given application is key to determining which of a variety of technical and non-technical solutions could help to prevent harm.},
  keywords = {classification,discrimination,inequality,machine learning,opacity,spam filtering}
}

@article{burrell2016How,
  title = {How the Machine 'thinks: {{Understanding}} Opacity in Machine Learning Algorithms},
  author = {Burrell, J.},
  year = {2016},
  journal = {Big Data \& Society},
  volume = {3},
  number = {1},
  pages = {1--12},
  issn = {2053-9517},
  doi = {10.1177/2053951715622512},
  keywords = {a problem,classification,discrimination,for socially consequential mechanisms,inequality,issue of opacity as,machine learning,of classification,opacity,spam filtering,this article considers the},
  file = {/Users/brownsarahm/Zotero/storage/VSJ2ESUW/Burrell - 2016 - How the machine 'thinks Understanding opacity in machine learning algorithms(3).pdf}
}

@article{busemeyer2015what,
  title = {What {{Is Quantum Cognition}}, and {{How Is It Applied}} to {{Psychology}}?},
  author = {Busemeyer, J. R. and Wang, Z.},
  year = {2015},
  journal = {Current Directions in Psychological Science},
  volume = {24},
  number = {3},
  pages = {163--169},
  issn = {0963-7214},
  doi = {10.1177/0963721414568663},
  keywords = {best empirically confirmed scientific,complementarity,context effects,interference effects,law of total probability,quantum cognition,quantum mechanics is arguably,superposition,the most important and,theory in human},
  file = {/Users/brownsarahm/Zotero/storage/DS67LEHY/Busemeyer, Wang - 2015 - What Is Quantum Cognition, and How Is It Applied to Psychology(3).pdf}
}

@article{button2013power,
  title = {Power Failure: Why Small Sample Size Undermines the Reliability of Neuroscience},
  author = {Button, Katherine S and Ioannidis, John PA and Mokrysz, Claire and Nosek, Brian A and Flint, Jonathan and Robinson, Emma SJ and Munaf{\`o}, Marcus R},
  year = {2013},
  journal = {Nature reviews neuroscience},
  volume = {14},
  number = {5},
  pages = {365--376},
  publisher = {Nature Publishing Group}
}

@article{cabrera2019fairvis,
  title = {{{FairVis}}: {{Visual}} Analytics for Discovering Intersectional Bias in Machine Learning},
  author = {Cabrera, {\'A}ngel Alexander and Epperson, Will and Hohman, Fred and Kahng, Minsuk and Morgenstern, Jamie and Chau, Duen Horng},
  year = {2019},
  journal = {arXiv preprint arXiv:1904.05419},
  eprint = {1904.05419},
  archiveprefix = {arXiv}
}

@article{cacioppo1997psychophysiology,
  title = {Psychophysiology of Emotion across the Life Span},
  author = {Cacioppo, {\relax JT} and Berntson, {\relax GG}},
  year = {1997},
  journal = {Annual review of {\textbackslash}ldots},
  file = {/Users/brownsarahm/Zotero/storage/WUI7PUZA/Cacioppo, Berntson - 1997 - Psychophysiology of emotion across the life span(3).pdf}
}

@article{cacioppo2000psychophysiology,
  title = {The Psychophysiology of Emotion},
  author = {Cacioppo, John T. and Berntson, Gary G. and Larsen, Jeff T. and Poehlmann, Kirsten M. and {Tiffany A. Ito}},
  year = {2000},
  journal = {Handbook of Emotions 2},
  pages = {173--191},
  file = {/Users/brownsarahm/Zotero/storage/6XTHW7CF/Cacioppo et al. - 2000 - The psychophysiology of emotion(3).pdf}
}

@article{cadez1999probabilistic,
  title = {Probabilistic Clustering Using Hierarchical Models},
  author = {Cadez, Igor and Smyth, Padhraic},
  year = {1999},
  number = {99},
  file = {/Users/brownsarahm/Zotero/storage/PZUKTABI/Cadez, Smyth - 1999 - Probabilistic clustering using hierarchical models(3).pdf}
}

@article{calders2010three,
  title = {Three Naive {{Bayes}} Approaches for Discrimination-Free Classification},
  author = {Calders, Toon and Verwer, Sicco},
  year = {2010},
  journal = {Data Mining and Knowledge Discovery},
  volume = {21},
  number = {2},
  pages = {277--292}
}

@article{calhoun2014chronnectome,
  title = {The {{Chronnectome}}: {{Time-Varying Connectivity Networks}} as the {{Next Frontier}} in {{fMRI Data Discovery}}},
  author = {Calhoun, Vince D. and Miller, Robyn and Pearlson, Godfrey and Adal{\i}, Tulay},
  year = {2014},
  journal = {Neuron},
  issn = {08966273},
  doi = {10.1016/j.neuron.2014.10.015},
  file = {/Users/brownsarahm/Zotero/storage/B5D566TR/Calhoun et al. - 2014 - The Chronnectome Time-Varying Connectivity Networks as the Next Frontier in fMRI Data Discovery(3).pdf}
}

@article{cameliasimoiusamcorbett-daviesandsharadgoelproblem,
  title = {{{THE PROBLEM OF INFRA-MARGINALITY IN OUTCOME TESTS FOR DISCRIMINATION}}},
  author = {{CAMELIA SIMOIU, SAM CORBETT-DAVIES AND SHARAD GOEL}}
}

@article{carbonell1992machine,
  title = {Machine {{Learning}}: {{A Maturing Field}}},
  author = {Carbonell, Jaime},
  year = {1992},
  journal = {Machine Learning},
  volume = {9},
  number = {1},
  pages = {5--7},
  issn = {15730565},
  doi = {10.1023/A:1022665512030},
  file = {/Users/brownsarahm/Zotero/storage/M6MQJJJ7/Carbonell - 1992 - Machine Learning A Maturing Field.pdf}
}

@misc{Carpentries,
  title = {The {{Carpentries Teaching Demo Report}}},
  journal = {Google Docs},
  urldate = {2021-12-14},
  abstract = {Thank you for hosting a Teaching Demo for new Instructor Trainees!  Please complete this form after hosting your Teaching Demo.},
  howpublished = {https://docs.google.com/forms/d/e/1FAIpQLSeNiTE1NmNWcavQNwrS76N7Cpmb75ZXnZwsq-Zeh-z3VyBxFw/viewform?pli=1\&usp=send\_form\&pli=1\&usp=embed\_facebook},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/SS8K9NTH/viewform.html}
}

@article{carreira-perpinan2008constrained,
  title = {Constrained Spectral Clustering through Affinity Propagation},
  author = {{\noopsort{carreira-perpinan}}a. {Carreira-Perpinan}, Miguel},
  year = {2008},
  month = jun,
  journal = {2008 IEEE Conference on Computer Vision and Pattern Recognition},
  number = {M},
  pages = {1--8},
  doi = {10.1109/CVPR.2008.4587451},
  file = {/Users/brownsarahm/Zotero/storage/9U9N9Q2A/Carreira-Perpinan - 2008 - Constrained spectral clustering through affinity propagation(3).pdf}
}

@incollection{carriveperiaqueductal,
  title = {Periaqueductal Gray},
  booktitle = {The {{Human Nervous System}}},
  author = {Carrive, Pascal and Morgan, Michael M},
  pages = {393--423}
}

@article{carson2000psychophysiologic,
  title = {Psychophysiologic Assessment of Posttraumatic Stress Disorder in {{Vietnam}} Nurse Veterans Who Witnessed Injury or Death.},
  author = {Carson, Margaret A and Paulus, Lynn A and Lasko, Natasha B and Metzger, Linda J and Wolfe, Jessica and Orr, Scott P and Pitman, Roger K},
  year = {2000},
  journal = {Journal of consulting and clinical psychology},
  volume = {68},
  number = {5},
  pages = {890}
}

@article{caruana1997multitask,
  title = {Multitask Learning},
  author = {Caruana, Rich},
  year = {1997},
  journal = {Machine learning},
  volume = {28},
  number = {1},
  pages = {41--75},
  publisher = {Springer}
}

@book{casella1990statistical,
  title = {Statistical Inference},
  author = {Casella, G and Berger, {\relax RL}},
  year = {1990},
  edition = {Second Edi},
  publisher = {Duxbury},
  address = {Pacific Grove, CA},
  isbn = {0-534-24312-6},
  file = {/Users/brownsarahm/Zotero/storage/LDDNJRVN/Casella, Berger - 1990 - Statistical inference(3).pdf}
}

@article{celledoni2021structure,
  ids = {celledoni2021Structurepreserving},
  title = {Structure-Preserving Deep Learning},
  author = {Celledoni, Elena and Ehrhardt, Matthias J and Etmann, Christian and McLachlan, Robert I and Owren, Brynjulf and Schonlieb, C-B and Sherry, Ferdia},
  year = {2021},
  journal = {European Journal of Applied Mathematics},
  volume = {32},
  number = {5},
  pages = {888--936},
  publisher = {Cambridge University Press}
}

@inproceedings{chakraborty2020fairway,
  title = {Fairway: A Way to Build Fair {{ML}} Software},
  booktitle = {Proceedings of the 28th {{ACM}} Joint Meeting on {{European}} Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  author = {Chakraborty, Joymallya and Majumder, Suvodeep and Yu, Zhe and Menzies, Tim},
  year = {2020},
  pages = {654--665}
}

@article{chamberlin1965method,
  title = {The {{Method}} of {{Multiple Working Hypotheses}}},
  author = {Chamberlin, T.C.},
  year = {1965},
  journal = {Science (New York, N.Y.)},
  volume = {148},
  number = {3671},
  pages = {754--759},
  issn = {0022-1376},
  doi = {10.1086/629752},
  abstract = {suggests using multiple working hypotheses (instead of a single one) to have meaningful alternatives; this should help prevent bad theories from becoming dogmatic and should provide more meaningful results that combine causes realistically; fun, old school language; some consider this something that still needs to be done/important, while others consider it rubbish;},
  pmid = {17782687},
  file = {/Users/brownsarahm/Zotero/storage/DCFGQDBA/Chamberlin - 1965 - The Method of Multiple Working Hypotheses(3).pdf}
}

@inproceedings{chan2023Harms,
  title = {Harms from {{Increasingly Agentic Algorithmic Systems}}},
  booktitle = {2023 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Chan, Alan and Salganik, Rebecca and Markelius, Alva and Pang, Chris and Rajkumar, Nitarshan and Krasheninnikov, Dmitrii and Langosco, Lauro and He, Zhonghao and Duan, Yawen and Carroll, Micah and Lin, Michelle and Mayhew, Alex and Collins, Katherine and Molamohammadi, Maryam and Burden, John and Zhao, Wanru and Rismani, Shalaleh and Voudouris, Konstantinos and Bhatt, Umang and Weller, Adrian and Krueger, David and Maharaj, Tegan},
  year = {2023},
  month = jun,
  pages = {651--666},
  publisher = {ACM},
  address = {Chicago IL USA},
  doi = {10.1145/3593013.3594033},
  urldate = {2024-09-28},
  abstract = {Research in Fairness, Accountability, Transparency, and Ethics (FATE)1 has established many sources and forms of algorithmic harm, in domains as diverse as health care, finance, policing, and {$\ast$}Major contributions to the project direction and framing.},
  isbn = {9798400701924},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/XBL2AL8I/Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic System.pdf}
}

@article{chandler2015world,
  title = {A {{World}} without {{Causation}}: {{Big Data}} and the {{Coming}} of {{Age}} of {{Posthumanism}}},
  author = {Chandler, David},
  year = {2015},
  journal = {Millennium},
  volume = {43},
  number = {3},
  pages = {833--851},
  doi = {10.1177/0305829815576817},
  abstract = {Advocates of Big Data assert that we are in the midst of an epistemological revolution, promising the displacement of the modernist methodological hegemony of causal analysis and theory generation. It is alleged that the growing `deluge' of digitally generated data, and the development of computational algorithms to analyse them, has enabled new inductive ways of accessing everyday relational interactions through their `datafication'. This article critically engages with these discourses of Big Data and complexity, particularly as they operate in the discipline of International Relations, where it is alleged that Big Data approaches have the potential for developing self-governing societal capacities for resilience and adaptation through the real-time reflexive awareness and management of risks and problems as they arise. The epistemological and ontological assumptions underpinning Big Data are then analysed to suggest that critical and posthumanist approaches have come of age through these discourses, enabling process-based and relational understandings to be translated into policy and governance practices. The article thus raises some questions for the development of critical approaches to new posthuman forms of governance and knowledge production.}
}

@article{chanes2016redefining,
  title = {Redefining the {{Role}} of {{Limbic Areas}} in {{Cortical Processing}}},
  author = {Chanes, Lorena and Barrett, Lisa Feldman},
  year = {2016},
  journal = {Trends in Cognitive Sciences},
  volume = {20},
  number = {2},
  pages = {96--106},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2015.11.005},
  keywords = {active inference,consciousness,cortical processing,intrinsic networks,limbic cortices,predictive coding,structural model},
  file = {/Users/brownsarahm/Zotero/storage/T52HFJDV/Chanes, Barrett - 2016 - Redefining the Role of Limbic Areas in Cortical Processing(3).pdf}
}

@article{chang2005orthogonal,
  title = {Orthogonal Subspace Projection ({{OSP}}) Revisited: A Comprehensive Study and Analysis},
  author = {Chang, {\relax CI}},
  year = {2005},
  journal = {IEEE Transactions on Geoscience and Remote Sensing,},
  volume = {43},
  number = {3},
  pages = {502--518},
  file = {/Users/brownsarahm/Zotero/storage/XDQHTS8S/Chang - 2005 - Orthogonal subspace projection (OSP) revisited a comprehensive study and analysis(3).pdf}
}

@inproceedings{chang2009reading,
  title = {Reading {{Tea Leaves}}: {{How Humans Interpret Topic Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 22},
  author = {Chang, Jonathan and Gerrish, Sean and Wang, Chong and Blei, David M},
  year = {2009},
  pages = {288---296},
  doi = {10.1.1.100.1089},
  abstract = {Probabilistic topic models are a popular tool for the unsupervised analysis of text, providing both a predictive model of future text and a latent topic representation of the corpus. Practitioners typically assume that the latent space is semantically meaningful. It is used to check models, summarize the corpus, and guide exploration of its contents. However, whether the latent space is interpretable is in need of quantitative evaluation. In this paper, we present new quantitative methods for measuring semantic meaning in inferred topics. We back these measures with large-scale user studies, showing that they capture aspects of the model that are undetected by previous measures of model quality based on held-out likelihood. Surprisingly, topic models which perform better on held-out likelihood may infer less semantically meaningful topics.},
  isbn = {978-1-61567-911-9},
  file = {/Users/brownsarahm/Zotero/storage/I8HF92K4/Chang et al. - 2009 - Reading Tea Leaves How Humans Interpret Topic Models(3).pdf}
}

@article{chang2017informative,
  title = {Informative {{Subspace Learning}} for {{Counterfactual Inference}}},
  author = {Chang, Yale and Dy, Jennifer G},
  year = {2017},
  journal = {Aaai},
  pages = {1770--1776},
  keywords = {Machine Learning Methods},
  file = {/Users/brownsarahm/Zotero/storage/VMLGVJ9Q/Chang, Dy - 2017 - Informative Subspace Learning for Counterfactual Inference.pdf}
}

@article{charig1986comparison,
  title = {Comparison of Treatment of Renal Calculi by Open Surgery, Percutaneous Nephrolithotomy, and Extracorporeal Shockwave Lithotripsy.},
  author = {Charig, Clive R and Webb, David R and Payne, Stephen Richard and Wickham, John E},
  year = {1986},
  journal = {Br Med J (Clin Res Ed)},
  volume = {292},
  number = {6524},
  pages = {879--882}
}

@article{chater2010bayesian,
  title = {Bayesian Models of Cognition},
  author = {Chater, Nick and Oaksford, Mike and Hahn, Ulrike and Heit, Evan},
  year = {2010},
  journal = {Wiley Interdisciplinary Reviews: Cognitive Science},
  volume = {1},
  number = {6},
  pages = {811--823},
  issn = {19395078},
  doi = {10.1002/wcs.79},
  abstract = {Griffiths, Thomas L., Charles Kemp, and Joshua B. Tenenbaum. "Bayesian models of cognition." Cambridge handbook of computational cognitive modeling (2008): 59-100.},
  pmid = {14907735},
  file = {/Users/brownsarahm/Zotero/storage/NEYE79HH/Chater et al. - 2010 - Bayesian models of cognition(2).pdf}
}

@article{chater2020probabilistic,
  title = {Probabilistic Biases Meet the {{Bayesian}} Brain},
  author = {Chater, Nick and Zhu, Jian-Qiao and Spicer, Jake and Sundh, Joakim and {Le{\'o}n-Villagr{\'a}}, Pablo and Sanborn, Adam},
  year = {2020},
  journal = {Current Directions in Psychological Science},
  volume = {29},
  number = {5},
  pages = {506--512},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA}
}

@article{chen2009regression,
  title = {A Regression Paradox for Linear Models: {{Sufficient}} Conditions and Relation to {{Simpson}}'s Paradox},
  author = {Chen, Aiyou and Bengtsson, Thomas and Ho, Tin Kam},
  year = {2009},
  journal = {The American Statistician},
  volume = {63},
  number = {3},
  pages = {218--225}
}

@inproceedings{chen2012joint,
  title = {Joint {{Optimization}} and {{Variable Selection}} of {{High-dimensional Gaussian Processes}}},
  booktitle = {Proc. {{International Conference}} on {{Machine Learning}} ({{ICML}})},
  author = {Chen, Bo and Castro, Rui and Krause, Andreas},
  year = {2012}
}

@inproceedings{chen2018why,
  title = {Why Is My Classifier Discriminatory?},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Chen, Irene and Johansson, Fredrik D and Sontag, David},
  year = {2018},
  volume = {31},
  pages = {3539--3550},
  publisher = {Curran Associates, Inc.},
  address = {Montr{\'e}al, Canada}
}

@article{chen2020neural,
  title = {Neural Approximate Sufficient Statistics for Implicit Models},
  author = {Chen, Yanzhi and Zhang, Dinghuai and Gutmann, Michael and Courville, Aaron and Zhu, Zhanxing},
  year = {2020},
  journal = {arXiv preprint arXiv:2010.10079},
  eprint = {2010.10079},
  archiveprefix = {arXiv}
}

@article{chen2020Neural,
  title = {Neural Approximate Sufficient Statistics for Implicit Models},
  author = {Chen, Yanzhi and Zhang, Dinghuai and Gutmann, Michael and Courville, Aaron and Zhu, Zhanxing},
  year = {2020},
  journal = {arXiv preprint arXiv:2010.10079},
  eprint = {2010.10079},
  archiveprefix = {arXiv}
}

@inproceedings{chenneural,
  title = {Neural Approximate Sufficient Statistics for Implicit Models},
  booktitle = {International Conference on Learning Representations},
  author = {Chen, Yanzhi and Zhang, Dinghuai and Gutmann, Michael U and Courville, Aaron and Zhu, Zhanxing}
}

@article{cheour1998development,
  title = {Development of Language-Specific Phoneme Representations in the Infant Brain.},
  author = {Cheour, Marie and Ceponiene, Rita and Lehtokoski, Anne and Luuk, Aavo and Allik, J{\"u}ri and Alho, Kimmo and N{\"a}{\"a}t{\"a}nen, Risto},
  year = {1998},
  journal = {Nature neuroscience},
  volume = {1},
  number = {5},
  pages = {351--353},
  issn = {1097-6256},
  doi = {10.1038/1561},
  abstract = {Studies using behavioral methods, such as head-turning experiments, in which children are conditioned to turn their heads toward the sound source when they detect a change in the sound, have shown that environment has an important effect on how infants perceive language1, 2, 3, 4. Young infants are able to discriminate almost all phonetic contrasts, whereas older infants discriminate better between phonemes that occur in the language that they normally hear, rather than foreign-language phonemes. Here we demonstrate the development of language-specific 'memory traces' in the brains of the same group of infants between six months and one year of age},
  pmid = {10196522},
  file = {/Users/brownsarahm/Zotero/storage/B4TZA9T8/Cheour et al. - 1998 - Development of language-specific phoneme representations in the infant brain(3).pdf}
}

@article{chiappa2004hmm,
  title = {{{HMM}} and {{IOHMM Modeling}} of {{EEG Rhythms}} for {{Asynchronous BCI Systems}}},
  author = {Chiappa, Silvia and Bengio, Samy},
  year = {2004},
  journal = {Neural Networks},
  number = {April},
  pages = {199--204},
  abstract = {We compare the use of two Markovian models, HMMs and IOHMMs, to discriminate between three mental tasks for Brain Computer Interface systems using an asynchronous protocol. We show that IOHMMs outperform HMMs but that, probably due to the lack of any a priori information on the state dynamics, no practical advantage in the use of these models over their static counterparts is obtained.},
  keywords = {Brain Computer Interfaces,Learning/Statistics \& Optimisation},
  file = {/Users/brownsarahm/Zotero/storage/DBJJRS4K/Chiappa, Bengio - 2004 - HMM and IOHMM Modeling of EEG Rhythms for Asynchronous BCI Systems(3).pdf}
}

@article{chiel2009brain,
  title = {The Brain in Its Body: Motor Control and Sensing in a Biomechanical Context},
  author = {Chiel, Hillel J and Ting, Lena H and Ekeberg, Orjan and Hartmann, Mitra J Z},
  year = {2009},
  journal = {The Journal of Neuroscience},
  volume = {29},
  number = {41},
  pages = {12807--12814}
}

@inproceedings{chiu2003probabilistic,
  title = {Probabilistic Discovery of Time Series Motifs},
  booktitle = {Proceedings of the Ninth {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining},
  author = {Chiu, Bill and Keogh, Eamonn and Lonardi, Stefano},
  year = {2003},
  pages = {493--498},
  publisher = {ACM Press},
  address = {New York, New York, USA},
  doi = {10.1145/956804.956808},
  isbn = {1-58113-737-0},
  keywords = {application domains mentioned above,data mining,discovery can be very,in addition to the,motif,motifs,randomized algorithms,right as an exploratory,time series,useful in its own},
  file = {/Users/brownsarahm/Zotero/storage/8MV2E9JJ/Chiu, Keogh, Lonardi - 2003 - Probabilistic discovery of time series motifs(3).pdf}
}

@article{chomsky1980rules,
  title = {Rules and Representations},
  author = {Chomsky, N},
  year = {1980},
  journal = {Behavioral and Brain Sciences},
  volume = {3},
  number = {1},
  pages = {1--15}
}

@article{chou2014democratizing,
  title = {Democratizing {{Data Science}}: {{Effecting}} Positive Social Change with Data Science},
  author = {Chou, Sophie and Li, Willliam and Sridharan, Ramesh},
  year = {2014},
  pages = {4},
  keywords = {data science,democratization,society},
  file = {/Users/brownsarahm/Zotero/storage/X6S5E2A2/Chou, Li, Sridharan - 2014 - Democratizing Data Science Effecting positive social change with data science(3).pdf}
}

@article{chouldechova2017fair,
  title = {Fair Prediction with Disparate Impact: {{A}} Study of Bias in Recidivism Prediction Instruments},
  author = {Chouldechova, Alexandra},
  year = {2017},
  journal = {Big data},
  volume = {5},
  number = {2},
  pages = {153--163},
  publisher = {Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA}
}

@article{christie2002multivariate,
  title = {Multivariate Discrimination of Emotion-Specific Autonomic Nervous System Activity},
  author = {Christie, {\relax IC}},
  year = {2002},
  keywords = {autonomic nervous system activity,autonomic specificity,christie,copyright 2002,emotion,israel c,multivariate discrimination of emotion-specific,multivariate pattern classification},
  file = {/Users/brownsarahm/Zotero/storage/6IGTE2DQ/Christie - 2002 - Multivariate discrimination of emotion-specific autonomic nervous system activity(4).pdf}
}

@article{christin2020Ethnographer,
  title = {The Ethnographer and the Algorithm: Beyond the Black Box},
  shorttitle = {The Ethnographer and the Algorithm},
  author = {Christin, Ang{\`e}le},
  year = {2020},
  month = oct,
  journal = {Theory and Society},
  volume = {49},
  number = {5-6},
  pages = {897--918},
  issn = {0304-2421, 1573-7853},
  doi = {10.1007/s11186-020-09411-3},
  urldate = {2024-09-28},
  abstract = {A common theme in social science studies of algorithms is that they are profoundly opaque and function as ``black boxes.'' Scholars have developed several methodological approaches in order to address algorithmic opacity. Here I argue that we can explicitly enroll algorithms in ethnographic research, which can shed light on unexpected aspects of algorithmic systems---including their opacity. I delineate three mesolevel strategies for algorithmic ethnography. The first, algorithmic refraction, examines the reconfigurations that take place when computational software, people, and institutions interact. The second strategy, algorithmic comparison, relies on a similarity-anddifference approach to identify the instruments' unique features. The third strategy, algorithmic triangulation, enrolls algorithms to help gather rich qualitative data. I conclude by discussing the implications of this toolkit for the study of algorithms and future of ethnographic fieldwork.},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/5RHYAXZ8/Christin - 2020 - The ethnographer and the algorithm beyond the bla.pdf}
}

@article{cisek2010neural,
  title = {Neural Mechanisms for Interacting with a World Full of Action Choices},
  author = {Cisek, Paul and Kalaska, John F},
  year = {2010},
  journal = {Annual review of neuroscience},
  volume = {33},
  pages = {269--298}
}

@article{ciuciu2014interplay,
  title = {Interplay between Functional Connectivity and Scale-Free Dynamics in Intrinsic {{fMRI}} Networks},
  author = {Ciuciu, Philippe and Abry, Patrice and He, Biyu J.},
  year = {2014},
  journal = {NeuroImage},
  volume = {95},
  pages = {248--263},
  issn = {10959572},
  doi = {10.1016/j.neuroimage.2014.03.047},
  abstract = {Studies employing functional connectivity-type analyses have established that spontaneous fluctuations in functional magnetic resonance imaging (fMRI) signals are organized within large-scale brain networks. Meanwhile, fMRI signals have been shown to exhibit 1/f-type power spectra - a hallmark of scale-free dynamics. We studied the interplay between functional connectivity and scale-free dynamics in fMRI signals, utilizing the fractal connectivity framework - a multivariate extension of the univariate fractional Gaussian noise model, which relies on a wavelet formulation for robust parameter estimation. We applied this framework to fMRI data acquired from healthy young adults at rest and while performing a visual detection task. First, we found that scale-invariance existed beyond univariate dynamics, being present also in bivariate cross-temporal dynamics. Second, we observed that frequencies within the scale-free range do not contribute evenly to inter-regional connectivity, with a systematically stronger contribution of the lowest frequencies, both at rest and during task. Third, in addition to a decrease of the Hurst exponent and inter-regional correlations, task performance modified cross-temporal dynamics, inducing a larger contribution of the highest frequencies within the scale-free range to global correlation. Lastly, we found that across individuals, a weaker task modulation of the frequency contribution to inter-regional connectivity was associated with better task performance manifesting as shorter and less variable reaction times. These findings bring together two related fields that have hitherto been studied separately - resting-state networks and scale-free dynamics, and show that scale-free dynamics of human brain activity manifest in cross-regional interactions as well. ?? 2014 Elsevier Inc.},
  pmid = {24675649},
  keywords = {Cross-temporal dynamics,fMRI,FMRI,Intrinsic brain activity,Scale-free dynamics,Task modulation},
  file = {/Users/brownsarahm/Zotero/storage/B9FYYTIW/Ciuciu, Abry, He - 2014 - NeuroImage Interplay between functional connectivity and scale-free dynamics in intrinsic fMRI networks(2).pdf}
}

@article{clark-polner2016multivoxel,
  title = {Multivoxel {{Pattern Analysis Does Not Provide Evidence}} to {{Support}} the {{Existence}} of {{Basic Emotions}}},
  author = {{Clark-Polner}, Elizabeth and Johnson, Timothy D. and Barrett, Lisa Feldman},
  year = {2016},
  journal = {Cerebral Cortex},
  number = {2015},
  pages = {bhw028},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhw028},
  abstract = {Saarimaki et al. (2015) published a paper claiming to find the neural "fingerprints" for anger, fear, disgust, happiness, sadness, and surprise using multivariate pattern analysis. There are 2 ways in which Saarimaki et al.'s interpretation mischaracterizes their actual findings. The first is statistical: a pattern that successfully distinguishes the members of one category from the members of another (with an accuracy greater than that which might be expected by chance) is not a "fingerprint" (i.e., an essence); it is an abstract, statistical summary of a variable population of instances. The second way in which Saarimaki et al.'s interpretation mischaracterizes their results is conceptual: their findings do not actually meet the specific criteria for basic emotion theory. Instead, their findings are more consistent with a theory of constructed emotion. In our view, Saarimaki et al. is elegant in method and important in that it demonstrates empirical support for a theory of emotion that relies on population thinking; it is also an example of how essentialism-the belief that all instances of a category possesses necessary features that define what is, and what is not, a category member-contributes to a fundamental misunderstanding of the neural basis of emotion.},
  pmid = {26931530},
  keywords = {basic emotion theory,conceptual act theory,construction,emotion,essentialism,multivoxel pattern analysis,pattern classi fi cation},
  file = {/Users/brownsarahm/Zotero/storage/QXDACBCV/Clark-Polner, Johnson, Barrett - 2016 - Multivoxel Pattern Analysis Does Not Provide Evidence to Support the Existence of Basic Emotions.pdf;/Users/brownsarahm/Zotero/storage/R7C9W8R6/Clark-Polner, Johnson, Barrett - 2016 - Multivoxel Pattern Analysis Does Not Provide Evidence to Support the Existence of Basic Emotions.pdf}
}

@article{clark2013whatever,
  title = {Whatever next? {{Predictive}} Brains, Situated Agents, and the Future of Cognitive Science},
  author = {Clark, Andy},
  year = {2013},
  journal = {Behavioral and Brain Sciences},
  volume = {36},
  number = {3},
  pages = {181--204}
}

@article{clithero2014informatic,
  title = {Informatic Parcellation of the Network Involved in the Computation of Subjective Value},
  author = {Clithero, John A and Rangel, Antonio},
  year = {2014},
  journal = {Social cognitive and affective neuroscience},
  volume = {9},
  number = {9},
  pages = {1289--1302}
}

@book{clyde2001experimental,
  title = {Experimental {{Design}} : {{A Bayesian Perspective}}},
  author = {Clyde, Merlise A},
  year = {2001},
  number = {April},
  abstract = {This entry provides an overview of experimental design using a Bayesian decision-theoretic framework. Scientific experimentation requires decisions about how an experiment will be conducted and analyzed. Such decisions depend on the goals and purpose of the experiment, but certain choices may be re- stricted by available resources and ethical considerations. Prior information may be available from earlier experiments or from conjectures which moti- vate the investigation. The Bayesian approach provides a coherent framework where prior information and uncertainties regarding unknown quantities can be combined to find an experimental design that optimizes the goals of the experiment.},
  file = {/Users/brownsarahm/Zotero/storage/FU3RD335/Clyde - 2001 - Experimental Design A Bayesian Perspective(3).pdf}
}

@article{coker2021Theory,
  title = {A {{Theory}} of {{Statistical Inference}} for {{Ensuring}} the {{Robustness}} of {{Scientific Results}}},
  author = {Coker, Beau and Rudin, Cynthia and King, Gary},
  year = {2021},
  month = oct,
  journal = {Management Science},
  volume = {67},
  number = {10},
  eprint = {1804.08646},
  primaryclass = {cs, stat},
  pages = {6174--6197},
  issn = {0025-1909, 1526-5501},
  doi = {10.1287/mnsc.2020.3818},
  urldate = {2023-04-28},
  abstract = {Inference is the process of using facts we know to learn about facts we do not know. A theory of inference gives assumptions necessary to get from the former to the latter, along with a definition for and summary of the resulting uncertainty. Any one theory of inference is neither right nor wrong, but merely an axiom that may or may not be useful. Each of the many diverse theories of inference can be valuable for certain applications. However, no existing theory of inference addresses the tendency to choose, from the range of plausible data analysis specifications consistent with prior evidence, those that inadvertently favor one's own hypotheses. Since the biases from these choices are a growing concern across scientific fields, and in a sense the reason the scientific community was invented in the first place, we introduce a new theory of inference designed to address this critical problem. We introduce hacking intervals, which are the range of a summary statistic one may obtain given a class of possible endogenous manipulations of the data. Hacking intervals require no appeal to hypothetical data sets drawn from imaginary superpopulations. A scientific result with a small hacking interval is more robust to researcher manipulation than one with a larger interval, and is often easier to interpret than a classical confidence interval. Some versions of hacking intervals turn out to be equivalent to classical confidence intervals, which means they may also provide a more intuitive and potentially more useful interpretation of classical confidence intervals.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/brownsarahm/Zotero/storage/QGRAM8PR/Coker et al. - 2021 - A Theory of Statistical Inference for Ensuring the.pdf}
}

@article{collaboration2012open,
  title = {An Open, Large-Scale, Collaborative Effort to Estimate the Reproducibility of Psychological Science},
  author = {Collaboration, Open Science and {Others}},
  year = {2012},
  journal = {Perspectives on Psychological Science},
  volume = {7},
  number = {6},
  pages = {657--660}
}

@article{collaboration2015estimating,
  title = {Estimating the Reproducibility of Psychological Science},
  author = {Collaboration, Open Science and {Others}},
  year = {2015},
  journal = {Science},
  volume = {349},
  number = {6251},
  pages = {aac4716}
}

@article{cooper1981diagnostic,
  title = {Diagnostic and Statistical Manual of Mental Disorders},
  author = {COOPER, ARNOLD M and Michels, Robert},
  year = {1981},
  journal = {American Journal of Psychiatry},
  volume = {138},
  number = {1},
  pages = {128--129}
}

@inproceedings{cooper2022Accountability,
  title = {Accountability in an {{Algorithmic Society}}: {{Relationality}}, {{Responsibility}}, and {{Robustness}} in {{Machine Learning}}},
  shorttitle = {Accountability in an {{Algorithmic Society}}},
  booktitle = {2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Cooper, A. Feder and Moss, Emanuel and Laufer, Benjamin and Nissenbaum, Helen},
  year = {2022},
  month = jun,
  pages = {864--876},
  publisher = {ACM},
  address = {Seoul Republic of Korea},
  doi = {10.1145/3531146.3533150},
  urldate = {2024-09-28},
  abstract = {In 1996, Accountability in a Computerized Society [95] issued a clarion call concerning the erosion of accountability in society due to the ubiquitous delegation of consequential functions to computerized systems. Nissenbaum [95] described four barriers to accountability that computerization presented, which we revisit in relation to the ascendance of data-driven algorithmic systems---i.e., machine learning or artificial intelligence---to uncover new challenges for accountability that these systems present. Nissenbaum's original paper grounded discussion of the barriers in moral philosophy; we bring this analysis together with recent scholarship on relational accountability frameworks and discuss how the barriers present difficulties for instantiating a unified moral, relational framework in practice for data-driven algorithmic systems. We conclude by discussing ways of weakening the barriers in order to do so.},
  isbn = {978-1-4503-9352-2},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/AJVNY67K/Cooper et al. - 2022 - Accountability in an Algorithmic Society Relation.pdf}
}

@article{cootes2001active,
  title = {Active {{Appearance Models}}},
  author = {Cootes, T F and Edwards, G J and Taylor, C J},
  year = {2001},
  journal = {IEEE Trans. Pattern Analysis and Machine Intelligence},
  volume = {23},
  pages = {681--685}
}

@article{copeland2007spatiotemporal,
  title = {Spatio-{{Temporal Data Fusion}} in {{Cerebral Angiography}} By},
  author = {Copeland, Andrew David},
  year = {2007},
  file = {/Users/brownsarahm/Zotero/storage/YE9G35KI/Copeland - 2007 - Spatio-Temporal Data Fusion in Cerebral Angiography by(3).pdf}
}

@article{corbett-davies2017Algorithmic,
  title = {Algorithmic Decision Making and the Cost of Fairness},
  author = {{Corbett-Davies}, Sam and Pierson, Emma and Feller, Avi and Goel, Sharad and Huq, Aziz},
  year = {2017},
  pages = {797--806},
  issn = {15232867},
  doi = {10.1145/3097983.309809},
  abstract = {Algorithms are now regularly used to decide whether defendants awaiting trial are too dangerous to be released back into the community. In some cases, black defendants are substantially more likely than white defendants to be incorrectly classified as high risk. To mitigate such disparities, several techniques recently have been proposed to achieve algorithmic fairness. Here we reformulate algorithmic fairness as constrained optimization: the objective is to maximize public safety while satisfying formal fairness constraints designed to reduce racial disparities. We show that for several past definitions of fairness, the optimal algorithms that result require detaining defendants above race-specific risk thresholds. We further show that the optimal unconstrained algorithm requires applying a single, uniform threshold to all defendants. The unconstrained algorithm thus maximizes public safety while also satisfying one important understanding of equality: that all individuals are held to the same standard, irrespective of race. Because the optimal constrained and unconstrained algorithms generally differ, there is tension between improving public safety and satisfying prevailing notions of algorithmic fairness. By examining data from Broward County, Florida, we show that this trade-off can be large in practice. We focus on algorithms for pretrial release decisions, but the principles we discuss apply to other domains, and also to human decision makers carrying out structured decision rules.},
  file = {/Users/brownsarahm/Zotero/storage/K3P9VRMQ/Corbett-Davies et al. - 2017 - Algorithmic decision making and the cost of fairness.pdf}
}

@inproceedings{corbett2017algorithmic,
  title = {Algorithmic Decision Making and the Cost of Fairness},
  booktitle = {Proceedings of the 23rd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining},
  author = {{Corbett-Davies}, Sam and Pierson, Emma and Feller, Avi and Goel, Sharad and Huq, Aziz},
  year = {2017},
  pages = {797--806}
}

@inproceedings{corbett2017algorithmic,
  title = {Algorithmic Decision Making and the Cost of Fairness},
  booktitle = {Proceedings of the 23rd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining},
  author = {{Corbett-Davies}, Sam and Pierson, Emma and Feller, Avi and Goel, Sharad and Huq, Aziz},
  year = {2017},
  pages = {797--806}
}

@inproceedings{corbett2017algorithmic,
  title = {Algorithmic Decision Making and the Cost of Fairness},
  booktitle = {Proceedings of the 23rd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining},
  author = {{Corbett-Davies}, Sam and Pierson, Emma and Feller, Avi and Goel, Sharad and Huq, Aziz},
  year = {2017},
  pages = {797--806}
}

@article{corbetta2002control,
  title = {Control of Goal-Directed and Stimulus-Driven Attention in the Brain},
  author = {Corbetta, Maurizio and Shulman, Gordon L},
  year = {2002},
  journal = {Nature reviews neuroscience},
  volume = {3},
  number = {3},
  pages = {201--215}
}

@article{corbetta2008reorienting,
  title = {The Reorienting System of the Human Brain: From Environment to Theory of Mind},
  author = {Corbetta, Maurizio and Patel, Gaurav and Schulman, Gordon L},
  year = {2008},
  journal = {Neuron},
  volume = {58},
  number = {3},
  pages = {306--324}
}

@article{corduas2010data,
  title = {Data {{Analysis}} and {{Classification}}},
  author = {Corduas, Marcella},
  editor = {Palumbo, Francesco and Lauro, Carlo Natale and Greenacre, Michael J.},
  year = {2010},
  series = {Studies in {{Classification}}, {{Data Analysis}}, and {{Knowledge Organization}}},
  number = {I},
  pages = {355--362},
  doi = {10.1007/978-3-642-03739-9},
  file = {/Users/brownsarahm/Zotero/storage/MY42PVQD/Corduas - 2010 - Data Analysis and Classification(2).pdf}
}

@incollection{corduas2010mining,
  title = {Mining {{Time Series Data}}: {{A Selective Survey}}},
  booktitle = {Mining {{Time Series Data}}: {{A Selective Survey}}},
  author = {Corduas, Marcella},
  editor = {Palumbo, Francesco and Lauro, Carlo Natale and Greenacre, Michael J.},
  year = {2010},
  series = {Studies in {{Classification}}, {{Data Analysis}}, and {{Knowledge Organization}}},
  number = {I},
  pages = {355--362},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-03739-9},
  isbn = {978-3-642-03738-2},
  file = {/Users/brownsarahm/Zotero/storage/GPZ2TJK5/Corduas - 2010 - Data Analysis and Classification(2).pdf}
}

@article{cornish2023Participatory,
  title = {Participatory Action Research},
  author = {Cornish, Flora and Breton, Nancy and {Moreno-Tabarez}, Ulises and Delgado, Jenna and Rua, Mohi and {\noopsort{aikins}}{de-Graft Aikins}, Ama and Hodgetts, Darrin},
  year = {2023},
  month = apr,
  journal = {Nature Reviews Methods Primers},
  volume = {3},
  number = {1},
  pages = {1--14},
  publisher = {Nature Publishing Group},
  issn = {2662-8449},
  doi = {10.1038/s43586-023-00214-1},
  urldate = {2024-04-19},
  abstract = {Participatory action research (PAR) is an approach to research that prioritizes the value of experiential knowledge for tackling problems caused by unequal and harmful social systems, and for envisioning and implementing alternatives. PAR involves the participation and leadership of those people experiencing issues, who take action to produce emancipatory social change, through conducting systematic research to generate new knowledge. This Primer sets out key considerations for the design of a PAR project. The core of the Primer introduces six building blocks for PAR project design: building relationships; establishing working practices; establishing a common understanding of the issue; observing, gathering and generating materials; collaborative analysis; and planning and taking action. We discuss key challenges faced by PAR projects, namely, mismatches with institutional research infrastructure; risks of co-option; power inequalities; and the decentralizing of control. To counter such challenges, PAR researchers may build PAR-friendly networks of people and infrastructures; cultivate a critical community to hold them to account; use critical reflexivity; redistribute powers; and learn to trust the process. PAR's societal contribution and methodological development, we argue, can best be advanced by engaging with contemporary social movements that demand the redressingl of inequities and the recognition of situated expertise.},
  copyright = {2023 Springer Nature Limited},
  langid = {english},
  keywords = {Communication,Developing world,Ethics,Psychology,Sociology},
  file = {/Users/brownsarahm/Zotero/storage/82NSME84/Cornish et al. - 2023 - Participatory action research.pdf}
}

@article{cortes1995supportvector,
  title = {Support-Vector Networks},
  author = {Cortes, C and Vapnik, V and Saitta, Lorenza},
  year = {1995},
  journal = {Machine learning},
  volume = {297},
  pages = {273--297},
  keywords = {efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers},
  file = {/Users/brownsarahm/Zotero/storage/88HW7843/Cortes, Vapnik - 1995 - Support-vector networks(2).pdf}
}

@incollection{cosmides2000evolutionary,
  title = {Evolutionary {{Psychology}} and the {{Emotions}}},
  author = {Cosmides, Leda and Tooby, John},
  editor = {Lewis, M and {Haviland-Jones}, J M},
  year = {2000},
  publisher = {Guilford},
  isbn = {0-7100-6964-2}
}

@article{council2024Stanford,
  title = {Stanford 'lying and Technology' Expert Admits to Shoddy Use of {{ChatGPT}} in Legal Filing},
  author = {Council, Stephen},
  year = {2024},
  month = dec,
  journal = {SFGATE},
  address = {San Fransisco, CA},
  urldate = {2024-12-20}
}

@article{coutanche2013informational,
  title = {Informational Connectivity: Identifying Synchronized Discriminability of Multi-Voxel Patterns across the Brain.},
  author = {Coutanche, Marc N and {Thompson-Schill}, Sharon L},
  year = {2013},
  journal = {Frontiers in human neuroscience},
  volume = {7},
  number = {February},
  pages = {15},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2013.00015},
  abstract = {The fluctuations in a brain region's activation levels over a functional magnetic resonance imaging (fMRI) time-course are used in functional connectivity (FC) to identify networks with synchronous responses. It is increasingly recognized that multi-voxel activity patterns contain information that cannot be extracted from univariate activation levels. Here we present a novel analysis method that quantifies regions' synchrony in multi-voxel activity pattern discriminability, rather than univariate activation, across a timeseries. We introduce a measure of multi-voxel pattern discriminability at each time-point, which is then used to identify regions that share synchronous time-courses of condition-specific multi-voxel information. This method has the sensitivity and access to distributed information that multi-voxel pattern analysis enjoys, allowing it to be applied to data from conditions not separable by univariate responses. We demonstrate this by analyzing data collected while people viewed four different types of man-made objects (typically not separable by univariate analyses) using both FC and informational connectivity (IC) methods. IC reveals networks of object-processing regions that are not detectable using FC. The IC results support prior findings and hypotheses about object processing. This new method allows investigators to ask questions that are not addressable through typical FC, just as multi-voxel pattern analysis (MVPA) has added new research avenues to those addressable with the general linear model (GLM).},
  pmid = {23403700},
  keywords = {connec,connectivity,fmri,fMRI,method,multivariate,mvpa,MVPA,networks,pattern discriminability},
  file = {/Users/brownsarahm/Zotero/storage/3YXWDIKD/Coutanche, Thompson-Schill - 2013 - Informational connectivity identifying synchronized discriminability of multi-voxel patterns acro(3).pdf}
}

@article{cratsley2024inventor,
  title = {``{{Inventor}}'s Bias'' at Work: {{When}} Low-Performing Algorithms Seem Fair},
  author = {Cratsley, Maya J and Fast, Nathanael J},
  year = {2024},
  journal = {International Journal of Human--Computer Interaction},
  volume = {40},
  number = {1},
  pages = {24--32},
  publisher = {Taylor \& Francis}
}

@inproceedings{crawford2017trouble,
  title = {The Trouble with Bias},
  booktitle = {Conference on {{Neural Information Processing Systems}}, Invited Speaker},
  author = {Crawford, Kate},
  year = {2017}
}

@book{crenshaw2017intersectionality,
  title = {On Intersectionality: {{Essential}} Writings},
  author = {Crenshaw, Kimberl{\'e} W},
  year = {2017},
  publisher = {The New Press}
}

@article{cronbach1955construct,
  title = {Construct Validity in Psychological Tests.},
  author = {CRONBACH, L J and MEEHL, P E},
  year = {1955},
  journal = {Psychological bulletin},
  issn = {0033-2909},
  doi = {10.1037/h0040957},
  pmid = {13245896},
  keywords = {SCALE},
  file = {/Users/brownsarahm/Zotero/storage/J888ZCVT/CRONBACH, MEEHL - 1955 - Construct validity in psychological tests(3).pdf}
}

@article{cukur2013attention,
  title = {Attention during Natural Vision Warps Semantic Representation across the Human Brain.},
  author = {{\c C}ukur, Tolga and Nishimoto, Shinji and Huth, Alexander G and Gallant, Jack L},
  year = {2013},
  journal = {Nature neuroscience},
  volume = {16},
  number = {6},
  pages = {763--70},
  issn = {1546-1726},
  doi = {10.1038/nn.3381},
  abstract = {Little is known about how attention changes the cortical representation of sensory information in humans. On the basis of neurophysiological evidence, we hypothesized that attention causes tuning changes to expand the representation of attended stimuli at the cost of unattended stimuli. To investigate this issue, we used functional magnetic resonance imaging to measure how semantic representation changed during visual search for different object categories in natural movies. We found that many voxels across occipito-temporal and fronto-parietal cortex shifted their tuning toward the attended category. These tuning shifts expanded the representation of the attended category and of semantically related, but unattended, categories, and compressed the representation of categories that were semantically dissimilar to the target. Attentional warping of semantic representation occurred even when the attended category was not present in the movie; thus, the effect was not a target-detection artifact. These results suggest that attention dynamically alters visual representation to optimize processing of behaviorally relevant objects during natural vision.},
  pmid = {23603707},
  keywords = {Adult,Attention,Attention: physiology,Brain Mapping,Brain Mapping: instrumentation,Brain Mapping: methods,Cerebral Cortex,Cerebral Cortex: physiology,Concept Formation,Concept Formation: physiology,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: instrumentation,Magnetic Resonance Imaging: methods,Male,Motion Pictures as Topic,Neuropsychological Tests,Semantics,Visual Perception,Visual Perception: physiology}
}

@article{cumming2014new,
  title = {The New Statistics: {{Why}} and How},
  author = {Cumming, Geoff},
  year = {2014},
  journal = {Psychological science},
  volume = {25},
  number = {1},
  pages = {7--29},
  publisher = {Sage Publications Sage CA: Los Angeles, CA}
}

@article{curcin2010design,
  title = {The Design and Implementation of a Workflow Analysis Tool.},
  author = {Curcin, Vasa and Ghanem, Moustafa and Guo, Yike},
  year = {2010},
  month = sep,
  journal = {Philosophical transactions. Series A, Mathematical, physical, and engineering sciences},
  volume = {368},
  number = {1926},
  eprint = {20679131},
  eprinttype = {pubmed},
  pages = {4193--208},
  issn = {1364-503X},
  doi = {10.1098/rsta.2010.0157},
  abstract = {Motivated by the use of scientific workflows as a user-oriented mechanism for building executable scientific data integration and analysis applications, this article introduces a framework and a set of associated methods for analysing the execution properties of scientific workflows. Our framework uses a number of formal modelling techniques to characterize the process and data behaviour of workflows and workflow components and to reason about their functional and execution properties. We use the framework to design the architecture of a customizable tool that can be used to analyse the key execution properties of scientific workflows at authoring stage. Our design is generic and can be applied to a wide variety of scientific workflow languages and systems, and is evaluated by building a prototype of the tool for the Discovery Net system. We demonstrate and discuss the utility of the framework and tool using workflows from a real-world medical informatics study.},
  pmid = {20679131},
  file = {/Users/brownsarahm/Zotero/storage/LJCXPY9L/Curcin, Ghanem, Guo - 2010 - The design and implementation of a workflow analysis tool(3).pdf}
}

@inproceedings{dai2020Label,
  title = {Label {{Bias}}, {{Label Shift}}: {{Fair Machine Learning}} with {{Unreliable Labels}}},
  booktitle = {Workshop on {{Consequential Decisions}} in {{Dynamic Environments NeurIPS}} 2020},
  author = {Dai, Jessica and Brown, Sarah M},
  year = {2020},
  month = dec,
  copyright = {All rights reserved}
}

@article{dallow2018better,
  title = {Better Decision Making in Drug Development through Adoption of Formal Prior Elicitation},
  author = {Dallow, Nigel and Best, Nicky and Montague, Timothy H.},
  year = {2018},
  journal = {Pharmaceutical Statistics},
  number = {July 2017},
  pages = {1--16},
  issn = {15391612},
  doi = {10.1002/pst.1854},
  abstract = {With the continued increase in the use of Bayesian methods in drug development, there is a need for statisticians to have tools to develop robust and defensible informative prior distributions. Whilst relevant empirical data should, where possible, provide the basis for such priors, it is often the case that limitations in data and/or our understanding may preclude direct construction of a data-based prior. Formal expert elicitation methods are a key technique that can be used to determine priors in these situations. Within GlaxoSmithKline (GSK), we have adopted a structured approach to prior elicitation based on the SHELF elicitation framework, and routinely use this in conjunction with calculation of probability of success (assurance) of the next study(s) to inform internal decision making at key project milestones. The aim of this paper is to share our experiences of embedding the use of prior elicitation within a large pharmaceutical company, highlighting both the benefits and challenges of prior elicitation through a series of case studies. We have found that putting team beliefs into the shape of a quantitative probability distribution provides a firm anchor for all internal decision making, enabling teams to provide investment boards with formally appropriate estimates of the probability of trial success as well as robust plans for interim decision rules where appropriate. As an added benefit, the elicitation process provides transparency about the beliefs and risks of the potential medicine, ultimately enabling better portfolio and company-wide decision making.},
  keywords = {Assurance,Bayesian,Prior elicitation,SHELF},
  file = {/Users/brownsarahm/Zotero/storage/LKJS7P82/Dallow, Best, Montague - 2018 - Better decision making in drug development through adoption of formal prior elicitation.pdf}
}

@article{damaraju2014dynamic,
  title = {Dynamic Functional Connectivity Analysis Reveals Transient States of Dysconnectivity in Schizophrenia},
  author = {Damaraju, E. and Allen, E.a. and Belger, a. and Ford, J.M. and McEwen, S. and Mathalon, D.H. and Mueller, B.a. and Pearlson, G.D. and Potkin, S.G. and Preda, a. and Turner, J.a. and Vaidya, J.G. and {\noopsort{erp}}{van Erp}, T.G. and Calhoun, V.D.},
  year = {2014},
  journal = {NeuroImage: Clinical},
  volume = {5},
  number = {July},
  pages = {298--308},
  issn = {22131582},
  doi = {10.1016/j.nicl.2014.07.003},
  abstract = {Schizophrenia is a psychotic disorder characterized by functional dysconnectivity or abnormal integration between distant brain regions. Recent functional imaging studies have implicated large-scale thalamo-cortical connectivity as being disrupted in patients. However, observed connectivity differences in schizophrenia have been inconsistent between studies, with reports of hyperconnectivity and hypoconnectivity between the same brain regions. Using resting state eyes-closed functional imaging and independent component analysis on a multi-site data that included 151 schizophrenia patients and 163 age- and gender matched healthy controls, we decomposed the functional brain data into 100 components and identified 47 as functionally relevant intrinsic connectivity networks. We subsequently evaluated group differences in functional network connectivity, both in a static sense, computed as the pairwise Pearson correlations between the full network time courses (5.4 minutes in length), and a dynamic sense, computed using sliding windows (44 s in length) and k-means clustering to characterize five discrete functional connectivity states. Static connectivity analysis revealed that compared to healthy controls, patients show significantly stronger connectivity, i.e., hyperconnectivity, between the thalamus and sensory networks (auditory, motor and visual), as well as reduced connectivity (hypoconnectivity) between sensory networks from all modalities. Dynamic analysis suggests that (1), on average, schizophrenia patients spend much less time than healthy controls in states typified by strong, large-scale connectivity, and (2), that abnormal connectivity patterns are more pronounced during these connectivity states. In particular, states exhibiting cortical--subcortical antagonism (anti-correlations) and strong positive connectivity between sensory networks are those that show the group differences of thalamic hyperconnectivity and sensory hypoconnectivity. Group differences are weak or absent during other connectivity states. Dynamic analysis also revealed hypoconnectivity between the putamen and sensory networks during the same states of thalamic hyperconnectivity; notably, this finding cannot be observed in the static connectivity analysis. Finally, in post-hoc analyses we observed that the relationships between sub-cortical low frequency power and connectivity with sensory networks is altered in patients, suggesting different functional interactions between sub-cortical nuclei and sensorimotor cortex during specific connectivity states. While important differences between patients with schizophrenia and healthy controls have been identified, one should interpret the results with caution given the history of medication in patients. Taken together, our results support and expand current knowledge regarding dysconnectivity in schizophrenia, and strongly advocate the use of dynamic analyses to better account for and understand functional connectivity differences.},
  pmid = {25161896},
  file = {/Users/brownsarahm/Zotero/storage/NUBYE73V/Damaraju et al. - 2014 - Dynamic functional connectivity analysis reveals transient states of dysconnectivity in schizophrenia(3).pdf}
}

@article{damianou2011variational,
  title = {Variational {{Gaussian Process Dynamical Systems}}},
  author = {Damianou, Andreas C. and Titsias, Michalis K. and Lawrence, Neil D.},
  year = {2011},
  journal = {Advances in Neural Information Processing},
  pages = {16},
  abstract = {High dimensional time series are endemic in applications of machine learning such as robotics (sensor data), computational biology (gene expression data), vision (video sequences) and graphics (motion capture data). Practical nonlinear probabilistic approaches to this data are required. In this paper we introduce the variational Gaussian process dynamical system. Our work builds on recent variational approximations for Gaussian process latent variable models to allow for nonlinear dimensionality reduction simultaneously with learning a dynamical prior in the latent space. The approach also allows for the appropriate dimensionality of the latent space to be automatically determined. We demonstrate the model on a human motion capture data set and a series of high resolution video sequences.},
  file = {/Users/brownsarahm/Zotero/storage/NGWRBC6A/Damianou, Titsias, Lawrence - 2011 - Variational Gaussian Process Dynamical Systems(3).pdf}
}

@article{damianou2013deep,
  title = {Deep {{Gaussian Processes}}},
  author = {Damianou, Andreas C and Lawrence, Neil D.},
  year = {2013},
  journal = {International Conference on Artificial Intelligence and Statistics},
  volume = {31},
  pages = {207--215},
  issn = {15337928},
  abstract = {In this paper we introduce deep Gaussian process (GP) models. Deep GPs are a deep belief net- work based on Gaussian process mappings. The data is modeled as the output of a multivariate GP. The inputs to that Gaussian process are then governed by another GP. A single layer model is equivalent to a standard GP or the GP latent vari- able model (GP-LVM).We perform inference in the model by approximate variational marginal- ization. This results in a strict lower bound on the marginal likelihood of the model which we use for model selection (number of layers and nodes per layer). Deep belief networks are typically ap- plied to relatively large data sets using stochas- tic gradient descent for optimization. Our fully Bayesian treatment allows for the application of deep models even when data is scarce. Model se- lection by our variational bound shows that a five layer hierarchy is justified even when modelling a digit data set containing only 150 examples.},
  file = {/Users/brownsarahm/Zotero/storage/QS8DS2PF/Damianou, Lawrence - 2013 - Deep Gaussian Processes(3).pdf}
}

@article{dancis2023participatory,
  title = {Participatory Action Research as Pedagogy: {{Stay}} Messy},
  author = {Dancis, Julia S and Coleman, Brett R and Ellison, Erin Rose},
  year = {2023},
  journal = {Journal of Participatory Research Methods},
  volume = {4},
  number = {2}
}

@article{dancis2024being,
  title = {Being Fractal: {{Embodying}} Antiracism Values in Course-Based Participatory Action Research},
  author = {Dancis, Julia},
  year = {2024},
  journal = {American Journal of Community Psychology},
  volume = {73},
  number = {1-2},
  pages = {234--249}
}

@book{danziger1997naming,
  title = {Naming the Mind: {{How}} Psychology Found Its Language},
  author = {Danziger, Kurt},
  year = {1997},
  publisher = {Sage}
}

@article{das1994filters,
  title = {Filters , {{Wrappers}} and a {{Boosting-Based Hybrid}} for {{Feature Selection}}},
  author = {Das, Sanmay},
  year = {1994},
  file = {/Users/brownsarahm/Zotero/storage/E4VPZ8T9/Das - 1994 - Filters , Wrappers and a Boosting-Based Hybrid for Feature Selection(3).pdf}
}

@inproceedings{dasch2020Opportunities,
  title = {Opportunities for a {{More Interdisciplinary Approach}} to {{Perceptions}} of {{Fairness}} in {{Machine Learning}}},
  booktitle = {{{NeurIPS}} 2020 {{Workshop}}: {{ML Retrospectives}}, {{Surveys}} \& {{Meta-Analyses}}},
  author = {Dasch, Sophia T. and Rice, Vincent and Lakshminarayanan, Venkat R. and Togun, Taiwo and Boykin, C Malik and Brown, Sarah M.},
  year = {2020},
  month = dec,
  copyright = {All rights reserved},
  file = {/Users/brownsarahm/Zotero/storage/DYVKIUZM/Opportunities for a More Interdisciplinary Approac.pdf}
}

@article{daum2004zero,
  title = {From {{Zero}} to {{Reproducing Kernel Hilbert Spaces}} in {{Twelve Pages}} or {{Less}}},
  author = {Daum, Hal},
  year = {2004},
  journal = {Most},
  number = {February},
  pages = {1--12},
  abstract = {Unpublished paper},
  file = {/Users/brownsarahm/Zotero/storage/ESV8Q549/Daum - 2004 - From Zero to Reproducing Kernel Hilbert Spaces in Twelve Pages or Less(3).pdf}
}

@article{daunizeau2012stochastic,
  title = {Stochastic Dynamic Causal Modelling of {{fMRI}} Data: Should We Care about Neural Noise?},
  author = {Daunizeau, J and Stephan, K E and Friston, K J},
  year = {2012},
  month = aug,
  journal = {NeuroImage},
  volume = {62},
  number = {1},
  eprint = {22579726},
  eprinttype = {pubmed},
  pages = {464--481},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2012.04.061},
  abstract = {Dynamic causal modelling (DCM) was introduced to study the effective connectivity among brain regions using neuroimaging data. Until recently, DCM relied on deterministic models of distributed neuronal responses to external perturbation (e.g., sensory stimulation or task demands). However, accounting for stochastic fluctuations in neuronal activity and their interaction with task-specific processes may be of particular importance for studying state-dependent interactions. Furthermore, allowing for random neuronal fluctuations may render DCM more robust to model misspecification and finesse problems with network identification. In this article, we examine stochastic dynamic causal models (sDCM) in relation to their deterministic counterparts (dDCM) and highlight questions that can only be addressed with sDCM. We also compare the network identification performance of deterministic and stochastic DCM, using Monte Carlo simulations and an empirical case study of absence epilepsy. For example, our results demonstrate that stochastic DCM can exploit the modelling of neural noise to discriminate between direct and mediated connections. We conclude with a discussion of the added value and limitations of sDCM, in relation to its deterministic homologue.},
  pmid = {22579726},
  keywords = {Brain Mapping,Brain Mapping: methods,Computer Simulation,Computer-Assisted,Computer-Assisted: methods,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Models,Nerve Net,Nerve Net: physiology,Neurological,Reproducibility of Results,Sensitivity and Specificity,Signal-To-Noise Ratio,Statistical,Stochastic Processes}
}

@article{dayan2001theoretical,
  title = {Theoretical {{Neuroscience}}: {{Computational}} and {{Mathematical Modeling}} of {{Neural Systems}}},
  author = {Dayan, Peter and Abbott, L F},
  year = {2001},
  journal = {Computational and Mathematical Modeling of Neural {\textbackslash}ldots},
  pages = {480},
  issn = {10974199},
  doi = {10.1016/j.neuron.2008.10.019},
  abstract = {Theoretical neuroscience provides a quantitative basis for describing what nervous systems do, determining how they function, and uncovering the general principles by which they operate. This text introduces the basic mathematical and computational methods of theoretical neuroscience and presents applications in a variety of areas including vision, sensory-motor integration, development, learning, and memory. The book is divided into three parts. Part I. discusses the relationship between sensory stimuli and neural responses, focusing on the representation of information by the spiking activity of neurons. Part II discusses the modeling of neurons and neural circuits on the basis of cellular and synaptic biophysics. Part III analyzes the role of plasticity in development and learning. An appendix covers the mathematical methods used, and exercises are available on the book's Web site.},
  pmid = {18995824},
  file = {/Users/brownsarahm/Zotero/storage/757ZNH6J/Dayan, Abbott - 2001 - Theoretical Neuroscience Computational and Mathematical Modeling of Neural Systems(3).pdf}
}

@article{deco2011dynamical,
  title = {The Dynamical Balance of the Brain at Rest.},
  author = {Deco, Gustavo and Corbetta, Maurizio},
  year = {2011},
  journal = {The Neuroscientist : a review journal bringing neurobiology, neurology and psychiatry},
  volume = {17},
  number = {1},
  pages = {107--123},
  issn = {1073-8584},
  doi = {10.1177/1073858409354384},
  abstract = {The authors review evidence that spontaneous, that is, not stimulus or task driven, activity in the brain at the level of large-scale neural systems is not noise, but orderly and organized in a series of functional networks that maintain, at all times, a high level of coherence. These networks of spontaneous activity correlation or resting state networks (RSN) are closely related to the underlying anatomical connectivity, but their topography is also gated by the history of prior task activation. Network coherence does not depend on covert cognitive activity, but its strength and integrity relates to behavioral performance. Some RSN are functionally organized as dynamically competing systems both at rest and during tasks. Computational studies show that one of such dynamics, the anticorrelation between networks, depends on noise-driven transitions between different multistable cluster synchronization states. These multistable states emerge because of transmission delays between regions that are modeled as coupled oscillators systems. Large-scale systems dynamics are useful for keeping different functional subnetworks in a state of heightened competition, which can be stabilized and fired by even small modulations of either sensory or internal signals.},
  pmid = {21196530},
  keywords = {1968,barlow 1990,computational models,emphasize the role of,feedforward,function,hubel and wiesel,neurodynamics,ongoing activity,resting state,slow oscillations,stochastic resonance,traditional accounts of brain},
  file = {/Users/brownsarahm/Zotero/storage/Z6YBKD8P/Deco, Corbetta - 2011 - The dynamical balance of the brain at rest(3).pdf}
}

@article{deco2011emerging,
  title = {Emerging Concepts for the Dynamical Organization of Resting-State Activity in the Brain.},
  author = {Deco, Gustavo and Jirsa, Viktor K and McIntosh, Anthony R},
  year = {2011},
  journal = {Nature reviews. Neuroscience},
  volume = {12},
  number = {1},
  pages = {43--56},
  issn = {1471-003X},
  doi = {10.1038/nrn2961},
  abstract = {A broad body of experimental work has demonstrated that apparently spontaneous brain activity is not random. At the level of large-scale neural systems, as measured with functional MRI (fMRI), this ongoing activity reflects the organization of a series of highly coherent functional networks. These so-called resting-state networks (RSNs) closely relate to the underlying anatomical connectivity but cannot be understood in those terms alone. Here we review three large-scale neural system models of primate neocortex that emphasize the key contributions of local dynamics, signal transmission delays and noise to the emerging RSNs. We propose that the formation and dissolution of resting-state patterns reflects the exploration of possible functional network configurations around a stable anatomical skeleton.},
  pmid = {21170073},
  file = {/Users/brownsarahm/Zotero/storage/9YUGDZEE/Deco, Jirsa, McIntosh - 2011 - Emerging concepts for the dynamical organization of resting-state activity in the brain(3).pdf}
}

@article{deco2015rethinking,
  title = {Rethinking Segregation and Integration: Contributions of Whole-Brain Modelling},
  author = {Deco, Gustavo and Tononi, Giulio and Boly, Melanie and Kringelbach, Morten L},
  year = {2015},
  journal = {Nature Reviews Neuroscience},
  file = {/Users/brownsarahm/Zotero/storage/3MPGKUGJ/Deco et al. - 2015 - Rethinking segregation and integration contributions of whole-brain modelling(3).pdf}
}

@misc{DefaultStage,
  title = {Default {{Stage}}},
  urldate = {2020-08-22},
  howpublished = {https://app.hopin.to/events/smart-funny-black-in-da-crib-nsbe-46th-annual-convention-edition/stages/371074cc-293e-43f2-8199-daca97babf4d}
}

@article{deist2018simulation,
  title = {Simulation Assisted Machine Learning},
  author = {Deist, Timo and Patti, Andrew and Wang, Zhaoqi and Krane, David and Sorenson, Taylor and Craft, David},
  year = {2018},
  pages = {1--15},
  abstract = {Predicting how a proposed cancer treatment will affect a given tumor can be cast as a machine learning problem, but the complexity of biological systems, the number of potentially relevant genomic and clinical features, and the lack of very large scale patient data repositories make this a unique challenge. "Pure data" approaches to this problem are underpowered to detect combinatorially complex interactions and are bound to uncover false correlations despite statistical precautions taken (1). To investigate this setting, we propose a method to integrate simulations, a strong form of prior knowledge, into machine learning, a combination which to date has been largely unexplored. The results of multiple simulations (under various uncertainty scenarios) are used to compute similarity measures between every pair of samples: sample pairs are given a high similarity score if they behave similarly under a wide range of simulation parameters. These similarity values, rather than the original high dimensional feature data, are used to train kernelized machine learning algorithms such as support vector machines, thus handling the curse-of-dimensionality that typically affects genomic machine learning. Using four synthetic datasets of complex systems--three biological models and one network flow optimization model--we demonstrate that when the number of training samples is small compared to the number of features, the simulation kernel approach dominates over no-prior-knowledge methods. In addition to biology and medicine, this approach should be applicable to other disciplines, such as weather forecasting, financial markets, and agricultural management, where predictive models are sought and informative yet approximate simulations are available. The Python SimKern software, the models (in MATLAB, Octave, and R), and the datasets are made freely available at https://github.com/davidcraft/SimKern .},
  file = {/Users/brownsarahm/Zotero/storage/8EAZKM9J/Deist et al. - 2018 - Simulation assisted machine learning.pdf}
}

@article{delaney2024OxonFair,
  title = {{{OxonFair}}: {{A Flexible Toolkit}} for {{Algorithmic Fairness}}},
  author = {Delaney, Eoin and Fu, Zihao and Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
  year = {2024},
  journal = {arXiv preprint arXiv:2407.13710},
  eprint = {2407.13710},
  archiveprefix = {arXiv}
}

@article{dempster1977maximum,
  title = {Maximum Likelihood from Incomplete Data via the {{EM}} Algorithm},
  author = {Dempster, A. P. AP and Laird, NM M. and Rubin, DB B.},
  year = {1977},
  journal = {Journal of the Royal Statistical Society.},
  volume = {39},
  eprint = {10.2307/2984875},
  eprinttype = {jstor},
  pages = {1--38},
  issn = {0035-9246},
  doi = {10.2307/2984875},
  abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis},
  pmid = {2984875},
  file = {/Users/brownsarahm/Zotero/storage/QH75PJEN/Dempster - 1977 - Maximum likelihood from incomplete data via the EM algorithm(2).pdf}
}

@article{deneve2008bayesian,
  title = {Bayesian Spiking Neurons {{I}}: Inference.},
  author = {Deneve, Sophie},
  year = {2008},
  journal = {Neural computation},
  volume = {20},
  number = {1},
  eprint = {18045002},
  eprinttype = {pubmed},
  pages = {91--117},
  issn = {0899-7667},
  doi = {10.1162/neco.2008.20.1.91},
  abstract = {We show that the dynamics of spiking neurons can be interpreted as a form of Bayesian inference in time. Neurons that optimally integrate evidence about events in the external world exhibit properties similar to leaky integrate-and-fire neurons with spike-dependent adaptation and maximally respond to fluctuations of their input. Spikes signal the occurrence of new information-what cannot be predicted from the past activity. As a result, firing statistics are close to Poisson, albeit providing a deterministic representation of probabilities.},
  pmid = {18045002},
  keywords = {Action Potentials,Action Potentials: physiology,Adaptation,Algorithms,Animals,Bayes Theorem,Central Nervous System,Central Nervous System: physiology,Computer Simulation,Humans,Markov Chains,Models,Movement,Movement: physiology,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurons,Neurons: physiology,Perception,Perception: physiology,Physiological,Physiological: physiology,Statistical,Synaptic Transmission,Synaptic Transmission: physiology},
  file = {/Users/brownsarahm/Zotero/storage/MBDP69JA/Deneve - 2008 - Bayesian spiking neurons I inference(3).pdf}
}

@article{deneve2016efficiency,
  title = {Efficiency Turns the Table on Neural Encoding, Decoding and Noise},
  author = {Deneve, Sophie and Chalk, Matthew},
  year = {2016},
  journal = {Current Opinion in Neurobiology},
  volume = {37},
  pages = {141--148},
  issn = {09594388},
  doi = {10.1016/j.conb.2016.03.002},
  file = {/Users/brownsarahm/Zotero/storage/FK4EYK99/Deneve, Chalk - 2016 - Efficiency turns the table on neural encoding, decoding and noise(3).pdf}
}

@article{deneve2016efficient,
  title = {Efficient Codes and Balanced Networks.},
  author = {Den{\`e}ve, Sophie and Machens, Christian K},
  year = {2016},
  journal = {Nature neuroscience},
  volume = {19},
  number = {3},
  eprint = {26906504},
  eprinttype = {pubmed},
  pages = {375--82},
  issn = {1546-1726},
  doi = {10.1038/nn.4243},
  abstract = {Recent years have seen a growing interest in inhibitory interneurons and their circuits. A striking property of cortical inhibition is how tightly it balances excitation. Inhibitory currents not only match excitatory currents on average, but track them on a millisecond time scale, whether they are caused by external stimuli or spontaneous fluctuations. We review, together with experimental evidence, recent theoretical approaches that investigate the advantages of such tight balance for coding and computation. These studies suggest a possible revision of the dominant view that neurons represent information with firing rates corrupted by Poisson noise. Instead, tight excitatory/inhibitory balance may be a signature of a highly cooperative code, orders of magnitude more precise than a Poisson rate code. Moreover, tight balance may provide a template that allows cortical neurons to construct high-dimensional population codes and learn complex functions of their inputs.},
  pmid = {26906504},
  keywords = {a n d t,c u s o,h e o r,n n e u,o m p u,r a l c,tat i o n,y}
}

@inproceedings{deng2022Exploring,
  ids = {deng2022Exploringa},
  title = {Exploring How Machine Learning Practitioners (Try to) Use Fairness Toolkits},
  booktitle = {Proceedings of the 2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Deng, Wesley Hanwen and Nagireddy, Manish and Lee, Michelle Seng Ah and Singh, Jatinder and Wu, Zhiwei Steven and Holstein, Kenneth and Zhu, Haiyi},
  year = {2022},
  pages = {473--484}
}

@article{denny2012metaanalysis,
  title = {A Meta-Analysis of Functional Neuroimaging Studies of Self-and Other Judgments Reveals a Spatial Gradient for Mentalizing in Medial Prefrontal Cortex},
  author = {Denny, Bryan T and Kober, Hedy and Wager, Tor D and Ochsner, Kevin N},
  year = {2012},
  journal = {Journal of cognitive Neuroscience},
  volume = {24},
  number = {8},
  pages = {1742--1752}
}

@article{depasquale2012cortical,
  title = {A {{Cortical Core}} for {{Dynamic Integration}} of {{Functional Networks}} in the {{Resting Human Brain}}},
  author = {{\noopsort{pasquale}}{de Pasquale}, Francesco and Della Penna, Stefania and Snyder, Abraham Z. and Marzetti, Laura and Pizzella, Vittorio and Romani, Gian Luca and Corbetta, Maurizio},
  year = {2012},
  journal = {Neuron},
  volume = {74},
  number = {4},
  pages = {753--764},
  issn = {08966273},
  doi = {10.1016/j.neuron.2012.03.031},
  abstract = {We used magneto-encephalography to study the temporal dynamics of band-limited power correlation at rest within and across six brain networks previously defined by prior functional magnetic resonance imaging (fMRI) studies. Epochs of transiently high within-network band limited power (BLP) correlation were identified and correlation of BLP time-series across networks was assessed in these epochs. These analyses demonstrate that functional networks are not equivalent with respect to cross-network interactions. The default-mode network and the posterior cingulate cortex, in particular, exhibit the highest degree of transient BLP correlation with other networks especially in the 14-25 Hz ({$\beta$} band) frequency range. Our results indicate that the previously demonstrated neuroanatomical centrality of the PCC and DMN has a physiological counterpart in the temporal dynamics of network interaction at behaviorally relevant timescales. This interaction involved subsets of nodes from other networks during periods in which their internal correlation was low.},
  pmid = {22632732},
  file = {/Users/brownsarahm/Zotero/storage/H8DU9QB8/de Pasquale et al. - 2012 - A Cortical Core for Dynamic Integration of Functional Networks in the Resting Human Brain(3).pdf}
}

@article{desai2002response,
  title = {Response {{Time Shift Estimates From Curve Evolution}}},
  author = {Desai, Mukund and Mangoubi, Rami and Shah, Jayant and Karl, William and Pien, Homer and Worth, Andrew and Kennedy, David},
  year = {2002},
  volume = {21},
  number = {11},
  pages = {1402--1412},
  file = {/Users/brownsarahm/Zotero/storage/CS5LGAIG/Desai et al. - 2002 - Response Time Shift Estimates From Curve Evolution(3).pdf}
}

@article{desai2003robust,
  title = {Robust Gaussian and Non-Gaussian Matched Subspace Detection},
  author = {Desai, M.N. and Mangoubi, R.S.},
  year = {2003},
  month = dec,
  journal = {IEEE Transactions on Signal Processing},
  volume = {51},
  number = {12},
  pages = {3115--3127},
  issn = {1053-587X},
  doi = {10.1109/TSP.2003.818907},
  file = {/Users/brownsarahm/Zotero/storage/7L25B6LH/Desai, Mangoubi - 2003 - Robust gaussian and non-gaussian matched subspace detection(7).pdf;/Users/brownsarahm/Zotero/storage/J4AWWTHW/Desai, Mangoubi - 2003 - Robust gaussian and non-gaussian matched subspace detection(9).pdf;/Users/brownsarahm/Zotero/storage/SU32CJRM/Desai, Mangoubi - 2003 - Robust gaussian and non-gaussian matched subspace detection(8).pdf}
}

@article{devillers2005challenges,
  title = {Challenges in Real-Life Emotion Annotation and Machine Learning Based Detection},
  author = {Devillers, L and Vidrascu, L and Lamel, L},
  year = {2005},
  month = may,
  journal = {Neural Networks},
  volume = {18},
  number = {4},
  pages = {407--422},
  issn = {08936080},
  doi = {10.1016/j.neunet.2005.03.007},
  keywords = {blended emotion,disfluency and lexical features,emotion annotation,emotion detection,machine learning,naturalistic spoken data,prosodic},
  file = {/Users/brownsarahm/Zotero/storage/7FHQD2CM/Devillers, Vidrascu, Lamel - 2005 - Challenges in real-life emotion annotation and machine learning based detection(3).pdf}
}

@article{devroye1979distributionfree,
  title = {Distribution-Free Performance Bounds for Potential Function Rules},
  author = {Devroye, L. and Wagner, T.},
  year = {1979},
  journal = {IEEE Transactions on Information Theory},
  volume = {25},
  number = {2},
  issn = {0018-9448},
  doi = {10.1109/TIT.1979.1056087},
  abstract = {In the discrimination problem the random variable{\textbackslash}textlesstex{\textbackslash}textgreatertheta{\textbackslash}textless/tex{\textbackslash}textgreater, known to take values in{\textbackslash}textlesstex{\textbackslash}textgreater\{1, cdots ,M\}{\textbackslash}textless/tex{\textbackslash}textgreater, is estimated from the random vector{\textbackslash}textlesstex{\textbackslash}textgreaterX{\textbackslash}textless/tex{\textbackslash}textgreater. All that is known about the joint distribution of{\textbackslash}textlesstex{\textbackslash}textgreater(X, theta){\textbackslash}textless/tex{\textbackslash}textgreateris that which can be inferred from a sample{\textbackslash}textlesstex{\textbackslash}textgreater(X\_\{1\}, theta\_\{1\}), cdots ,(X\_\{n\}, theta\_\{n\}){\textbackslash}textless/tex{\textbackslash}textgreaterof size{\textbackslash}textlesstex{\textbackslash}textgreatern{\textbackslash}textless/tex{\textbackslash}textgreaterdrawn from that distribution. A discrimination nde is any procedure which determines a decision{\textbackslash}textlesstex{\textbackslash}textgreaterhat\{ theta\}{\textbackslash}textless/tex{\textbackslash}textgreaterfor{\textbackslash}textlesstex{\textbackslash}textgreatertheta{\textbackslash}textless/tex{\textbackslash}textgreaterfrom{\textbackslash}textlesstex{\textbackslash}textgreaterX{\textbackslash}textless/tex{\textbackslash}textgreaterand{\textbackslash}textlesstex{\textbackslash}textgreater(X\_\{1\}, theta\_\{1\}) , cdots , (X\_\{n\}, theta\_\{n\}){\textbackslash}textless/tex{\textbackslash}textgreater. For rules which are determined by potential functions it is shown that the mean-square difference between the probability of error for the nde and its deleted estimate is bounded by{\textbackslash}textlesstex{\textbackslash}textgreaterA/ sqrt\{n\}{\textbackslash}textless/tex{\textbackslash}textgreaterwhere{\textbackslash}textlesstex{\textbackslash}textgreaterA{\textbackslash}textless/tex{\textbackslash}textgreateris an explicitly given constant depending only on{\textbackslash}textlesstex{\textbackslash}textgreaterM{\textbackslash}textless/tex{\textbackslash}textgreaterand the potential function. The{\textbackslash}textlesstex{\textbackslash}textgreaterO(n {\textasciicircum}\{-1/2\}){\textbackslash}textless/tex{\textbackslash}textgreaterbehavior is shown to be the best possible for one of the most commonly encountered rules of this type.},
  file = {/Users/brownsarahm/Zotero/storage/5IZ652LI/Devroye, Wagner - 1979 - Distribution-free performance bounds for potential function rules(3).pdf}
}

@article{dewey1896reflex,
  title = {The Reflex Arc Concept in Psychology},
  author = {Dewey, John},
  year = {1896},
  journal = {Psychological Review},
  volume = {3},
  number = {4},
  pages = {357}
}

@inproceedings{dhanawansa2022comparative,
  ids = {dhanawansa2022Comparative},
  title = {Comparative Study of Deep Learning Parameter Selection for Multi-Output Regression on Head Pose Estimation},
  booktitle = {2022 {{IEEE}} International Conference on Industrial Technology ({{ICIT}})},
  author = {Dhanawansa, Vidushani and Samarasinghe, Pradeepa and Yogarajah, Pratheepan and Gardiner, Bryan and Karunasena, Anuradha},
  year = {2022},
  pages = {1--6},
  publisher = {IEEE}
}

@book{dheeru2017uci,
  title = {{{UCI Machine Learning Repository}}},
  author = {Dheeru, Dua and Karra Taniskidou, Efi},
  year = {2017},
  publisher = {{University of California, Irvine, School of Information and Computer Sciences}}
}

@article{dias2005feeling,
  title = {Feeling and Reasoning: {{A}} Computational Model for Emotional Characters},
  author = {Dias, J and Paiva, Ana},
  year = {2005},
  journal = {Progress in artificial intelligence},
  file = {/Users/brownsarahm/Zotero/storage/M6H7Y5DZ/Dias, Paiva - 2005 - Feeling and reasoning A computational model for emotional characters(3).pdf}
}

@article{dieterich2016compas,
  title = {{{COMPAS}} Risk Scales: {{Demonstrating}} Accuracy Equity and Predictive Parity},
  author = {Dieterich, William and Mendoza, Christina and Brennan, Tim},
  year = {2016},
  journal = {Northpoint Inc}
}

@inproceedings{dietterich1991errorcorrecting,
  title = {Error-{{Correcting Output Codes}}: {{A General Method}} for {{Improving Multiclass Inductive Learning Programs}}},
  booktitle = {Ninth {{National Conference}} on {{Artificial Intelligence}}},
  author = {Dietterich, Thomas G. and Bakiri, Ghulum},
  year = {1991},
  pages = {572--577},
  abstract = {Multiclass learning problems involve finding a definition for an unknown function f(x) whose range is a discrete set containing k 2 values (i.e., k "classes"). The definition is acquired by studying large collections of training examples of the form hx i ; f(x i )i. Existing approaches to this problem include (a) direct application of multiclass algorithms such as the decision-tree algorithms ID3 and CART, (b) application of binary concept learning algorithms to learn individual binary functions for each of the k classes, and (c) application of binary concept learning algorithms with distributed output codes such as those employed by Sejnowski and Rosenberg in the NETtalk system. This paper compares these three approaches to a new technique in which BCH error-correcting codes are employed as a distributed output representation. We show that these output representations improve the performance of ID3 on the NETtalk task and of backpropagation on an isolated-letter speech-recognition t...},
  file = {/Users/brownsarahm/Zotero/storage/G2X5NWRR/Dietterich, Bakiri - 1991 - Error-Correcting Output Codes A General Method for Improving Multiclass Inductive Learning Programs(3).pdf}
}

@article{dietterich1995solving,
  title = {Solving Multiclass Learning Problems via Error-Correcting Output Codes},
  author = {Dietterich, {\relax TG} and Bakiri, G},
  year = {1995},
  journal = {Journal of Arti cial Intelligence Research},
  volume = {2},
  pages = {263--286},
  file = {/Users/brownsarahm/Zotero/storage/E9BJQI5W/Dietterich, Bakiri - 1995 - Solving multiclass learning problems via error-correcting output codes(3).pdf}
}

@article{dillon2011basic,
  title = {From {{Basic Processes}} to {{Real-World Problems}}: {{How Research}} on {{Emotion}} and {{Emotion Regulation Can Inform Understanding}} of {{Psychopathology}}, and {{Vice Versa}}.},
  author = {Dillon, Daniel G. and Pizzagalli, Diego A. and Deveney, Christen M. and Pizzagalli, Diego A.},
  year = {2011},
  month = jan,
  journal = {Emotion Rview},
  volume = {3},
  number = {1},
  pages = {74--82},
  issn = {1754-0739},
  doi = {10.1177/1754073910380973},
  abstract = {Research on emotion and emotion regulation is expected to improve our understanding of psychopathology. However, achieving this understanding requires overcoming several obstacles, including the paucity of objective markers of specific emotions or psychiatric diagnoses, and the fact that emotion regulation is a concept that can be difficult to operationalize. We review affective neuroscience research that has addressed these issues by focusing on psychological and neural mechanisms implicated in approach and avoidance behaviors, as revealed by studies of fear, anxiety, and reward processing. Dysfunction in these mechanisms may serve as risk markers for psychopathology, while emotion regulation research demonstrates that some of them are susceptible to volitional control. The conclusion acknowledges limitations of affective neuroscience and highlights goals for future work.},
  pmid = {21584224},
  keywords = {affective neuroscience,and psychopathology,emo-,emotion,emotion regulation,er,fear,on emotion,psychopathology,reward,this is an opportune,time to consider research,tion regulation,upcoming revisions},
  file = {/Users/brownsarahm/Zotero/storage/HGI7UVDE/Dillon, Deveney, Pizzagalli - 2011 - From Basic Processes to Real-World Problems How Research on Emotion and Emotion Regulation Can I(2).pdf}
}

@article{ding2021retiring,
  title = {Retiring Adult: {{New}} Datasets for Fair Machine Learning},
  author = {Ding, Frances and Hardt, Moritz and Miller, John and Schmidt, Ludwig},
  year = {2021},
  journal = {Advances in Neural Information Processing Systems},
  volume = {34},
  pages = {6478--6490}
}

@inproceedings{dobbe2022System,
  title = {System {{Safety}} and {{Artificial Intelligence}}},
  booktitle = {2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Dobbe, Roel},
  year = {2022},
  pages = {1584--1584}
}

@article{dominance1999intergroup,
  title = {An Intergroup Theory of Social Hierarchy and Oppression},
  author = {Dominance, Social},
  year = {1999},
  publisher = {New York: Cambridge University Press}
}

@article{domingos2000bayesian,
  title = {Bayesian Averaging of Classifiers and the Overfitting Problem},
  author = {Domingos, Pedro},
  year = {2000},
  journal = {Int. Conf. on Machine Learning},
  file = {/Users/brownsarahm/Zotero/storage/WWFZEP8S/Domingos - 2000 - Bayesian averaging of classifiers and the overfitting problem(3).pdf}
}

@article{dosenbach2006core,
  title = {A Core System for the Implementation of Task Sets},
  author = {Dosenbach, Nico and Visscher, Kristina M and Palmer, Erica D and Miezin, Francis M and Wenger, Kristin K and Hyunseon, C Kang and Burgund, E Darcy and Grimes, Ansley L and Schlaggar, Bradley L and Petersen, Steven E},
  year = {2006},
  journal = {Neuron},
  volume = {50},
  number = {5},
  pages = {799--812}
}

@article{dosenbach2007distinct,
  title = {Distinct Brain Networks for Adaptive and Stable Task Control in Humans},
  author = {Dosenbach, Nico F and Fair, Damien A and Miezin, Francis M and Cohen, Alexander L and Wenger, Kristin K and Dosenbach, Ronny and Fox, Michael D and Snyder, A Z and Vincent, J L and Raichle, M E and Schlaggar, B L},
  year = {2007},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {104},
  number = {26},
  pages = {11073--11078}
}

@article{doshi-velez2011infinite,
  title = {Infinite Dynamic Bayesian Networks},
  author = {{Doshi-velez}, Finale and Wingate, David and Tenenbaum, Joshua and Roy, Nicholas},
  year = {2011},
  journal = {Proceedings of the 28th International Conference on Machine Learning},
  keywords = {dynamic Bayesian networks,nonparametric Bayesian,nonparametric Bayesian models},
  file = {/Users/brownsarahm/Zotero/storage/KMJQ3CXQ/Doshi-velez et al. - 2011 - Infinite Dynamic Bayesian Networks(2).pdf}
}

@article{doshi-velez2017accountability,
  title = {Accountability of {{AI Under}} the {{Law}}: {{The Role}} of {{Explanation}}},
  author = {{Doshi-Velez}, Finale and Kortz, Mason and Budish, Ryan and Bavitz, Chris and Gershman, Sam and O'Brien, David and Schieber, Stuart and Waldo, James and Weinberger, David and Wood, Alexandra},
  year = {2017},
  journal = {arXiv preprint arXiv:1711.01134},
  eprint = {1711.01134},
  archiveprefix = {arXiv}
}

@article{doshi-velez2017rigorous,
  title = {Towards {{A Rigorous Science}} of {{Interpretable Machine Learning}}},
  author = {{Doshi-Velez}, Finale and Kim, Been},
  year = {2017},
  number = {Ml},
  pages = {1--13},
  abstract = {As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.},
  file = {/Users/brownsarahm/Zotero/storage/JB7T4W5Y/Doshi-Velez, Kim - 2017 - Towards A Rigorous Science of Interpretable Machine Learning.pdf;/Users/brownsarahm/Zotero/storage/ZNT8ZK29/Doshi-Velez, Kim - 2017 - Towards A Rigorous Science of Interpretable Machine Learning.pdf}
}

@article{doshi2009variational,
  title = {Variational {{Inference}} for the {{Indian Buffet Process}}},
  author = {Doshi, Finale and Miller, Kt Kurt Tadayuki and Gael, Jurgen Van and Van Gael, Jurgen and Teh, Yee Whye},
  year = {2009},
  journal = {Proceedings of the Intl Conf on Artificial Intelligence and Statistics},
  volume = {5},
  number = {April},
  pages = {137--144},
  issn = {15324435},
  abstract = {The Indian Buffet Process (IBP) is a nonparametric prior for latent feature models in which observations are influenced by a combination of hidden features. For example, images may be composed of several objects and sounds may consist of several notes. Latent feature models seek to infer these unobserved features from a set of observations; the IBP provides a principled prior in situations where the number of hidden features is unknown. Current inference methods for the IBP have all relied on sampling. While these methods are guaranteed to be accurate in the limit, samplers for the IBP tend to mix slowly in practice. We develop a deterministic variational method for inference in the IBP based on a truncated stick-breaking approximation, provide theoretical bounds on the truncation error, and evaluate our method in several data regimes.},
  file = {/Users/brownsarahm/Zotero/storage/I8YDSI7R/Doshi et al. - 2009 - Variational Inference for the Indian Buffet Process(3).pdf}
}

@misc{dotan2019Valueladen,
  title = {Value-Laden {{Disciplinary Shifts}} in {{Machine Learning}}},
  author = {Dotan, Ravit and Milli, Smitha},
  year = {2019},
  month = dec,
  number = {arXiv:1912.01172},
  eprint = {1912.01172},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2024-04-19},
  abstract = {As machine learning models are increasingly used for high-stakes decision making, scholars have sought to intervene to ensure that such models do not encode undesirable social and political values. However, little attention thus far has been given to how values influence the machine learning discipline as a whole. How do values influence what the discipline focuses on and the way it develops? If undesirable values are at play at the level of the discipline, then intervening on particular models will not suffice to address the problem. Instead, interventions at the disciplinary-level are required. This paper analyzes the discipline of machine learning through the lens of philosophy of science. We develop a conceptual framework to evaluate the process through which types of machine learning models (e.g. neural networks, support vector machines, graphical models) become predominant. The rise and fall of model-types is often framed as objective progress. However, such disciplinary shifts are more nuanced. First, we argue that the rise of a model-type is self-reinforcing--it influences the way model-types are evaluated. For example, the rise of deep learning was entangled with a greater focus on evaluations in compute-rich and data-rich environments. Second, the way model-types are evaluated encodes loaded social and political values. For example, a greater focus on evaluations in compute-rich and data-rich environments encodes values about centralization of power, privacy, and environmental concerns.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/brownsarahm/Zotero/storage/G4THY4XJ/Dotan and Milli - 2019 - Value-laden Disciplinary Shifts in Machine Learnin.pdf;/Users/brownsarahm/Zotero/storage/PECXSBCE/1912.html}
}

@inproceedings{dragicevic2019increasing,
  title = {Increasing the Transparency of Research Papers with Explorable Multiverse Analyses},
  booktitle = {Proceedings of the 2019 {{CHI}} Conference on Human Factors in Computing Systems},
  author = {Dragicevic, Pierre and Jansen, Yvonne and Sarma, Abhraneel and Kay, Matthew and Chevalier, Fanny},
  year = {2019},
  pages = {1--15}
}

@article{dressel2018accuracy,
  title = {The Accuracy, Fairness, and Limits of Predicting Recidivism},
  author = {Dressel, Julia and Farid, Hany},
  year = {2018},
  journal = {Science Advances},
  volume = {4},
  number = {1},
  pages = {1--6},
  issn = {23752548},
  doi = {10.1126/sciadv.aao5580},
  abstract = {Algorithms for predicting recidivism are commonly used to assess a criminal defendant's likelihood of committing a crime. These predictions are used in pretrial, parole, and sentencing decisions. Proponents of these systems argue that big data and advanced machine learning make these analyses more accurate and less biased than humans. We show, however, that the widely used commercial risk assessment software COMPAS is no more accurate or fair than predictions made by people with little or no criminal justice expertise. In addition, despite COMPAS's collection of 137 features, the same accuracy can be achieved with a simple linear classifier with only two features.},
  file = {/Users/brownsarahm/Zotero/storage/WRATY8B5/eaao5580.full.pdf}
}

@misc{drivendata2018deon,
  title = {About --- {{Deon}}},
  author = {DrivenData},
  year = {2018},
  journal = {deon: An ethics checklist for data scientists},
  urldate = {2020-05-08},
  howpublished = {https://deon.drivendata.org/}
}

@book{drivendataethics,
  title = {An Ethics Checklist for Data Scientists},
  author = {{DrivenData}},
  journal = {Deon}
}

@article{drukker2023Fairness,
  ids = {drukker2023Fairnessa,drukker2023Fairnessb},
  title = {Toward Fairness in Artificial Intelligence for Medical Image Analysis: Identification and Mitigation of Potential Biases in the Roadmap from Data Collection to Model Deployment},
  author = {Drukker, Karen and Chen, Weijie and Gichoya, Judy and Gruszauskas, Nicholas and {Kalpathy-Cramer}, Jayashree and Koyejo, Sanmi and Myers, Kyle and S{\'a}, Rui C and Sahiner, Berkman and Whitney, Heather},
  year = {2023},
  journal = {Journal of Medical Imaging},
  volume = {10},
  number = {6},
  pages = {061104--061104},
  publisher = {Society of Photo-Optical Instrumentation Engineers},
  issn = {2329-4302}
}

@incollection{duan2005which,
  title = {Which {{Is}} the {{Best Multiclass SVM Method}}? {{An Empirical Study}}},
  booktitle = {Multiple {{Classifier Systems}}},
  author = {Duan, Kai-bo and Keerthi, S Sathiya},
  year = {2005},
  volume = {3541},
  pages = {278--285},
  doi = {10.1007/b136985},
  abstract = {Multiclass SVMs are usually implemented by combining sev- eral two-class SVMs. The one-versus-all method using winner-takes-all strategy and the one-versus-one method implemented by max-wins vot- ing are popularly used for this purpose. In this paper we give empirical evidence to show that these methods are inferior to another one-versus- one method: one that uses Platt's posterior probabilities together with the pairwise coupling idea of Hastie and Tibshirani. The evidence is par- ticularly strong when the training dataset is sparse.},
  isbn = {978-3-540-26306-7},
  pmid = {124},
  file = {/Users/brownsarahm/Zotero/storage/XZRKI5A4/Duan, Keerthi - 2005 - Which Is the Best Multiclass SVM Method An Empirical Study(3).pdf}
}

@book{duda2001pattern,
  title = {Pattern {{Classification}}},
  author = {Duda, Richard O. and Hart, Peter E. and Stork, David G.},
  year = {2001},
  edition = {Second Edi},
  publisher = {John Wiley \& Sons, Inc}
}

@article{duh2011distributed,
  title = {Distributed {{Learning-to-Rank}} on {{Streaming Data}} Using {{Alternating Direction Method}} of {{Multipliers}}},
  author = {Duh, Kevin and Suzuki, Jun and Nagata, Masaaki},
  year = {2011},
  journal = {Proc. of NIPS Big Learning Workshop (2011)},
  number = {1},
  pages = {1--6},
  file = {/Users/brownsarahm/Zotero/storage/72PBBRZ9/Duh, Suzuki, Nagata - 2011 - Distributed Learning-to-Rank on Streaming Data using Alternating Direction Method of Multipliers(3).pdf}
}

@article{dunne2002solutions,
  title = {Solutions to Instability Problems with Sequential Wrapper-Based Approaches to Feature Selection},
  author = {Dunne, Kevin and Cunningham, Padraig and Azuaje, Francisco},
  year = {2002},
  journal = {Journal of Machine Learning Research},
  file = {/Users/brownsarahm/Zotero/storage/4XGY9SFQ/Dunne, Cunningham, Azuaje - 2002 - Solutions to instability problems with sequential wrapper-based approaches to feature selection(3).pdf}
}

@book{durbin2001time,
  title = {Time {{Series Analysis}} by {{State Space Models}}},
  author = {Durbin, J. and Koopman, S.J.},
  year = {2001},
  publisher = {Oxford University Press},
  address = {New York, New York, USA},
  isbn = {019852354}
}

@article{duvenaud2011additive,
  title = {Additive {{Gaussian}} Processes},
  author = {Duvenaud, David and Nickisch, H and Rasmussen, CE Carl Edward},
  year = {2011},
  journal = {arXiv preprint arXiv:1112.4394},
  eprint = {1112.4394},
  pages = {1--9},
  archiveprefix = {arXiv},
  file = {/Users/brownsarahm/Zotero/storage/8TUD2JIU/Duvenaud, Nickisch, Rasmussen - 2011 - Additive Gaussian processes(3).pdf}
}

@inproceedings{duvenaud2013structure,
  title = {Structure Discovery in Nonparametric Regression through Compositional Kernel Search},
  booktitle = {Proceedings of the {{International Conference}} on {{Machine Learning}} ({{ICML}})},
  author = {Duvenaud, David and Lloyd, James and Grosse, Roger and Tenenbaum, Joshua and Ghahramani, Zoubin},
  year = {2013},
  volume = {30},
  pages = {1166--1174},
  abstract = {Despite its importance, choosing the structural form of the kernel in nonparametric regression remains a black art. We define a space of kernel structures which are built compositionally by adding and multiplying a small number of base kernels. We present a method for searching over this space of structures which mirrors the scientific discovery process. The learned structures can often decompose functions into interpretable components and enable long-range extrapolation on time-series datasets. Our structure search method outperforms many widely used kernels and kernel combination methods on a variety of prediction tasks.},
  file = {/Users/brownsarahm/Zotero/storage/JTLFZL9C/Duvenaud et al. - 2013 - Structure discovery in nonparametric regression through compositional kernel search(3).pdf}
}

@phdthesis{duvenaud2014automatic,
  title = {Automatic {{Model Construction}} with \{\vphantom\}{{G}}\vphantom\{\}aussian {{Processes}}},
  author = {Duvenaud, David},
  year = {2014},
  school = {Computational and Biological Learning Laboratory, University of Cambridge}
}

@inproceedings{dwork2012fairness,
  title = {Fairness through Awareness},
  booktitle = {Proceedings of the 3rd Innovations in Theoretical Computer Science Conference},
  author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
  year = {2012},
  pages = {214--226},
  publisher = {ACM},
  address = {New York, NY, USA}
}

@article{dwork2015generalization,
  title = {Generalization in {{Adaptive Data Analysis}} and {{Holdout Reuse}}},
  author = {Dwork, Cynthia and Feldman, Vitaly and Reingold, Omer and Hardt, Moritz and Roth, Aaron and Pitassi, Toniann},
  year = {2015},
  journal = {arXiv cs.LG},
  pages = {1--22},
  abstract = {Overfitting is the bane of data analysts, even when data are plentiful. Formal approaches to understanding this problem focus on statistical inference and generalization of individual analysis procedures. Yet the practice of data analysis is an inherently interactive and adaptive process: new analyses and hypotheses are proposed after seeing the results of previous ones, parameters are tuned on the basis of obtained results, and datasets are shared and reused. An investigation of this gap has recently been initiated by the authors in (Dwork et al., 2014), where we focused on the problem of estimating expectations of adaptively chosen functions. In this paper, we give a simple and practical method for reusing a holdout (or testing) set to validate the accuracy of hypotheses produced by a learning algorithm operating on a training set. Reusing a holdout set adaptively multiple times can easily lead to overfitting to the holdout set itself. We give an algorithm that enables the validation of a large number of adaptively chosen hypotheses, while provably avoiding overfitting. We illustrate the advantages of our algorithm over the standard use of the holdout set via a simple synthetic experiment. We also formalize and address the general problem of data reuse in adaptive data analysis. We show how the differential-privacy based approach given in (Dwork et al., 2014) is applicable much more broadly to adaptive data analysis. We then show that a simple approach based on description length can also be used to give guarantees of statistical validity in adaptive settings. Finally, we demonstrate that these incomparable approaches can be unified via the notion of approximate max-information that we introduce.},
  file = {/Users/brownsarahm/Zotero/storage/R6X6Q6JM/Dwork et al. - 2015 - Generalization in Adaptive Data Analysis and Holdout Reuse(3).pdf}
}

@article{dy2004feature,
  title = {Feature {{Selection}} for {{Unsupervised Learning}}},
  author = {Dy, Jennifer G and Brodley, Carla E},
  year = {2004},
  journal = {Journal of Machine Learning Research},
  volume = {5},
  pages = {845--889},
  issn = {15337928},
  abstract = {In this paper, we identify two issues involved in developing an automated feature subset selection algorithm for unlabeled data: the need for finding the number of clusters in conjunction with feature selection, and the need for normalizing the bias of feature selection criteria with respect to dimension. We explore the feature selection problem and these issues through FSSEM (Feature Subset Selection using Expectation-Maximization (EM) clustering) and through two different performance criteria for evaluating candidate feature subsets: scatter separability and maximum likelihood. We present proofs on the dimensionality biases of these feature criteria, and present a cross-projection normalization scheme that can be applied to any criterion to ameliorate these biases. Our experiments show the need for feature selection, the need for addressing these two issues, and the effectiveness of our proposed solutions.},
  keywords = {clustering,expectation maximization,expectation-maximization,feature selection,unsupervised learning},
  file = {/Users/brownsarahm/Zotero/storage/LAKJ7CVF/Dy, Brodley - 2004 - Feature selection for unsupervised learning(2).pdf}
}

@article{eagle2014big,
  title = {Big {{Data}} for {{Social Good}}},
  author = {Eagle, Nathan},
  year = {2014},
  volume = {3},
  number = {1},
  pages = {11--12},
  issn = {2167-6461},
  doi = {10.1089/big.2015.1530},
  file = {/Users/brownsarahm/Zotero/storage/VURX9SNW/Eagle - 2014 - Big Data for Social Good(3).pdf}
}

@article{eckhouse2019layers,
  title = {Layers of Bias: {{A}} Unified Approach for Understanding Problems with Risk Assessment},
  author = {Eckhouse, Laurel and Lum, Kristian and {Conti-Cook}, Cynthia and Ciccolini, Julie},
  year = {2019},
  journal = {Criminal Justice and Behavior},
  volume = {46},
  number = {2},
  pages = {185--209},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA}
}

@article{edelman2001degeneracy,
  title = {Degeneracy and Complexity in Biological Systems},
  author = {Edelman, Gerald M and Gally, Joseph A},
  year = {2001},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {98},
  number = {24},
  pages = {13763--13768}
}

@article{eftekhari2009patterns,
  title = {Patterns of Emotion Regulation and Psychopathology.},
  author = {Eftekhari, Afsoon and {\noopsort{zoellner}}a Zoellner, Lori and {\noopsort{vigil}}a Vigil, Shree},
  year = {2009},
  month = oct,
  journal = {Anxiety, stress, and coping},
  volume = {22},
  number = {5},
  pages = {571--86},
  issn = {1477-2205},
  doi = {10.1080/10615800802179860},
  abstract = {Emotion regulatory strategies such as higher expressive suppression and lower cognitive reappraisal may be associated with increased psychopathology (Gross \& John, 2003). Yet, it is unclear whether these strategies represent distinct cognitive styles associated with psychopathology, such that there are individuals who are predominantly "suppressors" or "reappraisers." Using cluster analysis, we examined whether women with and without exposure to potentially traumatic events evidence distinct patterns of emotion regulation frequency, capacity, suppression, and cognitive reappraisal. Four patterns emerged: high regulators; high reappraisers/low suppressors; moderate reappraisers/low suppressors; and low regulators. Individuals who reported infrequently and ineffectively regulating their emotions (low regulators) also reported higher depression, anxiety, and posttraumatic stress disorder (PTSD). In contrast, individuals who reported frequently and effectively using reappraisal and low levels of suppression (high reappraisers/low suppressors) reported the lowest levels of these symptoms, suggesting that this specific combination of emotion regulation may be most adaptive. Our findings highlight that the capacity to regulate emotions and the ability to flexibly apply different strategies based on the context and timing may be associated with reduced psychopathology and more adaptive functioning.},
  pmid = {19381989},
  keywords = {Anxiety,Anxiety: epidemiology,Cluster Analysis,Cognition,Depression,Depression: epidemiology,Emotions,Female,Homeostasis,Humans,Post-Traumatic,Post-Traumatic: etiology,Post-Traumatic: psychology,Stress Disorders},
  file = {/Users/brownsarahm/Zotero/storage/ICN8NTHB/Eftekhari, Zoellner, Vigil - 2009 - Patterns of emotion regulation and psychopathology(3).pdf}
}

@book{einicke2012smoothing,
  title = {Smoothing, {{Filtering}} and {{Prediction}} - {{Estimating The Past}}, {{Present}} and {{Future}}},
  author = {Einicke, Garry A},
  editor = {A., Garry},
  year = {2012},
  month = feb,
  publisher = {InTech},
  doi = {10.5772/2706},
  isbn = {978-953-307-752-9},
  file = {/Users/brownsarahm/Zotero/storage/C7AC6E64/Einicke - 2012 - Smoothing, Filtering and Prediction - Estimating The Past, Present and Future(3).pdf}
}

@article{ekman1983autonomic,
  title = {Autonomic Nervous System Activity Distinguishes among Emotions.},
  author = {Ekman, Paul and Levenson, {\relax RW} and Friesen, {\relax WV}},
  year = {1983},
  journal = {Science},
  volume = {221},
  number = {4616},
  pages = {1208--1210},
  file = {/Users/brownsarahm/Zotero/storage/RV4QTW35/Ekman, Levenson, Friesen - 1983 - Autonomic nervous system activity distinguishes among emotions(3).pdf}
}

@incollection{ekman1999basic,
  title = {Basic {{Emotions}}},
  booktitle = {The {{Handbook}} of {{Cognition}} and {{Emotion}}},
  author = {Ekman, Paul},
  year = {1999},
  number = {1992},
  pages = {45--60},
  isbn = {ISBN-10: 0471978361\${\textbackslash}backslash\$rISBN-13: 978-0471978367},
  file = {/Users/brownsarahm/Zotero/storage/87RETVPN/Ekman - 1999 - Basic Emotions(3).pdf}
}

@article{ekman2011what,
  title = {What Is Meant by Calling Emotions Basic},
  author = {Ekman, Paul and Cordaro, Daniel},
  year = {2011},
  journal = {Emotion Review},
  volume = {3},
  number = {4},
  pages = {364--370}
}

@article{ekman2012predicting,
  title = {Predicting Errors from Reconfiguration Patterns in Human Brain Networks},
  author = {Ekman, Matthias and Derrfuss, Jan and Tittgemeyer, Marc and Fiebach, Christian J},
  year = {2012},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {109},
  number = {41},
  pages = {16714--16719}
}

@article{elfadaly2015eliciting,
  title = {Eliciting Prior Distributions for Extra Parameters in Some Generalized Linear Models},
  author = {Elfadaly, Fadlalla G. and Garthwaite, Paul H.},
  year = {2015},
  journal = {Statistical Modelling},
  volume = {15},
  number = {4},
  pages = {345--365},
  issn = {14770342},
  doi = {10.1177/1471082X14553374},
  abstract = {To elicit an informative prior distribution for a normal linear model or a gamma generalized linear model (GLM), expert opinion must be quantified about both the regression coefficients and the extra parameters of these models. The latter task has attracted comparatively little attention. In this article, we introduce two elicitation methods that aim to complete the prior structure of the normal and gamma GLMs. First, we develop a method of assessing a conjugate prior distribution for the error variance in normal linear models. The method quantifies an expert's opinions through assessments of a median and conditional medians. Second, we propose a novel method for eliciting a lognormal prior distribution for the scale parameter of gamma GLMs. Given the mean value of a gamma distributed response variable, the method is based on conditional quartile assessments. It can also be used to quantify an expert's opinion about the prior distribution for the shape parameter of any gamma random variable, if the mean of the distribution has been elicited or is assumed to be known. In the context of GLMs, the mean value is determined by the regression coefficients. Interactive graphics is the medium through which assessments for the two proposed methods are elicited. Examples illustrating use of the methods are given. Computer programs that implement both methods are available.},
  keywords = {Elicitation,gamma distribution,generalized linear model,interactive graphical software,normal linear model,Subjective prior distribution},
  file = {/Users/brownsarahm/Zotero/storage/V3WLE77B/Elfadaly, Garthwaite - 2015 - Eliciting prior distributions for extra parameters in some generalized linear models.pdf}
}

@article{elfadaly2017eliciting,
  title = {Eliciting {{Dirichlet}} and {{Gaussian}} Copula Prior Distributions for Multinomial Models},
  author = {Elfadaly, Fadlalla G. and Garthwaite, Paul H.},
  year = {2017},
  journal = {Statistics and Computing},
  volume = {27},
  number = {2},
  pages = {449--467},
  issn = {15731375},
  doi = {10.1007/s11222-016-9632-7},
  keywords = {Dirichlet distribution,Elicitation method,Gaussian copula elicitation,Interactive graphical software,Multinomial model,Prior distribution},
  file = {/Users/brownsarahm/Zotero/storage/S6LCCYJ2/Elfadaly, Garthwaite - 2017 - Eliciting Dirichlet and Gaussian copula prior distributions for multinomial models.pdf}
}

@article{else-quest2015intersectionality,
  title = {Intersectionality in {{Quantitative Psychological Research}}: {{I}}. {{Theoretical}} and {{Epistemological Issues}}},
  author = {{Else-Quest}, Nicole M. and Hyde, Janet Shibley},
  year = {2015},
  journal = {Psychology of Women Quarterly},
  volume = {40},
  number = {2},
  pages = {155--170},
  issn = {14716402},
  doi = {10.1177/0361684316629797},
  abstract = {Intersectionality has become something of a buzzword in psychology and is well-known in feminist writings throughout the social sciences. Across diverse definitions of intersectionality, we find three common assumptions: (1) There is a recognition that all people are characterized simultaneously by multiple social categories and that these categories are interconnected or intertwined. (2) Embedded within each of these categories is a dimension of inequality or power. (3) These categories are properties of the individual as well as characteristics of the social context inhabited by those individuals; as such, categories and their significance may be fluid and dynamic. Understanding intersectionality as an approach and critical theory, rather than as a falsifiable theory, we consider its potential within research using quantitative methods. We discuss positivism, social constructionism, and standpoint epistemology in order to examine the implications of these epistemologies for research methods and to explore how compatible an intersectional approach may be with each. With an eye toward expanding the incorporation of intersectional approaches in the psychology of women, we discuss both the challenges and the potential of combining quantitative methods and intersectionality. We contend that quantitative methods can be used within an intersectional approach and that doing so will expand and develop the study of intersectionality, insofar as more research tools will be available to intersectionality researchers. We also contend that quantitative researchers should incorporate an intersectional approach into their work and that doing so will enrich and deepen our understanding of psychological constructs and processes.},
  keywords = {epistemology,feminist methods,human sex differences,intersectionality,power,quantitative methods,racial and ethnic differences},
  file = {/Users/brownsarahm/Zotero/storage/BIZEDV8S/Else-Quest, Hyde - 2015 - Intersectionality in Quantitative Psychological Research I. Theoretical and Epistemological Issues.pdf}
}

@article{elton2015taskpositive,
  title = {Task-Positive Functional Connectivity of the Default Mode Network Transcends Task Domain},
  author = {Elton, Amanda and Gao, Wei},
  year = {2015},
  journal = {Journal of Cognitive Neuroscience}
}

@article{erdogmuslocal,
  title = {Local {{Linear ICA}} for {{Mutual Information Estimation}} in {{Feature Selection}}},
  author = {Erdogmus, D.},
  journal = {2005 IEEE Workshop on Machine Learning for Signal Processing},
  pages = {3--8},
  doi = {10.1109/MLSP.2005.1532865},
  keywords = {entropy estimation,feature selection,information,local linear ica,mutual},
  file = {/Users/brownsarahm/Zotero/storage/KZCEYU7P/Erdogmus - Unknown - Local Linear ICA for Mutual Information Estimation in Feature Selection(3).pdf}
}

@article{escola2011hidden,
  title = {Hidden Markov Models for the Stimulus-Response Relationships of Multistate Neural Systems.},
  author = {Escola, Sean and Fontanini, Alfredo and Katz, Don and Paninski, Liam},
  year = {2011},
  journal = {Neural computation},
  volume = {23},
  number = {5},
  pages = {1071--1132},
  issn = {0899-7667},
  doi = {10.1162/NECO_a_00118},
  abstract = {Given recent experimental results suggesting that neural circuits may evolve through multiple firing states, we develop a framework for estimating state-dependent neural response properties from spike train data. We modify the traditional hidden Markov model (HMM) framework to incorporate stimulus-driven, non-Poisson point-process observations. For maximal flexibility, we allow external, time-varying stimuli and the neurons' own spike histories to drive both the spiking behavior in each state and the transitioning behavior between states. We employ an appropriately modified expectation-maximization algorithm to estimate the model parameters. The expectation step is solved by the standard forward-backward algorithm for HMMs. The maximization step reduces to a set of separable concave optimization problems if the model is restricted slightly. We first test our algorithm on simulated data and are able to fully recover the parameters used to generate the data and accurately recapitulate the sequence of hidden states. We then apply our algorithm to a recently published data set in which the observed neuronal ensembles displayed multistate behavior and show that inclusion of spike history information significantly improves the fit of the model. Additionally, we show that a simple reformulation of the state space of the underlying Markov chain allows us to implement a hybrid half-multistate, half-histogram model that may be more appropriate for capturing the complexity of certain data sets than either a simple HMM or a simple peristimulus time histogram model alone.},
  pmid = {21299424},
  file = {/Users/brownsarahm/Zotero/storage/2N8GFEHE/Escola et al. - 2011 - Hidden markov models for the stimulus-response relationships of multistate neural systems(3).pdf}
}

@book{eslami2012patterns,
  title = {Patterns for {{Research}} in {{Machine Learning}}},
  author = {Eslami, Ali},
  year = {2012},
  urldate = {2016-11-03},
  file = {/Users/brownsarahm/Zotero/storage/MMUJPPKU/Eslami - 2012 - Patterns for Research in Machine Learning(3).html}
}

@article{eslami2015always,
  title = {"{{I}} Always Assumed That {{I}} Wasn't Really That Close to [Her]"},
  author = {Eslami, Motahhare and Rickman, Aimee and Vaccaro, Kristen and Aleyasen, Amirhossein and Vuong, Andy and Karahalios, Karrie and Hamilton, Kevin and Sandvig, Christian},
  year = {2015},
  journal = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems - CHI '15},
  pages = {153--162},
  doi = {10.1145/2702123.2702556},
  abstract = {Users incorrectly concluded that they held unpopular views or were being given the cold shoulder.},
  file = {/Users/brownsarahm/Zotero/storage/KDBBNDQL/Eslami et al. - 2015 - I always assumed that I wasn't really that close to her.pdf}
}

@article{evans2017prior,
  title = {Prior Elicitation, Assessment and Inference with a {{Dirichlet}} Prior},
  author = {Evans, Michael and Guttman, Irwin and Li, Peiying},
  year = {2017},
  journal = {Entropy},
  volume = {19},
  number = {10},
  pages = {1--17},
  issn = {10994300},
  doi = {10.3390/e19100564},
  abstract = {Methods are developed for eliciting a Dirichlet prior based upon stating bounds on the individual probabilities that hold with high prior probability. This approach to selecting a prior is applied to a contingency table problem where it is demonstrated how to assess the prior with respect to the bias it induces as well as how to check for prior-data conflict. It is shown that the assessment of a hypothesis via relative belief can easily take into account what it means for the falsity of the hypothesis to correspond to a difference of practical importance and provide evidence in favor of a hypothesis.},
  keywords = {Bias,Dirichlet prior,Elicitation,Multinomial distribution,Prior-data conflict,Relative belief inferences}
}

@incollection{fabris2000discovering,
  title = {Discovering Surprising Patterns by Detecting Occurrences of {{Simpson}}'s Paradox},
  booktitle = {Research and {{Development}} in {{Intelligent Systems XVI}}},
  author = {Fabris, Carem C and Freitas, Alex A},
  year = {2000},
  pages = {148--160},
  publisher = {Springer}
}

@article{fan2011there,
  title = {Is There a Core Neural Network in Empathy? {{An fMRI}} Based Quantitative Meta-Analysis},
  author = {Fan, Yan and Duncan, Niall W and {\noopsort{greck}}{de Greck}, Moritz and Northoff, Georg},
  year = {2011},
  journal = {Neuroscience \& Biobehavioral Reviews},
  volume = {35},
  number = {3},
  pages = {903--911}
}

@article{fayyad1996data,
  title = {From Data Mining to Knowledge Discovery in Databases},
  author = {Fayyad, Usama and {Piatetsky-Shapiro}, Gregory and Smyth, Padhraic},
  year = {1996},
  journal = {AI magazine},
  volume = {17},
  number = {3},
  pages = {37--37}
}

@article{feinstein2013fear,
  title = {Fear and Panic in Humans with Bilateral Amygdala Damage.},
  author = {Feinstein, Justin S and Buzza, Colin and Hurlemann, Rene and Follmer, Robin L and Dahdaleh, Nader S and Coryell, William H and Welsh, Michael J and Tranel, Daniel and {\noopsort{wemmie}}a Wemmie, John},
  year = {2013},
  journal = {Nature neuroscience},
  volume = {16},
  number = {3},
  pages = {270--2},
  issn = {1546-1726},
  doi = {10.1038/nn.3323},
  abstract = {Decades of research have highlighted the amygdala's influential role in fear. We found that inhalation of 35\% CO(2) evoked not only fear, but also panic attacks, in three rare patients with bilateral amygdala damage. These results indicate that the amygdala is not required for fear and panic, and make an important distinction between fear triggered by external threats from the environment versus fear triggered internally by CO(2).},
  pmid = {23377128},
  keywords = {Adult,Amygdala,Amygdala: physiopathology,Carbon Dioxide,Carbon Dioxide: administration \& dosage,Facial Expression,Fear,Fear: physiology,Female,Humans,Lipoid Proteinosis of Urbach and Wiethe,Lipoid Proteinosis of Urbach and Wiethe: physiopat,Middle Aged,Panic,Panic Disorder,Panic Disorder: physiopathology,Panic: physiology},
  file = {/Users/brownsarahm/Zotero/storage/TMS4M9PT/Feinstein et al. - 2013 - Fear and panic in humans with bilateral amygdala damage(3).pdf}
}

@article{feldman2010attention,
  title = {Attention, Uncertainty, and Free-Energy},
  author = {Feldman, Harriet and Friston, Karl},
  year = {2010},
  journal = {Frontiers in human neuroscience},
  volume = {4},
  pages = {215}
}

@inproceedings{feldman2015certifying,
  title = {Certifying and Removing Disparate Impact},
  booktitle = {Proceedings of the 21th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Feldman, Michael and Friedler, Sorelle A and Moeller, John and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  year = {2015},
  pages = {259--268},
  publisher = {ACM}
}

@article{feldman2017coresets,
  title = {Coresets for Differentially Private K-Means Clustering and Applications to Privacy in Mobile Sensor Networks},
  author = {Feldman, Dan and Xiang, Chongyuan and Zhu, Ruihao and Rus, Daniela},
  year = {2017},
  journal = {Proceedings of the 16th ACM/IEEE International Conference on Information Processing in Sensor Networks - IPSN '17},
  pages = {3--15},
  doi = {10.1145/3055031.3055090},
  abstract = {Mobile sensor networks are a great source of data. By collecting data with mobile sensor nodes from individuals in a user community, e.g. using their smartphones, we can learn global information such as traac congestion paaerns in the city, location of key community facilities, and locations of gathering places. Can we publish and run queries on mobile sensor network databases without disclosing information about individual nodes? Diierential privacy is a strong notion of privacy which guaran-tees that very liile will be learned about individual records in the database, no maaer what the aaackers already know or wish to learn. Still, there is no practical system applying diierential pri-vacy algorithms for clustering points on real databases. .is paper describes the construction of small coresets for computing k-means clustering of a set of points while preserving diierential privacy. As a result, we give the erst k-means clustering algorithm that is both diierentially private, and has an approximation error that depends sub-linearly on the data's dimension d. Previous results introduced errors that are exponential in d. We implemented this algorithm and used it to create diierentially private location data from GPS tracks. Speciically our algorithm al-lows clustering GPS databases generated from mobile nodes, while leeing the user control the introduced noise due to privacy. We provide experimental results for the system and algorithms, and compare them to existing techniques. To the best of our knowledge, this is the erst practical system that enables diierentially private clustering on real data.},
  keywords = {2017,acm reference format,and daniela rus,chongyuan xiang,coresets,Coresets,dan feldman,di erential privacy,differential privacy,mobile sensor netw,mobile sensor networks,ruihao zhu},
  file = {/Users/brownsarahm/Zotero/storage/IE3U4JLX/Feldman et al. - 2017 - Coresets for differentially private k-means clustering and applications to privacy in mobile sensor networks.pdf}
}

@article{feldmananother,
  title = {Another {{Riesz Representation Theorem}}},
  author = {Feldman, Joel},
  number = {i},
  pages = {1--5},
  file = {/Users/brownsarahm/Zotero/storage/XY8FPIKU/Feldman - Unknown - Another Riesz Representation Theorem(3).pdf}
}

@article{ferrara2023Fairness,
  ids = {ferrara2023Fairnessa},
  title = {Fairness and Bias in Artificial Intelligence: {{A}} Brief Survey of Sources, Impacts, and Mitigation Strategies},
  author = {Ferrara, Emilio},
  year = {2023},
  journal = {Sci},
  volume = {6},
  number = {1},
  pages = {3},
  publisher = {MDPI},
  issn = {2413-4155}
}

@article{ferstl2008extended,
  title = {The Extended Language Network: A Meta-Analysis of Neuroimaging Studies on Text Comprehension},
  author = {Ferstl, Evelyn C and Neumann, Jane and Bogler, Carsten and Von Cramon, D Yves},
  year = {2008},
  journal = {Human brain mapping},
  volume = {29},
  number = {5},
  pages = {581--593}
}

@article{figueroa2012predicting,
  title = {Predicting Sample Size Required for Classification Performance.},
  author = {Figueroa, Rosa L and {Zeng-Treitler}, Qing and Kandula, Sasikiran and Ngo, Long H},
  year = {2012},
  month = jan,
  journal = {BMC medical informatics and decision making},
  volume = {12},
  number = {1},
  pages = {8},
  issn = {1472-6947},
  doi = {10.1186/1472-6947-12-8},
  abstract = {BACKGROUND: Supervised learning methods need annotated data in order to generate efficient models. Annotated data, however, is a relatively scarce resource and can be expensive to obtain. For both passive and active learning methods, there is a need to estimate the size of the annotated sample required to reach a performance target. METHODS: We designed and implemented a method that fits an inverse power law model to points of a given learning curve created using a small annotated training set. Fitting is carried out using nonlinear weighted least squares optimization. The fitted model is then used to predict the classifier's performance and confidence interval for larger sample sizes. For evaluation, the nonlinear weighted curve fitting method was applied to a set of learning curves generated using clinical text and waveform classification tasks with active and passive sampling methods, and predictions were validated using standard goodness of fit measures. As control we used an un-weighted fitting method. RESULTS: A total of 568 models were fitted and the model predictions were compared with the observed performances. Depending on the data set and sampling method, it took between 80 to 560 annotated samples to achieve mean average and root mean squared error below 0.01. Results also show that our weighted fitting method outperformed the baseline un-weighted method (p {\textbackslash}textless 0.05). CONCLUSIONS: This paper describes a simple and effective sample size prediction algorithm that conducts weighted fitting of learning curves. The algorithm outperformed an un-weighted algorithm described in previous literature. It can help researchers determine annotation sample size for supervised machine learning.},
  pmid = {22336388},
  keywords = {Algorithms,Automated,Computer-Assisted,Data Interpretation,Diagnosis,Humans,Learning Curve,Models,Nonlinear Dynamics,Pattern Recognition,Predictive Value of Tests,Probability Learning,Problem-Based Learning,Problem-Based Learning: methods,Reproducibility of Results,Sample Size,Statistical,Stochastic Processes},
  file = {/Users/brownsarahm/Zotero/storage/X66J36GE/Figueroa et al. - 2012 - Predicting sample size required for classification performance(3).pdf}
}

@article{finlay2015developmental,
  title = {Developmental Mechanisms Channeling Cortical Evolution},
  author = {Finlay, Barbara L. and Uchiyama, Ryutaro},
  year = {2015},
  journal = {Trends in Neurosciences},
  volume = {38},
  number = {2},
  pages = {69--76},
  issn = {01662236},
  doi = {10.1016/j.tins.2014.11.004},
  keywords = {axon arborization,cerebral cortex,evo-devo,rostrocaudal,topography},
  file = {/Users/brownsarahm/Zotero/storage/QBSHWBB8/Finlay, Uchiyama - 2015 - Developmental mechanisms channeling cortical evolution(3).pdf}
}

@article{fisher1936use,
  title = {The Use of Multiple Measurements in Taxonomic Problems},
  author = {Fisher, Ronald A},
  year = {1936},
  journal = {Annals of human genetics},
  volume = {7},
  number = {2},
  pages = {179--188}
}

@article{fitzgerald2012visual,
  title = {Visual Categorization and the Parietal Cortex},
  author = {Fitzgerald, Jamie K and Swaminathan, Sruthi K and Freedman, David J},
  year = {2012},
  journal = {Frontiers in Integrative Neuroscience},
  volume = {6},
  number = {18}
}

@misc{flood2020Integrated,
  title = {Integrated {{Public Use Microdata Series}}, {{Current Population Survey}}: {{Version}} 8.0 [Dataset].},
  author = {Flood, Sarah and King, Miriam and Rodgers, Renae and Ruggles, Steven and Warren, J.Robert},
  year = {2020},
  address = {Minneapolis, MN}
}

@book{fodor1983modularity,
  title = {The Modularity of Mind: {{An}} Essay on Faculty Psychology},
  author = {Fodor, Jerry A},
  year = {1983},
  publisher = {MIT press}
}

@inproceedings{fogliato2020Fairness,
  title = {Fairness Evaluation in Presence of Biased Noisy Labels},
  booktitle = {International Conference on Artificial Intelligence and Statistics},
  author = {Fogliato, Riccardo and Chouldechova, Alexandra and G'Sell, Max},
  year = {2020},
  pages = {2325--2336},
  publisher = {PMLR}
}

@article{fornito2012competitive,
  title = {Competitive and Cooperative Dynamics of Large-Scale Brain Functional Networks Supporting Recollection},
  author = {Fornito, Alex and Harrison, Ben J and Zalesky, Andrew and Simons, Jon S},
  year = {2012},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {109},
  number = {31},
  pages = {12788--12793}
}

@article{fornito2015connectomics,
  title = {The Connectomics of Brain Disorders},
  author = {Fornito, Alex and Zalesky, Andrew and Breakspear, Michael},
  year = {2015},
  journal = {Nature Publishing Group},
  volume = {16},
  number = {3},
  pages = {159--172},
  issn = {1471-003X},
  doi = {10.1038/nrn3901},
  file = {/Users/brownsarahm/Zotero/storage/CQARWCN9/Fornito, Zalesky, Breakspear - 2015 - The connectomics of brain disorders(3).pdf}
}

@inproceedings{foulds2020Intersectional,
  title = {An Intersectional Definition of Fairness},
  booktitle = {2020 {{IEEE}} 36th {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  author = {Foulds, James R and Islam, Rashidul and Keya, Kamrun Naher and Pan, Shimei},
  year = {2020},
  pages = {1918--1921},
  publisher = {IEEE},
  isbn = {1-72812-903-6}
}

@techreport{foundation2012smart,
  title = {Smart {{Health}} and {{Wellbeing PROGRAM SOLICITATION NSF}}},
  author = {Foundation, National Science},
  year = {2012},
  pages = {1--12},
  file = {/Users/brownsarahm/Zotero/storage/W8SHHTRH/Foundation - 2012 - Smart Health and Wellbeing PROGRAM SOLICITATION NSF(3).pdf}
}

@article{fox2010bayesian,
  title = {Bayesian {{Nonparametric Inference}} of {{Switching Linear Dynamical Systems}}},
  author = {Fox, Emily B and Sudderth, Erik B and Jordan, Michael I and Willsky, Alan S},
  year = {2010},
  journal = {Electrical Engineering},
  volume = {21},
  number = {4},
  pages = {50},
  issn = {1053-587X},
  doi = {10.1109/TSP.2010.2102756},
  abstract = {Many complex dynamical phenomena can be effectively modeled by a system that switches among a set of conditionally linear dynamical modes. We consider two such models: the switching linear dynamical system (SLDS) and the switching vector autoregressive (VAR) process. Our Bayesian nonparametric approach utilizes a hierarchical Dirichlet process prior to learn an unknown number of persistent, smooth dynamical modes. We additionally employ automatic relevance determination to infer a sparse set of dynamic dependencies allowing us to learn SLDS with varying state dimension or switching VAR processes with varying autoregressive order. We develop a sampling algorithm that combines a truncated approximation to the Dirichlet process with efficient joint sampling of the mode and state sequences. The utility and flexibility of our model are demonstrated on synthetic data, sequences of dancing honey bees, the IBOVESPA stock index, and a maneuvering target tracking application.},
  file = {/Users/brownsarahm/Zotero/storage/X4U5TPB7/Fox et al. - 2010 - Bayesian Nonparametric Inference of Switching Linear Dynamical Systems(2).pdf}
}

@inproceedings{fox2012multiresolution,
  title = {Multiresolution {{Gaussian Processes}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 25},
  author = {Fox, Emily B and Dunson, David B},
  editor = {Pereira, F and Burges, C J C and Bottou, L and Weinberger, K Q},
  year = {2012},
  pages = {737--745},
  publisher = {Curran Associates, Inc.},
  file = {/Users/brownsarahm/Zotero/storage/AMXTZMKT/Fox, Dunson - Unknown - Multiresolution Gaussian Processes(2).pdf}
}

@article{frank2010uci,
  title = {{{UCI Machine Learning Repository}} [{{http://archive.}} Ics. Uci. Edu/Ml]. {{Irvine}}, {{CA}}: {{University}} of {{California}}},
  author = {Frank, Andrew and Asuncion, Arthur},
  year = {2010},
  journal = {School of information and computer science},
  volume = {213}
}

@inproceedings{freitas1998objective,
  title = {On Objective Measures of Rule Surprisingness},
  booktitle = {European {{Symposium}} on {{Principles}} of {{Data Mining}} and {{Knowledge Discovery}}},
  author = {Freitas, Alex A},
  year = {1998},
  pages = {1--9},
  publisher = {Springer},
  file = {/Users/brownsarahm/Zotero/storage/CPAX8AR2/Freitas - 1998 - On objective measures of rule surprisingness.pdf;/Users/brownsarahm/Zotero/storage/RM4GGJ9E/Freitas - 1998 - On objective measures of rule surprisingness.pdf}
}

@article{friedler2016im,
  title = {On the (Im)Possibility of Fairness},
  author = {Friedler, Sorelle A. and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  year = {2016},
  number = {im},
  pages = {1--16},
  abstract = {What does it mean for an algorithm to be fair? Different papers use different notions of algorithmic fairness, and although these appear internally consistent, they also seem mutually incompatible. We present a mathematical setting in which the distinctions in previous papers can be made formal. In addition to characterizing the spaces of inputs (the "observed" space) and outputs (the "decision" space), we introduce the notion of a construct space: a space that captures unobservable, but meaningful variables for the prediction. We show that in order to prove desirable properties of the entire decision-making process, different mechanisms for fairness require different assumptions about the nature of the mapping from construct space to decision space. The results in this paper imply that future treatments of algorithmic fairness should more explicitly state assumptions about the relationship between constructs and observations.},
  file = {/Users/brownsarahm/Zotero/storage/RR67QGJF/Friedler, Scheidegger, Venkatasubramanian - 2016 - On the (im)possibility of fairness.pdf}
}

@inproceedings{friedler2019comparative,
  title = {A {{Comparative Study}} of {{Fairness-enhancing Interventions}} in {{Machine Learning}}},
  booktitle = {Proceedings of the {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Friedler, Sorelle A. and Scheidegger, Carlos and Venkatasubramanian, Suresh and Choudhary, Sonam and Hamilton, Evan P. and Roth, Derek},
  year = {2019},
  series = {{{FAT}}* '19},
  pages = {329--338},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/3287560.3287589},
  isbn = {978-1-4503-6125-5},
  keywords = {benchmarks,fairness-aware machine learning,Fairness-aware machine learning},
  file = {/Users/brownsarahm/Zotero/storage/7R4AYSX6/p329-Friedler.pdf}
}

@article{friedman2016analysis,
  title = {Analysis of Complex Neural Circuits with Nonlinear Multidimensional Hidden State Models},
  author = {Friedman, Alexander and Slocum, Joshua F. and Tyulmankov, Danil and Gibb, Leif G. and Altshuler, Alex and Ruangwises, Suthee and Shi, Qinru and Toro Arana, Sebastian E. and Beck, Dirk W. and Sholes, Jacquelyn E. C. and Graybiel, Ann M.},
  year = {2016},
  journal = {Proceedings of the National Academy of Sciences},
  pages = {201606280},
  issn = {0027-8424},
  doi = {10.1073/pnas.1606280113},
  pmid = {27222584},
  file = {/Users/brownsarahm/Zotero/storage/CG43PWPI/Friedman et al. - 2016 - Analysis of complex neural circuits with nonlinear multidimensional hidden state models(3).pdf}
}

@article{frigolabayesian,
  title = {Bayesian {{Inference}} and {{Learning}} in {{Gaussian Process State-Space Models}} with {{Particle MCMC}}},
  author = {Frigola, Roger and Lindsten, Fredrik and Sch, Thomas B},
  pages = {1--9},
  file = {/Users/brownsarahm/Zotero/storage/RNQSVJ7T/Frigola, Lindsten, Sch - Unknown - Bayesian Inference and Learning in Gaussian Process State-Space Models with Particle MCMC(3).pdf}
}

@article{friston2003dynamic,
  title = {Dynamic Causal Modelling},
  author = {Friston, K J and Harrison, L and Penny, W},
  year = {2003},
  month = aug,
  journal = {NeuroImage},
  volume = {19},
  number = {4},
  pages = {1273--1302},
  issn = {10538119},
  doi = {10.1016/S1053-8119(03)00202-7},
  keywords = {bilinear model,effective connectivity,fmri,functional neuroimaging,hemodynamic response function,nonlinear system identification}
}

@article{friston2009modalities,
  title = {Modalities, Modes, and Models in Functional Neuroimaging.},
  author = {Friston, Karl J},
  year = {2009},
  journal = {Science (New York, N.Y.)},
  volume = {326},
  pages = {399--403},
  issn = {0036-8075},
  doi = {10.1126/science.1174521},
  abstract = {In this, the 21st century, human-brain mapping celebrates 21 years of cognitive activation studies. This review looks at imaging neuroscience and key ideas it has pursued; some ideas portend exciting developments, and others have failed gloriously. In terms of achievements, there is much to celebrate, in the sense that it is difficult to imagine modern neuroscience without brain imaging. I will look at recent advances from the perspectives of functional segregation and integration in the brain, paying special attention to approaches that deal with the distributed and integrated nature of neuronal processing and the questions they address.},
  pmid = {19833961},
  file = {/Users/brownsarahm/Zotero/storage/Y3DWPJPZ/Friston - 2009 - Modalities, modes, and models in functional neuroimaging(3).pdf}
}

@article{friston2014nodes,
  title = {On Nodes and Modes in Resting State {{fMRI}}.},
  author = {Friston, Karl J and Kahan, Joshua and Razi, Adeel and Stephan, Klaas Enno and Sporns, Olaf},
  year = {2014},
  journal = {NeuroImage},
  volume = {99},
  eprint = {24862075},
  eprinttype = {pubmed},
  pages = {533--547},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2014.05.056},
  abstract = {This paper examines intrinsic brain networks in light of recent developments in the characterisation of resting state fMRI timeseries - and simulations of neuronal fluctuations based upon the connectome. Its particular focus is on patterns or modes of distributed activity that underlie functional connectivity. We first demonstrate that the eigenmodes of functional connectivity - or covariance among regions or nodes - are the same as the eigenmodes of the underlying effective connectivity, provided we limit ourselves to symmetrical connections. This symmetry constraint is motivated by appealing to proximity graphs based upon multidimensional scaling. Crucially, the principal modes of functional connectivity correspond to the dynamically unstable modes of effective connectivity that decay slowly and show long term memory. Technically, these modes have small negative Lyapunov exponents that approach zero from below. Interestingly, the superposition of modes - whose exponents are sampled from a power law distribution - produces classical 1/f (scale free) spectra. We conjecture that the emergence of dynamical instability - that underlies intrinsic brain networks - is inevitable in any system that is separated from external states by a Markov blanket. This conjecture appeals to a free energy formulation of nonequilibrium steady-state dynamics. The common theme that emerges from these theoretical considerations is that endogenous fluctuations are dominated by a small number of dynamically unstable modes. We use this as the basis of a dynamic causal model (DCM) of resting state fluctuations - as measured in terms of their complex cross spectra. In this model, effective connectivity is parameterised in terms of eigenmodes and their Lyapunov exponents - that can also be interpreted as locations in a multidimensional scaling space. Model inversion provides not only estimates of edges or connectivity but also the topography and dimensionality of the underlying scaling space. Here, we focus on conceptual issues with simulated fMRI data and provide an illustrative application using an empirical multi-region timeseries.},
  pmid = {24862075},
  keywords = {Bayesian,Criticality,dynamic causal modelling,Dynamic causal modelling,effective connectivity,Effective connectivity,fMRI,Free energy,functional connectivity,Functional connectivity,Lyapunov exponents,Proximity graph,Resting state,Self-organisation},
  file = {/Users/brownsarahm/Zotero/storage/N3U9I7HR/Friston et al. - 2014 - On nodes and modes in resting state fMRI(3).pdf}
}

@inproceedings{froelich2013mining,
  title = {Mining Association Rules from Database Tables with the Instances of {{Simpson}}'s Paradox},
  booktitle = {Advances in {{Databases}} and {{Information Systems}}},
  author = {Froelich, Wojciech},
  year = {2013},
  pages = {79--90},
  publisher = {Springer}
}

@article{frongillo2015elicitation,
  title = {On {{Elicitation Complexity}} and {{Conditional Elicitation}}},
  author = {Frongillo, Rafael and Kash, Ian A.},
  year = {2015},
  pages = {1--9},
  abstract = {Elicitation is the study of statistics or properties which are computable via empirical risk minimization. While several recent papers have approached the general question of which properties are elicitable, we suggest that this is the wrong question---all properties are elicitable by first eliciting the entire distribution or data set, and thus the important question is how elicitable. Specifically, what is the minimum number of regression parameters needed to compute the property? Building on previous work, we introduce a new notion of elicitation complexity and lay the foundations for a calculus of elicitation. We establish several general results and techniques for proving upper and lower bounds on elicitation complexity. These results provide tight bounds for eliciting the Bayes risk of any loss, a large class of properties which includes spectral risk measures and several new properties of interest. Finally, we extend our calculus to conditionally elicitable properties, which are elicitable conditioned on knowing the value of another property, giving a necessary condition for the elicitability of both properties together.},
  file = {/Users/brownsarahm/Zotero/storage/EPBEJ2IX/5832-on-elicitation-complexity.pdf;/Users/brownsarahm/Zotero/storage/G4VJSTWC/5832-on-elicitation-complexity.pdf;/Users/brownsarahm/Zotero/storage/V4IXXKX5/5832-on-elicitation-complexity.pdf}
}

@article{frongillo2016open,
  title = {Open {{Problem}}: {{Property Elicitation}} and {{Elicitation Complexity CU Boulder Microsoft Research}}},
  author = {Frongillo, Rafael and Kash, Ian A and Becker, Stephen},
  year = {2016},
  volume = {49},
  number = {2015},
  pages = {1--4},
  abstract = {The study of property elicitation is gaining ground in statistics and machine learning as a way to view and reason about the expressive power of emiprical risk minimization (ERM). Yet beyond a widening frontier of special cases, the two most fundamental questions in this area remain open: which statistics are elicitable (computable via ERM), and which loss functions elicit them? Moreover , recent work suggests a complementary line of questioning: given a statistic, how many ERM parameters are needed to compute it? We give concrete instantiations of these important questions, which have numerous applications to machine learning and related fields.},
  keywords = {empirical risk minimization,Property elicitation},
  file = {/Users/brownsarahm/Zotero/storage/2RXRC58E/frongillo16.pdf;/Users/brownsarahm/Zotero/storage/3ZT99WMS/frongillo16.pdf;/Users/brownsarahm/Zotero/storage/H787ANLW/frongillo16.pdf}
}

@article{fukumizu2004dimensionality,
  title = {Dimensionality Reduction for Supervised Learning with Reproducing Kernel {{Hilbert}} Spaces},
  author = {Fukumizu, Kenji and Bach, Francis R and Jordan, Michael I},
  year = {2004},
  journal = {The Journal of Machine Learning {\textbackslash}ldots},
  volume = {5},
  pages = {73--99},
  keywords = {conditional independence,dimensionality reduction,feature selection,kernel methods,regression,variable selection},
  file = {/Users/brownsarahm/Zotero/storage/A6ENKFCV/Fukumizu, Bach, Jordan - 2004 - Dimensionality Reduction for Supervised Learning with Reproducing Kernel Hilbert Spaces(2).pdf;/Users/brownsarahm/Zotero/storage/N5GU3TQF/Fukumizu, Bach, Jordan - 2004 - Dimensionality reduction for supervised learning with reproducing kernel Hilbert spaces(4).pdf}
}

@incollection{fukumizu2008kernel,
  title = {Kernel {{Measures}} of {{Conditional Dependence}}},
  author = {Fukumizu, K. and Gretton, A. and Sun, X. and Sch{\"o}lkopf, B.},
  year = {2008},
  pages = {1--13},
  abstract = {We propose a new measure of conditional dependence of random variables, based on normalized cross-covariance operators on reproducing kernel Hilbert spaces. Unlike previous kernel dependence measures, the proposed criterion does not depend on the choice of kernel in the limit of infinite data, for a wide class of kernels. At the same time, it has a straightforward empirical estimate with good convergence behaviour. We discuss the theoretical properties of the measure, and demonstrate its application in experiments.},
  isbn = {978-1-60560-352-0},
  keywords = {Brain Computer Interfaces,Computational,Information-Theoretic Learning with Statistics,Learning/Statistics \& Optimisation,Theory \& Algorithms},
  file = {/Users/brownsarahm/Zotero/storage/UGIYKCJ8/Fukumizu et al. - 2008 - Kernel Measures of Conditional Dependence(3).pdf}
}

@article{fyshe2014interpretable,
  title = {Interpretable {{Semantic Vectors}} from a {{Joint Model}} of {{Brain-and Text-Based Meaning}}},
  author = {Fyshe, Alona and Talukdar, Pp and Murphy, Brian and Mitchell, Tm},
  year = {2014},
  journal = {Cs.Cmu.Edu},
  file = {/Users/brownsarahm/Zotero/storage/NNG9F279/Fyshe et al. - 2014 - Interpretable Semantic Vectors from a Joint Model of Brain-and Text-Based Meaning(3).pdf}
}

@book{g.dallaglios.kotzadvances,
  title = {Advances in {{Probability Distributions}} with {{Given Marginals}}},
  author = {G. Dall'Aglio, S. Kotz, G.Dalinetti},
  volume = {ث ققثق},
  isbn = {978-94-010-5534-5}
}

@inproceedings{gao2016learnability,
  title = {Learnability of Non-Iid},
  booktitle = {Asian Conference on Machine Learning},
  author = {Gao, Wei and Niu, Xin-Yi and Zhou, Zhi-Hua},
  year = {2016},
  pages = {158--173}
}

@article{garcia-laencina2009pattern,
  title = {Pattern Classification with Missing Data: A Review},
  author = {{Garc{\'i}a-Laencina}, Pedro J. and {Sancho-G{\'o}mez}, Jos{\'e}-Luis and {Figueiras-Vidal}, An{\'i}bal R.},
  year = {2009},
  month = sep,
  journal = {Neural Computing and Applications},
  volume = {19},
  number = {2},
  pages = {263--282},
  issn = {0941-0643},
  doi = {10.1007/s00521-009-0295-6},
  keywords = {data {\'a},learning,neural networks {\'a} machine,pattern classification {\'a} missing}
}

@inproceedings{garrett2020More,
  ids = {garrett2020Morea,garrett2020Moreb},
  title = {More than" {{If Time Allows}}" the Role of Ethics in {{AI}} Education},
  booktitle = {Proceedings of the {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {Garrett, Natalie and Beard, Nathan and Fiesler, Casey},
  year = {2020},
  pages = {272--278}
}

@article{garthwaite2005statistical,
  title = {Statistical Methods for Eliciting Probability Distributions},
  author = {Garthwaite, Paul H. and Kadane, Joseph B. and O'Hagan, Anthony},
  year = {2005},
  journal = {Journal of the American Statistical Association},
  volume = {100},
  number = {470},
  pages = {680--700},
  issn = {01621459},
  doi = {10.1198/016214505000000105},
  abstract = {Elicitation is a key task for subjectivist Bayesians. Although skeptics hold that elicitation cannot (or perhaps should not) be done, in practice it brings statisticians closer to their clients and subject-matter expert colleagues. This article reviews the state of the art, reflecting the experience of statisticians informed by the fruits of a long line of psychological research into how people represent uncertain information cognitively and how they respond to questions about that information. In a discussion of the elicitation process, the first issue to address is what it means for an elicitation to be successful; that is, what criteria should be used. Our answer is that a successful elicitation faithfully represents the opinion of the person being elicited. It is not necessarily "true" in some objectivistic sense, and cannot be judged in that way. We see that elicitation as simply part of the process of statistical modeling. Indeed, in a hierarchical model at which point the likelihood ends and the prior begins is ambiguous. Thus the same kinds of judgment that inform statistical modeling in general also inform elicitation of prior distributions. The psychological literature suggests that people are prone to certain heuristics and biases in how they respond to situations involving uncertainty. As a result, some of the ways of asking questions about uncertain quantities are preferable to others, and appear to be more reliable. However, data are lacking on exactly how well the various methods work, because it is unclear, other than by asking using an elicitation method, just what the person believes. Consequently, one is reduced to indirect means of assessing elicitation methods. The tool chest of methods is growing. Historically, the first methods involved choosing hyperparameters using conjugate prior families, at a time when these were the only families for which posterior distributions could be computed. Modern computational methods, such as Markov chain Monte Carlo, have freed elicitation from this constraint. As a result, now both parametric and nonparametric methods are available for low-dimensional problems. High-dimensional problems are probably best thought of as lacking another hierarchical level, which has the effect of reducing the as-yet-unelicited parameter space. Special considerations apply to the elicitation of group opinions. Informal methods, such as Delphi, encourage the participants to discuss the issue in the hope of reaching consensus. Formal methods, such as weighted averages or logarithmic opinion pools, each have mathematical characteristics that are uncomfortable. Finally, there is the question of what a group opinion even means, because it is not necessarily the opinion of any participant.},
  keywords = {Bayesian,Group decision,Heuristics and biases,Prior distribution,Subjective probability}
}

@article{garthwaite2008use,
  title = {Use of Expert Knowledge in Evaluating Costs and Benefits of Alternative Service Provisions: {{A}} Case Study},
  author = {Garthwaite, Paul H. and Chilcott, James B. and Jenkinson, David J. and Tappenden, Paul},
  year = {2008},
  journal = {International Journal of Technology Assessment in Health Care},
  volume = {24},
  number = {3},
  pages = {350--357},
  issn = {02664623},
  doi = {10.1017/S026646230808046X},
  abstract = {{\textbackslash}textlessp{\textbackslash}textgreater {\textbackslash}textlessbold{\textbackslash}textgreaterObjectives:{\textbackslash}textless/bold{\textbackslash}textgreater A treatment pathway model was developed to examine the costs and benefits of the current bowel cancer service in England and to evaluate potential alternatives in service provision. To use the pathway model, various parameters and probability distributions had to be specified. They could not all be determined from empirical evidence and, instead, expert opinion was elicited in the form of statistical quantities that gave the required information. The purpose of this study is to describe the procedures used to quantify expert opinion and note examples of good practice contained in the case study. {\textbackslash}textless/p{\textbackslash}textgreater},
  pmid = {18601804},
  keywords = {Colorectal cancer,Elicitation,Expert opinion,Probability assessment,Subjective probability},
  file = {/Users/brownsarahm/Zotero/storage/WAU3CNXH/Garthwaite et al. - 2008 - Use of expert knowledge in evaluating costs and benefits of alternative service provisions A case study.pdf}
}

@article{gebru2018Datasheets,
  title = {Datasheets for {{Datasets}}},
  author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Daume{\'e}, Hal and Crawford, Kate},
  year = {2018},
  journal = {arXiv},
  volume = {64},
  number = {12},
  pages = {86--92},
  abstract = {Currently there is no standard way to identify how a dataset was created, and what characteristics, motivations, and potential skews it represents. To begin to address this issue, we propose the concept of a datasheet for datasets, a short document to accompany public datasets, commercial APIs, and pretrained models. The goal of this proposal is to enable better communication between dataset creators and users, and help the AI community move toward greater transparency and accountability. By analogy, in computer hardware, it has become industry standard to accompany everything from the simplest components (e.g., resistors), to the most complex microprocessor chips, with datasheets detailing standard operating characteristics, test results, recommended usage, and other information. We outline some of the questions a datasheet for datasets should answer. These questions focus on when, where, and how the training data was gathered, its recommended use cases, and, in the case of human-centric datasets, information regarding the subjects' demographics and consent as applicable. We develop prototypes of datasheets for two well-known datasets: Labeled Faces in The Wild and the Pang \${\textbackslash}backslash\$\& Lee Polarity Dataset.},
  file = {/Users/brownsarahm/Zotero/storage/SSYPKUJJ/datasheets.pdf}
}

@article{gelfand2009analysis,
  title = {Analysis of {{Marked Point Patterns}} with {{Spatial}} and {{Nonspatial Covariate Information}}},
  author = {Gelfand, A E and Le, S and Carlin, B P},
  year = {2009},
  journal = {Annals of Applied Statistics},
  volume = {3},
  pages = {943--962}
}

@article{gelman1996posterior,
  title = {Posterior Predictive Assessment of Model Fitness via Realized Discrepancies},
  author = {Gelman, Andrew and Meng, {\relax XL} and Stern, Hal},
  year = {1996},
  journal = {Statistica Sinica},
  volume = {6},
  pages = {733--807},
  keywords = {{$\chi$} 2 test,and phrases,bayesian p-value,discrepancy,graphical assess-,ment,mixture model,model criticism,p-value,posterior predictive p-value,prior predictive,realized discrepancy},
  file = {/Users/brownsarahm/Zotero/storage/CYJFAI85/Gelman, Meng, Stern - 1996 - Posterior predictive assessment of model fitness via realized discrepancies(3).pdf}
}

@article{gelman2012twothousand,
  title = {``{{Two-thousand}} Years of Stasis'': {{How}} Psychological Essentialism Impedes Evolutionary Understanding},
  author = {Gelman, Susan A and Rhodes, Marjorie},
  year = {2012},
  journal = {Evolution challenges: Integrating research and practice in teaching and learning about evolution},
  pages = {3}
}

@misc{gennarelli2017How,
  title = {How to Grade Programming Assignments on {{GitHub}}},
  author = {Gennarelli, Vanessa},
  year = {2017},
  month = jun,
  journal = {The GitHub Blog},
  urldate = {2020-09-01}
}

@inproceedings{george2008hybrid,
  title = {A {{Hybrid Wavelet Kernel Construction}} for {{Support Vector Machine Classification}}.},
  booktitle = {{{DMIN}}},
  author = {George, Jose and Kumaraswamy, Rajeev},
  year = {2008},
  volume = {0},
  pages = {96--101},
  isbn = {1-60132-062-0},
  keywords = {admissible kernel,and it satisfies the,hybrid wavelet kernel,hybrid wavelet kernel using,machine,multidimensional orthogonal sinc wavelet,support vector machine,the,wavelet support vector,we construct a new},
  file = {/Users/brownsarahm/Zotero/storage/QVXEX7WX/George, Kumaraswamy - 2008 - A Hybrid Wavelet Kernel Construction for Support Vector Machine Classification(3).pdf}
}

@article{gershman2012tutorial,
  title = {A Tutorial on {{Bayesian}} Nonparametric Models},
  author = {Gershman, Samuel J. and Blei, David M.},
  year = {2012},
  journal = {Journal of Mathematical Psychology},
  volume = {56},
  number = {1},
  pages = {1--12},
  issn = {00222496},
  doi = {10.1016/j.jmp.2011.08.004},
  abstract = {A key problem in statistical modeling is model selection, that is, how to choose a model at an appropriate level of complexity. This problem appears in many settings, most prominently in choosing the number of clusters in mixture models or the number of factors in factor analysis. In this tutorial, we describe Bayesian nonparametric methods, a class of methods that side-steps this issue by allowing the data to determine the complexity of the model. This tutorial is a high-level introduction to Bayesian nonparametric methods and contains several examples of their application. ?? 2011 Elsevier Inc.},
  keywords = {Bayesian methods,Chinese restaurant process,Indian buffet process},
  file = {/Users/brownsarahm/Zotero/storage/QD8NDVKC/Gershman, Blei - 2012 - A tutorial on Bayesian nonparametric models(2).pdf}
}

@article{ghadimi2013optimal,
  title = {Optimal Parameter Selection for the Alternating Direction Method of Multipliers ({{ADMM}}): Quadratic Problems},
  author = {Ghadimi, Euhanna and Teixeira, A},
  year = {2013},
  journal = {arXiv preprint arXiv: {\textbackslash}ldots},
  pages = {1--27},
  issn = {00189286},
  doi = {10.1109/TAC.2014.2354892},
  abstract = {The alternating direction method of multipliers (ADMM) has emerged as a powerful technique for large-scale structured optimization. Despite many recent results on the convergence properties of ADMM, a quantitative characterization of the impact of the algorithm parameters on the convergence times of the method is still lacking. In this paper we find the optimal algorithm parameters that minimize the convergence factor of the ADMM iterates in the context of l2-regularized minimization and constrained quadratic programming. Numerical examples show that our parameter selection rules significantly outperform existing alternatives in the literature.},
  file = {/Users/brownsarahm/Zotero/storage/J4CDYH22/Ghadimi, Teixeira - 2013 - Optimal parameter selection for the alternating direction method of multipliers (ADMM) quadratic problems(3).pdf}
}

@article{ghahramani2002graphical,
  title = {Graphical Models: Parameter Learning},
  author = {Ghahramani, Zoubin},
  year = {2002},
  journal = {Neuroscience},
  volume = {1},
  pages = {1--305},
  doi = {10.1561/2200000001},
  keywords = {BRAIN,learning,MODEL,models,Theories},
  file = {/Users/brownsarahm/Zotero/storage/333H4GCX/Ghahramani - 2002 - Graphical models parameter learning(3).pdf}
}

@article{ghahramani2003bayesian,
  title = {Bayesian Classifier Combination},
  author = {Ghahramani, Z and Kim, {\relax HC}},
  year = {2003},
  file = {/Users/brownsarahm/Zotero/storage/MYVZ9W8A/Ghahramani, Kim - 2003 - Bayesian classifier combination(3).pdf}
}

@article{ghassemi2018opportunities,
  title = {Opportunities in {{Machine Learning}} for {{Healthcare}}},
  author = {Ghassemi, Marzyeh and Naumann, Tristan and Schulam, Peter and Beam, Andrew L. and Ranganath, Rajesh},
  year = {2018},
  abstract = {Healthcare is a natural arena for the application of machine learning, especially as modern electronic health records (EHRs) provide increasingly large amounts of data to answer clinically meaningful questions. However, clinical data and practice present unique challenges that complicate the use of common methodologies. This article serves as a primer on addressing these challenges and highlights opportunities for members of the machine learning and data science communities to contribute to this growing domain.}
}

@article{ghazanfar2006neocortex,
  title = {Is Neocortex Essentially Multisensory?},
  author = {{\noopsort{ghazanfar}}a Ghazanfar, Asif and Schroeder, Charles E},
  year = {2006},
  month = jun,
  journal = {Trends in cognitive sciences},
  volume = {10},
  number = {6},
  eprint = {16713325},
  eprinttype = {pubmed},
  pages = {278--285},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2006.04.008},
  abstract = {Although sensory perception and neurobiology are traditionally investigated one modality at a time, real world behaviour and perception are driven by the integration of information from multiple sensory sources. Mounting evidence suggests that the neural underpinnings of multisensory integration extend into early sensory processing. This article examines the notion that neocortical operations are essentially multisensory. We first review what is known about multisensory processing in higher-order association cortices and then discuss recent anatomical and physiological findings in presumptive unimodal sensory areas. The pervasiveness of multisensory influences on all levels of cortical processing compels us to reconsider thinking about neural processing in unisensory terms. Indeed, the multisensory nature of most, possibly all, of the neocortex forces us to abandon the notion that the senses ever operate independently during real-world cognition.},
  pmid = {16713325},
  keywords = {Animals,Brain Mapping,Humans,Mental Processes,Mental Processes: physiology,Neocortex,Neocortex: physiology,Neural Pathways,Neural Pathways: physiology,Sensation,Sensation: physiology}
}

@article{ghorbani2019Automatic,
  ids = {ghorbani2019Automatica},
  title = {Towards Automatic Concept-Based Explanations},
  author = {Ghorbani, Amirata and Wexler, James and Zou, James Y and Kim, Been},
  year = {2019},
  journal = {Advances in neural information processing systems},
  volume = {32}
}

@article{gianaros2015brainbody,
  title = {Brain-{{Body Pathways Linking Psychological Stress}} and {{Physical Health}}},
  author = {Gianaros, Peter J and Wager, Tor D},
  year = {2015},
  journal = {Current directions in psychological science},
  volume = {24},
  number = {4},
  pages = {313--321},
  file = {/Users/brownsarahm/Zotero/storage/ZJUH8WXH/zotero-better-bibtex-5.2.22.xpi}
}

@incollection{giancarlo2012stabilitybased,
  title = {Stability-Based Model Selection for High Throughput Genomic Data: An Algorithmic Paradigm},
  booktitle = {Artificial {{Immune Systems}}},
  author = {Giancarlo, Raffaele and Utro, Filippo},
  year = {2012},
  pages = {260--270},
  publisher = {Springer},
  file = {/Users/brownsarahm/Zotero/storage/FC633YSC/Giancarlo, Utro - 2012 - Stability-based model selection for high throughput genomic data an algorithmic paradigm(3).pdf}
}

@article{girardgaussian,
  title = {Gaussian {{Process Priors With Uncertain Inputs}} -- {{Application}} to {{Multiple-Step Ahead Time Series Forecasting}}},
  author = {Girard, Agathe and Rasmussen, Carl Edward and {Murray-smith}, Roderick},
  file = {/Users/brownsarahm/Zotero/storage/9FNCRGUG/Girard, Rasmussen, Murray-smith - Unknown - Gaussian Process Priors With Uncertain Inputs – Application to Multiple-Step Ahead Time(2).pdf}
}

@inproceedings{giraud-carrier1998predictive,
  title = {Beyond Predictive Accuracy: What?},
  booktitle = {Proceedings of the {{ECML-98 Workshop}} on {{Upgrading Learning}} to {{Meta-Level}}: {{Model Selection}} and {{Data Transformation}}},
  author = {{Giraud-Carrier}, Christophe},
  year = {1998},
  pages = {78--85}
}

@article{glasgow2023biophysical,
  ids = {glasgow2023Biophysical},
  title = {A Biophysical and Statistical Modeling Paradigm for Connecting Neural Physiology and Function},
  author = {Glasgow, Nathan G and Chen, Yu and Korngreen, Alon and Kass, Robert E and Urban, Nathan N},
  year = {2023},
  journal = {Journal of Computational Neuroscience},
  pages = {1--20},
  publisher = {Springer}
}

@article{goldfinger1998psychophysiologic,
  title = {Psychophysiologic Responses to the {{Rorschach}} in {{PTSD}} Patients, Noncombat and Combat Controls},
  author = {Goldfinger, David A and Amdur, Richard L and Liberzon, Israel},
  year = {1998},
  journal = {Depression and anxiety},
  volume = {8},
  number = {3},
  pages = {112--120}
}

@article{goldstein2015peeking,
  title = {Peeking {{Inside}} the {{Black Box}}: {{Visualizing Statistical Learning With Plots}} of {{Individual Conditional Expectation}}},
  author = {Goldstein, Alex and Kapelner, Adam and Bleich, Justin and Pitkin, Emil},
  year = {2015},
  journal = {Journal of Computational and Graphical Statistics},
  volume = {24},
  number = {1},
  pages = {44--65},
  issn = {15372715},
  doi = {10.1080/10618600.2014.907095},
  abstract = {This article presents Individual Conditional Expectation (ICE) plots, a tool for visualizing the model estimated by any supervised learning algorithm. Classical partial dependence plots (PDPs) help visualize the average partial relationship between the predicted response and one or more features. In the presence of substantial interaction effects, the partial response relationship can be heterogeneous. Thus, an average curve, such as the PDP, can obfuscate the complexity of the modeled relationship. Accordingly, ICE plots refine the partial dependence plot by graphing the functional relationship between the predicted response and the feature for individual observations. Specifically, ICE plots highlight the variation in the fitted values across the range of a covariate, suggesting where and to what extent heterogeneities might exist. In addition to providing a plotting suite for exploratory analysis, we include a visual test for additive structure in the data generating model. Through simulated examples and real data sets, we demonstrate how ICE plots can shed light on estimated models in ways PDPs cannot. Procedures outlined are available in the R package ICEbox.},
  keywords = {Exploratory data analysis,Graphical method,Model visualization}
}

@article{gonzalez-castillo2012wholebrain,
  title = {Whole-Brain, Time-Locked Activation with Simple Tasks Revealed Using Massive Averaging and Model-Free Analysis.},
  author = {{Gonzalez-Castillo}, Javier and Saad, Ziad S and {\noopsort{handwerker}}a Handwerker, Daniel and Inati, Souheil J and Brenowitz, Noah and {\noopsort{bandettini}}a Bandettini, Peter},
  year = {2012},
  month = apr,
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {109},
  number = {14},
  eprint = {22431587},
  eprinttype = {pubmed},
  pages = {5487--92},
  issn = {1091-6490},
  doi = {10.1073/pnas.1121049109},
  abstract = {The brain is the body's largest energy consumer, even in the absence of demanding tasks. Electrophysiologists report on-going neuronal firing during stimulation or task in regions beyond those of primary relationship to the perturbation. Although the biological origin of consciousness remains elusive, it is argued that it emerges from complex, continuous whole-brain neuronal collaboration. Despite converging evidence suggesting the whole brain is continuously working and adapting to anticipate and actuate in response to the environment, over the last 20 y, task-based functional MRI (fMRI) have emphasized a localizationist view of brain function, with fMRI showing only a handful of activated regions in response to task/stimulation. Here, we challenge that view with evidence that under optimal noise conditions, fMRI activations extend well beyond areas of primary relationship to the task; and blood-oxygen level-dependent signal changes correlated with task-timing appear in over 95\% of the brain for a simple visual stimulation plus attention control task. Moreover, we show that response shape varies substantially across regions, and that whole-brain parcellations based on those differences produce distributed clusters that are anatomically and functionally meaningful, symmetrical across hemispheres, and reproducible across subjects. These findings highlight the exquisite detail lying in fMRI signals beyond what is normally examined, and emphasize both the pervasiveness of false negatives, and how the sparseness of fMRI maps is not a result of localized brain function, but a consequence of high noise and overly strict predictive response models.},
  pmid = {22431587},
  keywords = {Brain,Brain: physiology,Humans,Magnetic Resonance Imaging,Models,Task Performance and Analysis,Theoretical}
}

@book{gonzalez2008digital,
  title = {Digital {{Image Procesing}}},
  author = {Gonzalez, R C and Woods, R E},
  year = {2008},
  edition = {Third},
  publisher = {Pearson Prentice Hall}
}

@book{goodger2007code,
  title = {Code {{Like}} a {{Pythonista}}: {{Idiomatic Python}}},
  author = {Goodger, David},
  year = {2007},
  urldate = {2016-11-03},
  file = {/Users/brownsarahm/Zotero/storage/4UGKDTXD/Goodger - 2007 - Code Like a Pythonista Idiomatic Python(3).html}
}

@misc{googleFairness,
  title = {Fairness {{Indicators}}},
  author = {{Google}},
  journal = {Fairness Indicator Tensorflow}
}

@misc{googleWhat,
  title = {What {{If Tool}}},
  author = {{Google}}
}

@article{gorgolewski2011nipype,
  title = {Nipype: A Flexible, Lightweight and Extensible Neuroimaging Data Processing Framework in Python.},
  author = {Gorgolewski, Krzysztof and Burns, Christopher D and Madison, Cindee and Clark, Dav and Halchenko, Yaroslav O and Waskom, Michael L and Ghosh, Satrajit S},
  year = {2011},
  journal = {Frontiers in neuroinformatics},
  volume = {5},
  number = {August},
  pages = {13},
  issn = {1662-5196},
  doi = {10.3389/fninf.2011.00013},
  abstract = {Current neuroimaging software offer users an incredible opportunity to analyze their data in different ways, with different underlying assumptions. Several sophisticated software packages (e.g., AFNI, BrainVoyager, FSL, FreeSurfer, Nipy, R, SPM) are used to process and analyze large and often diverse (highly multi-dimensional) data. However, this heterogeneous collection of specialized applications creates several issues that hinder replicable, efficient, and optimal use of neuroimaging analysis approaches: (1) No uniform access to neuroimaging analysis software and usage information; (2) No framework for comparative algorithm development and dissemination; (3) Personnel turnover in laboratories often limits methodological continuity and training new personnel takes time; (4) Neuroimaging software packages do not address computational efficiency; and (5) Methods sections in journal articles are inadequate for reproducing results. To address these issues, we present Nipype (Neuroimaging in Python: Pipelines and Interfaces; http://nipy.org/nipype), an open-source, community-developed, software package, and scriptable library. Nipype solves the issues by providing Interfaces to existing neuroimaging software with uniform usage semantics and by facilitating interaction between these packages using Workflows. Nipype provides an environment that encourages interactive exploration of algorithms, eases the design of Workflows within and between packages, allows rapid comparative development of algorithms and reduces the learning curve necessary to use different packages. Nipype supports both local and remote execution on multi-core machines and clusters, without additional scripting. Nipype is Berkeley Software Distribution licensed, allowing anyone unrestricted usage. An open, community-driven development philosophy allows the software to quickly adapt and address the varied needs of the evolving neuroimaging community, especially in the context of increasing demand for reproducible research.},
  pmid = {21897815},
  keywords = {data processing,neuroimaging,pipeline,python,reproducible research,workflow},
  file = {/Users/brownsarahm/Zotero/storage/F69CSTGH/Gorgolewski et al. - 2011 - Nipype a flexible, lightweight and extensible neuroimaging data processing framework in python(3).pdf}
}

@article{gosling2007nonparametric,
  title = {Nonparametric Elicitation for Heavy-Tailed Prior Distributions},
  author = {Gosling, John Paul and Oakley, Jeremy E. and O'Hagan, Anthony},
  year = {2007},
  journal = {Bayesian Analysis},
  volume = {2},
  number = {4},
  pages = {693--718},
  issn = {19360975},
  doi = {10.1214/07-BA228},
  abstract = {In the context of statistical analysis, elicitation is the process of translating someone's beliefs about some uncertain quantities into a probability distribution. The person's judgements about the quantities are usually fitted to some member of a convenient parametric family. This approach does not allow for the possibility that any number of distributions could fit the same judgements.},
  keywords = {Expert elicitation,Gaussian process,Heavy-tailed distribution,Non-parametric density estimation}
}

@book{gould1996mismeasure,
  title = {The Mismeasure of Man},
  author = {Gould, Stephen Jay},
  year = {1996},
  publisher = {WW Norton \& Company}
}

@article{GPBV19,
  title = {{{DPPy}}: {{DPP}} Sampling with Python},
  author = {Gautier, Guillaume and Polito, Guillermo and Bardenet, R{\'e}mi and Valko, Michal},
  year = {2019},
  journal = {Journal of Machine Learning Research - Machine Learning Open Source Software (JMLR-MLOSS)},
  archiveprefix = {arXiv},
  arxivid = {1809.07258},
  keywords = {Computer Science - Machine Learning,Computer Science - Mathematical Software,Statistics - Machine Learning}
}

@incollection{grant2008graph,
  title = {Graph Implementations for Nonsmooth Convex Programs},
  booktitle = {Recent {{Advances}} in {{Learning}} and {{Control}}},
  author = {Grant, Michael and Boyd, Stephen},
  editor = {Blondel, V and Boyd, S and Kimura, H},
  year = {2008},
  series = {Lecture {{Notes}} in {{Control}} and {{Information Sciences}}},
  pages = {95--110},
  publisher = {Springer-Verlag Limited}
}

@book{grant2014cvx,
  title = {{{CVX Matlab Software}} for {{Disciplined Convex Programming}}, Version 2.1},
  author = {Grant, Michael and Boyd, Stephen},
  year = {2014},
  month = mar,
  annotation = {Published: \${\textbackslash}backslash\$url\{http://cvxr.com/cvx\}}
}

@article{gratch2004domain,
  title = {A Domain Independent Framework for Modeling Emotion},
  author = {Gratch, Jonathan and Marsella, Stacy},
  year = {2004},
  journal = {Cognitive Systems Research},
  volume = {5},
  number = {4},
  pages = {269??306},
  file = {/Users/brownsarahm/Zotero/storage/GMPZDBM5/Gratch, Marsella - 2004 - A domain independent framework for modeling emotion(3).pdf}
}

@book{greblicki2008nonparametric,
  title = {Nonparametric System Identification},
  author = {Greblicki, W\${\textbackslash}backslash\$lodzimierz and Pawlak, Miros\${\textbackslash}backslash\$law},
  year = {2008},
  publisher = {Cambridge University Press Cambridge},
  file = {/Users/brownsarahm/Zotero/storage/X396P9WB/Unknown - 2007 - Nonparametric System Identification(2).pdf}
}

@inproceedings{green2020Algorithmic,
  ids = {10.1145/3351095.3372840},
  title = {Algorithmic Realism: {{Expanding}} the Boundaries of Algorithmic Thought},
  booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  author = {Green, Ben and Viljoen, Salom{\'e}},
  year = {2020},
  series = {{{FAT}}* '20},
  pages = {19--31},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3351095.3372840},
  isbn = {978-1-4503-6936-7},
  keywords = {algorithms,critical algorithm studies,epistemology,law,STS}
}

@article{greene2001fmri,
  title = {An {{fMRI}} Investigation of Emotional Engagement in Moral Judgment},
  author = {Greene, Joshua D and Sommerville, R Brian and Nystrom, Leigh E and Darley, John M and Cohen, Jonathan D},
  year = {2001},
  journal = {Science},
  volume = {293},
  number = {5537},
  pages = {2105--2108}
}

@article{greicius2004defaultmode,
  title = {Default-Mode Network Activity Distinguishes {{Alzheimer}}'s Disease from Healthy Aging: Evidence from Functional {{MRI}}},
  author = {Greicius, Michael D and Srivastava, Gaurav and Reiss, Allan L and Menon, Vinod},
  year = {2004},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {101},
  number = {3},
  pages = {4637--4642}
}

@article{greicius2009restingstate,
  title = {Resting-State Functional Connectivity Reflects Structural Connectivity in the Default Mode Network},
  author = {Greicius, Michael D and Kaustubh, Supekar and Menon, Vinod and Dougherty, Robert F},
  year = {2009},
  journal = {Cerebral Cortex},
  volume = {19},
  number = {1},
  pages = {72--78}
}

@article{gretton2005measuring,
  title = {Measuring {{Statistical Dependence}} with {{Hilbert-Schmidt Norms Measuring Statistical Dependence}} with {{Hilbert-Schmidt Norms}}},
  author = {Gretton, Arthur and Bousquet, Olivier and Sch, Bernhard and Smola, Alexander},
  year = {2005},
  journal = {PROCEEDINGS ALGORITHMIC LEARNING THEORY},
  pages = {63---77},
  file = {/Users/brownsarahm/Zotero/storage/NMQJ7376/Gretton et al. - 2005 - Measuring Statistical Dependence with Hilbert-Schmidt Norms Measuring Statistical Dependence with Hilbert-Sch(3).pdf}
}

@article{greve2009accurate,
  title = {Accurate and Robust Brain Image Alignment Using Boundary-Based Registration},
  author = {Greve, Douglas N and Fischl, Bruce},
  year = {2009},
  journal = {Neuroimage},
  volume = {48},
  number = {1},
  pages = {63--72}
}

@article{griffiths2011indian,
  title = {The {{Indian Buffet Process}}: {{An Introduction}} and {{Review}}},
  author = {Griffiths, Thomas L. and Ghahramani, Zoubin},
  year = {2011},
  journal = {Journal ofMachine Learning Research},
  volume = {12},
  pages = {1185--1224},
  issn = {15324435},
  abstract = {The Indian buffet process is a stochastic process defining a probability distribution over equiva- lence classes of sparse binary matrices with a finite number of rows and an unbounded number of columns. This distribution is suitable for use as a prior in probabilisticmodels that represent objects using a potentially infinite array of features, or that involve bipartite graphs in which the size of at least one class of nodes is unknown. We give a detailed derivation of this distribution, and illustrate its use as a prior in an infinite latent featuremodel. We then review recent applications of the Indian buffet process in machine learning, discuss its extensions, and summarize its connections to other stochastic processes.},
  pmid = {290096100001},
  keywords = {beta process,chinese,exchangeable distributions,latent variable models,markov chain monte carlo,nonparametric bayes,restaurant processes,sparse binary matrices},
  file = {/Users/brownsarahm/Zotero/storage/FNW9DCB9/Griffiths, Ghahramani - 2011 - The Indian Buffet Process An Introduction and Review(3).pdf}
}

@article{grillner2016worldwide,
  title = {Worldwide Initiatives to Advance Brain Research},
  author = {Grillner, Sten and Ip, Nancy and Koch, Christof and Koroshetz, Walter and Okano, Hideyuki and Polachek, Miri and Poo, Mu-ming},
  year = {2016},
  journal = {Nature Publishing Group},
  volume = {19},
  number = {9},
  pages = {1118--1122},
  issn = {1097-6256},
  doi = {10.1038/nn.4371},
  abstract = {To highlight worldwide efforts to fund neuroscience research and address the growing threat of brain disorders, Nature Neuroscience asked leaders of six global brain initiatives to write about their programs.},
  pmid = {27571190},
  file = {/Users/brownsarahm/Zotero/storage/8JZCRRTW/Grillner et al. - 2016 - Worldwide initiatives to advance brain research(3).pdf}
}

@article{guan2010variational,
  title = {Variational {{Inference}} for {{Nonparametric Multiple Clustering}}},
  author = {Guan, Yue and Dy, Jennifer G. and Niu, Donglin and Ghahramani, Zoubin},
  year = {2010},
  journal = {KDD10 Workshop on Discovering, Summarizing, and Using Multiple Clusterings},
  abstract = {Most clustering algorithms produce a single clustering solution. Similarly, feature selection for clustering tries to find one feature subset where one interesting clustering solution resides. However, a single data set may be multi-faceted and can be grouped and interpreted in many different ways, especially for high dimensional data, where feature selection is typically needed. Moreover, different clustering solutions are interesting for different purposes. Instead of committing to one clustering solution, in this paper we introduce a probabilistic nonparametric Bayesian model that can discover several possible clustering solutions and the feature subset views that generated each cluster partitioning simultaneously. We provide a variational inference approach to learn the features and clustering partitions in each view. Our model allows us not only to learn the multiple clusterings and views but also allows us to automatically learn the number of views and the number of clusters in each view.},
  keywords = {disparate clustering,feature se-,lection,multiple clustering,non-redundant,nonparametric bayes,variational inference},
  file = {/Users/brownsarahm/Zotero/storage/Y825AXZU/Guan et al. - 2010 - Variational Inference for Nonparametric Multiple Clustering.pdf}
}

@article{gulgezen2009stable,
  title = {Stable and Accurate Feature Selection},
  author = {Gulgezen, Gokhan and Cataltepe, Zehra and Yu, Lei},
  year = {2009},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {5781 LNAI},
  number = {105},
  pages = {455--468},
  issn = {03029743},
  doi = {10.1007/978-3-642-04180-8_47},
  abstract = {Rough sets are widely used in feature evaluation and attribute reduction and a number of rough set based evaluation functions and search algorithms were reported. However, little attention has been paid to compute and compare stability of feature evaluation functions. In this work, we introduce three coefficients to calculate the stabilities of feature significance via perturbing samples. Experimental results show that entropy and fuzzy entropy based evaluation functions are more stable than the others and fuzzy rough set based functions are stable compared with the crisp functions. These results give a guideline to select feature evaluation for different applications.},
  keywords = {Feature selection,MRMR (Minimum Redundancy Maximum Relevance),Stability,Stable feature selection},
  file = {/Users/brownsarahm/Zotero/storage/S9DDGCUW/Gulgezen, Cataltepe, Yu - 2009 - Stable and accurate feature selection(3).pdf}
}

@inproceedings{guo2017what,
  title = {What You See Is Not What You Get!: {{Detecting Simpson}}'s {{Paradoxes}} during {{Data Exploration}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Human-In-the-Loop Data Analytics}}},
  author = {Guo, Yue and Binnig, Carsten and Kraska, Tim},
  year = {2017},
  pages = {2},
  publisher = {ACM}
}

@article{gustafsson2010particle,
  title = {Particle Filter Theory and Practice with Positioning Applications},
  author = {Gustafsson, Fredrik},
  year = {2010},
  journal = {Aerospace and Electronic Systems Magazine, {\textbackslash}ldots},
  volume = {25},
  number = {7},
  pages = {53--81},
  abstract = {The particle filter (PF) was introduced in 1993 as a numerical approximation to the nonlinear Bayesian filtering problem, and there is today a rather mature theory as well as a number of successful applications described in literature. This tutorial serves two purposes: to survey the part of the theory that is most important for applications and to survey a number of illustrative positioning applications from which conclusions relevant for the theory can be drawn. The theory part first surveys the nonlinear filtering problem and then describes the general PF algorithm in relation to classical solutions based on the extended Kalman filter (EKF) and the point mass filter (PMF). Tuning options, design alternatives, and user guidelines are described, and potential computational bottlenecks are identified and remedies suggested. Finally, the marginalized (or Rao-Blackwellized) PF is overviewed as a general framework for applying the PF to complex systems. The application part is more or less a stand-alone tutorial without equations that does not require any background knowledge in statistics or nonlinear filtering. It describes a number of related positioning applications where geographical information systems provide a nonlinear measurement and where it should be obvious that classical approaches based on Kalman filters (KFs) would have poor performance. All applications are based on real data and several of them come from real-time implementations. This part also provides complete code examples.}
}

@article{gustafsson2012relations,
  title = {Some {{Relations Between Extended}} and {{Unscented Kalman Filters}}},
  author = {Gustafsson, Fredrik and Hendeby, Gustaf},
  year = {2012},
  month = feb,
  journal = {IEEE Transactions on Signal Processing},
  volume = {60},
  number = {2},
  pages = {545--555},
  issn = {1053-587X},
  doi = {10.1109/TSP.2011.2172431}
}

@techreport{guyon1997scaling,
  title = {A Scaling Law for the Validation-Set Training-Set Size Ratio},
  author = {Guyon, Isabelle},
  year = {1997},
  pages = {1--11},
  abstract = {We address the problem of determining what fraction of the training set should be reserved\${\textbackslash}backslash\$nas development test set or validation set. We determine that the ratio of the validation set size\${\textbackslash}backslash\$nover the training set size scales like the square root of two complexity parameters: the complexity\${\textbackslash}backslash\$nof the second level of inference (minimizing the validation error) over the complexity\${\textbackslash}backslash\$nof the first level of inference (minimizing the error rate on the training set).\${\textbackslash}backslash\$n\${\textbackslash}backslash\$nKeywords: Cross-validation; Learning...},
  keywords = {cross-validation,experiment design,learning theory,machine learning,nition,pattern recog-,statistics,test set,training set,validation set},
  file = {/Users/brownsarahm/Zotero/storage/Y9BXYZA4/Guyon - 1997 - A scaling law for the validation-set training-set size ratio(3).pdf}
}

@article{guyon1998what,
  title = {What Size Test Set Gives Good Error Rate Estimates?},
  author = {Guyon, Isabelle and Makhoul, John},
  year = {1998},
  journal = {IEEE transactions on Pattern Analysis and Machine Intelligence},
  volume = {20},
  number = {1},
  pages = {52--64},
  file = {/Users/brownsarahm/Zotero/storage/YFC5TVPG/Guyon, Makhoul - 1998 - What size test set gives good error rate estimates(3).pdf}
}

@article{guyon2003introduction,
  title = {An {{Introduction}} to {{Variable}} and {{Feature Selection}}},
  author = {Guyon, Isabelle and Elisseeff, Andre},
  year = {2003},
  journal = {Journal of Machine Learning Research},
  volume = {3},
  pages = {1157--1182},
  keywords = {bioinformatics,clustering,computational biology,ery,feature selection,filters,gene expression,genomics,information retrieval,information theory,microarray,model selection,pattern discov-,proteomics,qsar,space dimensionality reduction,statistical testing,support vector machines,text classification,variable selection,wrappers},
  file = {/Users/brownsarahm/Zotero/storage/Z4JW9FG4/Guyon, Elisseeff - 2003 - An Introduction to Variable and Feature Selection(3).pdf}
}

@article{guyon2008design,
  title = {Design and {{Analysis}} of the {{Causation}} and {{Prediction Challenge}}},
  author = {Guyon, Isabelle and Aliferis, Constantin and Cooper, Greg and Elisseeff, Andre and Pellet, Jean-Philippe and Spirtes, Peter and Statnikov, Alexander},
  year = {2008},
  journal = {New York},
  volume = {3},
  pages = {1--33},
  abstract = {We organized for WCCI 2008 a challenge to evaluate causal modeling techniques, focusing on predicting the effect of "interventions" performed by an external agent. Examples of that problem are found in the medical domain to predict the effect of a drug prior to administering it, or in econometrics to predict the effect of a new policy prior to issuing it. We concentrate on a given target variable to be predicted (e.g., health status of a patient) from a number of candidate predictive variables or "features" (e.g., risk factors in the medical domain). Under interventions, variable predictive power and causality are tied together. For instance, both smoking and coughing may be predictive of lung cancer (the target) in the absence of external intervention; however, prohibiting smoking (a possible cause) may prevent lung cancer, but administering a cough medicine to stop coughing (a possible consequence) would not. We propose four tasks from various application domains, each dataset including a training set drawn from a natural" distribution and three test sets: one from the same distribution as the training set and two corresponding to data drawn when an external agent is manipulating certain variables. The goal is to predict a binary target variable, whose values on test data are withheld. The participants were asked to provide predictions of the target variable on test data and the list of variables (features) used to make predictions. The challenge platform remains open for post-challenge submissions and the organization of other events is under way (see http://clopinet.com/causality).},
  keywords = {learning,statistics \& optimisation,theory \& algorithms},
  file = {/Users/brownsarahm/Zotero/storage/58MQKWWC/Guyon et al. - 2008 - Design and Analysis of the Causation and Prediction Challenge.pdf}
}

@article{hagemann2003central,
  title = {Central and Autonomic Nervous System Integration in Emotion},
  author = {Hagemann, D},
  year = {2003},
  month = jun,
  journal = {Brain and Cognition},
  volume = {52},
  number = {1},
  pages = {79--87},
  issn = {02782626},
  doi = {10.1016/S0278-2626(03)00011-3},
  keywords = {autonomic nervous system,central nervous system,dynamical models,emotion,hemispheric lateralization,inhibitory control},
  file = {/Users/brownsarahm/Zotero/storage/S9IUIVV7/Hagemann - 2003 - Central and autonomic nervous system integration in emotion(3).pdf}
}

@inproceedings{halfaker2014snuggle,
  title = {Snuggle: Designing for Efficient Socialization and Ideological Critique},
  shorttitle = {Snuggle},
  booktitle = {Proceedings of the 32nd Annual {{ACM}} Conference on {{Human}} Factors in Computing Systems - {{CHI}} '14},
  author = {Halfaker, Aaron and Geiger, R. Stuart and Terveen, Loren G.},
  year = {2014},
  pages = {311--320},
  publisher = {ACM Press},
  address = {Toronto, Ontario, Canada},
  doi = {10.1145/2556288.2557313},
  urldate = {2020-05-09},
  isbn = {978-1-4503-2473-1},
  langid = {english}
}

@article{halfaker2019ores,
  title = {{{ORES}}: {{Lowering Barriers}} with {{Participatory Machine Learning}} in {{Wikipedia}}},
  shorttitle = {{{ORES}}},
  author = {Halfaker, Aaron and Geiger, R. Stuart},
  year = {2019},
  month = sep,
  journal = {arXiv:1909.05189 [cs]},
  eprint = {1909.05189},
  primaryclass = {cs},
  urldate = {2020-05-09},
  abstract = {Algorithmic systems -- from rule-based bots to machine learning classifiers -- have a long history of supporting the essential work of content moderation and other curation work in peer production projects. From counter-vandalism to task routing, basic machine prediction has allowed open knowledge projects like Wikipedia to scale to the largest encyclopedia in the world, while maintaining quality and consistency. However, conversations about how quality control should work and what role algorithms should play have generally been led by the expert engineers who have the skills and resources to develop and modify these complex algorithmic systems. In this paper, we describe ORES: an algorithmic scoring service that supports real-time scoring of wiki edits using multiple independent classifiers trained on different datasets. ORES decouples several activities that have typically all been performed by engineers: choosing or curating training data, building models to serve predictions, auditing predictions, and developing interfaces or automated agents that act on those predictions. This meta-algorithmic system was designed to open up socio-technical conversations about algorithmic systems in Wikipedia to a broader set of participants. In this paper, we discuss the theoretical mechanisms of social change ORES enables and detail case studies in participatory machine learning around ORES from the 4 years since its deployment.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning},
  file = {/Users/brownsarahm/Zotero/storage/PSQV3WEG/Halfaker and Geiger - 2019 - ORES Lowering Barriers with Participatory Machine.pdf;/Users/brownsarahm/Zotero/storage/XBQVPHPQ/1909.html}
}

@article{hampton2006role,
  title = {The Role of the Ventromedial Prefrontal Cortex in Abstract State-Based Inference during Decision Making in Humans.},
  author = {Hampton, Alan N and Bossaerts, Peter and O'Doherty, John P},
  year = {2006},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  volume = {26},
  number = {32},
  pages = {8360--8367},
  issn = {0270-6474},
  abstract = {Many real-life decision-making problems incorporate higher-order structure, involving interdependencies between different stimuli, actions, and subsequent rewards. It is not known whether brain regions implicated in decision making, such as the ventromedial prefrontal cortex (vmPFC), use a stored model of the task structure to guide choice (model-based decision making) or merely learn action or state values without assuming higher-order structure as in standard reinforcement learning. To discriminate between these possibilities, we scanned human subjects with functional magnetic resonance imaging while they performed a simple decision-making task with higher-order structure, probabilistic reversal learning. We found that neural activity in a key decision-making region, the vmPFC, was more consistent with a computational model that exploits higher-order structure than with simple reinforcement learning. These results suggest that brain regions, such as the vmPFC, use an abstract model of task structure to guide behavioral choice, computations that may underlie the human capacity for complex social interactions and abstract strategizing.},
  pmid = {16899731},
  keywords = {bayesian,decision making,fmri,reversal learning,state-based inference,ventromedial prefrontal cortex},
  file = {/Users/brownsarahm/Zotero/storage/ERD648YG/Hampton, Bossaerts, O'Doherty - 2006 - The role of the ventromedial prefrontal cortex in abstract state-based inference during decisi(3).pdf}
}

@article{han2012transelliptical,
  title = {Transelliptical {{Component Analysis}}},
  author = {Han, Fang and Liu, Han},
  year = {2012},
  journal = {Advances in Neural Information Processing Systems {\textbackslash}ldots},
  pages = {1--9},
  issn = {10495258},
  file = {/Users/brownsarahm/Zotero/storage/EU4AMVF6/Han, Liu - 2012 - Transelliptical Component Analysis(3).pdf}
}

@inproceedings{hanna2020towards,
  title = {Towards a Critical Race Methodology in Algorithmic Fairness},
  booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  author = {Hanna, Alex and Denton, Emily and Smart, Andrew and {Smith-Loud}, Jamila},
  year = {2020},
  pages = {501--512}
}

@inproceedings{hardt2016equality,
  title = {Equality of Opportunity in Supervised Learning},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Hardt, Moritz and Price, Eric and Srebro, Nati and others},
  year = {2016},
  pages = {3315--3323}
}

@article{hari2015brain,
  title = {The Brain Timewise : How Timing Shapes and Supports Brain Function},
  author = {Hari, Riitta and Parkkonen, Lauri},
  year = {2015},
  keywords = {neuroscience,physiology},
  file = {/Users/brownsarahm/Zotero/storage/BHK47R8Y/Hari, Parkkonen - 2015 - The brain timewise how timing shapes and supports brain function(3).pdf}
}

@article{harris2022bayesian,
  ids = {harris2022Bayesian},
  title = {Bayesian Persuasion for Algorithmic Recourse},
  author = {Harris, Keegan and Chen, Valerie and Kim, Joon and Talwalkar, Ameet and Heidari, Hoda and Wu, Steven Z},
  year = {2022},
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {11131--11144}
}

@inproceedings{harrison2020empirical,
  ids = {harrisonEmpiricalStudyPerceived2020},
  title = {An Empirical Study on the Perceived Fairness of Realistic, Imperfect Machine Learning Models},
  booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  author = {Harrison, Galen and Hanson, Julia and Jacinto, Christine and Ramirez, Julio and Ur, Blase},
  year = {2020},
  pages = {392--402}
}

@article{hassabis2009construction,
  title = {The Construction System of the Brain},
  author = {Hassabis, Demis and Maguire, Eleanor A},
  year = {2009},
  journal = {Philosophical Transactions of the Royal Society of London B: Biological Sciences},
  volume = {364},
  number = {1521},
  pages = {1263--1271}
}

@article{hauder2011making,
  title = {Making Data Analysis Expertise Broadly Accessible through Workflows},
  author = {Hauder, M and Gil, Y and Sethi, R and Liu, Y and Jo, H},
  year = {2011},
  journal = {WORKS'11 - Proceedings of the 6th Workshop on Workflows in Support of Large-Scale Science, Co-located with SC'11},
  pages = {77--86},
  doi = {10.1145/2110497.2110507},
  abstract = {The demand for advanced skills in data analysis spans many areas of science, computing, and business analytics. This paper discusses how non-expert users reuse workflows created by experts and representing complex data mining processes for text analytics. They include workflows for document classification, document clustering, and topic detection, all assembled from components available in well-known text analytics software libraries. The workflows expose to non-experts expert-level knowledge on how these individual components need to be combined with data preparation and feature selection steps to make the underlying statistical learning algorithms most effective. The framework allows non-experts to easily experiment with different combinations of data analysis processes, represented as workflows of computations that they can easily reconfigure. We report on our experiences to date on having users with limited data analytic knowledge and even basic programming skills to apply workflows to their data. {\copyright} 2010 ACM.},
  keywords = {Business analytics,Complex data,Data preparation,Document Classification,Document Clustering,Individual components,Information retrieval systems,Learning algorithms,Limited data,Programming skills,Scientific workflows,Semantic workflows,Software libraries,Statistical learning,Text analytics,Text processing,Topic detection,Work-flows},
  file = {/Users/brownsarahm/Zotero/storage/49SQ5URT/Hauder et al. - 2011 - Making data analysis expertise broadly accessible through workflows(3).pdf}
}

@article{he2013spontaneous,
  title = {Spontaneous and Task-Evoked Brain Activity Negatively Interact},
  author = {He, Biyu J},
  year = {2013},
  journal = {The Journal of Neuroscience},
  volume = {33},
  number = {11},
  pages = {4672--4682},
  file = {/Users/brownsarahm/Zotero/storage/R2L5HIW2/He - 2013 - Spontaneous and task-evoked brain activity negatively interact(3).pdf}
}

@inproceedings{head2021Augmenting,
  title = {Augmenting {{Scientific Papers}} with {{Just-in-Time}}, {{Position-Sensitive Definitions}} of {{Terms}} and {{Symbols}}},
  booktitle = {Proceedings of the 2021 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Head, Andrew and Lo, Kyle and Kang, Dongyeop and Fok, Raymond and Skjonsberg, Sam and Weld, Daniel S. and Hearst, Marti A.},
  year = {2021},
  series = {{{CHI}} '21},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3411764.3445648},
  abstract = {Despite the central importance of research papers to scientific progress, they can be difficult to read. Comprehension is often stymied when the information needed to understand a passage resides somewhere else---in another section, or in another paper. In this work, we envision how interfaces can bring definitions of technical terms and symbols to readers when and where they need them most. We introduce ScholarPhi, an augmented reading interface with four novel features: (1) tooltips that surface position-sensitive definitions from elsewhere in a paper, (2) a filter over the paper that ``declutters'' it to reveal how the term or symbol is used across the paper, (3) automatic equation diagrams that expose multiple definitions in parallel, and (4) an automatically generated glossary of important terms and symbols. A usability study showed that the tool helps researchers of all experience levels read papers. Furthermore, researchers were eager to have ScholarPhi's definitions available to support their everyday reading.},
  isbn = {978-1-4503-8096-6},
  keywords = {definitions,interactive documents,nonce words,reading interfaces,scientific papers}
}

@article{heckerman1996tutorial,
  title = {A {{Tutorial}} on {{Learning With Bayesian Networks}}},
  author = {Heckerman, David},
  year = {1996},
  journal = {Innovations in Bayesian Networks},
  volume = {1995},
  number = {November},
  pages = {33--82},
  issn = {1860949X},
  doi = {10.1007/978-3-540-85066-3},
  abstract = {A Bayesian network is a graphical model that encodes probabilistic relationships among variables of interest. When used in conjunction with statistical techniques, the graphical model has several advantages for data analysis. One, because the model encodes dependencies among all variables, it readily handles situations where some data entries are missing. Two, a Bayesian network can be used to learn causal relationships, and hence can be used to gain understanding about a problem domain and to predict the consequences of intervention. Three, because the model has both a causal and probabilistic semantics, it is an ideal representation for combining prior knowledge (which often comes in causal form) and data. Four, Bayesian statistical methods in conjunction with Bayesian networks offer an efficient and principled approach for avoiding the overfitting of data. In this paper, we discuss methods for constructing Bayesian networks from prior knowledge and summarize Bayesian statistical methods for using data to improve these models. With regard to the latter task, we describe methods for learning both the parameters and structure of a Bayesian network, including techniques for learning with incomplete data. In addition, we relate Bayesian-network methods for learning to techniques for supervised and unsupervised learning. We illustrate the graphical-modeling approach using a real-world case study.},
  pmid = {20108943},
  file = {/Users/brownsarahm/Zotero/storage/Q8L7B328/Heckerman - 1996 - A Tutorial on Learning With Bayesian Networks(3).pdf}
}

@inproceedings{hennig2012quasinewton,
  title = {Quasi-{{Newton Methods}}: {{A New Direction}}},
  booktitle = {Proceedings of the 29th {{International Conference}} on {{Machine Learning}} ({{ICML-12}})},
  author = {Hennig, Philipp and Kiefel, Martin},
  year = {2012},
  volume = {14},
  pages = {25--32},
  isbn = {978-1-4503-1285-1},
  keywords = {gaussian processes,numerical analysis,optimization,probability},
  file = {/Users/brownsarahm/Zotero/storage/E7R89I4R/Kiefel - 2013 - Quasi-Newton Methods A New Direction(3).pdf;/Users/brownsarahm/Zotero/storage/PJHIZXKK/Hennig, Kiefel - 1977 - Quasi-Newton Methods A New Direction(2).pdf}
}

@techreport{hennig2013animating,
  type = {Technical {{Report}}},
  title = {Animating Samples from Gaussian Distributions},
  author = {Hennig, Philipp},
  year = {2013},
  month = sep,
  number = {8},
  pages = {1--6},
  address = {Tuebingen},
  institution = {Max Planck},
  abstract = {The animations displayed below are animated samples from correlated Gaussian beliefs, following closed trajectories along equipotential lines of the probability distribution. They offer a more expressive view of the structure of samples from Gaussian processes than static samples. This document explains how to generate them, using Matlab, tikz, and L ATEX, in that order. If you do not see two animations with wobbly lines on the first proper page of this document, try opening it with Adobe Reader.},
  file = {/Users/brownsarahm/Zotero/storage/CLZ4CUYL/Hennig - 2013 - ANIMATING SAMPLES FROM(2).pdf}
}

@article{hennig2013fast,
  title = {Fast {{Probabilistic Optimization}} from {{Noisy Gradients}}},
  author = {Hennig, Philipp},
  year = {2013},
  volume = {28},
  number = {1},
  file = {/Users/brownsarahm/Zotero/storage/DSZXM3DX/Hennig - 2013 - Fast Probabilistic Optimization from Noisy Gradients(3).pdf}
}

@article{hennigprobabilistic,
  title = {Probabilistic {{Numerics}} and {{Uncertainty}} in {{Computations}}},
  author = {Hennig, Philipp and Osborne, Michael A and Girolami, Mark},
  keywords = {artificial intelligence,computational,mathematics,statistics},
  file = {/Users/brownsarahm/Zotero/storage/3K4ZK9B6/Hennig, Osborne, Girolami - Unknown - Probabilistic Numerics and Uncertainty in Computations(3).pdf}
}

@inproceedings{henning2012kernel,
  title = {Kernel {{Topic Models}}},
  booktitle = {Proceedings of the 15th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}} ({{AISTATS}})},
  author = {Henning, P and Stern, David and Herbrich, Ralf and Graepel, Thore and Hennig, Philipp},
  year = {2012},
  volume = {22},
  pages = {511--519},
  abstract = {Latent Dirichlet Allocation models discrete data as a mixture of discrete distributions, using Dirichlet beliefs over the mixture weights. We study a variation of this concept, in which the documents' mixture weight beliefs are replaced with squashed Gaussian distributions. This allows documents to be associated with elements of a Hilbert space, admitting kernel topic models (KTM), modelling temporal, spatial, hierarchical, social and other structure between documents. The main challenge is efficient approximate inference on the latent Gaussian. We present an approximate algorithm cast around a Laplace approximation in a transformed basis. The KTM can also be interpreted as a type of Gaussian process latent variable model, or as a topic model conditional on document features, uncovering links between earlier work in these areas.},
  keywords = {Kernel methods,Laplace approximation,topic models},
  file = {/Users/brownsarahm/Zotero/storage/2JJMMG5D/Henning et al. - 2012 - Kernel Topic Models(3).pdf}
}

@article{hensman2012fast,
  title = {Fast {{Variational Inference}} in the {{Conjugate Exponential Family}}},
  author = {Hensman, James and Rattray, Magnus and Lawrence, Neil D},
  year = {2012},
  journal = {CoRR},
  volume = {abs/1206.5},
  file = {/Users/brownsarahm/Zotero/storage/2V5VTITR/Hensman, Rattray, Lawrence - 2012 - Fast Variational Inference in the Conjugate Exponential Family(3).pdf}
}

@article{hensman2013gaussian,
  title = {Gaussian {{Processes}} for {{Big Data}}},
  author = {Hensman, James and Sheffield, Uk and Fusi, N and Lawrence, Nd},
  year = {2013},
  journal = {Proceedings of UAI 29},
  pages = {282--290},
  abstract = {We introduce stochastic variational inference for Gaussian process models. This enables the application of Gaussian process (GP) models to data sets containing millions of data points. We show how GPs can be vari- ationally decomposed to depend on a set of globally relevant inducing variables which factorize the model in the necessary manner to perform variational inference. Our ap- proach is readily extended to models with non-Gaussian likelihoods and latent variable models based around Gaussian processes. We demonstrate the approach on a simple toy problem and two real world data sets.},
  file = {/Users/brownsarahm/Zotero/storage/U8IQKRV7/Hensman et al. - 2013 - Gaussian Processes for Big Data(3).pdf}
}

@article{hensman2015fast,
  title = {Fast Nonparametric Clustering of Structured Time-Series},
  author = {Hensman, James and Rattray, Magnus and Lawrence, Neil D.},
  year = {2015},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {37},
  number = {2},
  pages = {383--393},
  issn = {01628828},
  doi = {10.1109/TPAMI.2014.2318711},
  abstract = {In this publication, we combine two Bayesian nonparametric models: the Gaussian Process (GP) and the Dirichlet Process (DP). Our innovation in the GP model is to introduce a variation on the GP prior which enables us to model structured time-series data, i.e. data containing groups where we wish to model inter- and intra-group variability. Our innovation in the DP model is an implementation of a new fast collapsed variational inference procedure which enables us to optimize our variational approximation significantly faster than standard VB approaches. In a biological time series application we show how our model better captures salient features of the data, leading to better consistency with existing biological classifications, while the associated inference algorithm provides a significant speed-up over EM-based variational inference.},
  pmid = {26353249},
  file = {/Users/brownsarahm/Zotero/storage/3J4P2TLY/Hensman, Rattray, Lawrence - 2015 - Fast nonparametric clustering of structured time-series(3).pdf}
}

@techreport{herbrich2006trueskill,
  title = {{{TrueSkill}}: {{A Bayesian Skill Rating System}}},
  author = {Herbrich, Ralf and Graepel, Thore},
  year = {2006},
  number = {80},
  doi = {10.1007/s13398-014-0173-7.2},
  pmid = {15003161},
  file = {/Users/brownsarahm/Zotero/storage/T7KHG4NU/Herbrich, Graepel - 2006 - TrueSkill A Bayesian Skill Rating System(3).pdf}
}

@article{hermans2011stressrelated,
  title = {Stress-Related Noradrenergic Activity Prompts Large-Scale Neural Network Reconfiguration},
  author = {Hermans, Erno J and {\noopsort{marle}}{van Marle}, Hein J F and Ossewaarde, Lindsey and Henckens, Marloes and Qin, Shaozheng and {\noopsort{kesteren}}{van Kesteren}, Marlieke and Schoots, Vincent C and Cousijn, H and Rijpkema, M and Oostenveld, R and Fernandez, G},
  year = {2011},
  journal = {Science},
  volume = {334},
  number = {6059},
  pages = {1151--1153}
}

@article{hermundstad2013structural,
  title = {Structural Foundations of Resting-State and Task-Based Functional Connectivity in the Human Brain.},
  author = {Hermundstad, Ann M and Bassett, Danielle S and Brown, Kevin S and Aminoff, Elissa M and Clewett, David and Freeman, Scott and Frithsen, Amy and Johnson, Arianne and Tipper, Christine M and Miller, Michael B and Grafton, Scott T and Carlson, Jean M},
  year = {2013},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {110},
  pages = {6169--74},
  issn = {1091-6490},
  doi = {10.1073/pnas.1219562110},
  abstract = {Magnetic resonance imaging enables the noninvasive mapping of both anatomical white matter connectivity and dynamic patterns of neural activity in the human brain. We examine the relationship between the structural properties of white matter streamlines (structural connectivity) and the functional properties of correlations in neural activity (functional connectivity) within 84 healthy human subjects both at rest and during the performance of attention- and memory-demanding tasks. We show that structural properties, including the length, number, and spatial location of white matter streamlines, are indicative of and can be inferred from the strength of resting-state and task-based functional correlations between brain regions. These results, which are both representative of the entire set of subjects and consistently observed within individual subjects, uncover robust links between structural and functional connectivity in the human brain.},
  pmid = {23530246},
  keywords = {Aging,Attention,Brain,Brain Mapping,Brain: physiology,Cognition,Computational Biology,Diffusion Magnetic Resonance Imaging,Humans,Magnetic Resonance Imaging,Memory,Models,Neural Pathways,Software,Statistical},
  file = {/Users/brownsarahm/Zotero/storage/EJFGMT9G/Hermundstad et al. - 2013 - Structural foundations of resting-state and task-based functional connectivity in the human brain(3).pdf}
}

@article{hermundstad2014structurallyconstrained,
  title = {Structurally-Constrained Relationships between Cognitive States in the Human Brain},
  author = {Hermundstad, Ann M and Brown, Kevin S and Bassett, Danielle S and Aminoff, Elissa M and Fristhen, Amy and Johnson, Arianne and Tipper, Christine and Miller, Michael B and Grafton, Scott T and Carlson, Jean M},
  year = {2014},
  journal = {PloS Computational Biology},
  volume = {10},
  number = {5},
  pages = {e1003591}
}

@article{hernan2011simpson,
  title = {The {{Simpson}}'s Paradox Unraveled},
  author = {Hern{\'a}n, Miguel A and Clayton, David and Keiding, Niels},
  year = {2011},
  journal = {International journal of epidemiology},
  volume = {40},
  number = {3},
  pages = {780--785}
}

@incollection{herschbach2015mental,
  title = {Mental Mechanisms and Psychological Construction.},
  booktitle = {The Psychological Construction of Emotion},
  author = {Herschbach, Mitchell and Bechtel, William},
  editor = {Barrett, Lisa Feldman and Russell, James Albert},
  year = {2015},
  pages = {21--44}
}

@inproceedings{hertweck2021moral,
  title = {On the Moral Justification of Statistical Parity},
  booktitle = {Proceedings of the 2021 {{ACM}} Conference on Fairness, Accountability, and Transparency},
  author = {Hertweck, Corinna and Heitz, Christoph and Loi, Michele},
  year = {2021},
  pages = {747--757}
}

@article{hesselmann2010predictive,
  title = {Predictive Coding or Evidence Accumulation? {{False}} Inference and Neuronal Fluctuations},
  author = {Hesselmann, Guido and Sadaghiani, Sepideh and Friston, Karl J and Kleinschmidt, Andreas},
  year = {2010},
  journal = {PloS One},
  volume = {5},
  number = {3},
  pages = {e9926}
}

@article{hicks2024chatgpt,
  title = {{{ChatGPT}} Is Bullshit},
  author = {Hicks, Michael Townsen and Humphries, James and Slater, Joe},
  year = {2024},
  journal = {Ethics and Information Technology},
  volume = {26},
  number = {2},
  pages = {38},
  publisher = {Springer}
}

@article{higger2013robust,
  title = {Robust {{Classification}} in {{RSVP Keyboard}}},
  author = {Higger, Matt and Akcakaya, Murat},
  year = {2013},
  journal = {Foundations of Augmented {\textbackslash}ldots},
  pages = {443--449},
  keywords = {bci,erp,spelling},
  file = {/Users/brownsarahm/Zotero/storage/SZRD3KUF/Higger, Akcakaya - 2013 - Robust Classification in RSVP Keyboard(3).pdf}
}

@book{hill2002theory,
  title = {Theory of {{Modelling}} and {{Simulation}}: {{Integrating Discrete Event}} and {{Continuous Complex Dynamic Systems}}: {{Second Edition}} by {{B}}. {{P}}. {{Zeigler}}, {{H}}. {{Praehofer}}, {{T}}. {{G}}. {{Kim}}, {{Academic Press}}, {{San Diego}}, {{CA}}, 2000.},
  author = {Hill, David R. C.},
  year = {2002},
  volume = {12},
  doi = {10.1002/rnc.610},
  abstract = {The FDC toolbox for Matlab and Simulink makes it possible to analyze aircraft and flight control attempts to create the constructive the virtual by removing information. Learn to identify the objective of the , interactions in the virtual world, objects that must be},
  isbn = {0-12-778455-1},
  file = {/Users/brownsarahm/Zotero/storage/9IYAPCEG/Hill - 2002 - Theory of Modelling and Simulation Integrating Discrete Event and Continuous Complex Dynamic Systems Second Edition by B.pdf}
}

@article{hodgkin1952quantitative,
  title = {A Quantitative Description of Membrane Current and Its Application to Conduction and Excitation in Nerve},
  author = {Hodgkin, Alan L and Huxley, Andrew F},
  year = {1952},
  journal = {The Journal of Physiology},
  volume = {117},
  number = {4},
  pages = {500}
}

@article{hoeting1999bayesian,
  title = {Bayesian Model Averaging: A Tutorial},
  author = {Hoeting, {\relax JA} and Madigan, David and Raftery, {\relax AE} and Volinsky, {\relax CT}},
  year = {1999},
  journal = {Statistical science},
  volume = {14},
  number = {4},
  eprint = {2676803},
  eprinttype = {jstor},
  pages = {382--401},
  keywords = {and phrases,bayesian graphical,bayesian model averaging,learning,markov chain monte carlo,model uncertainty,models},
  file = {/Users/brownsarahm/Zotero/storage/RBAGRZU7/Hoeting et al. - 1999 - Bayesian model averaging a tutorial(3).pdf}
}

@article{holland2018dataset,
  ids = {hollandDatasetNutritionLabel2018},
  title = {The Dataset Nutrition Label: {{A}} Framework to Drive Higher Data Quality Standards},
  author = {Holland, Sarah and Hosny, Ahmed and Newman, Sarah and Joseph, Joshua and Chmielinski, Kasia},
  year = {2018},
  journal = {arXiv preprint arXiv:1805.03677},
  eprint = {1805.03677},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society,Computer Science - Databases},
  file = {/Users/brownsarahm/Zotero/storage/ES7QYD6B/Holland et al. - 2018 - The Dataset Nutrition Label A Framework To Drive .pdf;/Users/brownsarahm/Zotero/storage/8I5TYSSJ/1805.html}
}

@inproceedings{holstein2019improving,
  title = {Improving Fairness in Machine Learning Systems: {{What}} Do Industry Practitioners Need?},
  booktitle = {Proceedings of the 2019 {{CHI}} Conference on Human Factors in Computing Systems},
  author = {Holstein, Kenneth and Wortman Vaughan, Jennifer and Daum{\'e}, Hal and Dudik, Miro and Wallach, Hanna},
  year = {2019},
  series = {{{CHI}} '19},
  pages = {1--16},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3290605.3300830},
  isbn = {978-1-4503-5970-2},
  numpages = {16},
  keywords = {algorithmic bias,empirical study,fair machine learning,needfinding,product teams,ux of machine learning}
}

@article{honey2007network,
  title = {Network Structure of Cerebral Cortex Shapes Functional Connectivity on Multiple Time Scales},
  author = {Honey, Christopher J and K{\"o}tter, Rolf and Breakspear, Michael and Sporns, Olaf},
  year = {2007},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {104},
  number = {24},
  pages = {10240--10245}
}

@article{honey2009predicting,
  title = {Predicting Human Resting-State Functional Connectivity from Structural Connectivity},
  author = {Honey, C J and Sporns, O and Cammoun, Leila and Gigandet, Xavier and Thiran, Jean-Philippe and Meuli, Reto and Hagmann, Patric},
  year = {2009},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {106},
  number = {6},
  pages = {2035--2040}
}

@article{hsu2008spectral,
  title = {A {{Spectral Algorithm}} for {{Learning Hidden Markov Models}}},
  author = {Hsu, Daniel and Kakade, Sham M. and Zhang, Tong},
  year = {2008},
  month = nov,
  journal = {Journal of Computer and System Sciences},
  volume = {78},
  number = {5},
  pages = {1460--1480},
  issn = {00220000},
  doi = {10.1016/j.jcss.2011.12.025},
  abstract = {Hidden Markov Models (HMMs) are one of the most fundamental and widely used statistical tools for modeling discrete time series. In general, learning HMMs from data is computationally hard (under cryptographic assumptions), and practitioners typically resort to search heuristics which suffer from the usual local optima issues. We prove that under a natural separation condition (bounds on the smallest singular value of the HMM parameters), there is an efficient and provably correct algorithm for learning HMMs. The sample complexity of the algorithm does not explicitly depend on the number of distinct (discrete) observations---it implicitly depends on this quantity through spectral properties of the underlying HMM. This makes the algorithm particularly applicable to settings with a large number of observations, such as those in natural language processing where the space of observation is sometimes the words in a language. The algorithm is also simple, employing only a singular value decomposition and matrix multiplications.},
  file = {/Users/brownsarahm/Zotero/storage/HW8QW26A/Hsu, Kakade, Zhang - 2012 - A spectral algorithm for learning Hidden Markov Models(2).pdf}
}

@article{hudson2014recovery,
  title = {Recovery of Consciousness Is Mediated by a Network of Discrete Metastable Activity States.},
  author = {Hudson, Andrew E and Calderon, Diany Paola and Pfaff, Donald W and Proekt, Alex},
  year = {2014},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {111},
  number = {25},
  pages = {9283--8},
  issn = {1091-6490},
  doi = {10.1073/pnas.1408296111},
  abstract = {It is not clear how, after a large perturbation, the brain explores the vast space of potential neuronal activity states to recover those compatible with consciousness. Here, we analyze recovery from pharmacologically induced coma to show that neuronal activity en route to consciousness is confined to a low-dimensional subspace. In this subspace, neuronal activity forms discrete metastable states persistent on the scale of minutes. The network of transitions that links these metastable states is structured such that some states form hubs that connect groups of otherwise disconnected states. Although many paths through the network are possible, to ultimately enter the activity state compatible with consciousness, the brain must first pass through these hubs in an orderly fashion. This organization of metastable states, along with dramatic dimensionality reduction, significantly simplifies the task of sampling the parameter space to recover the state consistent with wakefulness on a physiologically relevant timescale.},
  pmid = {24927558},
  keywords = {Anesthesia,Consciousness,Consciousness: anesthesia},
  file = {/Users/brownsarahm/Zotero/storage/2M62UHLT/Hudson et al. - 2014 - Recovery of consciousness is mediated by a network of discrete metastable activity states(3).pdf}
}

@article{hughes2015scalable,
  title = {Scalable {{Adaptation}} of {{State Complexity}} for {{Nonparametric Hidden Markov Models}}},
  author = {Hughes, Michael C and Sudderth, Erik B},
  year = {2015},
  journal = {NIPS},
  pages = {1--21},
  issn = {10495258},
  file = {/Users/brownsarahm/Zotero/storage/ZLT8VJ5M/Hughes, Sudderth - 2015 - Scalable Adaptation of State Complexity for Nonparametric Hidden Markov Models(3).pdf}
}

@article{hull1965effect,
  title = {The Effect of Essentialism on Taxonomy--Two Thousand Years of Stasis ({{I}})},
  author = {Hull, David L},
  year = {1965},
  journal = {British Journal for the Philosophy of Science},
  pages = {314--326}
}

@article{hullman2017imagining,
  title = {Imagining Replications: {{Graphical}} Prediction \& Discrete Visualizations Improve Recall \& Estimation of Effect Uncertainty},
  author = {Hullman, Jessica and Kay, Matthew and Kim, Yea-Seul and Shrestha, Samana},
  year = {2017},
  journal = {IEEE transactions on visualization and computer graphics},
  volume = {24},
  number = {1},
  pages = {446--456},
  publisher = {IEEE}
}

@article{hutchinson2009modeling,
  title = {Modeling {{fMRI}} Data Generated by Overlapping Cognitive Processes with Unknown Onsets Using {{Hidden Process Models}}},
  author = {{\noopsort{hutchinson}}a. Hutchinson, Rebecca and Niculescu, Radu Stefan and {\noopsort{keller}}a. Keller, Timothy and Rustandi, Indrayana and Mitchell, Tom M.},
  year = {2009},
  journal = {NeuroImage},
  volume = {46},
  number = {1},
  pages = {87--104},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2009.01.025},
  abstract = {We present a new method for modeling fMRI time series data called Hidden Process Models (HPMs). Like several earlier models for fMRI analysis, Hidden Process Models assume that the observed data is generated by a sequence of underlying mental processes that may be triggered by stimuli. HPMs go beyond these earlier models by allowing for processes whose timing may be unknown, and that might not be directly tied to specific stimuli. HPMs provide a principled, probabilistic framework for simultaneously learning the contribution of each process to the observed data, as well as the timing and identities of each instantiated process. They also provide a framework for evaluating and selecting among competing models that assume different numbers and types of underlying mental processes. We describe the HPM framework and its learning and inference algorithms, and present experimental results demonstrating its use on simulated and real fMRI data. Our experiments compare several models of the data using cross-validated data log-likelihood in an fMRI study involving overlapping mental processes whose timings are not fully known. ?? 2009 Elsevier Inc. All rights reserved.},
  pmid = {19457397},
  keywords = {Functional magnetic resonance imaging,Hemodynamic response,Machine learning,Mental chronometry,Statistical methods},
  file = {/Users/brownsarahm/Zotero/storage/B4ZKCQ6D/Hutchinson et al. - 2009 - Modeling fMRI data generated by overlapping cognitive processes with unknown onsets using Hidden Process M(3).pdf}
}

@article{hutchinson201950,
  title = {50 {{Years}} of {{Test}} ({{Un}})Fairness},
  author = {Hutchinson, Ben and Mitchell, Margaret},
  year = {2019},
  pages = {49--58},
  doi = {10.1145/3287560.3287600},
  abstract = {Quantitative definitions of what is unfair and what is fair have been introduced in multiple disciplines for well over 50 years, including in education, hiring, and machine learning. We trace how the notion of fairness has been defined within the testing communities of education and hiring over the past half century, exploring the cultural and social context in which different fairness definitions have emerged. In some cases, earlier definitions of fairness are similar or identical to definitions of fairness in current machine learning research, and foreshadow current formal work. In other cases, insights into what fairness means and how to measure it have largely gone overlooked. We compare past and current notions of fairness along several dimensions, including the fairness criteria, the focus of the criteria (e.g., a test, a model, or its use), the relationship of fairness to individuals, groups, and subgroups, and the mathematical method for measuring fairness (e.g., classification, regression). This work points the way towards future research and measurement of (un)fairness that builds from our modern understanding of fairness while incorporating insights from the past.},
  keywords = {2019,50 years of test,acm reference format,ben hutchinson and margaret,fairness,history,mitchell,ml fairness,ML fairness,psy,psychometrics,test fairness,un},
  file = {/Users/brownsarahm/Zotero/storage/DGK6LCDD/p49-Hutchinson.pdf}
}

@article{hutchison2013dynamic,
  title = {Dynamic Functional Connectivity: {{Promise}}, Issues, and Interpretations},
  author = {Hutchison, R. Matthew and Womelsdorf, Thilo and {\noopsort{allen}}a. Allen, Elena and {\noopsort{bandettini}}a. Bandettini, Peter and Calhoun, Vince D. and Corbetta, Maurizio and Della Penna, Stefania and Duyn, Jeff H. and Glover, Gary H. and {Gonzalez-Castillo}, Javier and {\noopsort{handwerker}}a. Handwerker, Daniel and Keilholz, Shella and Kiviniemi, Vesa and {\noopsort{leopold}}a. Leopold, David and {\noopsort{pasquale}}{de Pasquale}, Francesco and Sporns, Olaf and Walter, Martin and Chang, Catie},
  year = {2013},
  journal = {NeuroImage},
  volume = {80},
  pages = {360--378},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2013.05.079},
  abstract = {The brain must dynamically integrate, coordinate, and respond to internal and external stimuli across multiple time scales. Non-invasive measurements of brain activity with fMRI have greatly advanced our understanding of the large-scale functional organization supporting these fundamental features of brain function. Conclusions from previous resting-state fMRI investigations were based upon static descriptions of functional connectivity (FC), and only recently studies have begun to capitalize on the wealth of information contained within the temporal features of spontaneous BOLD FC. Emerging evidence suggests that dynamic FC metrics may index changes in macroscopic neural activity patterns underlying critical aspects of cognition and behavior, though limitations with regard to analysis and interpretation remain. Here, we review recent findings, methodological considerations, neural and behavioral correlates, and future directions in the emerging field of dynamic FC investigations. {\copyright} 2013 Elsevier Inc.},
  pmid = {23707587},
  keywords = {Dynamics,Fluctuations,Functional connectivity,Functional MRI (fMRI),Resting state,Spontaneous activity},
  file = {/Users/brownsarahm/Zotero/storage/BV5SRFCP/Hutchison et al. - 2013 - Dynamic functional connectivity Promise, issues, and interpretations(6).pdf;/Users/brownsarahm/Zotero/storage/VNLRJ72N/Hutchison et al. - 2013 - Dynamic functional connectivity Promise, issues, and interpretations(5).pdf}
}

@article{huth2012continuous,
  title = {A {{Continuous Semantic Space Describes}} the {{Representation}} of {{Thousands}} of {{Object}} and {{Action Categories}} across the {{Human Brain}}},
  author = {Huth, Alexander G. and Nishimoto, Shinji and Vu, An T. and Gallant, Jack L.},
  year = {2012},
  journal = {Neuron},
  volume = {76},
  pages = {1210--1224},
  issn = {08966273},
  doi = {10.1016/j.neuron.2012.10.014},
  abstract = {Humans can see and name thousands of distinct object and action categories, so it is unlikely that each category is represented in a distinct brain area. A more efficient scheme would be to represent categories as locations in a continuous semantic space mapped smoothly across the cortical surface. To search for such a space, we used fMRI to measure human brain activity evoked by natural movies. We then used voxelwise models to examine the cortical representation of 1,705 object and action categories. The first few dimensions of the underlying semantic space were recovered from the fit models by principal components analysis. Projection of the recovered semantic space onto cortical flat maps shows that semantic selectivity is organized into smooth gradients that cover much of visual and nonvisual cortex. Furthermore, both the recovered semantic space and the cortical organization of the space are shared across different individuals.},
  pmid = {23259955},
  file = {/Users/brownsarahm/Zotero/storage/CVYTL9AV/Huth et al. - 2012 - A Continuous Semantic Space Describes the Representation of Thousands of Object and Action Categories across the(3).pdf}
}

@article{id2013impact,
  title = {The {{Impact}} of {{Self-efficacy}} , through {{Experiential Education}} , on the {{Reten-}} Tion of {{Engineering Students The Impact}} of {{Self-efficacy}} , {{Through Experiential Education}} , on the {{Retention}} of {{Engineering Students}}},
  author = {Id, Paper and Metghalchi, Mohamad and Engineering, Industrial and Journal, Asme and Technology, Energy Resources and Harris, Richard and Scholarship, Academic and Chapters, N U and Society, National and Engineers, Black and Engineers, Hispanic Professional and Alliance, Northeast-louis Stokes and {Co-pi}, Minority Participation and Engineering, Multicultural and Advocates, Program and Member, Board and Program, Massachusetts Pre-engineering and Academy, Massachusetts and Prof, Sciences Fellow and Mason, Emanuel and Duggan, Claire},
  year = {2013},
  file = {/Users/brownsarahm/Zotero/storage/944UYP44/Id et al. - 2013 - The Impact of Self-efficacy , through Experiential Education , on the Reten- tion of Engineering Students The Impa(3).pdf}
}

@misc{Integratinga,
  ids = {Integrating},
  title = {Integrating Explanation and Prediction in Computational Social Science {\textbar} {{Nature}}},
  urldate = {2024-02-23},
  howpublished = {https://www.nature.com/articles/s41586-021-03659-0},
  file = {/Users/brownsarahm/Zotero/storage/3LRSEXAB/s41586-021-03659-0.html}
}

@article{ishwaran2001gibbs,
  title = {Gibbs {{Sampling Methods}} for {{Stick-Breaking Priors}}},
  author = {Ishwaran, Hemant and James, Lancelot F},
  year = {2001},
  journal = {Journal of the American Statistical Association},
  volume = {96},
  number = {453},
  pages = {161--173},
  issn = {0162-1459},
  doi = {10.1198/016214501750332758},
  abstract = {A rich and flexible class of random probability measures, which we call stick-breaking priors, can be constructed using a sequence of independent beta random variables. Examples of random measures that have this characterization include the Dirichlet process, its two-parameter extension, the two-parameter Poisson--Dirichlet process, finite dimensional Dirichlet priors, and beta two-parameter processes. The rich nature of stick-breaking priors offers Bayesians a useful class of priors for nonparametric problems, while the similar construction used in each prior can be exploited to develop a general computational procedure for pltting them. In this article we present two general types of Gibbs samplers that can be used to fit posteriors of Bayesian hierarchical models based on stick-breaking priors. The first type of Gibbs sampler, referred to as a P{\'o}lya urn Gibbs sampler, is a generalized version of a widely used Gibbs sampling method currently employed for Dirichlet process computing. This method applies to stick-breaking priors with a known P{\'o}lya urn characterization, that is, priors with an explicit and simple prediction rule. Our second method, the blocked Gibbs sampler, is based on an entirely different approach that works by directly sampling values from the posterior of the random measure. The blocked Gibbs sampler can be viewed as a more general approach because it works without requiring an explicit prediction rule. We find that the blocked},
  keywords = {blocked gibbs sampler,dirichlet process,generalized dirichlet distribution,p{\'o}lya urn gibbs,pitman,prediction rule,random probability measure,random weights,sampler,stable law,yor process},
  file = {/Users/brownsarahm/Zotero/storage/RWQGDW7Y/Ishwaran, James - 2001 - Gibbs Sampling Methods for Stick-Breaking Priors(3).pdf}
}

@inproceedings{jacobs2021measurement,
  title = {Measurement and Fairness},
  booktitle = {Proceedings of the 2021 {{ACM}} Conference on Fairness, Accountability, and Transparency},
  author = {Jacobs, Abigail Z and Wallach, Hanna},
  year = {2021},
  pages = {375--385}
}

@inproceedings{jagadeesan2022regret,
  ids = {jagadeesan2022Regret,jagadeesan2022Regreta},
  title = {Regret Minimization with Performative Feedback},
  booktitle = {International Conference on Machine Learning},
  author = {Jagadeesan, Meena and Zrnic, Tijana and {Mendler-D{\"u}nner}, Celestine},
  year = {2022},
  pages = {9760--9785},
  publisher = {PMLR}
}

@article{jain2010data,
  title = {Data {{Clustering}} : 50 {{Years Beyond K-Means}}},
  author = {Jain, Anil K and Lansing, East},
  year = {2010},
  journal = {Pattern Recognition Letters},
  volume = {31},
  number = {8},
  pages = {651---666},
  file = {/Users/brownsarahm/Zotero/storage/FYVT2F3K/Jain, Lansing - 2009 - Data Clustering 50 Years Beyond K-Means 1 Anil K . Jain Michigan State University(2).pdf}
}

@article{james1890principles,
  title = {The {{Principles}} of {{Psychology}}},
  author = {James, William},
  year = {1890}
}

@article{janoos2011spatiotemporal,
  title = {Spatio-Temporal Models of Mental Processes from {{fMRI}}.},
  author = {Janoos, Firdaus and Machiraju, Raghu and Singh, Shantanu and Morocz, Istvan {\'A}kos},
  year = {2011},
  month = jul,
  journal = {NeuroImage},
  volume = {57},
  number = {2},
  eprint = {21440069},
  eprinttype = {pubmed},
  pages = {362--77},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2011.03.047},
  abstract = {Understanding the highly complex, spatially distributed and temporally organized phenomena entailed by mental processes using functional MRI is an important research problem in cognitive and clinical neuroscience. Conventional analysis methods focus on the spatial dimension of the data discarding the information about brain function contained in the temporal dimension. This paper presents a fully spatio-temporal multivariate analysis method using a state-space model (SSM) for brain function that yields not only spatial maps of activity but also its temporal structure along with spatially varying estimates of the hemodynamic response. Efficient algorithms for estimating the parameters along with quantitative validations are given. A novel low-dimensional feature-space for representing the data, based on a formal definition of functional similarity, is derived. Quantitative validation of the model and the estimation algorithms is provided with a simulation study. Using a real fMRI study for mental arithmetic, the ability of this neurophysiologically inspired model to represent the spatio-temporal information corresponding to mental processes is demonstrated. Moreover, by comparing the models across multiple subjects, natural patterns in mental processes organized according to different mental abilities are revealed.},
  pmid = {21440069},
  keywords = {Algorithms,Brain,Brain Mapping,Brain Mapping: methods,Brain: physiology,Computer-Assisted,Computer-Assisted: methods,Humans,Image Interpretation,Magnetic Resonance Imaging,Mental Processes,Mental Processes: physiology,Models,Multivariate Analysis,Neurological},
  file = {/Users/brownsarahm/Zotero/storage/IDWWYNUA/Janoos et al. - 2011 - Spatio-temporal models of mental processes from fMRI(6).pdf;/Users/brownsarahm/Zotero/storage/P2D9GCZX/Janoos et al. - 2011 - Spatio-temporal models of mental processes from fMRI(5).pdf}
}

@article{janoos2011statespace,
  title = {State-Space Models of Mental Processes from {{fMRI}}.},
  author = {Janoos, Firdaus and Singh, Shantanu and Machiraju, Raghu and Wells, William M and {\noopsort{m{\'o}rocz}}a M{\'o}rocz, Istvan},
  year = {2011},
  month = jan,
  journal = {Information processing in medical imaging},
  volume = {22},
  eprint = {21761688},
  eprinttype = {pubmed},
  pages = {588--99},
  issn = {1011-2499},
  abstract = {In addition to functional localization and integration, the problem of determining whether the data encode some information about the mental state of the subject, and if so, how this information is represented has become an important research agenda in functional neuroimaging. Multivariate classifiers, commonly used for brain state decoding, are restricted to simple experimental paradigms with a fixed number of alternatives and are limited in their representation of the temporal dimension of the task. Moreover, they learn a mapping from the data to experimental conditions and therefore do not explain the intrinsic patterns in the data. In this paper, we present a data-driven approach to building a spatio-temporal representation of mental processes using a state-space formalism, without reference to experimental conditions. Efficient Monte Carlo algorithms for estimating the parameters of the model along with a method for model-size selection are developed. The advantages of such a model in determining the mental-state of the subject over pattern classifiers are demonstrated using an fMRI study of mental arithmetic.},
  pmid = {21761688},
  keywords = {Brain,Brain: physiopathology,Cognition,Cognition Disorders,Cognition Disorders: diagnosis,Cognition Disorders: physiopathology,Computer Simulation,Computer-Assisted,Computer-Assisted: methods,Female,Humans,Image Interpretation,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Models,Neurological,Reproducibility of Results,Sensitivity and Specificity},
  file = {/Users/brownsarahm/Zotero/storage/5AL96EAG/Janoos et al. - 2011 - State-space models of mental processes from fMRI(3).pdf}
}

@article{janoos2012spatiotemporal,
  title = {Spatio-{{Temporal Representations}} and {{Analysis}} of {{Brain Function}} from {{fMRI}}},
  author = {Janoos, Firdaus},
  year = {2012},
  file = {/Users/brownsarahm/Zotero/storage/FSCL2EQ2/Janoos - 2012 - Spatio-Temporal Representations and Analysis of Brain Function from fMRI(3).pdf}
}

@article{janzing2013quantifying,
  title = {Quantifying Causal Influences},
  author = {Janzing, Dominik and Balduzzi, David and {Grosse-Wentrup}, Moritz and Sch{\"o}lkopf, Bernhard},
  year = {2013},
  month = oct,
  journal = {The Annals of Statistics},
  volume = {41},
  number = {5},
  pages = {2324--2358},
  issn = {0090-5364},
  doi = {10.1214/13-AOS1145},
  file = {/Users/brownsarahm/Zotero/storage/QX2JQL94/Janzing et al. - 2013 - Quantifying causal influences(3).pdf}
}

@article{jaynes2005probability,
  title = {Probability Theory: The Logic of Science},
  author = {Jaynes, E T},
  year = {2005},
  journal = {The Mathematical Intelligencer},
  volume = {27},
  pages = {83--83},
  issn = {0343-6993},
  doi = {10.1007/BF02985800},
  abstract = {The standard rules of probability can be interpreted as uniquely valid principles in logic. In this book, E. T. Jaynes dispels the imaginary distinction between 'probability theory' and 'statistical inference', leaving a logical unity and simplicity, which provides greater technical power and flexibility in applications. This book goes beyond the conventional mathematics of probability theory, viewing the subject in a wider context. New results are discussed, along with applications of probability theory to a wide variety of problems in physics, mathematics, economics, chemistry and biology. It contains many exercises and problems, and is suitable for use as a textbook on graduate level courses involving data analysis. The material is aimed at readers who are already familiar with applied mathematics at an advanced undergraduate level or higher. The book will be of interest to scientists working in any area where inference from incomplete information is necessary.},
  pmid = {4362089},
  file = {/Users/brownsarahm/Zotero/storage/QR9X7VIZ/Jaynes - 1995 - Probability Theory The Logic of Science(2).pdf}
}

@article{jenkinson2001global,
  title = {A Global Optimisation Method for Robust Affine Registration of Brain Images},
  author = {Jenkinson, Mark and Smith, Stephen},
  year = {2001},
  journal = {Medical image analysis},
  volume = {5},
  number = {2},
  pages = {143--156}
}

@article{jenkinson2002improved,
  title = {Improved Optimization for the Robust and Accurate Linear Registration and Motion Correction of Brain Images},
  author = {Jenkinson, Mark and Bannister, Peter and Brady, Michael and Smith, Stephen},
  year = {2002},
  journal = {Neuroimage},
  volume = {17},
  number = {2},
  pages = {825--841}
}

@article{jenkinson2002improveda,
  title = {Improved Optimisation for the Robust and Accurate Linear Registration and Motion Correction of Brain Images. {{Neuroimage}} 17: {{825841Kearns DN}}, {{Weiss SJ}}, {{Schindler CW}}, {{Panlilio LV}} (2005) {{Conditioned}} Inhibition of Cocaine Seeking in Rats},
  author = {Jenkinson, M and Bannister, P and Brady, M and Smith, S},
  year = {2002},
  journal = {J Exp Psychol},
  volume = {31},
  pages = {247253}
}

@article{jenkinson2005elicitation,
  title = {The {{Elicitation}} of {{Probabilities}} - {{A Review}} of the {{Statistical Literature}}},
  author = {Jenkinson, David},
  year = {2005},
  journal = {Tba},
  number = {1988},
  pages = {1--72},
  file = {/Users/brownsarahm/Zotero/storage/7HHK4SQR/Jenkinson - 2005 - The Elicitation of Probabilities - A Review of the Statistical Literature.pdf;/Users/brownsarahm/Zotero/storage/WCHZFFB6/Jenkinson - 2005 - The Elicitation of Probabilities - A Review of the Statistical Literature.pdf}
}

@article{jenkinson2012fsl,
  title = {{{FSL}}},
  author = {Jenkinson, Mark and Beckmann, Christian F and Behrens, Timothy E J and Woolrich, Mark W and Smith, Stephen M},
  year = {2012},
  journal = {Neuroimage},
  volume = {62},
  pages = {782--790},
  doi = {10.1016/j.neuroimage.2011.09.015},
  file = {/Users/brownsarahm/Zotero/storage/P4JEAF98/Jenkinson et al. - 2012 - FSL(3).pdf}
}

@inproceedings{jiang2020identifying,
  title = {Identifying and Correcting Label Bias in Machine Learning},
  booktitle = {International Conference on Artificial Intelligence and Statistics},
  author = {Jiang, Heinrich and Nachum, Ofir},
  year = {2020},
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {108},
  pages = {702--712},
  publisher = {PMLR}
}

@inproceedings{jo2020lessons,
  title = {Lessons from Archives: {{Strategies}} for Collecting Sociocultural Data in Machine Learning},
  booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  author = {Jo, Eun Seo and Gebru, Timnit},
  year = {2020},
  pages = {306--316}
}

@article{joachims2002optimizing,
  title = {Optimizing Search Engines Using Clickthrough Data},
  author = {Joachims, Thorsten},
  year = {2002},
  journal = {Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '02},
  pages = {133},
  doi = {10.1145/775066.775067},
  file = {/Users/brownsarahm/Zotero/storage/I4AKT3YS/Joachims - 2002 - Optimizing search engines using clickthrough data(3).pdf}
}

@book{johnson1998applied,
  title = {Applied {{Multivariate Statistical Analysis}}},
  author = {Johnson, Richard A. and Wichern, Dean W.},
  year = {1998},
  edition = {4th},
  publisher = {Prentice-Hall},
  address = {Upper Saddle River, NJ}
}

@book{jollife2005principal,
  title = {Principal {{Component Analysis}}},
  author = {Jollife, Ian},
  year = {2005},
  publisher = {Wiley Online Library}
}

@article{jones2012nonstationarity,
  title = {Non-Stationarity in the "Resting Brain's" Modular Architecture},
  author = {Jones, David T. and Vemuri, Prashanthi and Murphy, Matthew C. and Gunter, Jeffrey L. and Senjem, Matthew L. and Machulda, Mary M. and {\noopsort{przybelski}}a. Przybelski, Scott and Gregg, Brian E. and Kantarci, Kejal and Knopman, David S. and Boeve, Bradley F. and Petersen, Ronald C. and Jack, Clifford R.},
  year = {2012},
  journal = {PLoS ONE},
  volume = {7},
  number = {6},
  issn = {19326203},
  doi = {10.1371/journal.pone.0039731},
  abstract = {Task-free functional magnetic resonance imaging (TF-fMRI) has great potential for advancing the understanding and treatment of neurologic illness. However, as with all measures of neural activity, variability is a hallmark of intrinsic connectivity networks (ICNs) identified by TF-fMRI. This variability has hampered efforts to define a robust metric of connectivity suitable as a biomarker for neurologic illness. We hypothesized that some of this variability rather than representing noise in the measurement process, is related to a fundamental feature of connectivity within ICNs, which is their non-stationary nature. To test this hypothesis, we used a large (n = 892) population-based sample of older subjects to construct a well characterized atlas of 68 functional regions, which were categorized based on independent component analysis network of origin, anatomical locations, and a functional meta-analysis. These regions were then used to construct dynamic graphical representations of brain connectivity within a sliding time window for each subject. This allowed us to demonstrate the non-stationary nature of the brain's modular organization and assign each region to a "meta-modular" group. Using this grouping, we then compared dwell time in strong sub-network configurations of the default mode network (DMN) between 28 subjects with Alzheimer's dementia and 56 cognitively normal elderly subjects matched 1:2 on age, gender, and education. We found that differences in connectivity we and others have previously observed in Alzheimer's disease can be explained by differences in dwell time in DMN sub-network configurations, rather than steady state connectivity magnitude. DMN dwell time in specific modular configurations may also underlie the TF-fMRI findings that have been described in mild cognitive impairment and cognitively normal subjects who are at risk for Alzheimer's dementia.},
  pmid = {22761880},
  file = {/Users/brownsarahm/Zotero/storage/26G8T7DP/Jones et al. - 2012 - Non-stationarity in the resting brain's modular architecture(3).pdf}
}

@book{jordan1998learning,
  title = {Learning in {{Graphical Models}}:},
  author = {Jordan, Michael Irwin},
  year = {1998},
  volume = {89},
  publisher = {Springer Science \& Business Media}
}

@inproceedings{jordan2001discriminative,
  title = {On Discriminative vs. Generative Classifiers: {{A}} Comparison of Logistic Regression and Naive Bayes},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Jordan, Michael I and Ng, Andrew Y},
  year = {2001},
  file = {/Users/brownsarahm/Zotero/storage/MUPG8QCL/Jordan, Ng - 2001 - On discriminative vs. generative classifiers A comparison of logistic regression and naive bayes(3).pdf}
}

@article{jordan2015machine,
  title = {Machine Learning: {{Trends}}, Perspectives, and Prospects},
  author = {Jordan, Mi and Mitchell, Tm},
  year = {2015},
  journal = {Science},
  volume = {349},
  number = {6245},
  file = {/Users/brownsarahm/Zotero/storage/VLSCNIDW/Jordan, Mitchell - 2015 - Machine learning Trends, perspectives, and prospects(3).pdf}
}

@book{joreskog2016multivariate,
  title = {Multivariate Analysis with {{LISREL}}},
  author = {J{\"o}reskog, Karl G and Olsson, Ulf H and Wallentin, Fan Y},
  year = {2016},
  publisher = {Springer}
}

@article{julier2004unscented,
  title = {Unscented {{Filtering}} and {{Nonlinear Estimation}}},
  author = {Julier, S.J. and Uhlmann, J.K.},
  year = {2004},
  month = mar,
  journal = {Proceedings of the IEEE},
  volume = {92},
  number = {3},
  pages = {401--422},
  issn = {0018-9219},
  doi = {10.1109/JPROC.2003.823141},
  keywords = {estimation,kalman filtering,nonlinear systems}
}

@article{juliernew,
  title = {A New Approach for Filtering Nonlinear Systems},
  author = {Julier, S.J. and Uhlmann, J.K. and {Durrant-Whyte}, H.F.},
  journal = {Proceedings of 1995 American Control Conference - ACC'95},
  volume = {3},
  number = {3},
  pages = {1628--1632},
  doi = {10.1109/ACC.1995.529783},
  file = {/Users/brownsarahm/Zotero/storage/8GNEXQ73/Julier, Uhlmann, Durrant-Whyte - Unknown - A new approach for filtering nonlinear systems(3).pdf}
}

@article{julious1994confounding,
  title = {Confounding and {{Simpson}}'s Paradox},
  author = {Julious, Steven A and Mullee, Mark A},
  year = {1994},
  journal = {BMJ},
  volume = {309},
  number = {6967},
  pages = {1480--1481}
}

@misc{jupytextteam2020JupyText,
  title = {{{JupyText}}: {{Using}} at the {{Command Line}}},
  shorttitle = {{{JupyText}}: {{Using}} at the {{Command Line}}},
  author = {JupyText Team},
  year = {2020},
  howpublished = {https://jupytext.readthedocs.io/en/latest/using-cli.html}
}

@article{jwo2007practical,
  title = {A Practical Note on Evaluating {{Kalman}} Filter Performance Optimality and Degradation},
  author = {Jwo, Dah-Jing and Cho, Ta-Shun},
  year = {2007},
  month = nov,
  journal = {Applied Mathematics and Computation},
  volume = {193},
  number = {2},
  pages = {482--505},
  issn = {00963003},
  doi = {10.1016/j.amc.2007.04.008},
  keywords = {adaptive,consistency,integrity,kalman filter,optimality,sensitivity}
}

@article{kahn2009space,
  title = {The Space between Us and Them: {{Perceptions}} of Status Differences},
  author = {Kahn, Kimberly and Ho, Arnold K and Sidanius, Jim and Pratto, Felicia},
  year = {2009},
  journal = {Group Processes \& Intergroup Relations},
  volume = {12},
  number = {5},
  pages = {591--604},
  publisher = {Sage Publications Sage UK: London, England}
}

@article{kailath1968innovations,
  title = {An {{Innovations Approach}} to {{Leas-Squares Estimation Part I}}: {{Linear Filtering}} in {{Additive White Noise}}},
  author = {Kailath, Thomas},
  year = {1968},
  journal = {IEEE Transactions on Automatic Control},
  volume = {13},
  number = {6},
  pages = {646--655}
}

@inproceedings{kale2011crossvalidation,
  title = {Cross-{{Validation}} and {{Mean-Square Stability}}},
  booktitle = {Innovations in {{Computer Science}}},
  author = {Kale, Satyen and Kumar, Ravi and Vassilvitskii, Sergei},
  year = {2011},
  keywords = {cross-validation,generalization error,stability},
  file = {/Users/brownsarahm/Zotero/storage/KHF9NH2S/Kale, Kumar, Vassilvitskii - Unknown - Cross-Validation and Mean-Square Stability(2).pdf}
}

@article{kalman1959general,
  title = {On the General Theory of Control Systems},
  author = {Kalman, R.},
  year = {1959},
  journal = {IRE Transactions on Automatic Control},
  volume = {4},
  pages = {110},
  issn = {0096-199X},
  doi = {10.1109/TAC.1959.1104873},
  abstract = {This paper deals with further advances of the author's recent work on optimal design of control systems and Wiener filters. Specifically, we consider the problem of designing a system to control a plant when (1) not all state variables are measurable, (2) the measured state variables are contaminated with noise, and (3) there are random disturbances. An explicit design procedure (well adapted to digital computation) is presented. In addition, some fundamental new concepts (controllability, observability, etc.) are introduced. A general theory of control systems is outlined which answers many basic questions (what is controllable? why? how?) and gives a highly efficient method of computation. This paper is to be published in the Proceedings of the First IFAC Moscow Congress by Butterworth Scientific Publications in 1960.}
}

@article{kalman1960new,
  title = {A New Approach to Linear Filtering and Prediction Problems},
  author = {Kalman, {\relax RE}},
  year = {1960},
  journal = {Journal of Basic Engineering},
  volume = {82},
  number = {Series D},
  pages = {35--45}
}

@inproceedings{kalousis2005stability,
  title = {Stability of Feature Selection Algorithms},
  booktitle = {Data {{Mining}}, {{Fifth IEEE International Conference}} On},
  author = {Kalousis, Alexandros and Prados, Julien and Hilario, Melanie},
  year = {2005},
  pages = {8----pp},
  publisher = {IEEE},
  file = {/Users/brownsarahm/Zotero/storage/B6S9NEIY/Kalousis, Prados, Hilario - 2005 - Stability of feature selection algorithms(3).pdf}
}

@article{kalousis2007stability,
  title = {Stability of Feature Selection Algorithms: A Study on High-Dimensional Spaces},
  author = {Kalousis, Alexandros and Prados, Julien and Hilario, Melanie},
  year = {2007},
  journal = {Knowledge and information systems},
  volume = {12},
  number = {1},
  pages = {95--116},
  file = {/Users/brownsarahm/Zotero/storage/JUDJYJNK/Kalousis, Prados, Hilario - 2007 - Stability of feature selection algorithms a study on high-dimensional spaces(3).pdf}
}

@article{kannan2018downstream,
  title = {Downstream {{Effects}} of {{Affirmative Action}}},
  author = {Kannan, Sampath and Roth, Aaron and Ziani, Juba},
  year = {2018},
  pages = {240--248},
  abstract = {We study a two-stage model, in which students are 1) admitted to college on the basis of an entrance exam which is a noisy signal about their qualifications (type), and then 2) those students who were admitted to college can be hired by an employer as a function of their college grades, which are an independently drawn noisy signal of their type. Students are drawn from one of two populations, which might have different type distributions. We assume that the employer at the end of the pipeline is rational, in the sense that it computes a posterior distribution on student type conditional on all information that it has available (college admissions, grades, and group membership), and makes a decision based on posterior expectation. We then study what kinds of fairness goals can be achieved by the college by setting its admissions rule and grading policy. For example, the college might have the goal of guaranteeing equal opportunity across populations: that the probability of passing through the pipeline and being hired by the employer should be independent of group membership, conditioned on type. Alternately, the college might have the goal of incentivizing the employer to have a group blind hiring rule. We show that both goals can be achieved when the college does not report grades. On the other hand, we show that under reasonable conditions, these goals are impossible to achieve even in isolation when the college uses an (even minimally) informative grading policy.},
  keywords = {affirmative action,college admissions,job mar-,job market,long-term fairness,Long-term fairness}
}

@article{karimi2020algorithmic,
  ids = {karimi2020Algorithmic},
  title = {Algorithmic Recourse under Imperfect Causal Knowledge: A Probabilistic Approach},
  author = {Karimi, Amir-Hossein and Von K{\"u}gelgen, Julius and Sch{\"o}lkopf, Bernhard and Valera, Isabel},
  year = {2020},
  journal = {Advances in neural information processing systems},
  volume = {33},
  pages = {265--277}
}

@article{karimi2020survey,
  ids = {karimi2020Survey,karimi2020Surveya},
  title = {A Survey of Algorithmic Recourse: Definitions, Formulations, Solutions, and Prospects},
  author = {Karimi, Amir-Hossein and Barthe, Gilles and Sch{\"o}lkopf, Bernhard and Valera, Isabel},
  year = {2020},
  journal = {arXiv preprint arXiv:2010.04050},
  eprint = {2010.04050},
  archiveprefix = {arXiv}
}

@inproceedings{karimi2021algorithmic,
  ids = {karimi2021Algorithmic,karimi2021Algorithmica},
  title = {Algorithmic Recourse: From Counterfactual Explanations to Interventions},
  booktitle = {Proceedings of the 2021 {{ACM}} Conference on Fairness, Accountability, and Transparency},
  author = {Karimi, Amir-Hossein and Sch{\"o}lkopf, Bernhard and Valera, Isabel},
  year = {2021},
  pages = {353--362}
}

@article{karimi2022survey,
  ids = {karimi2022Survey,karimi2022Surveya},
  title = {A Survey of Algorithmic Recourse: Contrastive Explanations and Consequential Recommendations},
  author = {Karimi, Amir-Hossein and Barthe, Gilles and Sch{\"o}lkopf, Bernhard and Valera, Isabel},
  year = {2022},
  journal = {ACM Computing Surveys},
  volume = {55},
  number = {5},
  pages = {1--29},
  publisher = {ACM New York, NY}
}

@techreport{kasy2020fairness,
  title = {Fairness, Equality, and Power in Algorithmic Decision Making},
  author = {Kasy, Maximilian and Abebe, Rediet},
  year = {2020},
  institution = {Working paper}
}

@inproceedings{katell2020toward,
  title = {Toward Situated Interventions for Algorithmic Equity: Lessons from the Field},
  booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  author = {Katell, Michael and Young, Meg and Dailey, Dharma and Herman, Bernease and Guetler, Vivian and Tam, Aaron and Bintz, Corinne and Raz, Daniella and Krafft, {\relax PM}},
  year = {2020},
  pages = {45--55}
}

@book{kay1998fundamentals,
  title = {Fundamentals of {{Statistical Signal Processing}}: {{Detection}} Theory},
  author = {Kay, SM M},
  year = {1998},
  series = {Prentice {{Hall Signal Processing Series}}},
  publisher = {Prentice-Hall PTR},
  isbn = {978-0-13-504135-2},
  file = {/Users/brownsarahm/Zotero/storage/HB7G6DYT/Kay - 1998 - Fundamentals of statistical signal processing detection theory(2).pdf}
}

@book{kay2013fundamentals,
  title = {Fundamentals of {{Statistical Signal Processing}}, {{Volume III}}: {{Practical Algorithm Development}}},
  author = {Kay, S M},
  year = {2013},
  series = {Fundamentals of {{Statistical Signal Processing}}},
  publisher = {Prentice-Hall PTR},
  isbn = {978-0-13-280803-3}
}

@inproceedings{kay2016researcher,
  title = {Researcher-Centered Design of Statistics: {{Why Bayesian}} Statistics Better Fit the Culture and Incentives of {{HCI}}},
  booktitle = {Proceedings of the 2016 {{CHI}} Conference on Human Factors in Computing Systems},
  author = {Kay, Matthew and Nelson, Gregory L and Hekler, Eric B},
  year = {2016},
  pages = {4521--4532}
}

@article{kayser2010multisensory,
  title = {The {{Multisensory Nature}} of {{Unisensory Cortices}}: {{A Puzzle Continued}}},
  author = {Kayser, Christoph},
  year = {2010},
  journal = {Neuron},
  volume = {67},
  number = {2},
  pages = {178--180},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2010.07.012}
}

@article{kearns1997algorithmic,
  title = {Algorithmic Stability and Sanity-Check Bounds for Leave-One-out Cross-Validation},
  author = {Kearns, Michael and Ron, Dana},
  year = {1997},
  journal = {Proceedings of the tenth annual conference on Computational learning theory - COLT '97},
  volume = {11},
  number = {6},
  pages = {152--162},
  doi = {10.1145/267460.267491},
  file = {/Users/brownsarahm/Zotero/storage/65QUTHSW/Kearns, Ron - 1997 - Algorithmic stability and sanity-check bounds for leave-one-out cross-validation(3).pdf}
}

@article{kello2013critical,
  title = {Critical Branching Neural Networks.},
  author = {Kello, Christopher T},
  year = {2013},
  journal = {Psychological review},
  volume = {120},
  number = {1},
  eprint = {23356781},
  eprinttype = {pubmed},
  pages = {230--54},
  issn = {1939-1471},
  doi = {10.1037/a0030970},
  abstract = {It is now well-established that intrinsic variations in human neural and behavioral activity tend to exhibit scaling laws in their fluctuations and distributions. The meaning of these scaling laws is an ongoing matter of debate between isolable causes versus pervasive causes. A spiking neural network model is presented that self-tunes to critical branching and, in doing so, simulates observed scaling laws as pervasive to neural and behavioral activity. These scaling laws are related to neural and cognitive functions, in that critical branching is shown to yield spiking activity with maximal memory and encoding capacities when analyzed using reservoir computing techniques. The model is also shown to account for findings of pervasive 1/f scaling in speech and cued response behaviors that are difficult to explain by isolable causes. Issues and questions raised by the model and its results are discussed from the perspectives of physics, neuroscience, computer and information sciences, and psychological and cognitive sciences.},
  pmid = {23356781},
  keywords = {Behavior,Behavior: physiology,Brain,Brain: physiology,Cognition,Cognition: physiology,Humans,Neural Networks (Computer)},
  file = {/Users/brownsarahm/Zotero/storage/MDFAV9X9/Kello - 2013 - Critical branching neural networks(3).pdf}
}

@article{kenneth1948distinction,
  title = {On a {{Distinction Between Hypothetical Constructs}} and {{Intervening Varialbes}}},
  author = {Kenneth, B Y and Corquodale, M A C and Meehl, Paul E},
  year = {1948},
  journal = {Pyschologial Review},
  volume = {55},
  pages = {95--107},
  file = {/Users/brownsarahm/Zotero/storage/LQUYT2BH/Kenneth, Corquodale, Meehl - 1948 - On a Distinction Between Hypothetical Constructs and Intervening Varialbes(3).pdf}
}

@inproceedings{keogh2003need,
  title = {On the {{Need}} for {{Time Series Data Mining Benchmarks}}: {{A Survey}} and {{Empirical Demonstration}}},
  booktitle = {Data {{Mining}} and {{Knowledge Discovery}}},
  author = {Keogh, Eamonn and Kasetty, Shruti},
  year = {2003},
  volume = {7},
  pages = {349--371},
  doi = {10.1023/A:1024988512476},
  abstract = {On pr{\'e}sente les biais qui peuvent apparaitre avec une m{\'e}thode de temporal data mining du fait des donn{\'e}es},
  isbn = {1-58113-567-X},
  keywords = {data mining,Data mining,experimental evaluation,Experimental evaluation,time series,Time series},
  file = {/Users/brownsarahm/Zotero/storage/TZMUXN5E/Keogh, Kasetty - Unknown - On the Need for Time Series Data Mining Benchmarks A Survey and Empirical Demonstration(2).pdf}
}

@article{kerr2020expectations,
  ids = {kerr2020Expectation,kerr2020Expectationsa},
  title = {Expectations of Artificial Intelligence and the Performativity of Ethics: {{Implications}} for Communication Governance},
  author = {Kerr, Aphra and Barry, Marguerite and Kelleher, John D},
  year = {2020},
  journal = {Big Data \& Society},
  volume = {7},
  number = {1},
  pages = {2053951720915939},
  publisher = {Sage Publications Sage UK: London, England}
}

@article{keshav2007how,
  title = {How to {{Read}} a {{Paper}}},
  author = {Keshav, S},
  year = {2007},
  journal = {Work},
  volume = {37},
  number = {3},
  pages = {2--3},
  issn = {01464833},
  doi = {10.1145/1273445.1273458},
  pmid = {15735874},
  keywords = {4,at the end of,glance over the references,hints,mentally ticking o ff,ones you,paper,reading,the,the first pass,to answer,ve already read,you should be able},
  file = {/Users/brownsarahm/Zotero/storage/WCEG5A4P/Keshav - 2007 - How to Read a Paper(3).pdf}
}

@article{kesslerronaldcandberglundpatriciaanddemlerolgaandjinrobertandmerikangaskathleenrandwalters2005lifetime,
  title = {Lifetime Prevalence and Age-of-Onset Distributions of {{DSM-IV}} Disorders in the {{National Comorbidity Survey Replication}}},
  author = {{Kessler, Ronald C {and} Berglund, Patricia {and} Demler, Olga {and} Jin, Robert {and} Merikangas, Kathleen R {and} Walters}, Ellen E},
  year = {2005},
  journal = {Archives of general psychiatry},
  volume = {62},
  number = {6},
  pages = {593}
}

@unpublished{khajah2015designing,
  title = {Designing {{Engaging Games Using Bayesian Optimization}}},
  author = {Khajah, Mohammad M and Roads, Brett D and Lindsey, Robert V and Mozer, Michael C},
  year = {2015},
  file = {/Users/brownsarahm/Zotero/storage/TXJWVVGV/Khajah et al. - 2015 - Designing Engaging Games Using Bayesian Optimization(3).pdf}
}

@article{khodadadian2021information,
  title = {Information Theoretic Measures for Fairness-Aware Feature Selection},
  author = {Khodadadian, Sajad and Nafea, Mohamed and Ghassami, AmirEmad and Kiyavash, Negar},
  year = {2021},
  journal = {arXiv preprint arXiv:2106.00772},
  volume = {abs/2106.00772},
  eprint = {2106.00772},
  archiveprefix = {arXiv}
}

@article{kievit2013simpson,
  title = {Simpson's Paradox in Psychological Science: {{A}} Practical Guide},
  author = {Kievit, Rogier A. and Frankenhuis, Willem E. and Waldorp, Lourens J. and Borsboom, Denny},
  year = {2013},
  journal = {Frontiers in Psychology},
  volume = {4},
  number = {AUG},
  pages = {1--14},
  issn = {16641078},
  doi = {10.3389/fpsyg.2013.00513},
  abstract = {The direction of an association at the population-level may be reversed within the subgroups comprising that population-a striking observation called Simpson's paradox. When facing this pattern, psychologists often view it as anomalous. Here, we argue that Simpson's paradox is more common than conventionally thought, and typically results in incorrect interpretations-potentially with harmful consequences. We support this claim by reviewing results from cognitive neuroscience, behavior genetics, clinical psychology, personality psychology, educational psychology, intelligence research, and simulation studies. We show that Simpson's paradox is most likely to occur when inferences are drawn across different levels of explanation (e.g., from populations to subgroups, or subgroups to individuals). We propose a set of statistical markers indicative of the paradox, and offer psychometric solutions for dealing with the paradox when encountered-including a toolbox in R for detecting Simpson's paradox. We show that explicit modeling of situations in which the paradox might occur not only prevents incorrect interpretations of data, but also results in a deeper understanding of what data tell us about the world.},
  pmid = {23964259},
  keywords = {Ecological fallacy,Measurement,Paradox,Reductionism,Simpson's paradox,Statistical inference},
  file = {/Users/brownsarahm/Zotero/storage/3D8T6RT9/Kievit et al. - 2013 - Simpson's paradox in psychological science A practical guide.pdf}
}

@inproceedings{kilbertus2017avoiding,
  title = {Avoiding Discrimination through Causal Reasoning},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Kilbertus, Niki and Carulla, Mateo Rojas and Parascandolo, Giambattista and Hardt, Moritz and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
  year = {2017},
  pages = {656--666}
}

@article{kilmer2011invisible,
  title = {Invisible Wounds, Visible Savings? {{Using}} Microsimulation to Estimate the Costs and Savings Associated with Providing Evidence-Based Treatment for {{PTSD}} and Depression to Veterans of {{Operation Enduring Freedom}} and {{Operation Iraqi Freedom}}.},
  author = {Kilmer, Beau and Eibner, Christine and Ringel, Jeanne S and Pacula, Rosalie Liccardo},
  year = {2011},
  journal = {Psychological Trauma: Theory, Research, Practice, and Policy},
  volume = {3},
  number = {2},
  pages = {201}
}

@article{kim2010mask,
  title = {Behind the Mask: The Influence of Mask-Type on Amygdala Response to Fearful Faces},
  author = {Kim, M Justin and Loucks, Rebecca A and Neta, Maital and Davis, F Caroline and Oler, Jonathan A and Mazzulla, Emily C and Whalen, Paul J},
  year = {2010},
  journal = {Social cognitive and affective neuroscience},
  volume = {5},
  number = {4},
  pages = {363--368}
}

@article{kim2014bayesian,
  title = {The {{Bayesian Case Model}}: {{A Generative Approach}} for {{Case-Based Reasoning}} and {{Prototype Classification}}},
  author = {Kim, Been and Rudin, Cynthia and Shah, Julie},
  year = {2014},
  journal = {Neural Information Processing Systems},
  pages = {1--9},
  abstract = {We present the Bayesian Case Model (BCM), a general framework for Bayesian case-based reasoning (CBR) and prototype classification and clustering. BCM brings the intuitive power of CBR to a Bayesian generative framework. The BCM learns prototypes, the ``quintessential'' observations that best represent clusters in a dataset, by performing joint inference on cluster labels, prototypes and important features. Simultaneously, BCM pursues sparsity by learning subspaces, the sets of features that play important roles in the characterization of the prototypes. The prototype and subspace representation provides quantitative benefits in interpretability while preserving classification accuracy. Human subject experiments verify statistically significant improvements to participants' understanding when using explanations produced by BCM, compared to those given by prior art.},
  file = {/Users/brownsarahm/Zotero/storage/GEXXBZLW/Kim, Rudin, Shah - 2014 - The Bayesian Case Model A Generative Approach for Case-Based Reasoning and Prototype Classification(3).pdf}
}

@techreport{kim2015computer,
  title = {Computer {{Science}} and {{Artificial Intelligence Laboratory Technical Report iBCM}} : {{Interactive Bayesian Case Model Empowering Humans}} via {{Intuitive Interaction}}},
  author = {Kim, Been and Glassman, Elena and Johnson, Brittney and Kim, Been and Glassman, Elena and Johnson, Brittney and Shah, Julie},
  year = {2015},
  file = {/Users/brownsarahm/Zotero/storage/YJU8N27Q/Kim et al. - 2015 - Computer Science and Artificial Intelligence Laboratory Technical Report iBCM Interactive Bayesian Case Model Emp(3).pdf}
}

@inproceedings{kim2017explaining,
  title = {Explaining the Gap: {{Visualizing}} One's Predictions Improves Recall and Comprehension of Data},
  booktitle = {Proceedings of the 2017 {{CHI}} Conference on Human Factors in Computing Systems},
  author = {Kim, Yea-Seul and Reinecke, Katharina and Hullman, Jessica},
  year = {2017},
  pages = {1375--1386}
}

@inproceedings{kim2018Interpretability,
  ids = {kim2018Interpretabilitya},
  title = {Interpretability beyond Feature Attribution: {{Quantitative}} Testing with Concept Activation Vectors (Tcav)},
  booktitle = {International Conference on Machine Learning},
  author = {Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and others},
  year = {2018},
  pages = {2668--2677},
  publisher = {PMLR}
}

@inproceedings{kim2019bayesian,
  title = {A Bayesian Cognition Approach to Improve Data Visualization},
  booktitle = {Proceedings of the 2019 {{CHI}} Conference on Human Factors in Computing Systems},
  author = {Kim, Yea-Seul and Walls, Logan A and Krafft, Peter and Hullman, Jessica},
  year = {2019},
  pages = {1--14}
}

@inproceedings{kim2020fact,
  title = {{{FACT}}: {{A}} Diagnostic for Group Fairness Trade-Offs},
  author = {Kim, Joon Sik and Chen, Jiahao and Talwalkar, Ameet},
  year = {2020},
  organization = {ICML}
}

@inproceedings{king2006fast,
  title = {Fast {{Variational Inference}} for {{Gaussian Process Models Through KL-Correction}}},
  booktitle = {{{ECML}}},
  author = {King, Nathaniel J and Lawrence, Neil D},
  year = {2006},
  pages = {270--281}
}

@article{kinnison2012network,
  title = {Network Analysis Reveals Increased Integration during Emotional and Motivational Processing},
  author = {Kinnison, Joshua and Padmala, Srikanth and Choi, Jong-Moon and Pessoa, Luiz},
  year = {2012},
  journal = {The Journal of Neuroscience},
  volume = {32},
  number = {24},
  pages = {8361--8372}
}

@article{kiraly2022navigating,
  ids = {kiraly2022Navigating},
  title = {Navigating the Statistical Minefield of Model Selection and Clustering in Neuroscience},
  author = {Kir{\'a}ly, B{\'a}lint and Hangya, Bal{\'a}zs},
  year = {2022},
  journal = {Eneuro},
  volume = {9},
  number = {4},
  publisher = {Society for Neuroscience}
}

@article{kircher1988human,
  title = {Human versus Computerized Evaluations of Polygraph Data in a Laboratory Setting.},
  author = {Kircher, J C and Raskin, D C},
  year = {1988},
  month = may,
  journal = {The Journal of applied psychology},
  volume = {73},
  number = {2},
  eprint = {3384775},
  eprinttype = {pubmed},
  pages = {291--302},
  issn = {0021-9010},
  pmid = {3384775},
  keywords = {Blood Pressure,Computer Simulation,Galvanic Skin Response,Heart Rate,Humans,Lie Detection,Probability,Respiration},
  file = {/Users/brownsarahm/Zotero/storage/JUXJFNH3/Kircher, Raskin - 1988 - Human versus computerized evaluations of polygraph data in a laboratory setting(3).pdf}
}

@article{kirkland2016hightech,
  title = {High-{{Tech Brains}}: {{A Histoy}} of {{Technoogy Based Anaolgies}} and {{Models}} of {{Nerve}} and {{Brain Function}}},
  author = {Kirkland, Kyle},
  year = {2016},
  journal = {Perspectives in Biology and Medicine},
  volume = {45},
  number = {2},
  pages = {212--223},
  file = {/Users/brownsarahm/Zotero/storage/772XDTJI/Kirkland - 2016 - High-Tech Brains A Histoy of Technoogy Based Anaolgies and Models of Nerve and Brain Function(3).pdf}
}

@article{kitagawa1987nongaussian,
  title = {Non-{{Gaussian State-Space Modeling}} of {{Time Series Nonstationary}}},
  author = {Kitagawa, Genshiro},
  year = {1987},
  journal = {Journal of the American Statistical Association},
  volume = {82},
  number = {400},
  pages = {1032--1041},
  keywords = {filter,smoothing},
  file = {/Users/brownsarahm/Zotero/storage/MD3HCTYG/Kitagawa - 1987 - Non-Gaussian State-Space Modeling of Time Series Nonstationary(3).pdf}
}

@article{kitagawa1987nongaussiana,
  title = {Non-{{Gaussian State-Space Modeling}} of {{Nonstationary Time Series}}},
  author = {Kitagawa, Genshiro},
  year = {1987},
  journal = {Journal of the American Statistical Association},
  volume = {82},
  number = {400},
  pages = {1032--1041},
  file = {/Users/brownsarahm/Zotero/storage/577Y8LIB/Kitagawa - 1987 - Non-Gaussian State-Space Modeling of Time Series Nonstationary(3).pdf}
}

@article{kitchin2016what,
  title = {What Makes {{Big Data}}, {{Big Data}}? {{Exploring}} the Ontological Characteristics of 26 Datasets},
  author = {Kitchin, Rob and McArdle, Gavin},
  year = {2016},
  journal = {Big Data \& Society},
  volume = {3},
  number = {1},
  pages = {205395171663113},
  issn = {2053-9517},
  doi = {10.1177/2053951716631130},
  abstract = {Big Data has been variously defined in the literature. In the main, definitions suggest that Big Data possess a suite of key traits: volume, velocity and variety (the 3Vs), but also exhaustivity, resolution, indexicality, relationality, extensionality and scalability. However, these definitions lack ontological clarity, with the term acting as an amorphous, catch-all label for a wide selection of data. In this paper, we consider the question `what makes Big Data, Big Data?', applying Kitchin's taxonomy of seven Big Data traits to 26 datasets drawn from seven domains, each of which is considered in the literature to constitute Big Data. The results demonstrate that only a handful of datasets possess all seven traits, and some do not possess either volume and/or variety. Instead, there are multiple forms of Big Data. Our analysis reveals that the key definitional boundary markers are the traits of velocity and exhaustivity. We contend that Big Data as an analytical category needs to be unpacked, with the genus of Big Data further delineated and its various species identified. It is only through such ontological work that we will gain conceptual clarity about what constitutes Big Data, formulate how best to make sense of it, and identify how it might be best used to make sense of the world.},
  keywords = {big data,characteristics,ontology,taxonomy,types}
}

@article{kitchin2017thinking,
  title = {Thinking Critically about and Researching Algorithms},
  author = {Kitchin, Rob},
  year = {2017},
  month = jan,
  journal = {Information, Communication \& Society},
  volume = {20},
  number = {1},
  pages = {14--29},
  issn = {1369-118X, 1468-4462},
  doi = {10.1080/1369118X.2016.1154087},
  urldate = {2020-05-09},
  abstract = {More and more aspects of our everyday lives are being mediated, augmented, produced and regulated by software-enabled technologies. Software is fundamentally composed of algorithms: sets of defined steps structured to process instructions/data to produce an output. This paper synthesises and extends emerging critical thinking about algorithms and considers how best to research them in practice. Four main arguments are developed. First, there is a pressing need to focus critical and empirical attention on algorithms and the work that they do given their increasing importance in shaping social and economic life. Second, algorithms can be conceived in a number of ways --technically, computationally, mathematically, politically, culturally, economically, contextually, materially, philosophically, ethically --but are best understood as being contingent, ontogenetic and performative in nature, and embedded in wider socio-technical assemblages. Third, there are three main challenges that hinder research about algorithms (gaining access to their formulation; they are heterogeneous and embedded in wider systems; their work unfolds contextually and contingently), which require practical and epistemological attention. Fourth, the constitution and work of algorithms can be empirically studied in a number of ways, each of which has strengths and weaknesses that need to be systematically evaluated. Six methodological approaches designed to produce insights into the nature and work of algorithms are critically appraised. It is contended that these methods are best used in combination in order to help overcome epistemological and practical challenges.},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/2KJPBIFS/Kitchin - 2017 - Thinking critically about and researching algorith.pdf}
}

@article{kitzbichler2011cognitive,
  title = {Cognitive Effort Drives Workspace Configuration of Human Brain Functional Networks},
  author = {Kitzbichler, Manfred G and Henson, Richard N A and Smith, Marie L and Nathan, Pradeep J and Bullmore, Edward T},
  year = {2011},
  journal = {The Journal of Neuroscience},
  volume = {31},
  number = {22},
  pages = {8259--8270}
}

@book{kitzes2017practice,
  title = {The Practice of Reproducible Research: Case Studies and Lessons from the Data-Intensive Sciences},
  author = {Kitzes, Justin and Turek, Daniel and Deniz, Fatma},
  year = {2017},
  publisher = {Univ of California Press}
}

@article{kivva2022Identifiability,
  title = {Identifiability of Deep Generative Models without Auxiliary Information},
  author = {Kivva, Bohdan and Rajendran, Goutham and Ravikumar, Pradeep and Aragam, Bryon},
  year = {2022},
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {15687--15701}
}

@book{klein1970history,
  title = {A {{History}} of {{Scientific Psychology}}: {{Its Origins}} and {{Philosophical Backgrounds}}},
  author = {Klein, David Ballin},
  year = {1970},
  publisher = {Basic Books},
  isbn = {0-7100-6964-2}
}

@article{kleinberg2016inherent,
  title = {Inherent Trade-Offs in the Fair Determination of Risk Scores},
  author = {Kleinberg, Jon and Mullainathan, Sendhil and Raghavan, Manish},
  year = {2016},
  journal = {arXiv preprint arXiv:1609.05807},
  eprint = {1609.05807},
  archiveprefix = {arXiv}
}

@article{kleinberg2016inherent,
  title = {Inherent Trade-Offs in the Fair Determination of Risk Scores},
  author = {Kleinberg, Jon and Mullainathan, Sendhil and Raghavan, Manish},
  year = {2016},
  journal = {arXiv preprint arXiv:1609.05807},
  eprint = {1609.05807},
  archiveprefix = {arXiv}
}

@inproceedings{kleinberg2017inherent,
  title = {Inherent {{Trade-Offs}} in the {{Fair Determination}} of {{Risk Scores}}},
  booktitle = {8th {{Innovations}} in {{Theoretical Computer Science Conference}} ({{ITCS}} 2017)},
  author = {Kleinberg, Jon and Mullainathan, Sendhil and Raghavan, Manish},
  year = {2017},
  publisher = {Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik}
}

@article{kleinbergInherentTradeoffsFair2016,
  title = {Inherent Trade-Offs in the Fair Determination of Risk Scores},
  author = {Kleinberg, Jon and Mullainathan, Sendhil and Raghavan, Manish},
  year = {2016},
  journal = {arXiv preprint arXiv:1609.05807},
  eprint = {1609.05807},
  archiveprefix = {arXiv}
}

@article{kleindorfer1998validation,
  title = {Validation in {{Simulation}}: {{Various Positions}} in the {{Philosophy}} of {{Science}}},
  author = {Kleindorfer, George B. and O'Neill, Liam and Ganeshan, Ram},
  year = {1998},
  journal = {Management Science},
  volume = {44},
  number = {8},
  pages = {1087--1099},
  issn = {0025-1909},
  doi = {10.1287/mnsc.44.8.1087},
  abstract = {There is still considerable doubt and even anxiety among simulation modelers as to what the methodologically correct guidelines or procedures for validating simulation models should be. Epistemically, the approaches one finds in the simulation literature run the gamut from objectivist to relativist with shades in between. At present in the philosophy of science, there appears to be a convergence toward a nonalgorithmic but discursive and nonrelativistic view of the argumentation involved in warranting scientific theorizing. The present paper attempts to give a description of the various philosophical positions as well as to summarize their problems and the kinds of evidentiary arguments they would each allow in arriving at defensible simulation models. From the debate, we attempt to set out a perspective that frees the practioner to pursue a varied set of approaches to validation with a diminished burden of methodological anxiety. Reciprocally this perspective does not let the modeler off of the hook but rather converts the validation problem into an ethical problem in which the practitioner must responsibly and professionally argue for the warrant of the model. [ABSTRACT FROM AUTHOR]},
  pmid = {1113622},
  file = {/Users/brownsarahm/Zotero/storage/PJD8ITH2/Kleindorfer, O'Neill, Ganeshan - 1998 - Validation in Simulation Various Positions in the Philosophy of Science.pdf}
}

@book{kline2015principles,
  title = {Principles and Practice of Structural Equation Modeling},
  author = {Kline, Rex B},
  year = {2015},
  publisher = {Guilford publications}
}

@article{kober2008functional,
  title = {Functional Grouping and Cortical-Subcortical Interactions in Emotion: {{A}} Meta-Analysis of Neuroimaging Studies.},
  author = {Kober, Hedy and Barrett, Lisa Feldman and Joseph, Josh and {Bliss-Moreau}, Eliza and Lindquist, Kristen and Wager, Tor D},
  year = {2008},
  month = aug,
  journal = {NeuroImage},
  volume = {42},
  number = {2},
  pages = {998--1031},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2008.03.059},
  abstract = {We performed an updated quantitative meta-analysis of 162 neuroimaging studies of emotion using a novel multi-level kernel-based approach, focusing on locating brain regions consistently activated in emotional tasks and their functional organization into distributed functional groups, independent of semantically defined emotion category labels (e.g., "anger," "fear"). Such brain-based analyses are critical if our ways of labeling emotions are to be evaluated and revised based on consistency with brain data. Consistent activations were limited to specific cortical sub-regions, including multiple functional areas within medial, orbital, and inferior lateral frontal cortices. Consistent with a wealth of animal literature, multiple subcortical activations were identified, including amygdala, ventral striatum, thalamus, hypothalamus, and periaqueductal gray. We used multivariate parcellation and clustering techniques to identify groups of co-activated brain regions across studies. These analyses identified six distributed functional groups, including medial and lateral frontal groups, two posterior cortical groups, and paralimbic and core limbic/brainstem groups. These functional groups provide information on potential organization of brain regions into large-scale networks. Specific follow-up analyses focused on amygdala, periaqueductal gray (PAG), and hypothalamic (Hy) activations, and identified frontal cortical areas co-activated with these core limbic structures. While multiple areas of frontal cortex co-activated with amygdala sub-regions, a specific region of dorsomedial prefrontal cortex (dmPFC, Brodmann's Area 9/32) was the only area co-activated with both PAG and Hy. Subsequent mediation analyses were consistent with a pathway from dmPFC through PAG to Hy. These results suggest that medial frontal areas are more closely associated with core limbic activation than their lateral counterparts, and that dmPFC may play a particularly important role in the cognitive generation of emotional states.},
  pmid = {18579414},
  keywords = {Brain Mapping,Brain Mapping: methods,Cerebral Cortex,Cerebral Cortex: physiology,Diagnostic Imaging,Diagnostic Imaging: methods,Emotions,Emotions: physiology,Humans,Nerve Net,Nerve Net: physiology,Neural Pathways,Neural Pathways: physiology,Neuroanatomy,Neuroanatomy: methods}
}

@article{kockelman2020epistemic,
  ids = {kockelman2020Epistemic},
  title = {The Epistemic and Performative Dynamics of Machine Learning Praxis},
  author = {Kockelman, Paul},
  year = {2020},
  journal = {Signs and Society},
  volume = {8},
  number = {2},
  pages = {319--355},
  publisher = {The University of Chicago Press Chicago, IL}
}

@article{kohler-hausmann2018introduction,
  title = {Introduction : {{Defining}} and {{Detecting Discrimination}}},
  author = {{Kohler-hausmann}, Issa},
  year = {2018},
  number = {February},
  pages = {1--46},
  file = {/Users/brownsarahm/Zotero/storage/32XSVMV2/Kohler-hausmann - 2018 - Introduction Defining and Detecting Discrimination.pdf}
}

@book{koller2011probabilistic,
  title = {Probabilistic {{Graphical Models}}},
  author = {Koller, Daphne and Friedman, Nir},
  year = {2011},
  publisher = {MIT press},
  doi = {10.1007/978-3-319-11433-0},
  isbn = {978-0-262-01319-2}
}

@article{kolodyazhniy2011affective,
  title = {An Affective Computing Approach to Physiological Emotion Specificity: {{Toward}} Subject-Independent and Stimulus-Independent Classification of Film-Induced Emotions.},
  author = {Kolodyazhniy, Vitaliy and Kreibig, Sylvia D and Gross, James J and Roth, Walton T and Wilhelm, Frank H},
  year = {2011},
  month = jul,
  journal = {Psychophysiology},
  volume = {48},
  number = {7},
  pages = {908--22},
  issn = {1540-5958},
  doi = {10.1111/j.1469-8986.2010.01170.x},
  abstract = {The hypothesis of physiological emotion specificity has been tested using pattern classification analysis (PCA). To address limitations of prior research using PCA, we studied effects of feature selection (sequential forward selection, sequential backward selection), classifier type (linear and quadratic discriminant analysis, neural networks, k-nearest neighbors method), and cross-validation method (subject- and stimulus-(in)dependence). Analyses were run on a data set of 34 participants watching two sets of three 10-min film clips (fearful, sad, neutral) while autonomic, respiratory, and facial muscle activity were assessed. Results demonstrate that the three states can be classified with high accuracy by most classifiers, with the sparsest model having only five features, even for the most difficult task of identifying the emotion of an unknown subject in an unknown situation (77.5\%). Implications for choosing PCA parameters are discussed.},
  pmid = {21261632},
  file = {/Users/brownsarahm/Zotero/storage/JMV7ETM5/Kolodyazhniy et al. - 2011 - An affective computing approach to physiological emotion specificity Toward subject-independent and stim(3).pdf}
}

@article{koole2012replication,
  title = {Rewarding Replications: {{A}} Sure and Simple Way to Improve Psychological Science},
  author = {Koole, Sander L. and Lakens, Dani{\"e}l},
  year = {2012},
  journal = {Perspectives on Psychological Science},
  volume = {7},
  number = {6},
  pages = {608--614}
}

@article{kornblith1993our,
  title = {Our Native Inferential Tendencies},
  author = {Kornblith, Hilary},
  year = {1993},
  journal = {Readings in philosophy and cognitive science},
  pages = {69}
}

@inproceedings{kotlowski2008statistical,
  title = {Statistical Approach to Ordinal Classification with Monotonicity Constraints},
  booktitle = {Preference {{Learning ECML}}/{{PKDD}} 2008 {\textbackslash}ldots},
  author = {Kotlowski, Wojciech and S{\textbackslash}lowi{\'n}ski, Roman},
  year = {2008}
}

@article{koyejodecoding,
  title = {Decoding {{Cognitive Processes}} from Functional {{MRI}}},
  author = {Koyejo, Oluwasanmi and Poldrack, Russell A},
  file = {/Users/brownsarahm/Zotero/storage/G2PVCD9T/Koyejo, Poldrack - Unknown - Decoding Cognitive Processes from functional MRI(3).pdf}
}

@article{kragel2015multivariate,
  title = {Multivariate Neural Biomarkers of Emotional States Are Categorically Distinct},
  author = {Kragel, Philip A and LaBar, Kevin S},
  year = {2015},
  journal = {Social cognitive and affective neuroscience}
}

@article{kreibig2010autonomic,
  title = {Autonomic Nervous System Activity in Emotion: A Review.},
  author = {Kreibig, Sylvia D},
  year = {2010},
  month = jul,
  journal = {Biological psychology},
  volume = {84},
  number = {3},
  eprint = {20371374},
  eprinttype = {pubmed},
  pages = {394--421},
  issn = {1873-6246},
  doi = {10.1016/j.biopsycho.2010.03.010},
  abstract = {Autonomic nervous system (ANS) activity is viewed as a major component of the emotion response in many recent theories of emotion. Positions on the degree of specificity of ANS activation in emotion, however, greatly diverge, ranging from undifferentiated arousal, over acknowledgment of strong response idiosyncrasies, to highly specific predictions of autonomic response patterns for certain emotions. A review of 134 publications that report experimental investigations of emotional effects on peripheral physiological responding in healthy individuals suggests considerable ANS response specificity in emotion when considering subtypes of distinct emotions. The importance of sound terminology of investigated affective states as well as of choice of physiological measures in assessing ANS reactivity is discussed.},
  pmid = {20371374},
  keywords = {Autonomic Nervous System,Autonomic Nervous System: physiology,Emotions,Emotions: physiology,Humans},
  file = {/Users/brownsarahm/Zotero/storage/5FJ9ZKXM/Kreibig - 2010 - Autonomic nervous system activity in emotion a review(3).pdf}
}

@article{kriegeskorte2006informationbased,
  title = {Information-Based Functional Brain Mapping},
  author = {Kriegeskorte, Nikolas and Goebel, Rainer and Bandettini, Peter},
  year = {2006},
  journal = {Proceedings of the National Academy of Sciences},
  pages = {3863--3868}
}

@article{kriegeskorte2007analyzing,
  title = {Analyzing for Information, Not Activation, to Exploit High-Resolution {{fMRI}}},
  author = {Kriegeskorte, Nikolaus and Bandettini, Peter},
  year = {2007},
  journal = {Neuroimage},
  volume = {38},
  number = {4},
  pages = {649--662}
}

@article{krizek2007improving,
  title = {Improving {{Stability}} of {{Feature Selecction Methods}}},
  author = {Kr{\'i}zek, Pavel and Kittler, Josef and Hlav{\'a}c, V{\'a}clav},
  year = {2007},
  journal = {Lecture Notes in Computer Science},
  volume = {4673},
  pages = {929--936},
  issn = {0302-9743},
  doi = {10.1007/978-3-540-74272-2},
  abstract = {An improper design of feature selection methods can often lead to incorrect conclusions. Moreover, it is not generally realised that functional values of the criterion guiding the search for the best feature set are random variables with some probability distribution. This contribution examines the influence of several estimation techniques on the consistency of the final result. We propose an entropy based measure which can assess the stability of feature selection methods with respect to perturbations in the data. Results show that filters achieve a better stability and performance if more samples are employed for the estimation, i.e., using leave-one-out cross-validation, for instance. However, the best results for wrappers are acquired with the 50/50 holdout validation.},
  keywords = {entropy,feature selection,stability}
}

@article{kucyi2014dynamic,
  title = {Dynamic Functional Connectivity of the Default Mode Network Tracks Daydreaming},
  author = {Kucyi, Aaron and Davis, Karen D.},
  year = {2014},
  journal = {NeuroImage},
  volume = {100},
  pages = {471--480},
  issn = {10959572},
  doi = {10.1016/j.neuroimage.2014.06.044},
  abstract = {Humans spend much of their time engaged in stimulus-independent thoughts, colloquially known as "daydreaming" or "mind-wandering." A fundamental question concerns how awake, spontaneous brain activity represents the ongoing cognition of daydreaming versus unconscious processes characterized as "intrinsic." Since daydreaming involves brief cognitive events that spontaneously fluctuate, we tested the hypothesis that the dynamics of brain network functional connectivity (FC) are linked with daydreaming. We determined the general tendency to daydream in healthy adults based on a daydreaming frequency scale (DDF). Subjects then underwent both resting state functional magnetic resonance imaging (rs-fMRI) and fMRI during sensory stimulation with intermittent thought probes to determine the occurrences of mind-wandering events. Brain regions within the default mode network (DMN), purported to be involved in daydreaming, were assessed for 1) static FC across the entire fMRI scans, and 2) dynamic FC based on FC variability (FCV) across 30. s progressively sliding windows of 2. s increments within each scan. We found that during both resting and sensory stimulation states, individual differences in DDF were negatively correlated with static FC between the posterior cingulate cortex and a ventral DMN subsystem involved in future-oriented thought. Dynamic FC analysis revealed that DDF was positively correlated with FCV within the same DMN subsystem in the resting state but not during stimulation. However, dynamic but not static FC, in this subsystem, was positively correlated with an individual's degree of self-reported mind-wandering during sensory stimulation. These findings identify temporal aspects of spontaneous DMN activity that reflect conscious and unconscious processes. {\copyright} 2014 Elsevier Inc.},
  pmid = {24973603},
  keywords = {Awareness,Brain dynamics,Consciousness,Spontaneous cognition,Stimulus-independent thought},
  file = {/Users/brownsarahm/Zotero/storage/Y6FDVGBV/Kucyi, Davis - 2014 - Dynamic functional connectivity of the default mode network tracks daydreaming(3).pdf}
}

@article{kucyi2015dynamic,
  title = {The Dynamic Pain Connectome},
  author = {Kucyi, A and Davis, K D},
  year = {2015},
  journal = {Trends in Neurosciences},
  volume = {2},
  number = {38},
  pages = {86--95}
}

@article{kuhl1992linguistic,
  title = {Linguistic Experience Alters Phonetic Perception in Infants by 6 Months of Age},
  author = {Kuhl, P K and Williams, K A and Lacerda, F and Stevens, K N and Lindblom, B},
  year = {1992},
  journal = {Science (New York, N.Y.)},
  issn = {0036-8075},
  doi = {10.1126/science.1736364},
  pmid = {1736364},
  file = {/Users/brownsarahm/Zotero/storage/95YCP2XK/Kuhl et al. - 1992 - Linguistic experience alters phonetic perception in infants by 6 months of age(3).pdf}
}

@article{kuhl2004early,
  title = {Early Language Acquisition: Cracking the Speech Code.},
  author = {Kuhl, Patricia K},
  year = {2004},
  month = nov,
  journal = {Nature reviews. Neuroscience},
  volume = {5},
  number = {11},
  eprint = {15496861},
  eprinttype = {pubmed},
  pages = {831--43},
  issn = {1471-003X},
  doi = {10.1038/nrn1533},
  abstract = {Infants learn language with remarkable speed, but how they do it remains a mystery. New data show that infants use computational strategies to detect the statistical and prosodic patterns in language input, and that this leads to the discovery of phonemes and words. Social interaction with another human being affects speech learning in a way that resembles communicative learning in songbirds. The brain's commitment to the statistical and prosodic patterns that are experienced early in life might help to explain the long-standing puzzle of why infants are better language learners than adults. Successful learning by infants, as well as constraints on that learning, are changing theories of language acquisition.},
  pmid = {15496861},
  keywords = {Brain,Brain: physiology,Humans,Infant,Interpersonal Relations,Language Development,Speech},
  file = {/Users/brownsarahm/Zotero/storage/DZDQA5ZD/Kuhl - 2004 - Early language acquisition cracking the speech code(3).pdf}
}

@article{kuhl2010brain,
  title = {Brain Mechanisms in Early Language Acquisition},
  author = {Kuhl, Patricia K},
  year = {2010},
  journal = {Neuron},
  volume = {67},
  number = {5},
  pages = {713--727},
  doi = {10.1016/j.neuron.2010.08.038.Brain},
  file = {/Users/brownsarahm/Zotero/storage/RB45ICRN/Kuhl - 2011 - NIH Public Access(2).pdf}
}

@book{kuhn2012structure,
  title = {The Structure of Scientific Revolutions},
  author = {Kuhn, Thomas S},
  year = {2012},
  publisher = {University of Chicago press}
}

@article{kullmann2012functional,
  title = {Functional Network Connectivity Underlying Food Processing: Disturbed Salience and Visual Processing in Overweight and Obese Adults},
  author = {Kullmann, Stephanie and Pape, Anna-Antonia and Heni, Martin and Ketterer, Caroline and Schick, Fritz and H{\"a}ring, Hans-Ulrich and Fritsche, Andreas and Preissl, Hubert and Veit, Ralf},
  year = {2012},
  journal = {Cerebral Cortex},
  pages = {bhs124}
}

@inproceedings{kumar2013nearoptimal,
  title = {Near-{{Optimal Bounds}} for {{Cross-Validation}} via {{Loss Stability}}},
  booktitle = {Proceedings of the 30th {{International Conference}} on {{Machine Learning}} ({{ICML-13}})},
  author = {Kumar, Ravi and Lokshtanov, Daniel and Vassilvitskii, Sergei and Vattani, Andrea},
  year = {2013},
  volume = {28},
  pages = {27--35},
  file = {/Users/brownsarahm/Zotero/storage/CJS8PUXK/Kumar - 2013 - Near-Optimal Bounds for Cross-Validation via Loss Stability(2).pdf}
}

@article{kumar2024human,
  title = {Human Creativity in the Age of Llms: {{Randomized}} Experiments on Divergent and Convergent Thinking},
  author = {Kumar, Harsh and Vincentius, Jonathan and Jordan, Ewan and Anderson, Ashton},
  year = {2024},
  journal = {arXiv preprint arXiv:2410.03703},
  eprint = {2410.03703},
  archiveprefix = {arXiv}
}

@article{kuncheva2007stability,
  title = {A Stability Index for Feature Selection.},
  author = {Kuncheva, {\relax LI}},
  year = {2007},
  journal = {Artificial intelligence and applications},
  pages = {390--395},
  keywords = {and result in a,feature selection,features being se-,pattern recognition,quential forward selection,se-,sfs,stability index,very different subset of},
  file = {/Users/brownsarahm/Zotero/storage/DMPXH66K/Kuncheva - 2007 - A stability index for feature selection(3).pdf}
}

@article{kutin2002almosteverywhere,
  title = {Almost-Everywhere Algorithmic Stability and Generalization Error},
  author = {Kutin, S and Niyogi, P},
  year = {2002},
  journal = {In UAI-2002: Uncertainty in Artificial Intelligence},
  pages = {275--282},
  file = {/Users/brownsarahm/Zotero/storage/66966PZR/Kutin, Niyogi - 2002 - Almost-everywhere algorithmic stability and generalization error(3).pdf}
}

@inproceedings{kvrizek2007improving,
  title = {Improving Stability of Feature Selection Methods},
  booktitle = {Computer {{Analysis}} of {{Images}} and {{Patterns}}},
  author = {Kvr{\'i}{\v z}ek, Pavel and Kittler, Josef and Hlav{\'a}{\v c}, V{\'a}clav},
  year = {2007},
  volume = {4673},
  pages = {929--936},
  publisher = {Springer},
  doi = {10.1007/978-3-540-74272-2},
  abstract = {An improper design of feature selection methods can often lead to incorrect conclusions. Moreover, it is not generally realised that functional values of the criterion guiding the search for the best feature set are random variables with some probability distribution. This contribution examines the influence of several estimation techniques on the consistency of the final result. We propose an entropy based measure which can assess the stability of feature selection methods with respect to perturbations in the data. Results show that filters achieve a better stability and performance if more samples are employed for the estimation, i.e., using leave-one-out cross-validation, for instance. However, the best results for wrappers are acquired with the 50/50 holdout validation.},
  isbn = {978-3-540-74271-5},
  keywords = {entropy,feature selection,stability}
}

@inproceedings{kwekir-aggrey2020Measuring,
  title = {Measuring {{Bias}} with {{Wasserstein Distance}}},
  booktitle = {{{NeurIPS}} 2020 {{Workshop}} on {{Workshop}} on {{Dataset Curation}} and {{Security}}},
  author = {{Kwekir-Aggrey}, Kweku and Brown, Sarah M},
  year = {2020},
  month = dec,
  address = {virtual},
  copyright = {All rights reserved}
}

@article{lage2019evaluation,
  title = {An {{Evaluation}} of the {{Human-Interpretability}} of {{Explanation}}},
  author = {Lage, Isaac and Chen, Emily and He, Jeffrey and Narayanan, Menaka and Kim, Been and Gershman, Sam and {Doshi-Velez}, Finale},
  year = {2019},
  number = {Nips},
  abstract = {Recent years have seen a boom in interest in machine learning systems that can provide a human-understandable rationale for their predictions or decisions. However, exactly what kinds of explanation are truly human-interpretable remains poorly understood. This work advances our understanding of what makes explanations interpretable under three specific tasks that users may perform with machine learning systems: simulation of the response, verification of a suggested response, and determining whether the correctness of a suggested response changes under a change to the inputs. Through carefully controlled human-subject experiments, we identify regularizers that can be used to optimize for the interpretability of machine learning systems. Our results show that the type of complexity matters: cognitive chunks (newly defined concepts) affect performance more than variable repetitions, and these trends are consistent across tasks and domains. This suggests that there may exist some common design principles for explanation systems.}
}

@techreport{lang1999international,
  title = {International Affective Picture System ({{IAPS}}): {{Technical}} Manual and Affective Ratings},
  author = {Lang, {\relax PJ} and Bradley, {\relax MM} and Cuthbert, {\relax BN}},
  year = {1999},
  institution = {{NIMH Center for the Study of Emotion and Attention}},
  file = {/Users/brownsarahm/Zotero/storage/UBSINK4D/Lang, Bradley, Cuthbert - 1999 - International affective picture system (IAPS) Technical manual and affective ratings(3).pdf}
}

@inproceedings{lange2002stabilitybased,
  title = {Stability-Based Model Selection},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Lange, Tilman and Braun, Mikio L ML and Roth, Volker and Buhmann, Joachim M},
  year = {2002},
  pages = {617--624},
  file = {/Users/brownsarahm/Zotero/storage/MBJQYBGA/Lange, Braun - 2002 - Stability-based model selection(2).pdf}
}

@article{laparra2020information,
  title = {Information Theory Measures via Multidimensional {{Gaussianization}}},
  author = {Laparra, Valero and Johnson, J Emmanuel and {Camps-Valls}, Gustau and {Santos-Rodr{\'i}guez}, Raul and Malo, Jesus},
  year = {2020},
  journal = {arXiv preprint arXiv:2010.03807},
  volume = {2010.03807},
  eprint = {2010.03807},
  archiveprefix = {arXiv}
}

@article{lashley1924contributions,
  title = {Contributions of {{Freudism}} to {{Psychology}}},
  author = {Lashley, B Y K S},
  year = {1924},
  journal = {Psychological Review}
}

@article{lasserreprincipled,
  title = {Principled {{Hybrids}} of {{Generative}} and {{Discriminative Models}}},
  author = {Lasserre, J.a. and Bishop, C.M. and Minka, T.P.},
  journal = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 1 (CVPR'06)},
  volume = {1},
  number = {6},
  pages = {87--94},
  doi = {10.1109/CVPR.2006.227},
  file = {/Users/brownsarahm/Zotero/storage/AQV76UFG/Lasserre, Bishop, Minka - Unknown - Principled Hybrids of Generative and Discriminative Models(3).pdf}
}

@article{lathuiliere2019comprehensive,
  ids = {lathuiliere2019Comprehensive},
  title = {A Comprehensive Analysis of Deep Regression},
  author = {Lathuili{\`e}re, St{\'e}phane and Mesejo, Pablo and {Alameda-Pineda}, Xavier and Horaud, Radu},
  year = {2019},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  volume = {42},
  number = {9},
  pages = {2065--2081},
  publisher = {IEEE}
}

@inproceedings{laufer2022Four,
  title = {Four {{Years}} of {{FAccT}}: {{A Reflexive}}, {{Mixed-Methods Analysis}} of {{Research Contributions}}, {{Shortcomings}}, and {{Future Prospects}}},
  shorttitle = {Four {{Years}} of {{FAccT}}},
  booktitle = {2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Laufer, Benjamin and Jain, Sameer and Cooper, A. Feder and Kleinberg, Jon and Heidari, Hoda},
  year = {2022},
  month = jun,
  pages = {401--426},
  publisher = {ACM},
  address = {Seoul Republic of Korea},
  doi = {10.1145/3531146.3533107},
  urldate = {2024-04-19},
  isbn = {978-1-4503-9352-2},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/Z65GSWFS/Laufer et al. - 2022 - Four Years of FAccT A Reflexive, Mixed-Methods An.pdf}
}

@article{law2020designing,
  title = {Designing Tools for Semi-Automated Detection of Machine Learning Biases: {{An}} Interview Study},
  author = {Law, Po-Ming and Malik, Sana and Du, Fan and Sinha, Moumita},
  year = {2020},
  journal = {arXiv preprint arXiv:2003.07680},
  eprint = {2003.07680},
  archiveprefix = {arXiv}
}

@article{lawimpact,
  title = {The Impact of Presentation Style on Human-in-the-Loop Detection of Algorithmic Bias},
  author = {Law, Po-Ming and Malik, Sana and Du, Fan and Sinha, Moumita},
  journal = {Graphics Interface 2020 Conference}
}

@article{lawrence2015variational,
  title = {Variational {{Inference}} for {{Latent Variables}} and {{Uncertain Inputs}} in {{Gaussian}} Processes},
  author = {Lawrence, Neil D},
  year = {2015},
  journal = {Jmlr},
  pages = {1--58},
  keywords = {dynamical systems,gaussian processes,latent variable models,variational inference},
  file = {/Users/brownsarahm/Zotero/storage/S2EIEWY5/Lawrence - 2015 - Variational Inference for Latent Variables and Uncertain Inputs in Gaussian processes(3).pdf}
}

@article{laxminarayan2011modeling,
  title = {Modeling Habituation in Rat {{EEG-evoked}} Responses via a Neural Mass Model with Feedback},
  author = {Laxminarayan, Srinivas and Tadmor, Gilead and Diamond, Solomon G and Miller, Eric and Franceschini, Maria Angela and Brooks, Dana H},
  year = {2011},
  journal = {Biological cybernetics},
  volume = {105},
  number = {5-6},
  pages = {371--397}
}

@article{lazarFrontier,
  title = {Frontier {{AI}} Ethics {{Generative}} Agents Will Change Our Society in Weird, Wonderful and Worrying Ways. {{Can}} Philosophy Help Us Get a Grip on Them?},
  author = {Lazar, Seth},
  year = {2024},
  month = feb,
  journal = {Aeon}
}

@article{lazaro-gredilla2012overlapping,
  title = {Overlapping {{Mixtures}} of {{Gaussian Processes}} for the Data Association Problem},
  author = {{L{\'a}zaro-Gredilla}, Miguel and Vaerenbergh, Steven Van and Lawrence, Neil D},
  year = {2012},
  journal = {Pattern Recognition},
  volume = {45},
  number = {4},
  pages = {1386--1395}
}

@article{lee2011how,
  title = {How Cognitive Modeling Can Benefit from Hierarchical {{Bayesian}} Models},
  author = {Lee, Michael D.},
  year = {2011},
  journal = {Journal of Mathematical Psychology},
  volume = {55},
  number = {1},
  pages = {1--7},
  issn = {00222496},
  doi = {10.1016/j.jmp.2010.08.013},
  abstract = {Hierarchical Bayesian modeling provides a flexible and interpretable way of extending simple models of cognitive processes. To introduce this special issue, we discuss four of the most important potential hierarchical Bayesian contributions. The first involves the development of more complete theories, including accounting for variation coming from sources like individual differences in cognition. The second involves the capability to account for observed behavior in terms of the combination of multiple different cognitive processes. The third involves using a few key psychological variables to explain behavior on a wide range of cognitive tasks. The fourth involves the conceptual unification and integration of disparate cognitive models. For all of these potential contributions, we outline an appropriate general hierarchical Bayesian modeling structure. We also highlight current models that already use the hierarchical Bayesian approach, as well as identifying research areas that could benefit from its adoption. ?? 2010 Elsevier Inc.},
  file = {/Users/brownsarahm/Zotero/storage/B85WHVLK/Lee - 2011 - How cognitive modeling can benefit from hierarchical Bayesian models(2).pdf}
}

@article{lee2020power,
  title = {Power and Technology: {{Who}} Gets to Make the Decisions?},
  author = {Lee, Jennifer and Young, Meg and Krafft, {\relax PM} and Katell, Michael A},
  year = {2020},
  journal = {Interactions},
  volume = {28},
  number = {1},
  pages = {38--46}
}

@incollection{lee2021landscape,
  title = {The Landscape and Gaps in Open Source Fairness Toolkits},
  booktitle = {Proceedings of the 2021 {{CHI}} Conference on Human Factors in Computing Systems},
  author = {Lee, Michelle Seng Ah and Singh, Jat},
  year = {2021},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  abstract = {With the surge in literature focusing on the assessment and mitigation of unfair outcomes in algorithms, several open source `fairness toolkits' recently emerged to make such methods widely accessible. However, little studied are the differences in approach and capabilities of existing fairness toolkits, and their fit-for-purpose in commercial contexts. Towards this, this paper identifies the gaps between the existing open source fairness toolkit capabilities and the industry practitioners' needs. Specifically, we undertake a comparative assessment of the strengths and weaknesses of six prominent open source fairness toolkits, and investigate the current landscape and gaps in fairness toolkits through an exploratory focus group, a semi-structured interview, and an anonymous survey of data science/machine learning (ML) practitioners. We identify several gaps between the toolkits' capabilities and practitioner needs, highlighting areas requiring attention and future directions towards tooling that better support `fairness in practice.'},
  articleno = {699},
  isbn = {978-1-4503-8096-6}
}

@article{leek2015opinion,
  title = {Opinion: {{Reproducible}} Research Can Still Be Wrong: {{Adopting}} a Prevention Approach},
  author = {Leek, Jeffrey T and Peng, Roger D},
  year = {2015},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {112},
  number = {6},
  pages = {1645--1646},
  publisher = {National Acad Sciences}
}

@article{lenth2001practical,
  title = {Some {{Practical Guidelines}} for {{Effective Sample Size Determination}}},
  author = {Lenth, Russell V},
  year = {2001},
  number = {1964},
  keywords = {cohen,equivalence test-,ing,observed power,power,retrospective power,s effect measures,study de-},
  file = {/Users/brownsarahm/Zotero/storage/3AKA4VJV/Lenth - 2001 - Some Practical Guidelines for Effective Sample Size Determination(3).pdf}
}

@article{lerman2017computational,
  title = {Computational Social Scientist Beware: {{Simpson}}'s Paradox in Behavioral Data},
  author = {Lerman, Kristina},
  year = {2017},
  journal = {Journal of Computational Social Science},
  pages = {1--10}
}

@article{levay2016demographic,
  title = {The Demographic and Political Composition of {{Mechanical Turk}} Samples},
  author = {Levay, Kevin E and Freese, Jeremy and Druckman, James N},
  year = {2016},
  journal = {Sage Open},
  volume = {6},
  number = {1},
  pages = {2158244016636433},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA}
}

@article{levenson1990voluntary,
  title = {Voluntary Facial Action Generates Emotion-Specific Autonomic Nervous System Activity},
  author = {Levenson, {\relax RW} and Ekman, P and Friesen, {\relax WV}},
  year = {1990},
  journal = {Psychophysiology},
  file = {/Users/brownsarahm/Zotero/storage/24XGADXK/Levenson, Ekman, Friesen - 1990 - Voluntary facial action generates emotion-specific autonomic nervous system activity(3).pdf}
}

@article{lewis1992feature,
  title = {Feature Selection and Feature Extraction for Text Categorization},
  author = {Lewis, {\relax DD}},
  year = {1992},
  journal = {Proceedings of the workshop on Speech and Natural {\textbackslash}ldots},
  file = {/Users/brownsarahm/Zotero/storage/4JF56WRS/Lewis - 1992 - Feature selection and feature extraction for text categorization(3).pdf}
}

@article{li2011exploring,
  title = {Exploring the Stability of Feature Selection for Imbalanced Intrusion Detection Data},
  author = {Li, Fang and Mi, Hong and Yang, Fan},
  year = {2011},
  journal = {IEEE International Conference on Control and Automation, ICCA},
  pages = {750--754},
  issn = {19483449},
  doi = {10.1109/ICCA.2011.6138076},
  abstract = {The class imbalance problem is of great importance to network intrusion detection data. Previous studies on feature selection always evaluate the performance of feature selection process according to the model performance and the size of selected feature subset, which neglect the stability of feature selection. We investigate the problem of the stability of feature selection and study in detail the properties of two state-of-the-art feature selection method, i.e. support vector machine recursive feature elimination (SVM-RFE) and random forest variable importance measures (RF-VIM) on the imbalanced intrusion detection data. Experimental results on KDD Cup 99 network intrusion data show the influence of imbalance rate on the stability of the algorithms, and demonstrate that stability is an important evaluation indicator of algorithm in practical applications of intrusion detection.},
  keywords = {feature selection,imbalanced data,network intrusion detection,stability},
  file = {/Users/brownsarahm/Zotero/storage/P5D2GY27/Li, Mi, Yang - 2011 - Exploring the stability of feature selection for imbalanced intrusion detection data(3).pdf}
}

@article{liam2009decoding,
  title = {Decoding of Stimulus Velocity Using a Model of Ganglion Cell Populations in Primate Retina.},
  author = {Liam, Paninski},
  year = {2009},
  journal = {Frontiers in Systems Neuroscience},
  volume = {3},
  pages = {1--35},
  doi = {10.3389/conf.neuro.06.2009.03.022},
  file = {/Users/brownsarahm/Zotero/storage/XVX8E55B/Liam - 2009 - Decoding of stimulus velocity using a model of ganglion cell populations in primate retina(3).pdf}
}

@article{liang2008analyzing,
  title = {Analyzing the {{Errors}} of {{Unsupervised Learning}}},
  author = {Liang, Percy},
  year = {2008},
  number = {June},
  pages = {879--887},
  file = {/Users/brownsarahm/Zotero/storage/5EMSXJ7B/Liang - 2008 - Analyzing the Errors of Unsupervised Learning(3).pdf}
}

@article{liang2008asymptotic,
  title = {An Asymptotic Analysis of Generative, Discriminative, and Pseudolikelihood Estimators},
  author = {Liang, Percy and Jordan, Michael I},
  year = {2008},
  journal = {Proceedings of the 25th international conference on Machine learning - ICML '08},
  doi = {10.1145/1390156.1390230},
  file = {/Users/brownsarahm/Zotero/storage/AQRIESBI/Liang, Jordan - 2008 - An asymptotic analysis of generative, discriminative, and pseudolikelihood estimators(3).pdf}
}

@article{liang2013primary,
  title = {Primary Sensory Cortices Contain Distinguishable Spatial Patterns of Activity for Each Sense.},
  author = {Liang, M and Mouraux, a and Hu, L and Iannetti, G D},
  year = {2013},
  month = jan,
  journal = {Nature communications},
  volume = {4},
  number = {May},
  pages = {1979},
  issn = {2041-1723},
  doi = {10.1038/ncomms2979},
  abstract = {Whether primary sensory cortices are essentially multisensory or whether they respond to only one sense is an emerging debate in neuroscience. Here we use a multivariate pattern analysis of functional magnetic resonance imaging data in humans to demonstrate that simple and isolated stimuli of one sense elicit distinguishable spatial patterns of neuronal responses, not only in their corresponding primary sensory cortex, but in other primary sensory cortices. These results indicate that primary sensory cortices, traditionally regarded as unisensory, contain unique signatures of other senses and, thereby, prompt a reconsideration of how sensory information is coded in the human brain.},
  pmid = {23752667},
  keywords = {Humans,Magnetic Resonance Imaging,Physical Stimulation,Sensation,Sensation: physiology,Somatosensory Cortex,Somatosensory Cortex: physiology,Task Performance and Analysis},
  file = {/Users/brownsarahm/Zotero/storage/ZLTVPDIV/Liang et al. - 2013 - Primary sensory cortices contain distinguishable spatial patterns of activity for each sense(3).pdf}
}

@article{lichtenstein1978judged,
  title = {Judged Frequency of Lethal Events.},
  author = {Lichtenstein, Sarah and Slovic, Paul and Fischhoff, Baruch and Layman, Mark and Combs, Barbara},
  year = {1978},
  journal = {Journal of experimental psychology: Human learning and memory},
  volume = {4},
  number = {6},
  pages = {551},
  publisher = {American Psychological Association}
}

@article{lieberman2010social,
  title = {Social Cognitive Neuroscience},
  author = {Lieberman, Matthew D},
  year = {2010},
  journal = {Handbook of social psychology}
}

@inproceedings{lin2003symbolic,
  title = {A Symbolic Representation of Time Series, with Implications for Streaming Algorithms},
  booktitle = {Proceedings of the 8th {{ACM SIGMOD}} Workshop on {{Research}} Issues in Data Mining and Knowledge Discovery},
  author = {Lin, Jessica and Keogh, Eamonn and Lonardi, Stefano and Chiu, Bill},
  year = {2003},
  pages = {2--11},
  publisher = {ACM Press},
  address = {New York, New York, USA},
  doi = {10.1145/882085.882086},
  keywords = {data mining,data streams,discretize,symbolic,time series},
  file = {/Users/brownsarahm/Zotero/storage/UXXJ8AXI/Lin et al. - 2003 - A symbolic representation of time series, with implications for streaming algorithms(3).pdf}
}

@article{lin2005sigrnal,
  title = {Sigrnal {{Procassing}} and {{Machine Learning}} with {{DP}}},
  author = {Lin, Chih-jen},
  year = {2005},
  number = {August},
  pages = {86--94},
  file = {/Users/brownsarahm/Zotero/storage/ZKKQHZAT/SarwateC13spmag.pdf}
}

@article{lin2012computational,
  title = {Computational Models of Emotion and Cognition},
  author = {Lin, Jerry and Spraragen, Marc and Zyda, Michael},
  year = {2012},
  journal = {Advances in Cognitive Systems},
  volume = {2},
  pages = {59--76},
  abstract = {In this paper, we seek to review the broad landscape of research in computational emotions and cognition. We begin by classifying and organizing an enumeration of recent models and systems and then discuss some of the landmark models from the literature, such as EMA andWASABI.We then discuss open problems with the current state of research. These issues are standardizing criteria for evaluation of models, the complexity and breadth of the domain, and the need to implement a working system which addresses integration with more of the rich history of AI research. We also provide suggestions for future research, particularly standardization to facilitate community collaboration.},
  file = {/Users/brownsarahm/Zotero/storage/QUKTNZF5/Lin, Spraragen, Zyda - 2012 - Computational models of emotion and cognition(3).pdf}
}

@article{lindquist2012functional,
  title = {A Functional Architecture of the Human Brain: Emerging Insights from the Science of Emotion},
  author = {Lindquist, Kristen A and Barrett, Lisa Feldman},
  year = {2012},
  journal = {Trends in cognitive sciences},
  volume = {16},
  number = {11},
  pages = {533--540}
}

@article{lindquist2015does,
  title = {Does Language Do More than Communicate Emotion?},
  author = {Lindquist, Kristen A and Satpute, Ajay B and Gendron, Maria},
  year = {2015},
  journal = {Current Directions in Psychological Science},
  volume = {24},
  number = {2},
  pages = {99--108}
}

@article{lindsey2014improving,
  title = {Improving Students ' Long-Term Knowledge Retention through Personalized Review},
  author = {Lindsey, Robert V and Shroyer, Jeff D and Pashler, Harold and Mozer, Michael C},
  year = {2014},
  journal = {Psychological Science},
  volume = {25},
  pages = {639--647},
  doi = {10.1177/0956797613504302.Improving}
}

@article{lindstrom1990nonlinear,
  title = {Nonlinear Mixed Effects Models for Repeated Measures Data.},
  author = {Lindstrom, M L and Bates, D M},
  year = {1990},
  month = sep,
  journal = {Biometrics},
  volume = {46},
  number = {3},
  eprint = {2242409},
  eprinttype = {pubmed},
  pages = {673--87},
  issn = {0006-341X},
  abstract = {We propose a general, nonlinear mixed effects model for repeated measures data and define estimators for its parameters. The proposed estimators are a natural combination of least squares estimators for nonlinear fixed effects models and maximum likelihood (or restricted maximum likelihood) estimators for linear mixed effects models. We implement Newton-Raphson estimation using previously developed computational methods for nonlinear fixed effects models and for linear mixed effects models. Two examples are presented and the connections between this work and recent work on generalized linear mixed effects models are discussed.},
  pmid = {2242409},
  keywords = {Algorithms,Analysis of Variance,Biometry,Likelihood Functions,Models,Statistical},
  file = {/Users/brownsarahm/Zotero/storage/SJQR9BYH/Lindstrom, Bates - 1990 - Nonlinear mixed effects models for repeated measures data(3).pdf}
}

@article{lippert2008kernel,
  title = {A Kernel Method for Unsupervised Structured Network Inference},
  author = {Lippert, Christoph and Stegle, Oliver and Ghahramani, Zoubin and Borgwardt, Karsten},
  year = {2008},
  volume = {5},
  pages = {368--375},
  issn = {15324435},
  abstract = {Network inference is the problem of inferring edges between a set of real-world objects, for instance, interactions between pairs of proteins in bioinformatics. Current kernel-based approaches to this problem all share a set of common features: (i) they are supervised and hence require labeled training data; (ii) edges in the network are treated as mutually independent and hence topological properties are largely ignored; (iii) they lack a statistical interpretation. We argue that these common assumptions are often undesirable for network inference, and propose (i) an unsupervised kernel method (ii) that takes the global structure of the network into account and (iii) is statistically motivated. We show that our approach can explain commonly used heuristics in statistical terms. In experiments on social networks and unsupervised protein interaction prediction we compare different variants of our method which demonstrate appealing predictive performance.},
  keywords = {Learning/Statistics \& Optimisation},
  file = {/Users/brownsarahm/Zotero/storage/6CT9E3YY/Lippert et al. - 2008 - A kernel method for unsupervised structured network inference(3).pdf}
}

@article{lipton2018troubling,
  title = {Troubling {{Trends}} in {{Machine Learning Scholarship}}},
  author = {Lipton, Zachary C. and Steinhardt, Jacob},
  year = {2018},
  pages = {1--15},
  abstract = {Collectively, machine learning (ML) researchers are engaged in the creation and dissemination of knowledge about data-driven algorithms. In a given paper, researchers might aspire to any subset of the following goals, among others: to theoretically characterize what is learnable, to obtain understanding through empirically rigorous experiments, or to build a working system that has high predictive accuracy. While determining which knowledge warrants inquiry may be subjective, once the topic is fixed, papers are most valuable to the community when they act in service of the reader, creating foundational knowledge and communicating as clearly as possible. Recent progress in machine learning comes despite frequent departures from these ideals. In this paper, we focus on the following four patterns that appear to us to be trending in ML scholarship: (i) failure to distinguish between explanation and speculation; (ii) failure to identify the sources of empirical gains, e.g., emphasizing unnecessary modifications to neural architectures when gains actually stem from hyper-parameter tuning; (iii) mathiness: the use of mathematics that obfuscates or impresses rather than clarifies, e.g., by confusing technical and non-technical concepts; and (iv) misuse of language, e.g., by choosing terms of art with colloquial connotations or by overloading established technical terms. While the causes behind these patterns are uncertain, possibilities include the rapid expansion of the community, the consequent thinness of the reviewer pool, and the often-misaligned incentives between scholarship and short-term measures of success (e.g., bibliometrics, attention, and entrepreneurial opportunity). While each pattern offers a corresponding remedy (don't do it), we also discuss some speculative suggestions for how the community might combat these trends.}
}

@inproceedings{liu2018delayed,
  ids = {liu2019Delayed},
  title = {Delayed Impact of Fair Machine Learning},
  booktitle = {{{arXiv}} Preprint {{arXiv}}:1803.04383},
  author = {Liu, Lydia T and Dean, Sarah and Rolf, Esther and Simchowitz, Max and Hardt, Moritz},
  year = {2018},
  eprint = {1803.04383},
  address = {Stockholm, Sweeden},
  archiveprefix = {arXiv},
  file = {/Users/brownsarahm/Zotero/storage/PI46SDK4/Liu et al. - 2019 - Delayed Impact of Fair Machine Learning.pdf}
}

@article{liu2021density,
  title = {Density Estimation Using Deep Generative Neural Networks},
  author = {Liu, Qiao and Xu, Jiaze and Jiang, Rui and Wong, Wing Hung},
  year = {2021},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {118},
  number = {15},
  pages = {e2101344118},
  publisher = {National Acad Sciences}
}

@book{lord1991essential,
  title = {Essential {{Results}} of {{Functional Analysis}}},
  author = {Lord, Nick and Zimmer, Robert J.},
  year = {1991},
  month = jun,
  volume = {75},
  eprint = {3620295},
  eprinttype = {jstor},
  doi = {10.2307/3620295},
  isbn = {9998979695949},
  file = {/Users/brownsarahm/Zotero/storage/M9Q85GDW/Lord, Zimmer - 1991 - Essential Results of Functional Analysis(3).pdf}
}

@article{lou2013accurate,
  title = {Accurate Intelligible Models with Pairwise Interactions},
  author = {Lou, Yin and Caruana, Rich and Gehrke, Johannes and Hooker, Giles},
  year = {2013},
  journal = {Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '13},
  pages = {623},
  doi = {10.1145/2487575.2487579},
  keywords = {classification,interaction detection,regression},
  file = {/Users/brownsarahm/Zotero/storage/62ZDZZFG/Lou et al. - 2013 - Accurate Intelligible Models with Pairwise Interactions(2).pdf}
}

@article{luccioni2023estimating,
  title = {Estimating the Carbon Footprint of Bloom, a 176b Parameter Language Model},
  author = {Luccioni, Alexandra Sasha and Viguier, Sylvain and Ligozat, Anne-Laure},
  year = {2023},
  journal = {Journal of Machine Learning Research},
  volume = {24},
  number = {253},
  pages = {1--15}
}

@inproceedings{luccioni2024power,
  title = {Power Hungry Processing: {{Watts}} Driving the Cost of {{AI}} Deployment?},
  booktitle = {The 2024 {{ACM}} Conference on Fairness, Accountability, and Transparency},
  author = {Luccioni, Sasha and Jernite, Yacine and Strubell, Emma},
  year = {2024},
  pages = {85--99}
}

@article{lynch2004bayesian,
  title = {Bayesian {{Posterior Predictive Checks}} for {{Complex Models}}},
  author = {Lynch, Scott M. and Western, Bruce},
  year = {2004},
  month = feb,
  journal = {Sociological Methods \& Research},
  volume = {32},
  number = {3},
  pages = {301--335},
  issn = {00491241},
  doi = {10.1177/0049124103257303},
  keywords = {bayesian approach,bayesian posterior predictive distributions,statistics},
  file = {/Users/brownsarahm/Zotero/storage/6HGW2UJ4/Lynch, Western - 2004 - Bayesian Posterior Predictive Checks for Complex Models(3).pdf}
}

@article{ma2011spontaneous,
  title = {Spontaneous and Intentional Trait Inferences Recruit a Common Mentalizing Network to a Different Degree: Spontaneous Inferences Activate Only Its Core Areas},
  author = {Ma, Ning and Vandekerckhove, Marie and Van Overwalle, Frank and Seurinck, Ruth and Fias, Wim},
  year = {2011},
  journal = {Social Neuroscience},
  volume = {6},
  number = {2},
  pages = {123--138}
}

@inproceedings{maceachren2003exploring,
  title = {Exploring High-{{D}} Spaces with Multiform Matrices and Small Multiples},
  booktitle = {Information {{Visualization}}, 2003. {{INFOVIS}} 2003. {{IEEE Symposium}} On},
  author = {MacEachren, Alan and Xiping, D and Hardisty, Frank and Guo, Diansheng and Lengerich, Gene},
  year = {2003},
  pages = {31--38},
  publisher = {IEEE}
}

@book{mackay2008information,
  title = {Information {{Theory}}, {{Inference}}, and {{Learning Algorithms}}},
  author = {MacKay, D J},
  year = {2008},
  doi = {10.2277/0521642981},
  isbn = {0-521-64298-1},
  file = {/Users/brownsarahm/Zotero/storage/GG6R5YKC/MacKay - 2008 - Information Theory, Inference, and Learning Algorithms(3).pdf}
}

@article{maclean1949psychosomatic,
  title = {Psychosomatic Disease and the ``Visceral Brain'' Recent Developments Bearing on the Papez Theory of Emotion},
  author = {Maclean, P D},
  year = {1949},
  journal = {Psychosomatic Medicine},
  volume = {11},
  number = {6},
  pages = {338--353}
}

@inproceedings{madaio2020codesigning,
  ids = {madaio2020checklists},
  title = {Co-{{Designing Checklists}} to {{Understand Organizational Challenges}} and {{Opportunities}} around {{Fairness}} in {{AI}}},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Madaio, Michael A. and Stark, Luke and Wortman Vaughan, Jennifer and Wallach, Hanna},
  year = {2020},
  series = {{{CHI}} '20},
  pages = {1--14},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3313831.3376445},
  isbn = {978-1-4503-6708-0},
  numpages = {14},
  keywords = {AI,checklists,co-design,ethics,fairness,ML}
}

@article{madaio2022Assessing,
  ids = {madaio2022Assessinga},
  title = {Assessing the Fairness of Ai Systems: {{Ai}} Practitioners' Processes, Challenges, and Needs for Support},
  author = {Madaio, Michael and Egede, Lisa and Subramonyam, Hariharan and Wortman Vaughan, Jennifer and Wallach, Hanna},
  year = {2022},
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {6},
  number = {CSCW1},
  pages = {1--26},
  publisher = {ACM New York, NY, USA},
  issn = {2573-0142}
}

@article{madani2005covalidation,
  title = {Co-{{Validation}}: {{Using Model Disagreement}} on {{Unlabeled Data}} to {{Validate Classification Algorithms}}},
  author = {Madani, Omid and Pennock, David M and Flake, Gary W},
  year = {2005},
  journal = {Advances in Neural Information Processing Systems 17},
  pages = {873--880},
  file = {/Users/brownsarahm/Zotero/storage/KJFP5TIB/Madani, Pennock, Flake - 2005 - Co-Validation Using Model Disagreement on Unlabeled Data to Validate Classification Algorithms(3).pdf}
}

@inproceedings{madras2019fairness,
  title = {Fairness through Causal Awareness: {{Learning}} Causal Latent-Variable Models for Biased Data},
  booktitle = {Proceedings of the {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Madras, David and Creager, Elliot and Pitassi, Toniann and Zemel, Richard},
  year = {2019},
  pages = {349--358},
  publisher = {ACM}
}

@article{maffei2008multiple,
  title = {Multiple Modes of Network Homeostasis in Visual Cortical Layer 2/3},
  author = {Maffei, Arianna and Turrigiano, Gina G},
  year = {2008},
  journal = {The Journal of Neuroscience},
  volume = {28},
  number = {17},
  pages = {4377--4384}
}

@article{majeed2011spatiotemporal,
  title = {Spatiotemporal Dynamics of Low Frequency {{BOLD}} Fluctuations in Rats and Humans.},
  author = {Majeed, Waqas and Magnuson, Matthew and Hasenkamp, Wendy and Schwarb, Hillary and Schumacher, Eric H and Barsalou, Lawrence and Keilholz, Shella D},
  year = {2011},
  month = jan,
  journal = {NeuroImage},
  volume = {54},
  number = {2},
  pages = {1140--50},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2010.08.030},
  abstract = {Most studies involving spontaneous fluctuations in the BOLD signal extract connectivity patterns that show relationships between brain areas that are maintained over the length of the scanning session. In this study, however, we examine the spatiotemporal dynamics of the BOLD fluctuations to identify common patterns of propagation within a scan. A novel pattern finding algorithm was developed for detecting repeated spatiotemporal patterns in BOLD fMRI data. The algorithm was applied to high temporal resolution T2*-weighted multislice images obtained from rats and humans in the absence of any task or stimulation. In rats, the primary pattern consisted of waves of high signal intensity, propagating in a lateral to medial direction across the cortex, replicating our previous findings (Majeed et al., 2009a). These waves were observed primarily in sensorimotor cortex, but also extended to visual and parietal association areas. A secondary pattern, confined to subcortical regions consisted of an initial increase and subsequent decrease in signal intensity in the caudate-putamen. In humans, the most common spatiotemporal pattern consisted of an alteration between activation of areas comprising the "default-mode" (e.g., posterior cingulate and anterior medial prefrontal cortices) and the "task-positive" (e.g., superior parietal and premotor cortices) networks. Signal propagation from focal starting points was also observed. The pattern finding algorithm was shown to be reasonably insensitive to the variation in user-defined parameters, and the results were consistent within and between subjects. This novel approach for probing the spontaneous network activity of the brain has implications for the interpretation of conventional functional connectivity studies, and may increase the amount of information that can be obtained from neuroimaging data.},
  pmid = {20728554},
  keywords = {Adult,Aged,Algorithms,Animals,Brain,Brain Mapping,Brain Mapping: methods,Brain: physiology,Computer-Assisted,Computer-Assisted: methods,Female,Humans,Image Processing,Magnetic Resonance Imaging,Male,Middle Aged,Neural Pathways,Rats,Young Adult},
  file = {/Users/brownsarahm/Zotero/storage/ZB6GRVCW/Majeed et al. - 2011 - Spatiotemporal dynamics of low frequency BOLD fluctuations in rats and humans(3).pdf}
}

@article{makeig2002dynamic,
  title = {Dynamic Brain Sources of Visual Evoked Responses},
  author = {Makeig, S and Westerfield, M and Jung, T-P and Enghoff, S and Townsend, J and Courchesne, E and Sejnowski, T J},
  year = {2002},
  journal = {Science},
  volume = {295},
  number = {5555},
  pages = {690--694}
}

@article{makeig2004mining,
  title = {Mining Event-Related Brain Dynamics},
  author = {Makeig, Scott and Debener, Stefan and Onton, Julie and Delorme, Arnaud},
  year = {2004},
  journal = {Trends in cognitive sciences},
  volume = {8},
  number = {5},
  pages = {204--210}
}

@article{mallat1989multifrequency,
  title = {Multifrequency {{Channel Decomposition}} of {{Images}} and {{Wavelet Model}}},
  author = {Mallat, Stephane},
  year = {1989},
  journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
  file = {/Users/brownsarahm/Zotero/storage/G7RRB6GM/Mallat - 1989 - Multifrequency Channel Decomposition of Images and Wavelet Model(3).pdf}
}

@article{manathunga2009research,
  title = {Research as an Intercultural `contact Zone'},
  author = {Manathunga, Catherine},
  year = {2009},
  journal = {Discourse: Studies in the Cultural Politics of Education},
  volume = {30},
  number = {2},
  pages = {165--177},
  issn = {0159-6306},
  doi = {10.1080/01596300902809161},
  abstract = {Contemporary researchers need to work across many cultural boundaries between ethnicities, between disciplines, between universities and industry, between professional cultures, and between various workplace cultures. While many authors have sought to characterise aspects of this boundary work, there remains little research on how researchers, especially research higher degree students, might be adequately prepared to work sensitively in these cultural borderlands. This article draws upon the post-colonial concept of the `contact zone' to reconceptualise the knowledge and skills required by the successful intercultural researcher. It demonstrates how recognition of and engagement with cultural difference can create deconstructive, productive possibilities for innova- tive research and new knowledge. The article also examines the consequences of a lack of intercultural sensitivity and equity  the symbolic violence and exploitation present in the contemporary research arena. This recasting of research has significant implications for future research training.},
  keywords = {contact zone,intercultural skills,knowledge production,post-colonial theory,research,research training}
}

@book{mangoubi1998robust,
  title = {Robust {{Estimation}} and {{Failure Detection}}: {{A Concise Treatment}}},
  author = {Mangoubi, Rami S},
  year = {1998},
  publisher = {Springer-Verlag New York, Inc.},
  address = {Secaucus, NJ, USA},
  isbn = {3-540-76251-5}
}

@inproceedings{mansinghka2009crosscategorization,
  title = {Cross-Categorization: {{A}} Method for Discovering Multiple Overlapping Clusterings},
  booktitle = {Nonparametric {{Bayes Workshop}} at {{NIPS}}},
  author = {Mansinghka, V and Jonas, E and Petschulat, C and Cronin, B and Shafto, P and Tenenbaum, J},
  year = {2009}
}

@article{marblestone2016integration,
  title = {Towards an Integration of Deep Learning and Neuroscience},
  author = {Marblestone, Adam H and Wayne, Greg and Kording, Konrad P},
  year = {2016},
  journal = {Frontiers in computational neuroscience},
  pages = {1--61},
  doi = {10.1101/058545},
  keywords = {cognitive architecture,cost functions,neural networks,neuroscience},
  file = {/Users/brownsarahm/Zotero/storage/G5V28VFA/Marblestone, Wayne, Kording - 2016 - Towards an integration of deep learning and neuroscience(3).pdf}
}

@article{marder2002modeling,
  title = {Modeling Stability in Neuron and Network Function: The Role of Activity in Homeostasis},
  author = {Marder, Eve and Prinz, Astrid A},
  year = {2002},
  journal = {Bioessays},
  volume = {24},
  number = {12},
  pages = {1145--1154}
}

@article{marder2006variability,
  title = {Variability, Compensation and Homeostasis in Neuron and Network Function.},
  author = {Marder, Eve and Goaillard, Jean-Marc},
  year = {2006},
  journal = {Nature reviews. Neuroscience},
  volume = {7},
  number = {July},
  pages = {563--574},
  issn = {1471-003X},
  doi = {10.1038/nrn1949},
  abstract = {Neurons in most animals live a very long time relative to the half-lives of all of the proteins that govern excitability and synaptic transmission. Consequently, homeostatic mechanisms are necessary to ensure stable neuronal and network function over an animal's lifetime. To understand how these homeostatic mechanisms might function, it is crucial to understand how tightly regulated synaptic and intrinsic properties must be for adequate network performance, and the extent to which compensatory mechanisms allow for multiple solutions to the production of similar behaviour. Here, we use examples from theoretical and experimental studies of invertebrates and vertebrates to explore several issues relevant to understanding the precision of tuning of synaptic and intrinsic currents for the operation of functional neuronal circuits.},
  pmid = {16791145},
  file = {/Users/brownsarahm/Zotero/storage/GCFQGDWC/Marder, Goaillard - 2006 - Variability, compensation and homeostasis in neuron and network function(3).pdf}
}

@article{marder2011multiple,
  title = {Multiple Models to Capture the Variability in Biological Neurons and Networks},
  author = {Marder, Eve and Taylor, Adam L},
  year = {2011},
  journal = {Nature neuroscience},
  volume = {14},
  number = {2},
  pages = {133--138}
}

@article{marreiros2008dynamic,
  title = {Dynamic Causal Modelling for {{fMRI}}: A Two-State Model.},
  author = {Marreiros, A C and Kiebel, S J and Friston, K J},
  year = {2008},
  month = jan,
  journal = {NeuroImage},
  volume = {39},
  number = {1},
  eprint = {17936017},
  eprinttype = {pubmed},
  pages = {269--278},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2007.08.019},
  abstract = {Dynamical causal modelling (DCM) for functional magnetic resonance imaging (fMRI) is a technique to infer directed connectivity among brain regions. These models distinguish between a neuronal level, which models neuronal interactions among regions, and an observation level, which models the hemodynamic responses each region. The original DCM formulation considered only one neuronal state per region. In this work, we adopt a more plausible and less constrained neuronal model, using two neuronal states (populations) per region. Critically, this gives us an explicit model of intrinsic (between-population) connectivity within a region. In addition, by using positivity constraints, the model conforms to the organization of real cortical hierarchies, whose extrinsic connections are excitatory (glutamatergic). By incorporating two populations within each region we can model selective changes in both extrinsic and intrinsic connectivity. Using synthetic data, we show that the two-state model is internal consistent and identifiable. We then apply the model to real data, explicitly modelling intrinsic connections. Using model comparison, we found that the two-state model is better than the single-state model. Furthermore, using the two-state model we find that it is possible to disambiguate between subtle changes in coupling; we were able to show that attentional gain, in the context of visual motion processing, is accounted for sufficiently by an increased sensitivity of excitatory populations of neurons in V5, to forward afferents from earlier visual areas.},
  pmid = {17936017},
  keywords = {Attention,Attention: physiology,Computer Simulation,Computer-Assisted,Computer-Assisted: methods,Evoked Potentials,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Models,Motion Perception,Motion Perception: physiology,Neurological,Reproducibility of Results,Sensitivity and Specificity,Visual,Visual Cortex,Visual Cortex: physiology,Visual: physiology}
}

@incollection{marsella2010computational,
  title = {Computational Models of Emotion},
  booktitle = {A {{Blueprint}} for {{Affective Computing-A Sourcebook}} and {{Manual}}},
  author = {Marsella, Stacy and Gratch, Jonathan and Petta, Paolo},
  year = {2010},
  pages = {21--46},
  publisher = {Oxford University Press},
  file = {/Users/brownsarahm/Zotero/storage/P7WGJ65J/Marsella, Gratch, Petta - 2010 - Computational models of emotion(3).pdf}
}

@article{martinez-sanchez1998use,
  title = {The {{Use}} of {{Vibration Data}} for {{Liquid Rocket}}},
  author = {{Martinez-sanchez}, Manuel},
  year = {1998},
  pages = {1--10},
  file = {/Users/brownsarahm/Zotero/storage/A449WARA/Martinez-sanchez - 1998 - The Use of Vibration Data for Liquid Rocket(3).pdf}
}

@book{martinez2001computational,
  title = {Computational Statistics Handbook with {{MATLAB}}},
  author = {Martinez, {\relax WL} and Martinez, {\relax AR}},
  year = {2001},
  isbn = {1-58488-229-8},
  file = {/Users/brownsarahm/Zotero/storage/AN2YAKHX/Martinez, Martinez - 2001 - Computational statistics handbook with MATLAB(3).pdf}
}

@inproceedings{marx2020predictive,
  ids = {marx2020Predictive,marx2020Predictivea},
  title = {Predictive Multiplicity in Classification},
  booktitle = {International Conference on Machine Learning},
  author = {Marx, Charles and Calmon, Flavio and Ustun, Berk},
  year = {2020},
  pages = {6765--6774},
  publisher = {PMLR}
}

@article{masaeli2010transformationbased,
  title = {From Transformation-Based Dimensionality Reduction to Feature Selection},
  author = {Masaeli, Mahdokht and Fung, Glenn and Dy, {\relax JG}},
  year = {2010},
  journal = {Int. Conf. on Machine {\textbackslash}ldots},
  keywords = {feature selection,sparse meth,variable selection},
  file = {/Users/brownsarahm/Zotero/storage/5L6MS66B/Masaeli, Fung, Dy - 2010 - From transformation-based dimensionality reduction to feature selection(3).pdf}
}

@article{mason2015hidden,
  title = {Hidden in Plain View: Degeneracy in Complex Systems},
  author = {Mason, P.H. and Dom{\'i}nguez D., J.F. and Winter, B. and Grignolio, a.},
  year = {2015},
  journal = {Biosystems},
  volume = {128},
  pages = {1--8},
  issn = {03032647},
  doi = {10.1016/j.biosystems.2014.12.003},
  file = {/Users/brownsarahm/Zotero/storage/YS3TFSNX/Mason et al. - 2015 - Hidden in plain view degeneracy in complex systems(3).pdf}
}

@article{matsuyama2011fast,
  title = {Fast Estimation of {{Hidden Markov Models}} via Alpha-{{EM}} Algorithm},
  author = {Matsuyama, Yasuo and Hayashi, Ryunosuke and Yokote, Ryota},
  year = {2011},
  month = jun,
  journal = {2011 IEEE Statistical Signal Processing Workshop (SSP)},
  number = {6},
  pages = {89--92},
  doi = {10.1109/SSP.2011.5967835},
  file = {/Users/brownsarahm/Zotero/storage/ZWAU3P5T/Matsuyama, Hayashi, Yokote - 2011 - Fast estimation of Hidden Markov Models via alpha-EM algorithm(3).pdf}
}

@article{maxwell2004persistence,
  title = {The Persistence of Underpowered Studies in Psychological Research: Causes, Consequences, and Remedies.},
  author = {Maxwell, Scott E},
  year = {2004},
  journal = {Psychological methods},
  volume = {9},
  number = {2},
  pages = {147},
  publisher = {American Psychological Association}
}

@book{mayr1982growth,
  title = {The Growth of Biological Thought: Diversity, Evolution, and Inheritance},
  author = {Mayr, Ernst},
  year = {1982},
  publisher = {Harvard University Press}
}

@article{mazaheri2010rhythmic,
  title = {Rhythmic Pulsing: Linking Ongoing Brain Activity with Evoked Responses},
  author = {Mazaheri, Ali and Jensen, Ole},
  year = {2010},
  journal = {Frontiers in human neuroscience},
  volume = {4},
  number = {0}
}

@inproceedings{mccahan2012multidimensional,
  title = {A {{Multi-Dimensional Model}} for the {{Representation}} of {{Learning Through Service Activities}} in {{Engineering}}},
  booktitle = {American {{Society}} for {{Engineering Education}}},
  author = {McCahan, Susan (University of Toronto) and Ault, Holly K. (Wodrcester Polytechnic Institute) and Tsang, Edmund (Western Michigan University) and Henderson, Mark P, (Arizonal State University, Polytechnic) and Magleby, Spencer P. (Brigham Young University) and Soisson, Annie (Tufts University)},
  year = {2012},
  isbn = {978-0-87823-241-3}
}

@article{mcdaniel2014individual,
  title = {Individual Differences in Learning and Transfer: {{Stable}} Tendencies for Learning Exemplars versus Abstracting Rules.},
  author = {Mcdaniel, Mark A and Cahill, Michael J and Robbins, Mathew and Wiener, Chelsea},
  year = {2014},
  journal = {Journal of Experimental Psychology: General},
  volume = {143},
  number = {2},
  pages = {668},
  doi = {10.1037/a0032963.Individual},
  file = {/Users/brownsarahm/Zotero/storage/UNXPDGE9/Mcdaniel et al. - 2015 - Individual Differences in Learning and Transfer Stable Tendencies for Leanring Exemplars versus Abstracting (2).pdf}
}

@article{mcdiarmid1989method,
  title = {On the Method of Bounded Differences},
  author = {McDiarmid, Colin},
  year = {1989},
  journal = {Surveys in combinatorics},
  volume = {141},
  number = {1},
  pages = {148--188}
}

@article{mcfadden2013effects,
  title = {Effects of Exercise on Resting-State Default Mode and Salience Network Activity in Overweight/Obese Adults},
  author = {McFadden, Kristina L and Cornier, Marc-Andre and Melanson, Edward L and Bechtell, Jamie L and Tregellas, Jason R},
  year = {2013},
  journal = {Neuroreport},
  volume = {24},
  number = {15},
  pages = {866}
}

@article{mcintosh2000network,
  title = {Towards a Network Theory of Cognition},
  author = {McIntosh, a. R.},
  year = {2000},
  journal = {Neural Networks},
  volume = {13},
  pages = {861--870},
  issn = {08936080},
  doi = {10.1016/S0893-6080(00)00059-9},
  abstract = {For cognitive neuroscience to go forward a more explicit effort is needed to use neurophysiology to constrain how the brain produces human mental functions. This review begins with the suggestion that two fundamental features may be critical for this effort. The first is the connectivity of the brain, which occupies an intermediate position between complete redundant interconnections and independence. The term semiconnected is presented as a designation, which is an obvious derivation of the term semiconductors as used in engineering. The second is transient response plasticity where a given neuron or collection of neurons may show rapid changes in response characteristics depending on experience. Response plasticity is a ubiquitous property of the brain rather than a unique characteristic of 'neurocognitive' regions. These two properties may be brought together when brain areas interact such that their aggregate function embodies cognition. Three examples are used to illustrate these general principles and to develop the idea that a particular region in isolation may not act as a reliable index for a particular cognitive function. Instead, the neural context in which an area is active may define the cognitive function. Neural context emphasizes that the particular spatiotemporal pattern of neural interactions may hold the key to bridge between brain and mind. Copyright (C) 2000 Elsevier Science Ltd.},
  pmid = {11156197},
  keywords = {Cognitive neuroscience,Connectivity,Plasticity},
  file = {/Users/brownsarahm/Zotero/storage/W6Z995BD/McIntosh - 2000 - Towards a network theory of cognition(3).pdf}
}

@inproceedings{mckinney2010pandas,
  title = {Data {{Structures}} for {{Statistical Computing}} in {{Python}}},
  booktitle = {Proceedings of the 9th {{Python}} in {{Science Conference}}},
  author = {{Wes McKinney}},
  editor = {{\noopsort{walt}}{van der Walt}, St{\'e}fan and {Jarrod Millman}},
  year = {2010},
  pages = {56--61},
  doi = {10.25080/Majora-92bf1922-00a}
}

@article{mcneil1982elicitation,
  title = {On the Elicitation of Preferences for Alternative Therapies},
  author = {McNeil, Barbara J and Pauker, Stephen G and Sox Jr, Harold C and Tversky, Amos},
  year = {1982},
  journal = {New England journal of medicine},
  volume = {306},
  number = {21},
  pages = {1259--1262},
  publisher = {Mass Medical Soc}
}

@article{medin1989psychological,
  title = {Psychological Essentialism},
  author = {Medin, Douglas L and Ortony, Andrew},
  year = {1989},
  journal = {Similarity and analogical reasoning},
  pages = {179--195}
}

@article{mehrabi2021Survey,
  ids = {mehrabi2021Surveya},
  title = {A Survey on Bias and Fairness in Machine Learning},
  author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  year = {2021},
  journal = {ACM computing surveys (CSUR)},
  volume = {54},
  number = {6},
  pages = {1--35},
  publisher = {ACM New York, NY, USA},
  issn = {0360-0300}
}

@article{meltzoff2009foundations,
  title = {Foundations for a New Science of Learning},
  author = {Meltzoff, Andrew N and Kuhl, Patricia K and Movellan, Javier R. and Sejnowski, Terrence J},
  year = {2009},
  journal = {Science (New York, N.Y.)},
  volume = {325},
  number = {July},
  pages = {284--8},
  issn = {1095-9203},
  doi = {10.1126/science.1175626},
  abstract = {Human learning is distinguished by the range and complexity of skills that can be learned and the degree of abstraction that can be achieved compared with those of other species. Homo sapiens is also the only species that has developed formal ways to enhance learning: teachers, schools, and curricula. Human infants have an intense interest in people and their behavior and possess powerful implicit learning mechanisms that are affected by social interaction. Neuroscientists are beginning to understand the brain mechanisms underlying learning and how shared brain systems for perception and action support social learning. Machine learning algorithms are being developed that allow robots and computers to learn autonomously. New insights from many different fields are converging to create a new science of learning that may transform educational practices.},
  pmid = {19608908},
  keywords = {Artificial Intelligence,Attention,Brain,Brain: physiology,Child,Child Language,Education,Emotions,Empathy,Humans,Imitative Behavior,Infant,Interpersonal Relations,Language Development,Learning,Neuronal Plasticity,Perception,Preschool,Teaching},
  file = {/Users/brownsarahm/Zotero/storage/4FPVUYRN/Meltzoff et al. - 2009 - Foundations for a new science of learning(3).pdf}
}

@article{mendler2022anticipating,
  ids = {mendler-dunner2022Anticipating},
  title = {Anticipating Performativity by Predicting from Predictions},
  author = {{Mendler-D{\"u}nner}, Celestine and Ding, Frances and Wang, Yixin},
  year = {2022},
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {31171--31185}
}

@article{menon2011largescale,
  title = {Large-Scale Brain Networks and Psychopathology: A Unifying Triple Network Model},
  author = {Menon, Vinod},
  year = {2011},
  journal = {Trends in Cognitive Sciences},
  volume = {15},
  number = {10},
  pages = {483--506}
}

@book{mesquita2010mind,
  title = {The Mind in Context},
  author = {Mesquita, Batja and Barrett, Lisa Feldman and Smith, Eliot R},
  year = {2010},
  publisher = {Guilford Press}
}

@article{metula2011advanced,
  title = {Advanced {{Topics}}},
  author = {Metula, Erez},
  year = {2011},
  pages = {219--258},
  doi = {10.1016/B978-1-59749-574-5.00008-8},
  file = {/Users/brownsarahm/Zotero/storage/GU5BMXD4/Metula - 2011 - Advanced Topics(3).pdf}
}

@article{meyer1998morphology,
  title = {Morphology of Acallosal Brains as Assessed by {{MRI}} in Six Patients Leading a Normal Daily Life},
  author = {Meyer, B. U. and R{\"o}richt, S. and Niehaus, L.},
  year = {1998},
  journal = {Journal of Neurology},
  volume = {245},
  number = {2},
  pages = {106--110},
  issn = {03405354},
  doi = {10.1007/s004150050187},
  abstract = {The pattern of anatomical features of the brain revealed by magnetic resonance imaging (MRI) is described in six patients incidentally identified as having acallosal brains. The complex of morphological features associated with complete agenesis of the corpus callosum included lateral displacement of slitlike anterior horns of the lateral ventricles (bullhorn-like shape), dilatation of the posterior horns of the lateral ventricles, absence of the septum pellucidum, lateral displacement of the cingulate gyri, complete separation of fornices and the presence of the anterior commissure and longitudinal callosal bundles (Probst's bundles). No compensatory enlargement of the anterior commissure was seen in the patients. The planimetrically measured cross-sectional areas of the anterior commissures were between 2.0 and 4.2 mm2 (mean 3.1) (in ten normal subjects they were 4.5, SD 0.4; range 3.8-5.2 mm2) and were reduced in four and normal in two patients. Inconstant morphological features were an absence of the posterior commissure and a radial pattern of the sulci and gyri on the medial aspect of the hemispheres. Conventional clinical testing revealed no abnormalities except a slight impairment of walking heel-to-toe in two patients. None of the patients had subjective restrictions of activities of daily life, which shows the efficacy of unknown compensatory processes.},
  pmid = {9507417},
  keywords = {Agenesis of the corpus callosum,Asymptomatic,Magnetic resonance imaging}
}

@inproceedings{meyer2006use,
  title = {On the Use of Variable Complementarity for Feature Selection in Cancer Classification},
  booktitle = {Lecture {{Notes}} in {{Computer Science}} (Including Subseries {{Lecture Notes}} in {{Artificial Intelligence}} and {{Lecture Notes}} in {{Bioinformatics}})},
  author = {Meyer, Patrick E PE and Bontempi, Gianluca},
  year = {2006},
  volume = {3907 LNCS},
  pages = {91--102},
  publisher = {Springer},
  doi = {10.1007/11732242_9},
  abstract = {The paper presents an original filter approach for effective feature selection in classification tasks with a very large number of input variables. The approach is based on the use of a new information theo- retic selection criterion: the double input symmetrical relevance (DISR). The rationale of the criterion is that a set of variables can return an information on the output class that is higher than the sum of the infor- mations of each variable taken individually. This property will be made explicit by defining the measure of variable complementarity. A feature selection filter based on the DISR criterion is compared in theoretical and experimental terms to recently proposed information theoretic cri- teria. Experimental results on a set of eleven microarray classification tasks show that the proposed technique is competitive with existing fil- ter selection methods.},
  isbn = {3-540-33237-5},
  file = {/Users/brownsarahm/Zotero/storage/DS9I9J8D/Meyer, Bontempi - Unknown - On the Use of Variable Complementarity for Feature Selection in Cancer Classification(2).pdf}
}

@article{meyerowitz1987effect,
  title = {The Effect of Message Framing on Breast Self-Examination Attitudes, Intentions, and Behavior.},
  author = {Meyerowitz, Beth E and Chaiken, Shelly},
  year = {1987},
  journal = {Journal of personality and social psychology},
  volume = {52},
  number = {3},
  pages = {500},
  publisher = {American Psychological Association}
}

@article{michel1971accuracy,
  title = {The Accuracy of the Normal Approximation for Minimum Contrast Estimates},
  author = {Michel, R. and Pfanzagl, J.},
  year = {1971},
  month = mar,
  journal = {Zeitschrift f{\"u}r Wahrscheinlichkeitstheorie und Verwandte Gebiete},
  volume = {18},
  number = {1},
  pages = {73--84},
  issn = {1432-2064},
  doi = {10.1007/BF00538488},
  urldate = {2020-05-07},
  langid = {english}
}

@article{miconi2017impossibility,
  title = {The Impossibility of "Fairness": A Generalized Impossibility Result for Decisions},
  author = {Miconi, Thomas},
  year = {2017},
  abstract = {Various measures can be used to estimate bias or unfairness in a predictor. Previous work has already established that some of these measures are incompatible with each other. Here we show that, when groups differ in prevalence of the predicted event, several intuitive, reasonable measures of fairness (probability of positive prediction given occurrence or non-occurrence; probability of occurrence given prediction or non-prediction; and ratio of predictions over occurrences for each group) are all mutually exclusive: if one of them is equal among groups, the other two must differ. The only exceptions are for perfect, or trivial (always-positive or always-negative) predictors. As a consequence, any non-perfect, non-trivial predictor must necessarily be "unfair" under two out of three reasonable sets of criteria. This result readily generalizes to a wide range of well-known statistical quantities (sensitivity, specificity, false positive rate, precision, etc.), all of which can be divided into three mutually exclusive groups. Importantly, The results applies to all predictors, whether algorithmic or human. We conclude with possible ways to handle this effect when assessing and designing prediction methods.},
  file = {/Users/brownsarahm/Zotero/storage/3ECG59ZD/Miconi - 2017 - The impossibility of fairness a generalized impossibility result for decisions.pdf}
}

@inproceedings{mimno2011bayesian,
  title = {Bayesian {{Checking}} for {{Topic Models}}},
  booktitle = {Proceedings of the {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Mimno, David and Blei, David},
  year = {2011},
  isbn = {978-1-937284-11-4},
  keywords = {topic models},
  file = {/Users/brownsarahm/Zotero/storage/GZWZT77P/Mimno, Blei - 2011 - Bayesian Checking for Topic Models(3).pdf}
}

@article{min2010filterwrapper,
  title = {Filter-{{Wrapper Hybrid Method}} on {{Feature Selection}}},
  author = {Min, Hu and Fangfang, Wu},
  year = {2010},
  month = dec,
  journal = {2010 Second WRI Global Congress on Intelligent Systems},
  pages = {98--101},
  doi = {10.1109/GCIS.2010.235},
  keywords = {- feature selection,filter method,wrapper method},
  file = {/Users/brownsarahm/Zotero/storage/B5ABDX75/Min, Fangfang - 2010 - Filter-Wrapper Hybrid Method on Feature Selection(3).pdf}
}

@article{minka2000estimating,
  title = {Estimating a {{Dirichlet}} Distribution},
  author = {Minka, T},
  year = {2000},
  volume = {2000},
  number = {8},
  pages = {1--14},
  file = {/Users/brownsarahm/Zotero/storage/GNRKKFCZ/Minka - 2000 - Estimating a Dirichlet distribution(3).pdf}
}

@article{mitchell2008predicting,
  title = {Predicting Human Brain Activity Associated with the Meanings of Nouns.},
  author = {Mitchell, Tom M and Shinkareva, Svetlana V and Carlson, Andrew and Chang, Kai-Min and Malave, Vicente L and {\noopsort{mason}}a Mason, Robert and Just, Marcel Adam},
  year = {2008},
  journal = {Science (New York, N.Y.)},
  volume = {320},
  number = {2008},
  pages = {1191--1195},
  issn = {1095-9203},
  doi = {10.1126/science.1152876},
  abstract = {The question of how the human brain represents conceptual knowledge has been debated in many scientific fields. Brain imaging studies have shown that different spatial patterns of neural activation are associated with thinking about different semantic categories of pictures and words (for example, tools, buildings, and animals). We present a computational model that predicts the functional magnetic resonance imaging (fMRI) neural activation associated with words for which fMRI data are not yet available. This model is trained with a combination of data from a trillion-word text corpus and observed fMRI data associated with viewing several dozen concrete nouns. Once trained, the model predicts fMRI activation for thousands of other concrete nouns in the text corpus, with highly significant accuracies over the 60 nouns for which we currently have fMRI data.},
  pmid = {18511683},
  file = {/Users/brownsarahm/Zotero/storage/6555UIUT/Mitchell et al. - 2008 - Predicting human brain activity associated with the meanings of nouns(3).pdf}
}

@article{mitchell2012revisiting,
  title = {Revisiting Truth or Triviality: {{The}} External Validity of Research in the Psychological Laboratory},
  author = {Mitchell, Gregory},
  year = {2012},
  journal = {Perspectives on Psychological Science},
  volume = {7},
  number = {2},
  pages = {109--117}
}

@article{mitchell2018predictionbased,
  title = {Prediction-{{Based Decisions}} and {{Fairness}}: {{A Catalogue}} of {{Choices}}, {{Assumptions}}, and {{Definitions}}},
  author = {Mitchell, Shira and Potash, Eric and Barocas, Solon},
  year = {2018},
  pages = {1--17},
  abstract = {A recent flurry of research activity has attempted to quantitatively define "fairness" for decisions based on statistical and machine learning (ML) predictions. The rapid growth of this new field has led to wildly inconsistent terminology and notation, presenting a serious challenge for cataloguing and comparing definitions. This paper attempts to bring much-needed order. First, we explicate the various choices and assumptions made---often implicitly---to justify the use of prediction-based decisions. Next, we show how such choices and assumptions can raise concerns about fairness and we present a notationally consistent catalogue of fairness definitions from the ML literature. In doing so, we offer a concise reference for thinking through the choices, assumptions, and fairness considerations of prediction-based decision systems.}
}

@inproceedings{mitchell2019model,
  title = {Model Cards for Model Reporting},
  booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
  author = {Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
  year = {2019},
  pages = {220--229}
}

@article{mjolsness2001machine,
  title = {Machine Learning for Science: State of the Art and Future Prospects.},
  author = {Mjolsness, E and DeCoste, D},
  year = {2001},
  month = sep,
  journal = {Science (New York, N.Y.)},
  volume = {293},
  number = {5537},
  eprint = {11557883},
  eprinttype = {pubmed},
  pages = {2051--5},
  issn = {0036-8075},
  doi = {10.1126/science.293.5537.2051},
  abstract = {Recent advances in machine learning methods, along with successful applications across a wide variety of fields such as planetary science and bioinformatics, promise powerful new tools for practicing scientists. This viewpoint highlights some useful characteristics of modern machine learning methods and their relevance to scientific applications. We conclude with some speculations on near-term progress and promising directions.},
  pmid = {11557883},
  keywords = {Algorithms,Animals,Artificial Intelligence,Astronomical Phenomena,Astronomy,Cluster Analysis,Computational Biology,Computer Simulation,Computer-Assisted,Gene Expression Profiling,Gene Expression Regulation,Image Processing,Neural Networks (Computer),Physical Phenomena,Physics,Robotics},
  file = {/Users/brownsarahm/Zotero/storage/FQ8P4DR5/Mjolsness, DeCoste - 2001 - Machine learning for science state of the art and future prospects(3).pdf}
}

@article{moeslund2001Survey,
  ids = {moeslund2001Surveya,moeslund2001Surveyb},
  title = {A Survey of Computer Vision-Based Human Motion Capture},
  author = {Moeslund, Thomas B and Granum, Erik},
  year = {2001},
  journal = {Computer vision and image understanding},
  volume = {81},
  number = {3},
  pages = {231--268},
  publisher = {Academic Press}
}

@incollection{mohan2015missing,
  title = {Missing {{Data}} from a {{Causal Perspective}}},
  booktitle = {Advanced {{Methodologies}} for {{Bayesian Networks}}},
  author = {Mohan, Karthika and Pearl, Judea},
  editor = {Suzuki, Joe and Ueno, Maomi},
  year = {2015},
  volume = {9505},
  pages = {184--195},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-28379-1_13},
  urldate = {2019-11-21},
  abstract = {This paper applies graph based causal inference procedures for recovering information from missing data. We establish conditions that permit and prohibit recoverability. In the event of theoretical impediments to recoverability, we develop graph based procedures using auxiliary variables and external data to overcome such impediments. We demonstrate the perils of model-blind recovery procedures both in determining whether or not a query is recoverable and in choosing an estimation procedure when recoverability holds.},
  isbn = {978-3-319-28378-4 978-3-319-28379-1},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/9XBHFPDN/Mohan and Pearl - 2015 - Missing Data from a Causal Perspective.pdf}
}

@inproceedings{monroe-white2021Emancipatory,
  title = {Emancipatory {{Data Science}}: {{A Liberatory Framework}} for {{Mitigating Data Harms}} and {{Fostering Social Transformation}}},
  shorttitle = {Emancipatory {{Data Science}}},
  booktitle = {Proceedings of the 2021 on {{Computers}} and {{People Research Conference}}},
  author = {{Monroe-White}, Thema},
  year = {2021},
  month = jun,
  pages = {23--30},
  publisher = {ACM},
  address = {Virtual Event Germany},
  doi = {10.1145/3458026.3462161},
  urldate = {2024-04-15},
  isbn = {978-1-4503-8406-3},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/HK882CEJ/Monroe-White - 2021 - Emancipatory Data Science A Liberatory Framework .pdf}
}

@article{moriguchi2011differential,
  title = {Differential Hemodynamic Response in Affective Circuitry with Aging: An {{FMRI}} Study of Novelty, Valence, and Arousal.},
  author = {Moriguchi, Yoshiya and Negreira, Alyson and Weierich, Mariann and Dautoff, Rebecca and Dickerson, Bradford C and Wright, Christopher I and Barrett, Lisa Feldman},
  year = {2011},
  month = may,
  journal = {Journal of cognitive neuroscience},
  volume = {23},
  number = {5},
  pages = {1027--1041},
  issn = {1530-8898},
  doi = {10.1162/jocn.2010.21527},
  abstract = {Emerging evidence indicates that stimulus novelty is affectively potent and reliably engages the amygdala and other portions of the affective workspace in the brain. Using fMRI, we examined whether novel stimuli remain affectively salient across the lifespan, and therefore, whether novelty processing--a potentially survival-relevant function--is preserved with aging. Nineteen young and 22 older healthy adults were scanned during observing novel and familiar affective pictures while estimating their own subjectively experienced aroused levels. We investigated age-related difference of magnitude of activation, hemodynamic time course, and functional connectivity of BOLD responses in the amygdala. Although there were no age-related differences in the peak response of the amygdala to novelty, older individuals showed a narrower, sharper (i.e., "peakier") hemodynamic time course in response to novel stimuli, as well as decreased connectivity between the left amygdala and the affective areas including orbito-frontal regions. These findings have relevance for understanding age-related differences in memory and affect regulation.},
  pmid = {20521849},
  keywords = {80 and over,Adult,Affect,Affect: physiology,Aged,Aging,Aging: physiology,Amygdala,Amygdala: blood supply,Amygdala: physiology,Analysis of Variance,Arousal,Arousal: physiology,Brain Mapping,Cerebrovascular Circulation,Cerebrovascular Circulation: physiology,Discrimination (Psychology),Discrimination (Psychology): physiology,Exploratory Behavior,Exploratory Behavior: physiology,Female,Frontal Lobe,Frontal Lobe: blood supply,Frontal Lobe: physiology,Functional Laterality,Functional Laterality: physiology,Humans,Magnetic Resonance Imaging,Male,Middle Aged,Photic Stimulation,Recognition (Psychology),Recognition (Psychology): physiology,Reference Values,Young Adult}
}

@article{moriguchi2014sex,
  title = {Sex Differences in the Neural Correlates of Affective Experience},
  author = {Moriguchi, Yoshiya and Touroutoglou, Alexandra and Dickerson, Bradford C and Barrett, Lisa Feldman},
  year = {2014},
  journal = {Social cognitive and affective neuroscience},
  volume = {9},
  number = {5},
  pages = {591--600}
}

@book{morozov2013save,
  title = {To Save Everything, Click Here: {{The}} Folly of Technological Solutionism},
  author = {Morozov, Evgeny},
  year = {2013},
  publisher = {PublicAffairs}
}

@misc{morrisonAsked,
  title = {I Asked {{ChatGPT}} to Create Images Based on What It Knows about Me --- Here's How It Went},
  author = {Morrison, Ryan},
  journal = {Toms guide},
  urldate = {2024-11-05}
}

@article{mouzannar2018fair,
  title = {From {{Fair Decision Making}} to {{Social Equality}}},
  author = {Mouzannar, Hussein and Ohannessian, Mesrob I. and Srebro, Nathan},
  year = {2018},
  pages = {359--368},
  abstract = {The study of fairness in intelligent decision systems has mostly ignored long-term influence on the underlying population. Yet fairness considerations (e.g. affirmative action) have often the implicit goal of achieving balance among groups within the population. The most basic notion of balance is eventual equality between the qualifications of the groups. How can we incorporate influence dynamics in decision making? How well do dynamics-oblivious fairness policies fare in terms of reaching equality? In this paper, we propose a simple yet revealing model that encompasses (1) a selection process where an institution chooses from multiple groups according to their qualifications so as to maximize an institutional utility and (2) dynamics that govern the evolution of the groups' qualifications according to the imposed policies. We focus on demographic parity as the formalism of affirmative action. We then give conditions under which an unconstrained policy reaches equality on its own. In this case, surprisingly, imposing demographic parity may break equality. When it doesn't, one would expect the additional constraint to reduce utility, however, we show that utility may in fact increase. In more realistic scenarios, unconstrained policies do not lead to equality. In such cases, we show that although imposing demographic parity may remedy it, there is a danger that groups settle at a worse set of qualifications. As a silver lining, we also identify when the constraint not only leads to equality, but also improves all groups. This gives quantifiable insight into both sides of the mismatch hypothesis. These cases and trade-offs are instrumental in determining when and how imposing demographic parity can be beneficial in selection processes, both for the institution and for society on the long run.},
  keywords = {affirmative action,all or part of,demographic parity,dynamics,fairness,influence on society,or,or hard copies of,permission to make digital,selection processes,social equality,this work for personal},
  file = {/Users/brownsarahm/Zotero/storage/QLXNLY8G/p359-Mouzannar.pdf}
}

@article{mrkva2020moderating,
  title = {Moderating Loss Aversion: Loss Aversion Has Moderators, but Reports of Its Death Are Greatly Exaggerated},
  author = {Mrkva, Kellen and Johnson, Eric J and G{\"a}chter, Simon and Herrmann, Andreas},
  year = {2020},
  journal = {Journal of Consumer Psychology},
  volume = {30},
  number = {3},
  pages = {407--428},
  publisher = {Wiley Online Library}
}

@article{mufson1981insular,
  title = {Insular Interconnections with the Amygdala in the Rhesus Monkey},
  author = {Mufson, E J and Mesulam, M M and Pandya, D N},
  year = {1981},
  journal = {Neuroscience},
  volume = {6},
  pages = {1231--1248}
}

@article{mukherjee2006learning,
  title = {Learning Theory: Stability Is Sufficient for Generalization and Necessary and Sufficient for Consistency of Empirical Risk Minimization},
  author = {Mukherjee, Sayan and Niyogi, Partha and Poggio, Tomaso and Rifkin, Ryan},
  year = {2006},
  month = jul,
  journal = {Advances in Computational Mathematics},
  volume = {25},
  number = {1-3},
  pages = {161--193},
  issn = {1019-7168},
  doi = {10.1007/s10444-004-7634-z},
  keywords = {2000,62m20,68q32,68t05,68t10,cantelli,consistency,corresponding author,empirical risk minimiza-,generalization,inverse problems,mathematics subject classifications,stability,tion,uniform glivenko},
  file = {/Users/brownsarahm/Zotero/storage/BEEIC2X7/Mukherjee et al. - 2006 - Learning theory stability is sufficient for generalization and necessary and sufficient for consistency of (3).pdf}
}

@article{mumford1992computational,
  title = {On the Computational Architecture of the Neocortex},
  author = {Mumford, David},
  year = {1992},
  journal = {Biological Cybernetics},
  volume = {66},
  number = {3},
  pages = {241--251}
}

@article{munsen2012restingstate,
  title = {Resting-State Brain Functional Connectivity Is Altered in Type 2 Diabetes},
  author = {Munsen, Gail and Jacobson, Alan M and Bolo, Nicolas R and Simonson, Donald C and Shenton, Martha E and McCartney, Richard L and Flores, Veronica L and Hoogenboom, Wouter S},
  year = {2012},
  journal = {Diabetes},
  volume = {61},
  number = {9},
  pages = {2375--2379}
}

@book{murphy1991machine,
  title = {Machine {{Learning}}: {{A Probabilistic Perspective}}},
  author = {Murphy, Kevin P and P. Murphy, Kevin},
  year = {1991},
  publisher = {The MIT Press},
  address = {Cambridge, MA},
  doi = {10.1007/SpringerReference_35834},
  isbn = {978-0-262-01802-9},
  pmid = {20236947},
  file = {/Users/brownsarahm/Zotero/storage/DIXHSXUQ/P. Murphy - 1991 - Machine Learning A Probabilistic Perspective(2).pdf}
}

@article{murphy2001bayes,
  title = {The {{Bayes}} Net Toolbox for Matlab},
  author = {Murphy, K},
  year = {2001},
  journal = {Computing science and statistics},
  volume = {33},
  number = {2},
  pages = {1024--1034},
  file = {/Users/brownsarahm/Zotero/storage/5T866P8A/Murphy - 2001 - The Bayes net toolbox for matlab(2).pdf}
}

@article{murphy2001introduction,
  title = {An Introduction to Graphical Models},
  author = {Murphy, Kevin},
  year = {2001},
  journal = {Rap. tech},
  number = {May},
  pages = {1--19},
  file = {/Users/brownsarahm/Zotero/storage/2457YSE2/Murphy - 2001 - An introduction to graphical models(3).pdf}
}

@phdthesis{murphy2002dynamic,
  title = {Dynamic Bayesian Networks: Representation, Inference and Learning},
  author = {Murphy, {\relax KP}},
  year = {2002},
  school = {University of California, Berkeley},
  keywords = {dbn},
  file = {/Users/brownsarahm/Zotero/storage/BBWPTBMB/Murphy - 2002 - Dynamic bayesian networks representation, inference and learning(3).pdf}
}

@phdthesis{murphy2002dynamica,
  title = {Dynamic {{Bayesian Networks}} {$\ast$}},
  author = {Murphy, Kevin P},
  year = {2002},
  file = {/Users/brownsarahm/Zotero/storage/687XENCN/Murphy - 2002 - Dynamic Bayesian Networks ∗(3).pdf}
}

@techreport{nasr2023Extracting,
  title = {Extracting {{Training Data}} from {{ChatGPT}}},
  author = {Nasr, Milad and Carlini, Nicholas and Hayase, Jonathan and Jagielski, Matthew and Cooper, A Feder and Ippolito, Daphne and {Choquette-Choo}, Christopher A and Wallace, Eric and Tram{\`e}r, Florian and Lee, Katherine},
  year = {2023},
  month = nov
}

@article{nasr2023scalable,
  title = {Scalable Extraction of Training Data from (Production) Language Models},
  author = {Nasr, Milad and Carlini, Nicholas and Hayase, Jonathan and Jagielski, Matthew and Cooper, A Feder and Ippolito, Daphne and {Choquette-Choo}, Christopher A and Wallace, Eric and Tram{\`e}r, Florian and Lee, Katherine},
  year = {2023},
  journal = {arXiv preprint arXiv:2311.17035},
  eprint = {2311.17035},
  archiveprefix = {arXiv}
}

@article{nazlan2018effect,
  title = {The Effect of Availability Heuristics in Online Consumer Reviews},
  author = {Nazlan, Nadia Hanin and Tanford, Sarah and Montgomery, Rhonda},
  year = {2018},
  journal = {Journal of Consumer Behaviour},
  volume = {17},
  number = {5},
  pages = {449--460},
  publisher = {Wiley Online Library}
}

@article{nederbragt2020participatory,
  title = {Ten Quick Tips for Teaching with Participatory Live Coding},
  author = {Nederbragt, Alexander and Harris, Rayna Michelle and Hill, Alison Presmanes and Wilson, Greg},
  year = {2020},
  month = sep,
  journal = {PLOS Computational Biology},
  volume = {16},
  number = {9},
  pages = {1--7},
  publisher = {Public Library of Science},
  doi = {10.1371/journal.pcbi.1008090},
  abstract = {null}
}

@article{neta2015spatial,
  title = {Spatial and Temporal Characteristics of Error-Related Activity in the Human Brain.},
  author = {Neta, Maital and Miezin, Francis M and Nelson, Steven M and Dubis, Joseph W and Dosenbach, Nico U F and Schlaggar, Bradley L and Petersen, Steven E},
  year = {2015},
  journal = {The Journal of Neuroscience},
  volume = {35},
  number = {1},
  pages = {253--266},
  issn = {0270-6474},
  abstract = {A number of studies have focused on the role of specific brain regions, such as the dorsal anterior cingulate cortex during trials on which participants make errors, whereas others have implicated a host of more widely distributed regions in the human brain. Previous work has proposed that there are multiple cognitive control networks, raising the question of whether error-related activity can be found in each of these networks. Thus, to examine error-related activity broadly, we conducted a meta-analysis consisting of 12 tasks that included both error and correct trials. These tasks varied by stimulus input (visual, auditory), response output (button press, speech), stimulus category (words, pictures), and task type (e.g., recognition memory, mental rotation). We identified 41 brain regions that showed a differential fMRI BOLD response to error and correct trials across a majority of tasks. These regions displayed three unique response profiles: (1) fast, (2) prolonged, and (3) a delayed response to errors, as well as a more canonical response to correct trials. These regions were found mostly in several control networks, each network predominantly displaying one response profile. The one exception to this "one network, one response profile" observation is the frontoparietal network, which showed prolonged response profiles (all in the right hemisphere), and fast profiles (all but one in the left hemisphere). We suggest that, in the place of a single localized error mechanism, these findings point to a large-scale set of error-related regions across multiple systems that likely subserve different functions.},
  pmid = {1000106310},
  keywords = {error,functional networks,meta-analysis,resting state,task control},
  file = {/Users/brownsarahm/Zotero/storage/Y9FNYVEB/Neta et al. - 2015 - Spatial and temporal characteristics of error-related activity in the human brain(3).pdf}
}

@article{neyman1937outline,
  title = {Outline of a {{Theory}} of {{Statistical Estimation Based}} on the {{Classical Theory}} of {{Probability}}},
  author = {Neyman, J},
  year = {1937},
  journal = {Philosophical transactions of the Royal Society of London. Series A, Mathematicl and Physical Sciences},
  volume = {236},
  number = {767},
  pages = {333--380},
  file = {/Users/brownsarahm/Zotero/storage/A6F2PWJS/Unknown - 2013 - X-Outline of a Theory of Statistical Estimation Based on the Classical Theory of Probability(2).pdf}
}

@article{niebles2008Unsupervised,
  ids = {niebles2008Unsuperviseda,niebles2008Unsupervisedb},
  title = {Unsupervised Learning of Human Action Categories Using Spatial-Temporal Words},
  author = {Niebles, Juan Carlos and Wang, Hongcheng and {Fei-Fei}, Li},
  year = {2008},
  journal = {International journal of computer vision},
  volume = {79},
  pages = {299--318},
  publisher = {Springer US}
}

@article{nikolova2015can,
  title = {Can We Observe Epigenetic Effects on Human Brain Function?},
  author = {Nikolova, Yuliya S. and Hariri, Ahmad R.},
  year = {2015},
  journal = {Trends in Cognitive Sciences},
  volume = {19},
  number = {7},
  pages = {366--373},
  issn = {13646613},
  doi = {10.1016/j.tics.2015.05.003},
  file = {/Users/brownsarahm/Zotero/storage/9CAVHRX5/Nikolova, Hariri - 2015 - Can we observe epigenetic effects on human brain function(3).pdf}
}

@book{nilson2015specifications,
  title = {Specifications Grading: {{Restoring}} Rigor, Motivating Students, and Saving Faculty Time},
  author = {Nilson, Linda B},
  year = {2015},
  publisher = {Stylus Publishing, LLC}
}

@article{niu2013iterative,
  title = {Iterative {{Discovery}} of {{Multiple Alternative Clustering Views}}.},
  author = {Niu, Donglin and Dy, Jennifer G and Jordan, Michael I},
  year = {2013},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  volume = {36},
  number = {7},
  eprint = {24062536},
  eprinttype = {pubmed},
  pages = {1340--1353},
  issn = {1939-3539},
  doi = {C8E76D80-2899-423B-89CB-4AEAF1CE9299},
  abstract = {Complex data can be grouped and interpreted in many different ways. Most existing clustering algorithms, however, only find one clustering solution, and provide little guidance to data analysts who may not be satisfied with that single clustering and may wish to explore alternatives. We introduce a novel approach that provides several clustering solutions to the user for the purposes of exploratory data analysis. Our approach additionally captures the notion that alternative clusterings may reside in different subspaces (or views). We present an algorithm that simultaneously finds these subspaces and the corresponding clusterings. The algorithm is based on an optimization procedure that incorporates terms for cluster quality and novelty relative to previously discovered clustering solutions. We present a range of experiments that compare our approach to alternatives and explore the connections between simultaneous and iterative modes of discovery of multiple clusterings.},
  pmid = {24062536},
  file = {/Users/brownsarahm/Zotero/storage/NS568ZFT/Niu, Dy, Jordan - 2013 - Iterative Discovery of Multiple Alternative Clustering Views.pdf}
}

@inproceedings{nodelman2002continuous,
  title = {Continuous Time {{Bayesian}} Networks},
  booktitle = {Proceedings of the {{Eighteenth}} Conference on {{Uncertainty}} in Artificial Intelligence},
  author = {Nodelman, Uri and Shelton, Christian R CR and Koller, Daphne},
  year = {2002},
  pages = {378--387},
  publisher = {Morgan Kaufmann Publishers Inc.},
  file = {/Users/brownsarahm/Zotero/storage/6XL9RGN6/Nodelman, Shelton, Koller - 1995 - Continuous Time Bayesian Networks.pdf}
}

@article{noppeney2004degenerate,
  title = {Degenerate Neuronal Systems Sustaining Cognitive Functions},
  author = {Noppeney, Uta and Friston, Karl J. and Price, Cathy J.},
  year = {2004},
  journal = {Journal of Anatomy},
  volume = {205},
  number = {September},
  pages = {433--442},
  issn = {00218782},
  doi = {10.1111/j.0021-8782.2004.00343.x},
  abstract = {The remarkable resilience of cognitive functions to focal brain damage suggests that multiple degenerate neuronal systems can sustain the same function either via similar mechanisms or by implementing different cognitive strategies. In degenerate functional neuroanatomy, multiple degenerate neuronal systems might be present in a single brain where they are either co-activated or remain latent during task performance. In degeneracy over subjects, a particular function may be sustained by only one neuronal system within a subject, but by different systems over subjects. Degeneracy over subjects might have arisen from (ab)normal variation in neurodevelopmental trajectories or long-term plastic changes following structural lesions. We discuss how degenerate neuronal systems can be revealed using (1) intersubject variability, (2) multiple lesion studies and (3) an iterative approach integrating information from lesion and functional imaging studies.},
  pmid = {15610392},
  keywords = {Degeneracy,Functional imaging,Functional recovery,Pluripotentiality,Structure-function relationship},
  file = {/Users/brownsarahm/Zotero/storage/RSSCMV4V/Noppeney, Friston, Price - 2004 - Degenerate neuronal systems sustaining cognitive functions(3).pdf}
}

@article{ntziachristos2010molecular,
  title = {Molecular Imaging by Means of Multispectral Optoacoustic Tomography ({{MSOT}})},
  author = {Ntziachristos, Vasilis and Razansky, Daniel},
  year = {2010},
  journal = {Chemical Reviews},
  volume = {110},
  pages = {2783--2794},
  issn = {00092665},
  doi = {10.1021/cr9002566},
  pmid = {20387910},
  file = {/Users/brownsarahm/Zotero/storage/9KE2ZE8Z/Ntziachristos, Razansky - 2010 - Molecular imaging by means of multispectral optoacoustic tomography (MSOT)(3).pdf}
}

@book{nutt2001neurobiology,
  title = {Neurobiology of {{PTSD}}},
  author = {Nutt, D.J.},
  year = {2001},
  doi = {10.1016/S0924-977X(01)80075-4},
  file = {/Users/brownsarahm/Zotero/storage/ZK7JMIHJ/Nutt - 2001 - Neurobiology of PTSD(3).pdf}
}

@book{o2006uncertain,
  title = {Uncertain Judgements: Eliciting Experts' Probabilities},
  author = {O'Hagan, Anthony and Buck, Caitlin E and Daneshkhah, Alireza and Eiser, J Richard and Garthwaite, Paul H and Jenkinson, David J and Oakley, Jeremy E and Rakow, Tim},
  year = {2006},
  publisher = {John Wiley \& Sons}
}

@article{obermeyer2019dissecting,
  title = {Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations},
  author = {Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
  year = {2019},
  journal = {Science},
  volume = {366},
  number = {6464},
  pages = {447--453},
  publisher = {American Association for the Advancement of Science}
}

@article{of2011applications,
  title = {Applications to {{Statistical}}},
  author = {Of, Estimation and Variablesvectors, Random},
  year = {2011},
  pages = {700--789},
  file = {/Users/brownsarahm/Zotero/storage/LPUNX9XU/Of, Variablesvectors - 2011 - Applications to Statistical(3).pdf}
}

@article{olson2017open,
  title = {Open {{Access PMLB}} : A Large Benchmark Suite for Machine Learning Evaluation and Comparison},
  author = {Olson, Randal S and Cava, William La and Orzechowski, Patryk and Urbanowicz, Ryan J and Moore, Jason H},
  year = {2017},
  pages = {1--13},
  doi = {10.1186/s13040-017-0154-4},
  keywords = {benchmarking,data repository,machine learning,model evaluation},
  file = {/Users/brownsarahm/Zotero/storage/EECLFY6E/Olson et al. - 2017 - Open Access PMLB a large benchmark suite for machine learning evaluation and comparison.pdf}
}

@article{ongur1998prefrontal,
  title = {Prefrontal Cortical Projections to the Hypothalamus in Macaque Monkeys},
  author = {Ongur, D and An, X and Price, J L},
  year = {1998},
  journal = {Journal of Comparative Neurology},
  volume = {401},
  number = {4},
  pages = {480--505}
}

@article{open2015estimating,
  title = {Estimating the Reproducibility of Psychological Science},
  author = {Collaboration, Open Science},
  year = {2015},
  journal = {Science},
  volume = {349},
  number = {6251},
  pages = {aac4716}
}

@article{orhan2012rsvp,
  title = {{{RSVP Keyboard}}: {{An EEG Based Typing Interface}}.},
  author = {Orhan, Umut and Hild, Kenneth E and Erdogmus, Deniz and Roark, Brian and Oken, Barry and {Fried-Oken}, Melanie},
  year = {2012},
  month = jan,
  journal = {Proceedings of the ... IEEE International Conference on Acoustics, Speech, and Signal Processing / sponsored by the Institute of Electrical and Electronics Engineers Signal Processing Society. ICASSP},
  pages = {645--648},
  issn = {1520-6149},
  doi = {10.1109/ICASSP.2012.6287966},
  abstract = {Humans need communication. The desire to communicate remains one of the primary issues for people with locked-in syndrome (LIS). While many assistive and augmentative communication systems that use various physiological signals are available commercially, the need is not satisfactorily met. Brain interfaces, in particular, those that utilize event related potentials (ERP) in electroencephalography (EEG) to detect the intent of a person noninvasively, are emerging as a promising communication interface to meet this need where existing options are insufficient. Existing brain interfaces for typing use many repetitions of the visual stimuli in order to increase accuracy at the cost of speed. However, speed is also crucial and is an integral portion of peer-to-peer communication; a message that is not delivered timely often looses its importance. Consequently, we utilize rapid serial visual presentation (RSVP) in conjunction with language models in order to assist letter selection during the brain-typing process with the final goal of developing a system that achieves high accuracy and speed simultaneously. This paper presents initial results from the RSVP Keyboard system that is under development. These initial results on healthy and locked-in subjects show that single-trial or few-trial accurate letter selection may be possible with the RSVP Keyboard paradigm.},
  pmid = {24500542},
  file = {/Users/brownsarahm/Zotero/storage/XNXRDHLJ/Orhan et al. - 2012 - RSVP Keyboard An EEG Based Typing Interface(3).pdf}
}

@article{orhan2013offline,
  title = {Offline Analysis of Context Contribution to {{ERP-based}} Typing {{BCI}} Performance.},
  author = {Orhan, Umut and Erdogmus, Deniz and Roark, Brian and Oken, Barry and {Fried-Oken}, Melanie},
  year = {2013},
  month = dec,
  journal = {Journal of neural engineering},
  volume = {10},
  number = {6},
  eprint = {24099944},
  eprinttype = {pubmed},
  pages = {066003},
  issn = {1741-2552},
  doi = {10.1088/1741-2560/10/6/066003},
  abstract = {OBJECTIVE: We aim to increase the symbol rate of electroencephalography (EEG) based brain-computer interface (BCI) typing systems by utilizing context information. APPROACH: Event related potentials (ERP) corresponding to a stimulus in EEG can be used to detect the intended target of a person for BCI. This paradigm is widely utilized to build letter-by-letter BCI typing systems. Nevertheless currently available BCI typing systems still require improvement due to low typing speeds. This is mainly due to the reliance on multiple repetitions before making a decision to achieve higher typing accuracy. Another possible approach to increase the speed of typing while not significantly reducing the accuracy of typing is to use additional context information. In this paper, we study the effect of using a language model (LM) as additional evidence for intent detection. Bayesian fusion of an n-gram symbol model with EEG features is proposed, and a specifically regularized discriminant analysis ERP discriminant is used to obtain EEG-based features. The target detection accuracies are rigorously evaluated for varying LM orders, as well as the number of ERP-inducing repetitions. MAIN RESULTS: The results demonstrate that the LMs contribute significantly to letter classification accuracy. For instance, we find that a single-trial ERP detection supported by a 4-gram LM may achieve the same performance as using 3-trial ERP classification for the non-initial letters of words. SIGNIFICANCE: Overall, the fusion of evidence from EEG and LMs yields a significant opportunity to increase the symbol rate of a BCI typing system.},
  pmid = {24099944},
  file = {/Users/brownsarahm/Zotero/storage/CC5VS7TA/Orhan et al. - 2013 - Offline analysis of context contribution to ERP-based typing BCI performance(6).pdf;/Users/brownsarahm/Zotero/storage/FW9HDZTQ/Orhan et al. - 2013 - Offline analysis of context contribution to ERP-based typing BCI performance(5).pdf}
}

@incollection{orr1995psychophysiological,
  title = {Psychophysiological Assessment of {{PTSD}}},
  booktitle = {Assessing Psychological Trauma and {{PTSD}}},
  author = {Orr, Scott P and Metzger, Linda J and Miller, Mark W and Kaloupek, Danny G},
  editor = {Wilson, John Preston and Keane, Terence Martin},
  year = {1995},
  pages = {289--343},
  publisher = {Guilford Press},
  address = {New York, New York, USA},
  file = {/Users/brownsarahm/Zotero/storage/HMNFI4FQ/Orr et al. - 1995 - Psychophysiological assessment of PTSD(2).pdf}
}

@article{orr1998heart,
  title = {Heart Rate and Blood Pressure Resting Levels and Responses to Generic Stressors in {{Vietnam}} Veterans with Posttraumatic Stress Disorder},
  author = {Orr, Scott P and Meyerhoff, James L and Edwards, Joely V and Pitman, Roger K},
  year = {1998},
  journal = {Journal of Traumatic Stress},
  volume = {11},
  number = {1},
  pages = {155--164}
}

@article{orr2000novo,
  title = {De Novo Conditioning in Trauma-Exposed Individuals with and without Posttraumatic Stress Disorder.},
  author = {Orr, Scott P and Metzger, Linda J and Lasko, Natasha B and Macklin, Michael L and Peri, Tuvia and Pitman, Roger K},
  year = {2000},
  journal = {Journal of abnormal psychology},
  volume = {109},
  number = {2},
  pages = {290}
}

@article{orr2002psychophysiology,
  title = {Psychophysiology of Post-Traumatic Stress Disorder.},
  author = {Orr, Scott P and Metzger, Linda J and Pitman, Roger K},
  year = {2002},
  month = jul,
  journal = {The Psychiatric clinics of North America},
  volume = {25},
  number = {2},
  eprint = {15458759},
  eprinttype = {pubmed},
  pages = {271--93},
  issn = {0193-953X},
  abstract = {In general, the results of psychophysiologic research on PTSD support the presence of a variety of autonomic, sensory, and cognitive processing differences between individuals with and without the disorder. The findings are diverse and include heightened responsiveness to trauma reminders; exaggerated startle; increased conditionability and autonomic responsiveness to aversive, high-intensity stimuli; and elevated tonic or baseline physiologic activity. Increased sensitivity of the central nervous system is suggested by electrophysiologic evidence for a failure to habituate to redundant information, over-responsiveness to novel information, and reduced cortical responsiveness to overstimulation. Cognitive processing abnormalities are suggested by electrophysiologic evidence for a reduced ability to attend to task-relevant information and increased attention to task-irrelevant, trauma-related information in individuals with PTSD. Some findings, such as the heightened physiologic and P300 response amplitude responses to trauma-related stimuli and increased HR response to loud tones, have been highly replicable and appear to be as reliable as any biologic finding in the psychiatric literature. Other findings, such as increased eye-blink startle responses and tonic or baseline physiologic activity, have been less consistently replicated and have led investigators to explore how stressful or threatening experimental contexts might produce phasic alterations in the psychophysiology of individuals with PTSD. We hope that the broad range of psychophysiologic investigations and findings in PTSD will inspire others to consider possible applications of these methodologies to their own clinical and research endeavors.},
  pmid = {12136501},
  keywords = {Arousal,Brain,Brain: physiopathology,Cognition,Evoked Potentials,Humans,Learning,Life Change Events,Post-Traumatic,Post-Traumatic: physiopathology,Post-Traumatic: psychology,Psychophysiology,Psychophysiology: methods,Stress Disorders},
  file = {/Users/brownsarahm/Zotero/storage/36TQG2NK/Orr, Metzger, Pitman - 2002 - Psychophysiology of post-traumatic stress disorder(3).pdf}
}

@article{osmundsen2020framing,
  title = {Framing Political Risks: {{Individual}} Differences and Loss Aversion in Personal and Political Situations},
  author = {Osmundsen, Mathias and Petersen, Michael Bang},
  year = {2020},
  journal = {Political Psychology},
  volume = {41},
  number = {1},
  pages = {53--70},
  publisher = {Wiley Online Library}
}

@article{otti2013frequency,
  title = {Frequency Shifts in the Anterior Default Mode Network and the Salience Network in Chronic Pain Disorder},
  author = {Otti, Alexander and {Guendel Harald} and Wohlschlager, Afra and Zimmer, Claus and {Noll-Hussong}, Michael},
  year = {2013},
  journal = {BMC Psychiatry},
  volume = {13},
  number = {1},
  pages = {1}
}

@article{owens2020those,
  title = {Those Designing Healthcare Algorithms Must Become Actively Anti-Racist},
  author = {Owens, Kellie and Walker, Alexis},
  year = {2020},
  journal = {Nature medicine},
  volume = {26},
  number = {9},
  pages = {1327--1328},
  publisher = {Nature Publishing Group}
}

@incollection{oxley2020framing,
  title = {Framing and Political Decision Making: {{An}} Overview},
  booktitle = {Oxford Research Encyclopedia of Politics},
  author = {Oxley, Zoe},
  year = {2020}
}

@article{ozertem2006spectral,
  title = {Spectral Feature Projections That Maximize {{Shannon}} Mutual Information with Class Labels},
  author = {Ozertem, Umut and Erdogmus, Deniz and Jenssen, Robert},
  year = {2006},
  month = jul,
  journal = {Pattern Recognition},
  volume = {39},
  number = {7},
  pages = {1241--1252},
  issn = {00313203},
  doi = {10.1016/j.patcog.2006.01.014},
  keywords = {feature extraction,mutual information,optimal subspace projection},
  file = {/Users/brownsarahm/Zotero/storage/VFY87U35/Ozertem, Erdogmus, Jenssen - 2006 - Spectral feature projections that maximize Shannon mutual information with class labels(3).pdf}
}

@article{ozertem2009rkhs,
  title = {{{RKHS Bayes}} Discriminant: A Subspace Constrained Nonlinear Feature Projection for Signal Detection.},
  author = {Ozertem, Umut and Erdogmus, Deniz},
  year = {2009},
  month = jul,
  journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
  volume = {20},
  number = {7},
  eprint = {19497813},
  eprinttype = {pubmed},
  pages = {1195--203},
  issn = {1941-0093},
  doi = {10.1109/TNN.2009.2021473},
  abstract = {Given the knowledge of class probability densities, a priori probabilities, and relative risk levels, Bayes classifier provides the optimal minimum-risk decision rule. Specifically, focusing on the two-class (detection) scenario, under certain symmetry assumptions, matched filters provide optimal results for the detection problem. Noticing that the Bayes classifier is in fact a nonlinear projection of the feature vector to a single-dimensional statistic, in this paper, we develop a smooth nonlinear projection filter constrained to the estimated span of class conditional distributions as does the Bayes classifier. The nonlinear projection filter is designed in a reproducing kernel Hilbert space leading to an analytical solution both for the filter and the optimal threshold. The proposed approach is tested on typical detection problems, such as neural spike detection or automatic target detection in synthetic aperture radar (SAR) imagery. Results are compared with linear and kernel discriminant analysis, as well as classification algorithms such as support vector machine, AdaBoost and LogitBoost.},
  pmid = {19497813},
  keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Artificial Intelligence,Automated,Automated: methods,Bayes Theorem,Computer Simulation,Computer-Assisted,Neural Networks (Computer),Neurons,Neurons: physiology,Nonlinear Dynamics,Pattern Recognition,Psychological,Signal Detection,Signal Processing,Software},
  file = {/Users/brownsarahm/Zotero/storage/ANB59N8K/Ozertem, Erdogmus - 2009 - RKHS Bayes discriminant a subspace constrained nonlinear feature projection for signal detection(3).pdf}
}

@article{padmanabha2021solving,
  ids = {padmanabha2021Solving},
  title = {Solving Inverse Problems Using Conditional Invertible Neural Networks},
  author = {Padmanabha, Govinda Anantha and Zabaras, Nicholas},
  year = {2021},
  journal = {Journal of Computational Physics},
  volume = {433},
  pages = {110194},
  publisher = {Elsevier}
}

@article{pakman2014fast,
  title = {Fast State-Space Methods for Inferring Dendritic Synaptic Connectivity.},
  author = {Pakman, Ari and Huggins, Jonathan and Smith, Carl and Paninski, Liam},
  year = {2014},
  journal = {Journal of computational neuroscience},
  volume = {36},
  number = {3},
  eprint = {24077932},
  eprinttype = {pubmed},
  pages = {415--43},
  issn = {1573-6873},
  doi = {10.1007/s10827-013-0478-0},
  abstract = {We present fast methods for filtering voltage measurements and performing optimal inference of the location and strength of synaptic connections in large dendritic trees. Given noisy, subsampled voltage observations we develop fast l1-penalized regression methods for Kalman state-space models of the neuron voltage dynamics. The value of the l1-penalty parameter is chosen using cross-validation or, for low signal-to-noise ratio, a Mallows' Cp-like criterion. Using low-rank approximations, we reduce the inference runtime from cubic to linear in the number of dendritic compartments. We also present an alternative, fully Bayesian approach to the inference problem using a spike-and-slab prior. We illustrate our results with simulations on toy and real neuronal geometries. We consider observation schemes that either scan the dendritic geometry uniformly or measure linear combinations of voltages across several locations with random coefficients. For the latter, we show how to choose the coefficients to offset the correlation between successive measurements imposed by the neuron dynamics. This results in a "compressed sensing" observation scheme, with an important reduction in the number of measurements required to infer the synaptic weights.},
  pmid = {24077932},
  file = {/Users/brownsarahm/Zotero/storage/D8BCWFZI/Pakman et al. - 2014 - Fast state-space methods for inferring dendritic synaptic connectivity(3).pdf}
}

@article{paninski2003estimation,
  title = {Estimation of Entropy and Mutual Information},
  author = {Paninski, Liam},
  year = {2003},
  month = jun,
  journal = {Neural Computation},
  volume = {1253},
  number = {6},
  pages = {1191--1253},
  issn = {0899-7667},
  doi = {10.1162/089976603321780272},
  file = {/Users/brownsarahm/Zotero/storage/N792IDP9/Paninski - 2003 - Estimation of entropy and mutual information(3).pdf}
}

@article{paninski2009new,
  title = {A New Look at State-Space Models for Neural Data.},
  author = {Paninski, Liam and Ahmadian, Yashar and Ferreira, Daniel Gil and Koyama, Shinsuke and Rahnama Rad, Kamiar and Vidne, Michael and Vogelstein, Joshua T. and Wu, Wei},
  year = {2009},
  journal = {Journal of computational neuroscience},
  volume = {29},
  number = {1-2},
  pages = {107--126},
  issn = {1573-6873},
  doi = {10.1007/s10827-009-0179-x},
  abstract = {State space methods have proven indispensable in neural data analysis. However, common methods for performing inference in state-space models with non-Gaussian observations rely on certain approximations which are not always accurate. Here we review direct optimization methods that avoid these approximations, but that nonetheless retain the computational efficiency of the approximate methods. We discuss a variety of examples, applying these direct optimization techniques to problems in spike train smoothing, stimulus decoding, parameter estimation, and inference of synaptic properties. Along the way, we point out connections to some related standard statistical methods, including spline smoothing and isotonic regression. Finally, we note that the computational methods reviewed here do not in fact depend on the state-space setting at all; instead, the key property we are exploiting involves the bandedness of certain matrices. We close by discussing some applications of this more general point of view, including Markov chain Monte Carlo methods for neural decoding and efficient estimation of spatially-varying firing rates.},
  pmid = {19649698},
  keywords = {1 introduction,Action Potentials,Action Potentials: physiology,Animals,Computer Simulation,for inference in state-space,forward-backward methods,hidden markov model,models,neural coding,Neurological,Neurons,Neurons: physiology,Retinal Ganglion Cells,Retinal Ganglion Cells: physiology,state-space models,Statistical,Synapses,Synapses: physiology,tridiagonal matrix},
  file = {/Users/brownsarahm/Zotero/storage/E25J7TDD/Paninski et al. - 2009 - A new look at state-space models for neural data(3).pdf}
}

@article{paolacci2014inside,
  title = {Inside the Turk: {{Understanding}} Mechanical Turk as a Participant Pool},
  author = {Paolacci, Gabriele and Chandler, Jesse},
  year = {2014},
  journal = {Current Directions in Psychological Science},
  volume = {23},
  number = {3},
  pages = {184--188},
  publisher = {Sage Publications Sage CA: Los Angeles, CA}
}

@inproceedings{papalexakis2014goodenough,
  title = {Good-{{Enough Brain Model}} : {{Challenges}} , {{Algorithms}} and {{Discoveries}} in {{Multi-Subject MEG Data}}},
  booktitle = {{{KDD}} 2014},
  author = {Papalexakis, Evangelos E and Fyshe, Alona and Sidiropoulos, Nicholas D and Talukdar, Partha Pratim and Mitchell, Tom M and Faloutsos, Christos},
  year = {2014},
  pages = {216--229},
  publisher = {Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA},
  isbn = {978-1-4503-2956-9},
  file = {/Users/brownsarahm/Zotero/storage/G2TPTFER/Papalexakis et al. - 2014 - Good-Enough Brain Model Challenges , Algorithms and Discoveries in Multi-Subject MEG Data(3).pdf}
}

@book{papez1937proposed,
  title = {A {{Proposed Mechanism}} of {{Emotion}}},
  author = {Papez, J W},
  year = {1937},
  publisher = {American Medical Association}
}

@article{park2011seizure,
  title = {Seizure Prediction with Spectral Power of {{EEG}} Using Cost-Sensitive Support Vector Machines},
  author = {Park, Yun and Luo, Lan and Parhi, Keshab K. and Netoff, Theoden},
  year = {2011},
  journal = {Epilepsia},
  volume = {52},
  number = {10},
  pages = {1761--1770},
  issn = {00139580},
  doi = {10.1111/j.1528-1167.2011.03138.x},
  abstract = {PURPOSE: We propose a patient-specific algorithm for seizure prediction using multiple features of spectral power from electroencephalogram (EEG) and support vector machine (SVM) classification.\${\textbackslash}backslash\$n\${\textbackslash}backslash\$nMETHODS: The proposed patient-specific algorithm consists of preprocessing, feature extraction, SVM classification, and postprocessing. Preprocessing removes artifacts of intracranial EEG recordings and they are further preprocessed in bipolar and/or time-differential methods. Features of spectral power of raw, or bipolar and/or time-differential intracranial EEG (iEEG) recordings in nine bands are extracted from a sliding 20-s-long and half-overlapped window. Nine bands are selected based on standard EEG frequency bands, but the wide gamma bands are split into four. Cost-sensitive SVMs are used for classification of preictal and interictal samples, and double cross-validation is used to achieve in-sample optimization and out-of-sample testing. We postprocess SVM classification outputs using the Kalman Filter and it removes sporadic and isolated false alarms. The algorithm has been tested on iEEG of 18 patients of 20 available in the Freiburg EEG database who had three or more seizure events. To investigate the discriminability of the features between preictal and interictal, we use the Kernel Fisher Discriminant analysis.\${\textbackslash}backslash\$n\${\textbackslash}backslash\$nKEY FINDINGS: The proposed patient-specific algorithm for seizure prediction has achieved high sensitivity of 97.5\% with total 80 seizure events and a low false alarm rate of 0.27 per hour and total false prediction times of 13.0\% over a total of 433.2 interictal hours by bipolar preprocessing (92.5\% sensitivity, a false positive rate of 0.20 per hour, and false prediction times of 9.5\% by time-differential preprocessing). This high prediction rate demonstrates that seizures can be predicted by the patient-specific approach using linear features of spectral power and nonlinear classifiers. Bipolar and/or time-differential preprocessing significantly improves sensitivity and specificity. Spectral powers in high gamma bands are the most discriminating features between preictal and interictal.\${\textbackslash}backslash\$n\${\textbackslash}backslash\$nSIGNIFICANCE: High sensitivity and specificity are achieved by nonlinear classification of linear features of spectral power. Power changes in certain frequency bands already demonstrated their possibilities for seizure prediction indicators, but we have demonstrated that combining those spectral power features and classifying them in a multivariate approach led to much higher prediction rates. Employing only linear features is advantageous, especially when it comes to an implantable device, because they can be computed rapidly with low power consumption.},
  pmid = {21692794},
  keywords = {Detection,Electroencephalogram,Epilepsy,Prediction,Seizure},
  file = {/Users/brownsarahm/Zotero/storage/YFMLFD4S/Park et al. - 2011 - Seizure prediction with spectral power of EEG using cost-sensitive support vector machines(3).pdf}
}

@article{park2012are,
  title = {Are Brain Networks Stable during a 24-Hour Period?},
  author = {Park, Bumhee and Kim, Joong Il and Lee, Dongha and Jeong, Seok Oh and Lee, Jong Doo and Park, Hae Jeong},
  year = {2012},
  journal = {NeuroImage},
  volume = {59},
  number = {1},
  pages = {456--466},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2011.07.049},
  abstract = {Despite the widespread view of the brain as a large complex network, the dynamicity of the brain network over the course of a day has yet to be explored. To investigate whether the spontaneous human brain network maintains long-term stability throughout a day, we evaluated the intra-class correlation coefficient (ICC) of results from an independent component analysis (ICA), seed correlation analysis, and graph-theoretical analysis of resting state functional MRI, acquired from 12 young adults at three-hour intervals over 24 consecutive hours. According to the ICC of the usage strength of the independent network component defined by the root mean square of the temporal weights of the network components, the default mode network centered at the posterior cingulate cortex and precuneus, the superior parietal, and secondary motor networks showed a high temporal stability throughout the day (ICC {\textbackslash}textgreater 0.5). However, high intra-individual dynamicity was observed in the default mode network, including the anterior cingulate cortex and medial prefrontal cortex or posterior-anterior cingulate cortex, the hippocampal network, and the parietal and temporal networks. Seed correlation analysis showed a highly stable (ICC {\textbackslash}textgreater 0.5) extent of functionally connected regions from the posterior cingulate cortex, but poor stability from the hippocampus throughout the day. Graph-theoretical analysis using local and global network efficiency suggested that local brain networks are temporally stable but that long-range integration behaves dynamically in the course of a day. These results imply that dynamic network properties are a nature of the resting state brain network, which remains to be further researched. ?? 2011 Elsevier Inc.},
  pmid = {21807101},
  keywords = {Functional MRI,Intra-class correlation,Network dynamicity,Resting-state functional connectivity,Small-world network},
  file = {/Users/brownsarahm/Zotero/storage/DMF4ITLB/Park et al. - 2012 - Are brain networks stable during a 24-hour period(3).pdf}
}

@article{park2013structural,
  title = {Structural and Functional Brain Networks: From Connections to Cognition.},
  author = {Park, Hae-Jeong and Friston, Karl J},
  year = {2013},
  journal = {Science (New York, N.Y.)},
  volume = {342},
  number = {2013},
  eprint = {24179229},
  eprinttype = {pubmed},
  pages = {1238411},
  issn = {1095-9203},
  doi = {10.1126/science.1238411},
  abstract = {How rich functionality emerges from the invariant structural architecture of the brain remains a major mystery in neuroscience. Recent applications of network theory and theoretical neuroscience to large-scale brain networks have started to dissolve this mystery. Network analyses suggest that hierarchical modular brain networks are particularly suited to facilitate local (segregated) neuronal operations and the global integration of segregated functions. Although functional networks are constrained by structural connections, context-sensitive integration during cognition tasks necessarily entails a divergence between structural and functional networks. This degenerate (many-to-one) function-structure mapping is crucial for understanding the nature of brain networks. The emergence of dynamic functional networks from static structural connections calls for a formal (computational) approach to neuronal information processing that may resolve this dialectic between structure and function.},
  pmid = {24179229},
  keywords = {Brain,Brain: physiology,Brain: ultrastructure,Cognition,Cognition: physiology,Humans,Models,Nerve Net,Nerve Net: physiology,Nerve Net: ultrastructure,Neurological},
  file = {/Users/brownsarahm/Zotero/storage/8H6IHG8H/Park, Friston - 2013 - Structural and functional brain networks from connections to cognition(3).pdf}
}

@article{parvizi2006neural,
  title = {Neural Connections of the Posteromedial Cortex in the Macaque},
  author = {Parvizi, Josef and Van Hoesen, Gary W and Buckwalter, Joseph and Damasio, Antonio},
  year = {2006},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {103},
  number = {5},
  pages = {1563--1568}
}

@article{parzen1962estimation,
  title = {On Estimation of a Probability Density Function and Mode},
  author = {Parzen, E},
  year = {1962},
  journal = {The annals of mathematical statistics},
  eprint = {10.2307/2237880},
  eprinttype = {jstor},
  file = {/Users/brownsarahm/Zotero/storage/2AAJRBPJ/Parzen - 1962 - On estimation of a probability density function and mode(3).pdf}
}

@article{pashler2012editors,
  title = {Editors' Introduction to the Special Section on Replicability in Psychological Science a Crisis of Confidence?},
  author = {Pashler, Harold and Wagenmakers, Eric--Jan},
  year = {2012},
  journal = {Perspectives on Psychological Science},
  volume = {7},
  number = {6},
  pages = {528--530}
}

@inproceedings{passi2019problem,
  title = {Problem Formulation and Fairness},
  booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
  author = {Passi, Samir and Barocas, Solon},
  year = {2019},
  pages = {39--48},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA}
}

@article{patenaude2011bayesian,
  title = {A {{Bayesian}} Model of Shape and Appearance for Subcortical Brain Segmentation},
  author = {Patenaude, Brian and Smith, Stephen M and Kennedy, David N and Jenkinson, Mark},
  year = {2011},
  journal = {Neuroimage},
  volume = {56},
  number = {3},
  pages = {907--922}
}

@article{pavlides2009how,
  title = {How Likely Is {{Simpson}}'s {{Paradox}}?},
  author = {Pavlides, Marios G and Perlman, Michael D},
  year = {2009},
  journal = {The American Statistician},
  volume = {63},
  number = {3},
  pages = {226--233}
}

@inproceedings{pawelczyk2023privacy,
  ids = {pawelczyk2023Privacy,pawelczyk2023Privacya,pawelczyk2023Privacyb},
  title = {On the Privacy Risks of Algorithmic Recourse},
  booktitle = {International Conference on Artificial Intelligence and Statistics},
  author = {Pawelczyk, Martin and Lakkaraju, Himabindu and Neel, Seth},
  year = {2023},
  pages = {9680--9696},
  publisher = {PMLR}
}

@article{pearl2011simpson,
  title = {Simpson's Paradox: {{An}} Anatomy},
  author = {Pearl, Judea},
  year = {2011},
  journal = {Department of Statistics, UCLA}
}

@techreport{pearl2012causal,
  title = {The Causal Foundations of Structural Equation Modeling},
  author = {Pearl, Judea},
  year = {2012},
  institution = {CALIFORNIA UNIV LOS ANGELES DEPT OF COMPUTER SCIENCE}
}

@article{pedersen2008matrix,
  title = {The {{Matrix Cookbook}}},
  author = {Pedersen, Michael Syskind and Baxter, Bill and Templeton, Brian and Rish{\o}j, Christian and Theobald, Douglas L and {Hoegh-rasmussen}, Esben and Casteel, Glynne and Gao, Jun Bin and Dedecius, Kamil and Strim, Korbinian and Christiansen, Lars and Hansen, Lars Kai and Wilkinson, Leland and He, Liguo and Bar, Miguel and Winther, Ole and Sakov, Pavel and Hattinger, Stephan},
  editor = {Bloom, B R},
  year = {2008},
  journal = {Matrix},
  volume = {M},
  number = {1},
  pages = {1--71},
  issn = {09621083},
  doi = {10.1111/j.1365-294X.2006.03161.x},
  abstract = {Matrix identities, relations and approximations. A desktop reference for quick overview of mathematics of matrices.},
  pmid = {17284204},
  keywords = {acknowledgements,bill baxter,brian templeton,christian,christian rish{\o}j,contributions,derivative,derivative inverse matrix,determinant,differentiate a matrix,matrix algebra,matrix identities,matrix relations,suggestions,thank following,we would like}
}

@article{pedregosaScikitlearnMachineLearning2011,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  author = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  year = {2011},
  journal = {Journal of Machine Learning Research},
  volume = {12},
  pages = {2825--2830}
}

@article{peelen2010using,
  title = {Using Hierarchical Dynamic {{Bayesian}} Networks to Investigate Dynamics of Organ Failure in Patients in the {{Intensive Care Unit}}.},
  author = {Peelen, Linda and {\noopsort{keizer}}{de Keizer}, Nicolette F and Jonge, Evert De and Bosman, Robert-Jan and {Abu-Hanna}, Ameen and Peek, Niels},
  year = {2010},
  month = apr,
  journal = {Journal of biomedical informatics},
  volume = {43},
  number = {2},
  eprint = {19874913},
  eprinttype = {pubmed},
  pages = {273--86},
  issn = {1532-0480},
  doi = {10.1016/j.jbi.2009.10.002},
  abstract = {In intensive care medicine close monitoring of organ failure status is important for the prognosis of patients and for choices regarding ICU management. Major challenges in analyzing the multitude of data pertaining to the functioning of the organ systems over time are to extract meaningful clinical patterns and to provide predictions for the future course of diseases. With their explicit states and probabilistic state transitions, Markov models seem to fit this purpose well. In complex domains such as intensive care a choice is often made between a simple model that is estimated from the data, or a more complex model in which the parameters are provided by domain experts. Our primary aim is to combine these approaches and develop a set of complex Markov models based on clinical data. In this paper we describe the design choices underlying the models, which enable them to identify temporal patterns, predict outcomes, and test clinical hypotheses. Our models are characterized by the choice of the dynamic hierarchical Bayesian network structure and the use of logistic regression equations in estimating the transition probabilities. We demonstrate the induction, inference, evaluation, and use of these models in practice in a case-study of patients with severe sepsis admitted to four Dutch ICUs.},
  pmid = {19874913},
  keywords = {Bayes Theorem,Computational Biology,Computational Biology: methods,Female,Humans,Intensive Care Units,Intensive Care Units: statistics \& numerical data,Logistic Models,Male,Markov Chains,Multiple Organ Failure,Multiple Organ Failure: epidemiology,Predictive Value of Tests,Prognosis,Prospective Studies,Sepsis,Sepsis: diagnosis,Sepsis: mortality,Time Factors},
  file = {/Users/brownsarahm/Zotero/storage/43VXQ88V/Peelen et al. - 2010 - Using hierarchical dynamic Bayesian networks to investigate dynamics of organ failure in patients in the Inten(3).pdf}
}

@article{peng2005feature,
  title = {Feature {{Selection Based}} on {{Mutual Information}}: {{Criteria}} of {{Max-Dependency}}, {{Max-Relevancy}} and {{Min-Redundancy}}},
  author = {Peng, Hangchuan and LOng, Fuhui and Ding, Chris},
  year = {2005},
  journal = {IEEE Trans. Pattern Analysis and Machine Intelligence},
  volume = {27},
  number = {8},
  pages = {1226--1238},
  file = {/Users/brownsarahm/Zotero/storage/G53ZJEI4/Peng, LOng, Ding - 2005 - Feature Selection Based on Mutual Information Criteria of Max-Dependency, Max-Relevancy and Min-Redundancy(3).pdf}
}

@article{penny2003mixtures,
  title = {Mixtures of General Linear Models for Functional Neuroimaging},
  author = {Penny, Will and Friston, Karl},
  year = {2003},
  journal = {IEEE Transactions on Medical Imaging},
  volume = {22},
  number = {4},
  pages = {504--514},
  issn = {02780062},
  abstract = {We set out a new general framework for making inferences from neuroimaging data, which includes a standard approach to neuroimaging analysis, statistical parametric mapping (SPM), as a special case. The model offers numerous conceptual and statistical advantages that derive from analyzing data at the "cluster level" rather than the "voxel level" and from explicit modeling of the shape and position of clusters of activation. This provides a natural and principled way to pool data from nearby voxels for parameter and variance-component estimation. The model can also be viewed as performing a spatio-temporal cluster analysis. The parameters of the model are estimated using an expectation maximization (EM) algorithm.},
  pmid = {12774896},
  keywords = {Functional MRI,Mapping,Mixture models,Spatio-temporal clustering,Statistical parametric},
  file = {/Users/brownsarahm/Zotero/storage/VMPX7A9S/Penny, Friston - 2003 - Mixtures of general linear models for functional neuroimaging(3).pdf}
}

@article{pereira2009machine,
  title = {Machine Learning Classi!Ers and {{fMRI}}: {{A}} Tutorial Overview},
  author = {Pereira, F and Mitchell, T and Botvinick, M},
  year = {2009},
  journal = {NeuroImage},
  volume = {45},
  pages = {S199--S209},
  file = {/Users/brownsarahm/Zotero/storage/AUZ5KKSK/Pereira, Mitchell, Botvinick - 2009 - Machine learning classi!ers and fMRI A tutorial overview(3).pdf}
}

@article{pernet2014misconceptions,
  title = {Misconceptions in the Use of the {{General Linear Model}} Applied to Functional {{MRI}}: {{A}} Tutorial for Junior Neuro-Imagers},
  author = {Pernet, Cyril R.},
  year = {2014},
  journal = {Frontiers in Neuroscience},
  volume = {8},
  number = {8 JAN},
  pages = {1--12},
  issn = {1662453X},
  doi = {10.3389/fnins.2014.00001},
  abstract = {This tutorial presents several misconceptions related to the use the General Linear Model (GLM) in functional Magnetic Resonance Imaging (fMRI). The goal is not to present mathematical proofs but to educate using examples and computer code (in Matlab). In particular, I address issues related to (1) model parameterization (modeling baseline or null events) and scaling of the design matrix; (2) hemodynamic modeling using basis functions, and (3) computing percentage signal change. Using a simple controlled block design and an alternating block design, I first show why "baseline" should not be modeled (model over-parameterization), and how this affects effect sizes. I also show that, depending on what is tested; over-parameterization does not necessarily impact upon statistical results. Next, using a simple periodic vs. random event related design, I show how the hemodynamic model (hemodynamic function only or using derivatives) can affects parameter estimates, as well as detail the role of orthogonalization. I then relate the above results to the computation of percentage signal change. Finally, I discuss how these issues affect group analyses and give some recommendations.},
  pmid = {24478622},
  keywords = {Baseline,Derivatives,FMRI,GLM,Modeling,Percentage signal change},
  file = {/Users/brownsarahm/Zotero/storage/XA93UFLD/Pernet - 2014 - Misconceptions in the use of the General Linear Model applied to functional MRI A tutorial for junior neuro-imagers(3).pdf}
}

@article{pernice2011how,
  title = {How Structure Determines Correlations in Neuronal Networks},
  author = {Pernice, Volker and Staude, Benjamin and Cardanobile, Stefano and Rotter, Stephan},
  year = {2011},
  journal = {PLoS Computational Biology},
  volume = {7},
  number = {5},
  pages = {e1002059}
}

@article{peters2012causal,
  title = {Causal {{Inference}} on {{Time Series}} Using {{Structural Equation Models}}},
  author = {Peters, Jonas and Janzing, Dominik and Sch, Bernhard and Sch{\"o}lkopf, Bernhard},
  year = {2012},
  journal = {Advances in neural information processing systems},
  pages = {1--9},
  file = {/Users/brownsarahm/Zotero/storage/DFTNHXLP/Peters, Janzing, Sch - 2009 - Causal Inference on Time Series using Restricted Structural Equation Models(2).pdf}
}

@misc{ph.d2023NeurIPS,
  title = {{{NeurIPS}} 2023 and the {{State}} of {{AI Research}}},
  author = {Ph.D, Jacob Marks},
  year = {2023},
  month = dec,
  journal = {Voxel51},
  urldate = {2024-04-19},
  abstract = {Patterns and Trends in Accepted NeurIPS Papers},
  langid = {english}
}

@article{pierson2020large,
  title = {A Large-Scale Analysis of Racial Disparities in Police Stops across the {{United States}}},
  author = {Pierson, Emma and Simoiu, Camelia and Overgoor, Jan and {Corbett-Davies}, Sam and Jenson, Daniel and Shoemaker, Amy and Ramachandran, Vignesh and Barghouty, Phoebe and Phillips, Cheryl and Shroff, Ravi and others},
  year = {2020},
  journal = {Nature human behaviour},
  pages = {1--10},
  publisher = {Nature Publishing Group}
}

@article{pievani2011functional,
  title = {Functional Network Disruption in the Degenerative Dementias},
  author = {Pievani, Michela and {\noopsort{haan}}{de Haan}, Willem and Wu, Tao and Seeley, William W and Frisoni, Giovanni B},
  year = {2011},
  journal = {The Lancet Neurology},
  volume = {10},
  number = {9},
  pages = {829--843}
}

@article{pinelis2017optimal,
  title = {Optimal-Order Uniform and Nonuniform Bounds on the Rate of Convergence to Normality for Maximum Likelihood Estimators},
  author = {Pinelis, Iosif},
  year = {2017},
  journal = {Electronic Journal of Statistics},
  volume = {11},
  number = {1},
  pages = {1160--1179},
  publisher = {{The Institute of Mathematical Statistics and the Bernoulli Society}}
}

@article{pinker1997how,
  title = {How the Mind Works},
  author = {Pinker, Steven},
  year = {1997},
  journal = {Annals of the New York Academy of Sciences},
  volume = {882},
  number = {1},
  pages = {119--127},
  file = {/Users/brownsarahm/Zotero/storage/G6K8ADCC/Pinker - 1999 - How the mind works(2).pdf}
}

@book{pinker2003blank,
  title = {The Blank Slate: {{The}} Modern Denial of Human Nature},
  author = {Pinker, Steven},
  year = {2003},
  publisher = {Penguin}
}

@article{piramuthu1993integration,
  title = {Integration of Simulation Modeling and Inductive Learning in an Adaptive Decision Support System},
  author = {Piramuthu, Selwyn and Raman, Narayan and Shaw, Michael J. and Chan Park, Sang},
  year = {1993},
  journal = {Decision Support Systems},
  volume = {9},
  number = {1},
  pages = {127--142},
  issn = {01679236},
  doi = {10.1016/0167-9236(93)90027-Z},
  abstract = {This paper presents a decision support system (DSS) with inductive learning capability for model management. Simulation is used as the primary environment for modeling manufacturing systems and their processes. We propose an adaptive DSS framework for incorporating machine learning into the real time scheduling of a flexible manufacturing system and flexible flow system. The resulting DSS, referred to as pattern directed scheduling (PDS) system, has the unique characteristic of being an adaptive scheduler. While the bulk of previous research on dynamic machine scheduling deals with the relative effectiveness of a single scheduling rule, the approach presented in this study provides a mechanism for the state-dependent selection of one from among several rules. We address the PDS approach in the context of a model management system (MMS), with built-in simulation and inductive learning modules for heuristic acquisition and refinement. These modules complement each other in performing the decision support functions. Computational results show that such a pattern directed scheduling approach leads to superior system performance. It also provides a new framework for developing adaptive DSS. {\copyright} 1993.},
  keywords = {Adaptive decision support systems,Inductive learning,Model management,Pattern-directed scheduling},
  file = {/Users/brownsarahm/Zotero/storage/CBEL8LMU/Piramuthu et al. - 1993 - Integration of simulation modeling and inductive learning in an adaptive decision support system.pdf}
}

@inproceedings{pirolli2005sensemaking,
  title = {The Sensemaking Process and Leverage Points for Analyst Technology as Identified through Cognitive Task Analysis},
  booktitle = {Proceedings of International Conference on Intelligence Analysis},
  author = {Pirolli, Peter and Card, Stuart},
  year = {2005},
  volume = {5},
  pages = {2--4}
}

@article{pitman1987psychophysiologic,
  title = {Psychophysiologic Assessment of Posttraumatic Stress Disorder Imagery in {{Vietnam}} Combat Veterans.},
  author = {Pitman, R K and Orr, S P and Forgue, D F and {\noopsort{jong}}{de Jong}, J B and Claiborn, J M},
  year = {1987},
  month = nov,
  journal = {Archives of general psychiatry},
  volume = {44},
  number = {11},
  eprint = {3675137},
  eprinttype = {pubmed},
  pages = {970--5},
  issn = {0003-990X},
  abstract = {This study utilized psychophysiologic techniques to assess emotional arousal during imagery of psychologically traumatic experiences. All subjects were medication-free Vietnam combat veterans, classified on the basis of DSM-III-R criteria into groups with posttraumatic stress disorder (PTSD, n = 18) and no mental disorder (control, n = 15), which did not differ in extent of combat or in the judged severity of the traumatic experiences reported. "Scripts" describing each subject's combat experiences as well as other experiences were read to them in the laboratory, and they were instructed to imagine the events the scripts portrayed, while heart rate, skin conductance, and frontalis electromyogram were recorded. The PTSD subjects' physiologic responses to their combat scripts were markedly higher than the controls'. The combined physiologic variables identified PTSD subjects with a specificity of 100\% and a sensitivity of 61\%. The results demonstrate exaggerated physiologic arousal during recollection of traumatic experiences in PTSD.},
  pmid = {3675137},
  keywords = {Adult,Combat Disorders,Combat Disorders: physiopathology,Combat Disorders: psychology,Humans,Imagination,Male,Post-Traumatic,Post-Traumatic: physiopathology,Post-Traumatic: psychology,Psychophysiology,Psychophysiology: methods,Reference Values,Stress Disorders,Veterans,Veterans: psychology,Vietnam},
  file = {/Users/brownsarahm/Zotero/storage/6KZGVEW3/Pitman et al. - 1987 - Psychophysiologic assessment of posttraumatic stress disorder imagery in Vietnam combat veterans(3).pdf}
}

@article{pitman1995probability,
  title = {Probability {{Theory}} Fated {{Fields Exchangeable}} and Partially Exchangeable Random Partitions},
  author = {Pitman, Jim},
  year = {1995},
  journal = {Probability Theory and Related Fields},
  volume = {102},
  number = {2},
  pages = {145--158},
  issn = {01788051},
  doi = {10.1007/BF01213386},
  abstract = {Call a random partition of the positive integers partially exchange- able if for each finite sequence of positive integers nl,..., nk, the probabil- ity that the partition breaks the first nl +... {\textbackslash}S nk integers into k particular classes, of sizes nl .... , nk in order of their first elements, has the same value p(na ..... nk) for every possible choice of classes subject to the sizes con- straint. A random partition is exchangeable iff it is partially exchangeable for a symmetric function p(nl,.., nk). A representation is given for partially ex- changeable random partitions which provides a useful variation of Kingman's representation in the exchangeable case. Results are illustrated by the two- parameter generalization of Ewens' partition structure.},
  file = {/Users/brownsarahm/Zotero/storage/FLJW55UN/Pitman - 1995 - Probability Theory fated Fields Exchangeable and partially exchangeable random partitions(3).pdf}
}

@inproceedings{pmlr-v97-cvitkovic19a,
  title = {Minimal Achievable Sufficient Statistic Learning},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  author = {Cvitkovic, Milan and Koliander, G{\"u}nther},
  editor = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  year = {2019-06-09/2019-06-15},
  series = {Proceedings of Machine Learning Research},
  volume = {97},
  pages = {1465--1474},
  publisher = {PMLR},
  abstract = {We introduce Minimal Achievable Sufficient Statistic (MASS) Learning, a machine learning training objective for which the minima are minimal sufficient statistics with respect to a class of functions being optimized over (e.g., deep networks). In deriving MASS Learning, we also introduce Conserved Differential Information (CDI), an information-theoretic quantity that --- unlike standard mutual information --- can be usefully applied to deterministically-dependent continuous random variables like the input and output of a deep network. In a series of experiments, we show that deep networks trained with MASS Learning achieve competitive performance on supervised learning, regularization, and uncertainty quantification benchmarks.}
}

@article{podsakoff2003common,
  title = {Common Method Biases in Behavioral Research: A Critical Review of the Literature and Recommended Remedies.},
  author = {Podsakoff, Philip M and MacKenzie, Scott B and Lee, Jeong-Yeon and Podsakoff, Nathan P},
  year = {2003},
  journal = {Journal of applied psychology},
  volume = {88},
  number = {5},
  pages = {879},
  publisher = {American Psychological Association}
}

@article{podsakoff2003common,
  title = {Common Method Biases in Behavioral Research: A Critical Review of the Literature and Recommended Remedies.},
  author = {Podsakoff, Philip M and MacKenzie, Scott B and Lee, Jeong-Yeon and Podsakoff, Nathan P},
  year = {2003},
  journal = {Journal of applied psychology},
  volume = {88},
  number = {5},
  pages = {879},
  publisher = {American Psychological Association}
}

@article{poldrack2006can,
  title = {Can Cognitive Processes Be Inferred from Neuroimaging Data?},
  author = {Poldrack, Russell A},
  year = {2006},
  journal = {Trends in Cognitive Sciences},
  volume = {10},
  number = {2},
  pages = {59--63}
}

@article{pole2007psychophysiology,
  title = {The Psychophysiology of Posttraumatic Stress Disorder: A Meta-Analysis.},
  author = {Pole, Nnamdi},
  year = {2007},
  journal = {Psychological Bulletin},
  volume = {133},
  number = {5},
  pages = {725}
}

@article{poppe2010Survey,
  ids = {poppe2010Surveya},
  title = {A Survey on Vision-Based Human Action Recognition},
  author = {Poppe, Ronald},
  year = {2010},
  journal = {Image and vision computing},
  volume = {28},
  number = {6},
  pages = {976--990},
  publisher = {Elsevier}
}

@article{posner1988localization,
  title = {Localization of Cognitive Operations in the Human Brain},
  author = {Posner, Michael I and Petersen, Steven E and Fox, Peter T and Raichle, Marcus E},
  year = {1988},
  journal = {Science},
  volume = {240},
  number = {4859},
  pages = {1627--1631}
}

@article{postashpredictive,
  title = {Predictive {{Modeling}} for {{Public Health}}: {{Preventing Childhood Lead Poisoning}}},
  author = {Postash, Eric and Walsh, Joe and Majumdar, Subhabrata and Jorgensen, Emile and Brew, Joe and Reece, Andrew and Mansour, Raed and Loewi, Alexander and Rozier, Eric and Ghani, Rayid},
  pages = {2039--2047},
  file = {/Users/brownsarahm/Zotero/storage/LL246NID/Postash et al. - Unknown - Predictive Modeling for Public Health Preventing Childhood Lead Poisoning(3).pdf}
}

@article{power2011functional,
  title = {Functional Network Organization of the Human Brain},
  author = {Power, Jonathan D and Cohen, Alexander L and Nelson, Steven M and Wig, Gagan S and Barnes, Kelly Anne and Church, Jessica A and Vogel, Alecia C and Laumann, Timothy O and Miezin, Fran M and Schlaggar, Bradley L and {Others}},
  year = {2011},
  journal = {Neuron},
  volume = {72},
  number = {4},
  pages = {665--678}
}

@article{power2012spurious,
  title = {Spurious but Systematic Correlations in Functional Connectivity {{MRI}} Networks Arise from Subject Motion.},
  author = {Power, Jonathan D and {\noopsort{barnes}}a Barnes, Kelly and Snyder, Abraham Z and Schlaggar, Bradley L and Petersen, Steven E},
  year = {2012},
  month = feb,
  journal = {NeuroImage},
  volume = {59},
  number = {3},
  pages = {2142--54},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2011.10.018},
  abstract = {Here, we demonstrate that subject motion produces substantial changes in the timecourses of resting state functional connectivity MRI (rs-fcMRI) data despite compensatory spatial registration and regression of motion estimates from the data. These changes cause systematic but spurious correlation structures throughout the brain. Specifically, many long-distance correlations are decreased by subject motion, whereas many short-distance correlations are increased. These changes in rs-fcMRI correlations do not arise from, nor are they adequately countered by, some common functional connectivity processing steps. Two indices of data quality are proposed, and a simple method to reduce motion-related effects in rs-fcMRI analyses is demonstrated that should be flexibly implementable across a variety of software platforms. We demonstrate how application of this technique impacts our own data, modifying previous conclusions about brain development. These results suggest the need for greater care in dealing with subject motion, and the need to critically revisit previous rs-fcMRI work that may not have adequately controlled for effects of transient subject movements.},
  pmid = {22019881},
  keywords = {Algorithms,Artifacts,Brain,Brain: anatomy \& histology,Cohort Studies,Computer-Assisted,Computer-Assisted: methods,Head Movements,Humans,Image Processing,Magnetic Resonance Imaging,Magnetic Resonance Imaging: instrumentation,Magnetic Resonance Imaging: methods,Motion,Oxygen,Oxygen: blood,Software},
  file = {/Users/brownsarahm/Zotero/storage/XMFD9HYL/Power et al. - 2012 - Spurious but systematic correlations in functional connectivity MRI networks arise from subject motion(3).pdf}
}

@book{presidentBigDataReport2016,
  title = {Big Data: {{A}} Report on Algorithmic Systems, Opportunity, and Civil Rights},
  author = {{\noopsort{president}}of the President, Executive Office and Munoz, Cecilia and Director, Domestic Policy Council and {\noopsort{science}}of Science, Megan (US Chief Technology Officer Smith (Office and Policy)), Technology and Policy, DJ (Deputy Chief Technology Officer for Data and {\noopsort{science}}of Science, Chief Data Scientist Patil (Office and Policy)), Technology},
  year = {2016},
  publisher = {Executive Office of the President}
}

@misc{Pull,
  title = {Pull Requests {$\cdot$} Carpentries/Trainers},
  journal = {GitHub},
  urldate = {2021-08-22},
  abstract = {Repository for the Instructor Trainers community. Contribute to carpentries/trainers development by creating an account on GitHub.},
  howpublished = {https://github.com/carpentries/trainers},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/SWWT65YU/89.html}
}

@inproceedings{qi2008finding,
  title = {Finding Alternative Clusterings Using Constraints},
  booktitle = {{{IEEE Intl}}. {{Conf}}. on {{Data Mining}}},
  author = {Qi, Z J and Davidson, I},
  year = {2008},
  address = {Bari, Italy}
}

@article{qian2011phase,
  title = {Phase or Amplitude? {{The}} Relationship between Ongoing and Evoked Neural Activity},
  author = {Qian, Chencan and Di, Xin},
  year = {2011},
  journal = {The Journal of Neuroscience},
  volume = {31},
  number = {29},
  pages = {10425--10426}
}

@article{qin2023machine,
  ids = {qin2023Machine,qin2023Machinea},
  title = {Machine Learning-Based Data and Model Driven Bayesian Uncertanity Quantification of Inverse Problems for Suspended Non-Structural System},
  author = {Qin, Zhiyuan},
  year = {2023}
}

@inproceedings{qiu2014ensemble,
  title = {Ensemble Deep Learning for Regression and Time Series Forecasting},
  booktitle = {2014 {{IEEE}} Symposium on Computational Intelligence in Ensemble Learning ({{CIEL}})},
  author = {Qiu, Xueheng and Zhang, Le and Ren, Ye and Suganthan, Ponnuthurai N and Amaratunga, Gehan},
  year = {2014},
  pages = {1--6},
  publisher = {IEEE}
}

@inproceedings{qiu2014Ensemble,
  title = {Ensemble Deep Learning for Regression and Time Series Forecasting},
  booktitle = {2014 {{IEEE}} Symposium on Computational Intelligence in Ensemble Learning ({{CIEL}})},
  author = {Qiu, Xueheng and Zhang, Le and Ren, Ye and Suganthan, Ponnuthurai N and Amaratunga, Gehan},
  year = {2014},
  pages = {1--6},
  publisher = {IEEE}
}

@inproceedings{quinlan1993combining,
  title = {Combining Instance-Based and Model-Based Learning},
  booktitle = {Proceedings of the {{Tenth International Conference}} on {{Machine Learning}}},
  author = {Quinlan, J Ross},
  year = {1993},
  pages = {236--243}
}

@article{quiroga2005invariant,
  title = {Invariant Visual Representation by Single Neurons in the Human Brain},
  author = {Quiroga, R Quian and Reddy, Leila and Kreiman, Gabriel and Koch, Christof and Fried, Itzhak},
  year = {2005},
  journal = {Nature},
  volume = {435},
  number = {7045},
  pages = {1102--1107}
}

@article{rabiner1989tutorial,
  title = {A Tutorial on Hidden {{Markov}} Models and Selected Applications in Speech Recognition},
  author = {Rabiner, L R},
  year = {1989},
  journal = {Proceedings of the IEEE},
  volume = {77},
  pages = {257--286},
  issn = {00189219},
  doi = {10.1109/5.18626},
  abstract = {This tutorial provides an overview of the basic theory of hidden Markov models (HMMs) as originated by L.E. Baum and T. Petrie (1966) and gives practical details on methods of implementation of the theory along with a description of selected applications of the theory to distinct problems in speech recognition. Results from a number of original sources are combined to provide a single source of acquiring the background required to pursue further this area of research. The author first reviews the theory of discrete Markov chains and shows how the concept of hidden states, where the observation is a probabilistic function of the state, can be used effectively. The theory is illustrated with two simple examples, namely coin-tossing, and the classic balls-in-urns system. Three fundamental problems of HMMs are noted and several practical techniques for solving these problems are given. The various types of HMMs that have been studied, including ergodic as well as left-right models, are described},
  pmid = {21920608},
  keywords = {ai speech-recognition survey uncertainty hmm marko},
  file = {/Users/brownsarahm/Zotero/storage/RL3C7M22/Rabiner - 1989 - A tutorial on hidden Markov models and selected applications in speech recognition(3).pdf}
}

@article{rabinovich2015dynamical,
  title = {Dynamical Bridge between Brain and Mind},
  author = {Rabinovich, Mikhail I. and Simmons, Alan N. and Varona, Pablo},
  year = {2015},
  journal = {Trends in Cognitive Sciences},
  volume = {19},
  number = {8},
  pages = {453--461},
  issn = {13646613},
  doi = {10.1016/j.tics.2015.06.005},
  keywords = {cognitive dynamical principles,competition,functional cognitive networks,robust cognitive processing,sequential stability and winnerless,stable heteroclinic channel,transient brain dynamics},
  file = {/Users/brownsarahm/Zotero/storage/KGCQJNNQ/Rabinovich, Simmons, Varona - 2015 - Dynamical bridge between brain and mind(3).pdf}
}

@article{raichle2001default,
  title = {A Default Mode of Brain Function},
  author = {Raichle, Marcus E and MacLeod, Ann Mary and Snyder, Abraham Z and Powers, William J and Gusnard, Debra A and Shulman, Gordon L},
  year = {2001},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {98},
  number = {2},
  pages = {676--682}
}

@article{raichle2010two,
  title = {Two Views of Brain Function},
  author = {Raichle, Marcus E},
  year = {2010},
  journal = {Trends in Cognitive Sciences},
  volume = {14},
  number = {4},
  pages = {180--190}
}

@inproceedings{raji2020closing,
  title = {Closing the {{AI Accountability Gap}}: {{Defining}} an {{End-to-End Framework}} for {{Internal Algorithmic Auditing}}},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Raji, Inioluwa Deborah and Smart, Andrew and White, Rebecca N. and Mitchell, Margaret and Gebru, Timnit and Hutchinson, Ben and {Smith-Loud}, Jamila and Theron, Daniel and Barnes, Parker},
  year = {2020},
  series = {{{FAT}}* '20},
  pages = {33--44},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3351095.3372873},
  isbn = {978-1-4503-6936-7},
  keywords = {accountability,algorithmic audits,machine learning,responsible innovation}
}

@article{raji2021ai,
  title = {{{AI}} and the Everything in the Whole Wide World Benchmark},
  author = {Raji, Inioluwa Deborah and Bender, Emily M and Paullada, Amandalynne and Denton, Emily and Hanna, Alex},
  year = {2021},
  journal = {NeurIPS Dataset Track},
  volume = {abs/2111.15366}
}

@misc{raji2021AIa,
  title = {{{AI}} and the {{Everything}} in the {{Whole Wide World Benchmark}}},
  author = {Raji, Inioluwa Deborah and Bender, Emily M. and Paullada, Amandalynne and Denton, Emily and Hanna, Alex},
  year = {2021},
  month = nov,
  number = {arXiv:2111.15366},
  eprint = {2111.15366},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-04-19},
  abstract = {There is a tendency across different subfields in AI to valorize a small collection of influential benchmarks. These benchmarks operate as stand-ins for a range of anointed common problems that are frequently framed as foundational milestones on the path towards flexible and generalizable AI systems. State-of-the-art performance on these benchmarks is widely understood as indicative of progress towards these long-term goals. In this position paper, we explore the limits of such benchmarks in order to reveal the construct validity issues in their framing as the functionally "general" broad measures of progress they are set up to be.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Performance},
  file = {/Users/brownsarahm/Zotero/storage/HKRJ29QW/Raji et al. - 2021 - AI and the Everything in the Whole Wide World Benc.pdf;/Users/brownsarahm/Zotero/storage/DJPIJWY3/2111.html}
}

@inproceedings{raji2021You,
  ids = {raji2021Youa,raji2021Youb,raji2021Youc},
  title = {You Can't Sit with Us: Exclusionary Pedagogy in {{AI}} Ethics Education},
  booktitle = {Proceedings of the 2021 {{ACM}} Conference on Fairness, Accountability, and Transparency},
  author = {Raji, Inioluwa Deborah and Scheuerman, Morgan Klaus and Amironesei, Razvan},
  year = {2021},
  pages = {515--525},
  file = {/Users/brownsarahm/Zotero/storage/8EC6CFGZ/Raji et al. - 2021 - You Can't Sit With Us Exclusionary Pedagogy in AI.pdf}
}

@inproceedings{raji2022Fallacy,
  title = {The {{Fallacy}} of {{AI Functionality}}},
  booktitle = {2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Raji, Inioluwa Deborah and Kumar, I. Elizabeth and Horowitz, Aaron and Selbst, Andrew},
  year = {2022},
  month = jun,
  pages = {959--972},
  publisher = {ACM},
  address = {Seoul Republic of Korea},
  doi = {10.1145/3531146.3533158},
  urldate = {2024-04-19},
  isbn = {978-1-4503-9352-2},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/UI44LZPU/Raji et al. - 2022 - The Fallacy of AI Functionality.pdf}
}

@article{raji2023concrete,
  title = {Concrete Problems in {{AI}} Safety, Revisited},
  author = {Raji, Inioluwa Deborah and Dobbe, Roel},
  year = {2023},
  journal = {arXiv preprint arXiv:2401.10899},
  eprint = {2401.10899},
  archiveprefix = {arXiv}
}

@article{rakova2021responsible,
  title = {Where Responsible {{AI}} Meets Reality: {{Practitioner}} Perspectives on Enablers for Shifting Organizational Practices},
  author = {Rakova, Bogdana and Yang, Jingying and Cramer, Henriette and Chowdhury, Rumman},
  year = {2021},
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {5},
  number = {CSCW1},
  pages = {1--23},
  publisher = {ACM New York, NY, USA}
}

@book{rasmussen2006gaussian,
  title = {Gaussian Processes for Machine Learning.},
  author = {Rasmussen, Carl Edward and Williams, K.I.},
  year = {2006},
  doi = {10.1142/S0129065704001899},
  isbn = {0-262-18253-X},
  pmid = {15112367},
  file = {/Users/brownsarahm/Zotero/storage/93FZXFUG/Rasmussen, Williams - 2006 - Gaussian processes for machine learning(3).pdf}
}

@article{ratnagiri2010multiclass,
  title = {Multi-{{Class Classification Using}} a {{New Sigmoid Loss Function}} for {{Minimum Classification Error}} ({{MCE}})},
  author = {Ratnagiri, Madhavi V. and Rabiner, Lawrence and Juang, BiingHwang (Fred)},
  year = {2010},
  month = dec,
  journal = {2010 Ninth International Conference on Machine Learning and Applications},
  pages = {84--89},
  doi = {10.1109/ICMLA.2010.20},
  keywords = {-component,bayes risk,biing-hwang,classification error,computer engineering,fred,juang,minimum,savage loss,school of electrical and,sigmoid loss},
  file = {/Users/brownsarahm/Zotero/storage/FHI9VGUR/Ratnagiri, Rabiner, Juang - 2010 - Multi-Class Classification Using a New Sigmoid Loss Function for Minimum Classification Error (MCE(3).pdf}
}

@article{rau2019structure,
  title = {What Is the Structure of Perceiver Effects? {{On}} the Importance of Global Positivity and Trait-Specificity across Personality Domains and Judgment Contexts.},
  author = {Rau, Richard and Carlson, Erika N and Back, Mitja D and Barranti, Maxwell and Gebauer, Jochen E and Human, Lauren J and Leising, Daniel and Nestler, Steffen},
  year = {2019},
  journal = {Journal of Personality and Social Psychology},
  publisher = {American Psychological Association}
}

@article{raudys1991small,
  title = {Small Sample Size Effects in Statistical Pattern Recognition: {{Recommendations}} for Practitioners},
  author = {Raudys, SJ Sarunas J and Jain, {\relax AK} and Raudys, SJ Sarunas J},
  year = {1991},
  journal = {IEEE Transactions on pattern analysis and {\textbackslash}ldots},
  volume = {13},
  number = {3},
  pages = {252--264},
  file = {/Users/brownsarahm/Zotero/storage/XV2MKERX/Raudys, Raudys - 1991 - Small Sample Size Effects in Statistical Pattern Recognition Recommendations for Practitioners(2).pdf}
}

@article{raykov2007reliability,
  title = {Reliability If Deleted, Not `Alpha If Deleted': {{Evaluation}} of Scale Reliability Following Component Deletion},
  author = {Raykov, Tenko},
  year = {2007},
  journal = {British Journal of Mathematical and Statistical Psychology},
  volume = {60},
  number = {2},
  pages = {201--216},
  publisher = {Wiley Online Library}
}

@article{raz2012portraying,
  title = {Portraying Emotions at Their Unfolding: A Multilayered Approach for Probing Dynamics of Neural Networks.},
  author = {Raz, Gal and Winetraub, Yonatan and Jacob, Yael and Kinreich, Sivan and {Maron-Katz}, Adi and Shaham, Galit and Podlipsky, Ilana and Gilam, Gadi and Soreq, Eyal and Hendler, Talma},
  year = {2012},
  month = apr,
  journal = {NeuroImage},
  volume = {60},
  number = {2},
  eprint = {22285693},
  eprinttype = {pubmed},
  pages = {1448--1461},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2011.12.084},
  abstract = {Dynamic functional integration of distinct neural systems plays a pivotal role in emotional experience. We introduce a novel approach for studying emotion-related changes in the interactions within and between networks using fMRI. It is based on continuous computation of a network cohesion index (NCI), which is sensitive to both strength and variability of signal correlations between pre-defined regions. The regions encompass three clusters (namely limbic, medial prefrontal cortex (mPFC) and cognitive), each previously was shown to be involved in emotional processing. Two sadness-inducing film excerpts were viewed passively, and comparisons between viewer's rated sadness, parasympathetic, and inter-NCI and intra-NCI were obtained. Limbic intra-NCI was associated with reported sadness in both movies. However, the correlation between the parasympathetic-index, the rated sadness and the limbic-NCI occurred in only one movie, possibly related to a "deactivated" pattern of sadness. In this film, rated sadness intensity also correlated with the mPFC intra-NCI, possibly reflecting temporal correspondence between sadness and sympathy. Further, only for this movie, we found an association between sadness rating and the mPFC-limbic inter-NCI time courses. To the contrary, in the other film in which sadness was reported to commingle with horror and anger, dramatic events coincided with disintegration of these networks. Together, this may point to a difference between the cinematic experiences with regard to inter-network dynamics related to emotional regulation. These findings demonstrate the advantage of a multi-layered dynamic analysis for elucidating the uniqueness of emotional experiences with regard to an unguided processing of continuous and complex stimulation.},
  pmid = {22285693},
  keywords = {Adult,Brain,Brain Mapping,Brain: physiology,Emotions,Emotions: physiology,Female,Humans,Magnetic Resonance Imaging,Male,Nerve Net,Nerve Net: physiology}
}

@article{ren2003automatic,
  title = {Automatic Spectral Target Recognition in Hyperspectral Imagery},
  author = {Ren, Hsuan},
  year = {2003},
  month = oct,
  journal = {IEEE Transactions on Aerospace and Electronic Systems},
  volume = {39},
  number = {4},
  pages = {1232--1249},
  issn = {0018-9251},
  doi = {10.1109/TAES.2003.1261124},
  file = {/Users/brownsarahm/Zotero/storage/SGHWPJAQ/Ren - 2003 - Automatic spectral target recognition in hyperspectral imagery(3).pdf}
}

@article{ren2023water,
  title = {Making {{AI}} Less "Thirsty": {{Uncovering}} and Addressing the Secret Water Footprint of {{AI}} Models},
  author = {Li, Pengfei and Yang, Jianyi and Islam, Mohammad A. and Ren, Shaolei},
  year = {2023},
  journal = {arXiv preprint arXiv:2304.03271},
  eprint = {2304.03271},
  archiveprefix = {arXiv}
}

@article{resnik2009gibbs,
  title = {Gibbs {{Sampling}} for the {{Uninitiated}}},
  author = {Resnik, P and Resnik, P and Hardisty, E and Hardisty, E},
  year = {2009},
  journal = {Umiacs.Umd.Edu},
  number = {June},
  pages = {1--23},
  issn = {{\textbackslash}textlessnull{\textbackslash}textgreater},
  abstract = {This document is intended for computer scientists who would like to try out a Markov Chain Monte Carlo (MCMC) technique, particularly in order to do inference with Bayesian models on problems related to text processing. We try to keep theory to the absolute minimum needed, and we work through the details much more explicitly than you usually see even in ``introductory'' explanations. That means we've attempted to be ridiculously explicit in our exposition and notation. After providing the reasons and reasoning behind Gibbs sampling (and at least nodding our heads in the direction of theory), we work through two applications in detail. The first is the derivation of a Gibbs sampler for Naive Bayes models, which illustrates a simple case where the math works out very cleanly and it's possible to ``integrate out'' the model's continuous parameters to build a more efficient algorithm. The second application derives the Gibbs sampler for a model that is similar to Naive Bayes, but which adds an additional latent variable. Having gone through the two examples, we discuss some practical implementation issues. We conclude with some pointers to literature that we've found to be somewhat more friendly to uninitiated readers.},
  keywords = {{\i}ve bayes,bayesian inference,gibbs sampling,markov chain monte carlo,na},
  file = {/Users/brownsarahm/Zotero/storage/TDCTHUCG/Resnik et al. - 2009 - Gibbs Sampling for the Uninitiated(3).pdf}
}

@article{reynolds2008emotional,
  title = {Emotional Environments Retune the Valence of Appetitive versus Fearful Functions in Nucleus Accumbens},
  author = {Reynolds, Sheila M and Berridge, Kent C},
  year = {2008},
  journal = {Nature neuroscience},
  volume = {11},
  number = {4},
  pages = {423--425},
  file = {/Users/brownsarahm/Zotero/storage/HY48959X/Reynolds, Berridge - 2008 - Emotional environments retune the valence of appetitive versus fearful functions in nucleus accumbens(3).pdf}
}

@article{rhoten2007women,
  title = {Women in Interdisciplinary Science: {{Exploring}} Preferences and Consequences},
  author = {Rhoten, Diana and Pfirman, Stephanie},
  year = {2007},
  journal = {Research Policy},
  volume = {36},
  number = {1},
  pages = {56--75},
  issn = {00487333},
  doi = {10.1016/j.respol.2006.08.001},
  abstract = {For at least a decade, U.S. funding agencies and university campuses have promoted the expansion of interdisciplinary research. At the same time, federal and local programs have sought to increase the participation of women and minorities in science, mathematics, and engineering. Research has focused on each of these trends independently, but very few studies have considered their interaction by asking how intellectual preferences for and professional consequences of interdisciplinary science might be influenced by gender, race, and/or ethnicity. Focused specifically on gender, this paper considers the expectation that women will be more drawn to interdisciplinary research, and explores the learning styles, work preferences, and career behaviors that might anticipate and/or explicate gender differences in interdisciplinary science. Principal mechanisms by which researchers engage in interdisciplinarity - cross-fertilization, team-collaboration, field-creation, and problem-orientation - are tested for evidence of gendering using preliminary empirical data from three studies. The results of this exploratory analysis offer clues about possible tendencies and raise questions about the potential costs and benefits for those who adopt them. ?? 2006 Elsevier B.V. All rights reserved.},
  pmid = {2677},
  keywords = {Gender,Interdisciplinary science,Knowledge production,Reform},
  file = {/Users/brownsarahm/Zotero/storage/RRYVJLN5/Rhoten, Pfirman - 2007 - Women in interdisciplinary science Exploring preferences and consequences(3).pdf}
}

@techreport{ribeiro2004kalman,
  title = {Kalman and Extended Kalman Filters: {{Concept}}, Derivation and Properties},
  author = {Ribeiro, {\relax MI}},
  year = {2004},
  number = {February},
  institution = {{Institue for Systems and Robotics, Instituto Superio Tecnico}}
}

@article{richardson2010prevalence,
  title = {Prevalence Estimates of Combat-Related Post-Traumatic Stress Disorder: Critical Review},
  author = {Richardson, Lisa K and Frueh, B Christopher and Acierno, Ronald},
  year = {2010},
  journal = {Australian and New Zealand Journal of Psychiatry},
  volume = {44},
  number = {1},
  pages = {4--19}
}

@article{richardson2021framework,
  ids = {richardson2021Frameworka},
  title = {A Framework for Fairness: {{A}} Systematic Review of Existing Fair {{AI}} Solutions},
  author = {Richardson, Brianna and Gilbert, Juan E},
  year = {2021},
  journal = {arXiv preprint arXiv:2112.05700},
  eprint = {2112.05700},
  archiveprefix = {arXiv}
}

@inproceedings{richardson2021towards,
  title = {Towards Fairness in Practice: {{A}} Practitioner-Oriented Rubric for Evaluating {{Fair ML Toolkits}}},
  booktitle = {Proceedings of the 2021 {{CHI}} Conference on Human Factors in Computing Systems},
  author = {Richardson, Brianna and {Garcia-Gathright}, Jean and Way, Samuel F and Thom, Jennifer and Cramer, Henriette},
  year = {2021},
  pages = {1--13}
}

@article{ridgeway2013pitfalls,
  title = {The Pitfalls of Prediction},
  author = {Ridgeway, Greg},
  year = {2013},
  journal = {NIJ Journal},
  volume = {271},
  pages = {34--40}
}

@article{rigotti2013importance,
  title = {The Importance of Mixed Selectivity in Complex Cognitive Tasks.},
  author = {Rigotti, Mattia and Barak, Omri and Warden, Melissa R and Wang, Xiao-Jing and Daw, Nathaniel D and Miller, Earl K and Fusi, Stefano},
  year = {2013},
  journal = {Nature},
  volume = {497},
  number = {7451},
  eprint = {23685452},
  eprinttype = {pubmed},
  pages = {585--90},
  issn = {1476-4687},
  doi = {10.1038/nature12160},
  abstract = {Single-neuron activity in the prefrontal cortex (PFC) is tuned to mixtures of multiple task-related aspects. Such mixed selectivity is highly heterogeneous, seemingly disordered and therefore difficult to interpret. We analysed the neural activity recorded in monkeys during an object sequence memory task to identify a role of mixed selectivity in subserving the cognitive functions ascribed to the PFC. We show that mixed selectivity neurons encode distributed information about all task-relevant aspects. Each aspect can be decoded from the population of neurons even when single-cell selectivity to that aspect is eliminated. Moreover, mixed selectivity offers a significant computational advantage over specialized responses in terms of the repertoire of input-output functions implementable by readout neurons. This advantage originates from the highly diverse nonlinear selectivity to mixtures of task-relevant variables, a signature of high-dimensional neural representations. Crucially, this dimensionality is predictive of animal behaviour as it collapses in error trials. Our findings recommend a shift of focus for future studies from neurons that have easily interpretable response tuning to the widely observed, but rarely analysed, mixed selectivity neurons.},
  pmid = {23685452},
  keywords = {Animal,Animal: physiology,Animals,Behavior,Cognition,Cognition: physiology,Haplorhini,Haplorhini: physiology,Memory,Memory: physiology,Models,Neurological,Neurons,Neurons: physiology,Prefrontal Cortex,Prefrontal Cortex: cytology,Prefrontal Cortex: physiology,Single-Cell Analysis},
  file = {/Users/brownsarahm/Zotero/storage/EQVW3LKS/Rigotti et al. - 2013 - The importance of mixed selectivity in complex cognitive tasks(6).pdf;/Users/brownsarahm/Zotero/storage/RG2MXX5B/Rigotti et al. - 2013 - The importance of mixed selectivity in complex cognitive tasks(5).pdf}
}

@article{rizzo2010development,
  title = {Development and Early Evaluation of the {{Virtual Iraq}}/{{Afghanistan}} Exposure Therapy System for Combat-Related {{PTSD}}},
  author = {Rizzo, Albert and Difede, JoAnn and Rothbaum, Barbara O and Reger, Greg and Spitalnick, Josh and Cukor, Judith and Mclay, Rob and {Others}},
  year = {2010},
  journal = {Annals of the New York Academy of Sciences},
  volume = {1208},
  number = {1},
  pages = {114--125}
}

@book{robinsonspringer,
  title = {Springer {{Series}} in {{Operations Research}} and {{Financial Engineering Springer Series}} in {{Operation Research}} And},
  author = {Robinson, Stephen M},
  isbn = {978-0-387-30303-1},
  file = {/Users/brownsarahm/Zotero/storage/4AP55TD4/Robinson - Unknown - Springer Series in Operations Research and Financial Engineering Springer Series in Operation Research and(6).pdf;/Users/brownsarahm/Zotero/storage/7R98IRKE/Robinson - Unknown - Springer Series in Operations Research and Financial Engineering Springer Series in Operation Research and(5).pdf}
}

@article{roesch2011emotionoriented,
  title = {Emotion-{{Oriented Systems}}},
  author = {Roesch, Etienne B and Korsten, Nienke and Fragopanagos, Nickolaos F and Taylor, John G and Grandjean, Didier and Sander, David},
  editor = {Cowie, Roddy and Pelachaud, Catherine and Petta, Paolo},
  year = {2011},
  journal = {Neuroscience},
  series = {Cognitive {{Technologies}}},
  pages = {47--62},
  doi = {10.1007/978-3-642-15184-2},
  file = {/Users/brownsarahm/Zotero/storage/EMCZEK5A/Roesch et al. - 2011 - Emotion-Oriented Systems(3).pdf}
}

@article{rosenblatt1956remarks,
  title = {Remarks on Some Nonparametric Estimates of a Density Function},
  author = {Rosenblatt, M},
  year = {1956},
  journal = {The Annals of Mathematical Statistics},
  eprint = {10.2307/2237390},
  eprinttype = {jstor},
  file = {/Users/brownsarahm/Zotero/storage/PSS52L7M/Rosenblatt - 1956 - Remarks on some nonparametric estimates of a density function(3).pdf}
}

@article{ross2013nonparametric,
  title = {Nonparametric {{Mixture}} of {{Gaussian Processes}} with {{Constraints}}},
  author = {Ross, Jc and Dy, Jg},
  year = {2013},
  journal = {Jmlr.Org},
  volume = {28},
  abstract = {Abstract Motivated by the need to identify new and clinically relevant categories of lung disease, we propose a novel clustering with constraints method using a Dirichlet process mixture of Gaussian processes in a variational Bayesian nonparametric framework. We ...},
  file = {/Users/brownsarahm/Zotero/storage/BXFZN2ZG/Ross, Dy - 2013 - Nonparametric Mixture of Gaussian Processes with Constraints(3).pdf}
}

@article{ross2014dual,
  title = {Dual {{Beta Process Priors}} for {{Latent Cluster Discovery}} in {{Chronic Obstructive Pulmonary Disease}}},
  author = {Ross, James C and Cho, Michael H and Dy, Jennifer G and Castaldi, Peter J},
  year = {2014},
  journal = {Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '14},
  pages = {155--162},
  doi = {10.1145/2623330.2623750},
  abstract = {Chronic obstructive pulmonary disease (COPD) is a lung disease characterized by airflow limitation usually associated with an inflammatory response to noxious particles, such as cigarette smoke. COPD is currently the third leading cause of death in the},
  keywords = {chronic obstructive pulmonary disease,for latent cluster discovery,in,l beta process priors},
  file = {/Users/brownsarahm/Zotero/storage/CVXG728S/Ross et al. - 2014 - Dual Beta Process Priors for Latent Cluster Discovery in Chronic Obstructive Pulmonary Disease(3).pdf}
}

@article{ross2021Learning,
  title = {Learning Models for Actionable Recourse},
  author = {Ross, Alexis and Lakkaraju, Himabindu and Bastani, Osbert},
  year = {2021},
  journal = {Advances in Neural Information Processing Systems},
  volume = {34},
  pages = {18734--18746}
}

@article{roweis1999unifying,
  title = {A {{Unifying Review}} of {{Linear Gaussian Models}}},
  author = {Roweis, Sam and Ghahramani, Zoubin},
  year = {1999},
  journal = {Neural Computation},
  volume = {345},
  number = {1995},
  pages = {305--345},
  file = {/Users/brownsarahm/Zotero/storage/R8YUY6Y8/Roweis - 1999 - A Unifying Review of Linear Gaussian Models(2).pdf}
}

@article{rubin1984bayesianly,
  title = {Bayesianly Justifiable and Relevant Frequency Calculations for the Applies Statistician},
  author = {Rubin, {\relax DB}},
  year = {1984},
  journal = {The Annals of Statistics},
  volume = {12},
  number = {4},
  eprint = {10.2307/2240995},
  eprinttype = {jstor},
  pages = {1151--1172},
  file = {/Users/brownsarahm/Zotero/storage/WIINEG7P/Rubin - 1984 - Bayesianly justifiable and relevant frequency calculations for the applies statistician(3).pdf}
}

@article{rucker2008simpson,
  title = {Simpson's Paradox Visualized: The Example of the Rosiglitazone Meta-Analysis},
  author = {R{\"u}cker, Gerta and Schumacher, Martin},
  year = {2008},
  journal = {BMC medical research methodology},
  volume = {8},
  number = {1},
  pages = {34}
}

@article{rudin2014machine,
  title = {Machine Learning for Science and Society},
  author = {Rudin, Cynthia and Wagstaff, Kiri L},
  year = {2014},
  journal = {Machine Learning},
  volume = {95},
  number = {1},
  pages = {1--9}
}

@article{ruiz2014bayesian,
  title = {Bayesian Nonparametric Comorbidity Analysis of Psychiatric Disorders},
  author = {Ruiz, Francisco J R and Valera, Isabel and Blanco, Carlos and {Perez-Cruz}, Fernando},
  year = {2014},
  journal = {Journal of Machine Learning Research},
  volume = {15},
  pages = {1215--1247},
  issn = {15337928},
  abstract = {The analysis of comorbidity is an open and complex research Field in the branch of psychiatry, where clinical experience and several studies suggest that the relation among the psychiatric disorders may have etiological and treatment implications. In this paper, we are interested in applying latent feature modeling to Find the latent structure behind the psychiatric disorders that can help to examine and explain the relationships among them. To this end, we use the large amount of information collected in the National Epidemiologic Survey on Alcohol and Related Conditions (NESARC) database and propose to model these data using a nonparametric latent model based on the Indian BuFiet Process (IBP). Due to the discrete nature of the data, we First need to adapt the observation model for discrete random variables. We propose a generative model in which the observations are drawn from a multinomial-logit distribution given the IBP matrix. The implementation of an eFicient Gibbs sampler is accomplished using the Laplace approximation, which allows integrating out the weighting factors of the multinomial-logit likelihood model. We also provide a variational inference algorithm for this model, which provides a complementary (and less expensive in terms of computational complexity) alternative to the Gibbs sampler allowing us to deal with a larger number of data. Finally, we use the model to analyze comorbidity among the psychiatric disorders diagnosed by experts from the NESARC database. {\copyright} 2014 Francisco J. R. Ruiz, Isabel Valera, Carlos Blanco and Fernando Perez-Cruz.},
  keywords = {Bayesian nonparametrics,Categorical observations,Indian buffet process,Laplace approximation,Multinomial-logit function,Variational inference},
  file = {/Users/brownsarahm/Zotero/storage/2E2RY2CZ/Ruiz et al. - 2014 - Bayesian nonparametric comorbidity analysis of psychiatric disorders(3).pdf}
}

@article{russell2003core,
  title = {Core Affect and the Psychological Construction of Emotion.},
  author = {{\noopsort{russell}}a. Russell, James},
  year = {2003},
  journal = {Psychological Review},
  volume = {110},
  number = {1},
  pages = {145--172},
  issn = {0033-295X},
  doi = {10.1037/0033-295X.110.1.145},
  file = {/Users/brownsarahm/Zotero/storage/P6UV6FJT/Russell - 2003 - Core affect and the psychological construction of emotion(3).pdf}
}

@article{rutledge2014computational,
  title = {A Computational and Neural Model of Momentary Subjective Well-Being},
  author = {Rutledge, Robb B and Skandali, Nikolina and Dayan, Peter and Dolan, Raymond J},
  year = {2014},
  journal = {Proceedings of the National Academy of Sciences},
  pages = {1--6},
  issn = {0027-8424},
  doi = {10.1073/pnas.1407535111},
  abstract = {The subjective well-being or happiness of individuals is an important metric for societies. Although happiness is influenced by life circumstances and population demographics such as wealth, we know little about how the cumulative influence of daily life events are aggregated into subjective feelings. Using computational modeling, we show that emotional reactivity in the form of momentary happiness in response to outcomes of a probabilistic reward task is explained not by current task earnings, but by the combined influence of recent reward expectations and prediction errors arising from those expectations. The robustness of this account was evident in a large-scale replication involving 18,420 participants. Using functional MRI, we show that the very same influences account for task-dependent striatal activity in a manner akin to the influences underpinning changes in happiness.},
  pmid = {25092308},
  keywords = {dopamine,insula,reward prediction error,striatum},
  file = {/Users/brownsarahm/Zotero/storage/W6JBYRV2/Rutledge et al. - 2014 - A computational and neural model of momentary subjective well-being(3).pdf}
}

@article{rutten2012learning,
  title = {The Learning Effects of Computer Simulations in Science Education},
  author = {Rutten, Nico and Van Joolingen, Wouter R. and Van Der Veen, Jan T.},
  year = {2012},
  journal = {Computers and Education},
  volume = {58},
  number = {1},
  pages = {136--153},
  issn = {03601315},
  doi = {10.1016/j.compedu.2011.07.017},
  abstract = {This article reviews the (quasi)experimental research of the past decade on the learning effects of computer simulations in science education. The focus is on two questions: how use of computer simulations can enhance traditional education, and how computer simulations are best used in order to improve learning processes and outcomes. We report on studies that investigated computer simulations as a replacement of or enhancement to traditional instruction. In particular, we consider the effects of variations in how information is visualized, how instructional support is provided, and how computer simulations are embedded within the lesson scenario. The reviewed literature provides robust evidence that computer simulations can enhance traditional instruction, especially as far as laboratory activities are concerned. However, in most of this research the use of computer simulations has been approached without consideration of the possible impact of teacher support, the lesson scenario, and the computer simulation's place within the curriculum. {\copyright} 2011 Elsevier Ltd. All rights reserved.},
  keywords = {Interactive learning environments,Secondary education,Simulations},
  file = {/Users/brownsarahm/Zotero/storage/3WFCJU7W/Rutten, Van Joolingen, Van Der Veen - 2012 - The learning effects of computer simulations in science education.pdf}
}

@article{saad2012trouble,
  title = {Trouble at Rest: How Correlation Patterns and Group Differences Become Distorted after Global Signal Regression.},
  author = {Saad, Ziad S and Gotts, Stephen J and Murphy, Kevin and Chen, Gang and Jo, Hang Joon and Martin, Alex and Cox, Robert W},
  year = {2012},
  journal = {Brain connectivity},
  volume = {2},
  number = {1},
  pages = {25--32},
  issn = {2158-0022},
  doi = {10.1089/brain.2012.0080},
  abstract = {Resting-state functional magnetic resonance imaging (RS-FMRI) holds the promise of revealing brain functional connectivity without requiring specific tasks targeting particular brain systems. RS-FMRI is being used to find differences between populations even when a specific candidate target for traditional inferences is lacking. However, the problem with RS-FMRI is a lacking definition of what constitutes noise and signal. RS-FMRI is easy to acquire but is not easy to analyze or draw inferences from. In this commentary we discuss a problem that is still treated lightly despite its significant impact on RS-FMRI inferences; global signal regression (GSReg), the practice of projecting out signal averaged over the entire brain, can change resting-state correlations in ways that dramatically alter correlation patterns and hence conclusions about brain functional connectedness. Although Murphy et al. in 2009 demonstrated that GSReg negatively biases correlations, the approach remains in wide use. We revisit this issue to argue the problem that GSReg is more than negative bias or the interpretability of negative correlations. Its usage can fundamentally alter interregional correlations within a group, or their differences between groups. We used an illustrative model to clearly convey our objections and derived equations formalizing our conclusions. We hope this creates a clear context in which counterarguments can be made. We conclude that GSReg should not be used when studying RS-FMRI because GSReg biases correlations differently in different regions depending on the underlying true interregional correlation structure. GSReg can alter local and long-range correlations, potentially spreading underlying group differences to regions that may never have had any. Conclusions also apply to substitutions of GSReg for denoising with decompositions of signals aggregated over the network's regions to the extent they cannot separate signals of interest from noise. We touch on the need for careful accounting of nuisance parameters when making group comparisons of correlation maps.},
  pmid = {22432927},
  keywords = {Anatomic,Brain,Brain Mapping,Brain Mapping: methods,Brain: physiology,Computer Simulation,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Models,Rest,Rest: physiology,Signal-To-Noise Ratio},
  file = {/Users/brownsarahm/Zotero/storage/QLLIZIB4/Saad et al. - 2012 - Trouble at rest how correlation patterns and group differences become distorted after global signal regression(3).pdf}
}

@article{saad2013correcting,
  title = {Correcting {{Brain-Wide Correlation Differences}} in {{Resting-State FMRI}}},
  author = {Saad, Ziad S. and Reynolds, Richard C. and Jo, Hang Joon and Gotts, Stephen J. and Chen, Gang and Martin, Alex and Cox, Robert W.},
  year = {2013},
  journal = {Brain Connectivity},
  volume = {3},
  number = {4},
  pages = {339--352},
  issn = {2158-0014},
  doi = {10.1089/brain.2013.0156},
  abstract = {Brain function in ``resting'' state has been extensively studied with functional magnetic resonance imaging (FMRI). However, drawing valid inferences, particularly for group comparisons, is fraught with pitfalls. Differing levels of brain-wide correlations can confound group comparisons. Global signal regression (GSReg) attempts to reduce this confound and is commonly used, even though it differentially biases correlations over brain regions, potentially leading to false group differences. We propose to use average brain-wide correlations as a measure of global correlation (GCOR), and examine the circumstances under which it can be used to identify or correct for differences in global fluctuations. In the process,we show the bias induced by GSReg to be a function only of the data's covariance matrix, and use simulations to compare corrections with GCOR as covariate to GSReg under various scenarios.Wefind that unlike GSReg,GCOR is a conservative approach that can reduce global variations, while avoiding the introduction of false significant differences, as GSReg can. However, as with GSReg, one can- not escape the interaction effect between the grouping variable andGCOR covariate on effect size. WhileGCORis a complementary measure for resting state-FMRI applicable to legacy data, it is a lesser substitute for proper level- I denoising. We also assess the applicability of GCOR to empirical data with motion-based subject grouping and compare group differences to those using GSReg. We find that, while GCOR reduced correlation differences be- tween high and low movers, it is doubtful that motion was the sole driver behind the differences in the first place.},
  pmid = {23705677},
  keywords = {artifact removal,brain connectivity,functional magnetic resonance imaging,global signal regression,head motion effect,preprocessing,resting state},
  file = {/Users/brownsarahm/Zotero/storage/JCNVFRSU/Saad et al. - 2013 - Correcting Brain-Wide Correlation Differences in Resting-State FMRI(3).pdf}
}

@article{saarimaki2016discrete,
  title = {Discrete Neural Signatures of Basic Emotions},
  author = {Saarim{\"a}ki, Heini and Gotsopoulos, Athanasios and J{\"a}{\"a}skel{\"a}inen, Iiro P and Lampinen, Jouko and Vuilleumier, Patrik and Hari, Riitta and Sams, Mikko and Nummenmaa, Lauri},
  year = {2016},
  journal = {Cerebral Cortex},
  volume = {26},
  number = {6},
  pages = {2563--2573}
}

@article{saeys2008robust,
  title = {Robust {{Feature Selection Using Ensemble Feature Selection Techniques}}},
  author = {Saeys, Yvan and Saeys, Yvan and Abeel, Thomas and Abeel, Thomas and Peer, Yves and Peer, Yves and {\noopsort{peer}}{de Peer}, Yves},
  year = {2008},
  journal = {European conference on Machine Learning and Knowledge Discovery in Databases (ECML/PKDD)},
  pages = {313--325},
  issn = {0302-9743},
  doi = {10.1007/978-3-540-87481-2_21},
  abstract = {Robustness or stability of feature selection techniques is a topic of recent interest, and is an important issue when selected feature subsets are subsequently analysed by domain experts to gain more insight into the problem modelled. In this work, we investigate the use of ensemble feature selection techniques, where multiple feature selection methods are combined to yield more robust results. We show that these techniques show great promise for high-dimensional domains with small sample sizes, and provide more robust feature subsets than a single feature selection technique. In addition, we also investigate the effect of ensemble feature selection techniques on classification performance, giving rise to a new model selection strategy.},
  pmid = {19535010},
  file = {/Users/brownsarahm/Zotero/storage/XZCT3PGK/Saeys et al. - 2008 - Robust Feature Selection Using Ensemble Feature Selection Techniques(3).pdf}
}

@inproceedings{saha2019measuring,
  title = {Measuring Non-Expert Comprehension of Machine Learning Fairness Metrics},
  booktitle = {37th {{International Conference}} on {{Machine Learning}}},
  author = {Saha, Debjani and Schumann, Candice and McElfresh, Duncan C and Dickerson, John P and Mazurek, Michelle L and Tschantz, Michael Carl},
  year = {2020},
  volume = {119},
  publisher = {PMLR},
  address = {Vienna, Austria}
}

@article{saleiro2018aequitas,
  ids = {saleiro2018Aequitasa},
  title = {Aequitas: {{A}} Bias and Fairness Audit Toolkit},
  author = {Saleiro, Pedro and Kuester, Benedict and Hinkson, Loren and London, Jesse and Stevens, Abby and Anisfeld, Ari and Rodolfa, Kit T and Ghani, Rayid},
  year = {2018},
  journal = {arXiv preprint arXiv:1811.05577},
  eprint = {1811.05577},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning},
  file = {/Users/brownsarahm/Zotero/storage/RDSRZNLS/Saleiro et al. - 2019 - Aequitas A Bias and Fairness Audit Toolkit.pdf;/Users/brownsarahm/Zotero/storage/8MTDK86K/1811.html}
}

@article{saltz2019integrating,
  ids = {saltz2019Integrating,saltz2019Integratinga,saltz2019Integratingb},
  title = {Integrating Ethics within Machine Learning Courses},
  author = {Saltz, Jeffrey and Skirpan, Michael and Fiesler, Casey and Gorelick, Micha and Yeh, Tom and Heckman, Robert and Dewar, Neil and Beard, Nathan},
  year = {2019},
  journal = {ACM Transactions on Computing Education (TOCE)},
  volume = {19},
  number = {4},
  pages = {1--26},
  publisher = {ACM New York, NY, USA}
}

@article{sandryhaila2014discrete,
  title = {Discrete {{Signal Processing}} on {{Graphs}}: {{Frequency Analysis}}},
  author = {Sandryhaila, Aliaksei and Moura, Jose M. F.},
  year = {2014},
  month = jun,
  journal = {IEEE Transactions on Signal Processing},
  volume = {62},
  number = {12},
  pages = {3042--3054},
  issn = {1053-587X},
  doi = {10.1109/TSP.2014.2321121},
  file = {/Users/brownsarahm/Zotero/storage/5V5GJL26/Sandryhaila, Moura - 2014 - Discrete Signal Processing on Graphs Frequency Analysis(3).pdf}
}

@article{sandvig2016automation,
  title = {Automation, {{Algorithms}}, and {{Politics}} {\textbar} {{When}} the {{Algorithm Itself}} Is a {{Racist}}: {{Diagnosing Ethical Harm}} in the {{Basic Components}} of {{Software}}},
  author = {Sandvig, Christian and Hamilton, Kevin and Karahalios, Karrie and Langbort, Cedric},
  year = {2016},
  journal = {International Journal of Communication},
  volume = {10},
  number = {0},
  pages = {19},
  issn = {1932-8036},
  abstract = {Computer algorithms organize and select information across a wide range of applications and industries, from search results to social media. Abuses of power by Internet platforms have led to calls for algorithm transparency and regulation. Algorithms have a particularly problematic history of processing information about race. Yet some analysts have warned that foundational computer algorithms are not useful subjects for ethical or normative analysis due to complexity, secrecy, technical character, or generality. We respond by investigating what it is an analyst needs to know to determine whether the algorithm in a computer system is improper, unethical, or illegal in itself. We argue that an ``algorithmic ethics'' can analyze a particular published algorithm. We explain the importance of developing a practical algorithmic ethics that addresses virtues, consequences, and norms: We increasingly delegate authority to algorithms, and they are fast becoming obscure but important elements of social structure.},
  keywords = {algorithms,applied ethics,information and communication technologies (ICT),Internet studies,science and technology studies (STS)},
  file = {/Users/brownsarahm/Zotero/storage/6ZE8QC2X/Sandvig et al. - 2016 - Automation, Algorithms, and Politics When the Algorithm Itself is a Racist Diagnosing Ethical Harm in the Basic.pdf}
}

@article{sanei2007eeg,
  title = {{{EEG}} Signal Processing},
  author = {Sanei, Sacid and {\noopsort{chambers}}a. Chambers, J.},
  year = {2007},
  journal = {Computational intelligence and neuroscience},
  issn = {1687-5265},
  doi = {10.1155/2007/97026},
  pmid = {18301719},
  file = {/Users/brownsarahm/Zotero/storage/IVRNUF7S/Sanei, Chambers - 2007 - EEG signal processing(3).pdf}
}

@article{saria2007reasoning,
  title = {Reasoning at the Right Time Granularity},
  author = {Saria, Suchi and Nodelman, Uri and Koller, Daphne},
  year = {2007},
  journal = {Proceedings of the Twenty-third Conference on Uncertainty in AI (UAI)},
  pages = {9},
  abstract = {Most real-world dynamic systems are composed of different components that often evolve at very different rates. In traditional temporal graphical models, such as dynamic Bayesian networks, time is modeled at a fixed granularity, generally selected based on the rate at which the fastest component evolves. Inference must then be performed at this fastest granularity, potentially at significant computational cost. Continuous Time Bayesian Networks (CTBNs) avoid time-slicing in the representation by modeling the system as evolving continuously over time. The expectation-propagation (EP) inference algorithm of Nodelman et al. (2005) can then vary the inference granularity over time, but the granularity is uniform across all parts of the system, and must be selected in advance. In this paper, we provide a new EP algorithm that utilizes a general cluster graph architecture where clusters contain distributions that can overlap in both space (set of variables) and time. This architecture allows different parts of the system to be modeled at very different time granularities, according to their current rate of evolution. We also provide an information-theoretic criterion for dynamically re-partitioning the clusters during inference to tune the level of approximation to the current rate of evolution. This avoids the need to hand-select the appropriate granularity, and allows the granularity to adapt as information is transmitted across the network. We present experiments demonstrating that this approach can result in significant computational savings.},
  file = {/Users/brownsarahm/Zotero/storage/W64TA959/Saria, Nodelman, Koller - 2007 - Reasoning at the right time granularity(3).pdf}
}

@article{saria2010discovering,
  title = {Discovering Shared and Individual Latent Structure in Multiple Time Series},
  author = {Saria, Suchi and Koller, Daphne and Penn, Anna},
  year = {2010},
  journal = {Proc. Neural Information Processing Systems (NIPS), {\textbackslash}ldots},
  volume = {stat.ML},
  number = {d},
  pages = {1--9},
  abstract = {This paper proposes a nonparametric Bayesian method for exploratory data analysis and feature construction in continuous time series. Our method focuses on understanding shared features in a set of time series that exhibit significant individual variability. Our method builds on the framework of latent Diricihlet allocation (LDA) and its extension to hierarchical Dirichlet processes, which allows us to characterize each series as switching between latent ``topics'', where each topic is characterized as a distribution over ``words'' that specify the series dynamics. However, unlike standard applications of LDA, we discover the words as we learn the model. We apply this model to the task of tracking the physiological signals of premature infants; our model obtains clinically significant insights as well as useful features for supervised learning tasks.},
  file = {/Users/brownsarahm/Zotero/storage/9XPP3W2V/Saria, Koller, Penn - 2010 - Discovering shared and individual latent structure in multiple time series(3).pdf;/Users/brownsarahm/Zotero/storage/QWB992FJ/Saria, Koller, Penn - 2010 - Learning individual and population level traits from clinical temporal data(2).pdf}
}

@article{saria2011discovering,
  title = {Discovering Deformable Motifs in Continuous Time Series Data},
  author = {Saria, Suchi and Duchi, Andrew and Koller, Daphne and Duchi, Andrew and Saria, Suchi},
  year = {2011},
  journal = {IJCAI Proceedings-International Joint {\textbackslash}ldots},
  volume = {22},
  number = {1},
  pages = {1465},
  file = {/Users/brownsarahm/Zotero/storage/V28J7SVY/Saria, Duchi, Koller - 2011 - Discovering deformable motifs in continuous time series data(2).pdf}
}

@article{saria2015subtyping,
  title = {Subtyping: {{What It}} Is and {{Its Role}} in {{Precision Medicine}}},
  author = {Saria, Suchi and Goldenberg, Anna},
  year = {2015},
  journal = {IEEE Intelligent Systems},
  volume = {30},
  number = {4},
  pages = {70--75},
  issn = {1541-1672},
  doi = {10.1109/MIS.2015.60},
  file = {/Users/brownsarahm/Zotero/storage/SY8TF3BW/Saria, Goldenberg - 2015 - Subtyping What It is and Its Role in Precision Medicine(3).pdf}
}

@article{sarialearning,
  title = {Learning Individual and Population Level Traits from Clinical Temporal Data},
  author = {Saria, Suchi and Koller, Daphne and Penn, Anna},
  journal = {Word Journal Of The International Linguistic Association},
  number = {d},
  pages = {1--9},
  file = {/Users/brownsarahm/Zotero/storage/KTZW5ME2/Saria, Koller, Penn - 2010 - Discovering shared and individual latent structure in multiple time series(3).pdf}
}

@inproceedings{sarma2020prior,
  title = {Prior {{Setting In Practice}}: {{Strategies}} and Rationales Used in Choosing Prior Distributions for {{Bayesian}} Analysis},
  booktitle = {Proceedings of the 2020 {{CHI}} Conference on Human Factors in Computing Systems},
  author = {Sarma, Abhraneel and Kay, Matthew},
  year = {2020},
  pages = {1--12}
}

@article{sartori_sociotechnical_2022,
  title = {A Sociotechnical Perspective for the Future of {{AI}}: Narratives, Inequalities, and Human Control},
  shorttitle = {A Sociotechnical Perspective for the Future of {{AI}}},
  author = {Sartori, Laura and Theodorou, Andreas},
  year = {2022},
  month = mar,
  journal = {Ethics and Information Technology},
  volume = {24},
  number = {1},
  pages = {4},
  issn = {1388-1957, 1572-8439},
  doi = {10.1007/s10676-022-09624-3},
  urldate = {2024-09-28},
  abstract = {Different people have different perceptions about artificial intelligence (AI). It is extremely important to bring together all the alternative frames of thinking---from the various communities of developers, researchers, business leaders, policymakers, and citizens---to properly start acknowledging AI. This article highlights the `fruitful collaboration' that sociology and AI could develop in both social and technical terms. We discuss how biases and unfairness are among the major challenges to be addressed in such a sociotechnical perspective. First, as intelligent machines reveal their nature of `magnifying glasses' in the automation of existing inequalities, we show how the AI technical community is calling for transparency and explainability, accountability and contestability. Not to be considered as panaceas, they all contribute to ensuring human control in novel practices that include requirement, design and development methodologies for a fairer AI. Second, we elaborate on the mounting attention for technological narratives as technology is recognized as a social practice within a specific institutional context. Not only do narratives reflect organizing visions for society, but they also are a tangible sign of the traditional lines of social, economic, and political inequalities. We conclude with a call for a diverse approach within the AI community and a richer knowledge about narratives as they help in better addressing future technical developments, public debate, and policy. AI practice is interdisciplinary by nature and it will benefit from a socio-technical perspective.},
  langid = {english}
}

@article{sawicki1996democratization,
  title = {The Democratization of Data: {{Bridging}} the Gap for Community Groups},
  author = {Sawicki, David S. and Craig, William J.},
  year = {1996},
  journal = {Journal of the American Planning Association},
  volume = {62},
  number = {4},
  pages = {512--523},
  issn = {01944363},
  doi = {10.1080/01944369608975715},
  abstract = {Community groups from low-income neighborhoods have the most to gain from full access to data, yet the least capability to achieve that accessor make use of the data once they have it. The gap is being filed by intermediaries providing access to data and assistance with analysis and policy development. These efforts are empowering community groups, allowing them to participate fully in planning and policy discussions that affect their neighborhoods. This paper explores the nature of the information providers, the services they provide to community organizations, and the challenges they face in doing so. Combining their experiences with our view of the coming technical and societal issues allows us to forecast what the future might look like. We conclude that community groups will become more self-sufficient, but will continue to need outside expertise. Since not all community groups now have access to such intermediaries, more research and development should be undertaken to support the movement.}
}

@article{sayers1974mechanism,
  title = {The Mechanism of Auditory Evoked {{EEG}} Responses.},
  author = {Sayers, B McA and Beagley, H A and Henshall, W R},
  year = {1974},
  journal = {Nature}
}

@article{scheeringa2011modulation,
  title = {Modulation of Visually Evoked Cortical {{fMRI}} Responses by Phase of Ongoing Occipital Alpha Oscillations},
  author = {Scheeringa, Ren{\'e} and Mazaheri, Ali and Bojak, Ingo and Norris, David G and Kleinschmidt, Andreas},
  year = {2011},
  journal = {The Journal of Neuroscience},
  volume = {31},
  number = {10},
  pages = {3813--3820}
}

@article{schelter2017automatically,
  title = {Automatically {{Tracking Metadata}} and {{Provenance}} of {{Machine Learning Experiments}}},
  author = {Schelter, Sebastian and B{\"o}se, Joos-Hendrik and Kirschnick, Johannes and Klein, Thoralf and Seufert, Stephan},
  year = {2017},
  journal = {Machine Learning Systems Workshop at NIPS},
  abstract = {We present a lightweight system to extract, store and manage metadata and prove-nance information of common artifacts in machine learning (ML) experiments: datasets, models, predictions, evaluations and training runs. Our system accelerates users in their ML workflow, and provides a basis for comparability and repeata-bility of ML experiments. We achieve this by tracking the lineage of produced artifacts and automatically extracting metadata such as hyperparameters of models, schemas of datasets or layouts of deep neural networks. Our system provides a general declarative representation of said ML artifacts, is integrated with popular frameworks such as MXNet, SparkML and scikit-learn, and meets the demands of various production use cases at Amazon.}
}

@article{scheuerman2021Datasets,
  title = {Do {{Datasets Have Politics}}? {{Disciplinary Values}} in {{Computer Vision Dataset Development}}},
  shorttitle = {Do {{Datasets Have Politics}}?},
  author = {Scheuerman, Morgan Klaus and Hanna, Alex and Denton, Emily},
  year = {2021},
  month = oct,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {5},
  number = {CSCW2},
  pages = {1--37},
  issn = {2573-0142},
  doi = {10.1145/3476058},
  urldate = {2024-04-19},
  abstract = {Data is a crucial component of machine learning. The field is reliant on data to train, validate, and test models. With increased technical capabilities, machine learning research has boomed in both academic and industry settings, and one major focus has been on computer vision. Computer vision is a popular domain of machine learning increasingly pertinent to real-world applications, from facial recognition in policing to object detection for autonomous vehicles. Given computer vision's propensity to shape machine learning research and impact human life, we seek to understand disciplinary practices around dataset documentation - how data is collected, curated, annotated, and packaged into datasets for computer vision researchers and practitioners to use for model tuning and development. Specifically, we examine what dataset documentation communicates about the underlying values of vision data and the larger practices and goals of computer vision as a field. To conduct this study, we collected a corpus of about 500 computer vision datasets, from which we sampled 114 dataset publications across different vision tasks. Through both a structured and thematic content analysis, we document a number of values around accepted data practices, what makes desirable data, and the treatment of humans in the dataset construction process. We discuss how computer vision datasets authors value efficiency at the expense of care; universality at the expense of contextuality; impartiality at the expense of positionality; and model work at the expense of data work. Many of the silenced values we identify sit in opposition with social computing practices. We conclude with suggestions on how to better incorporate silenced values into the dataset creation and curation process.},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/QNVENDQE/Scheuerman et al. - 2021 - Do Datasets Have Politics Disciplinary Values in .pdf}
}

@inproceedings{schmidt2008datamining,
  title = {Data-Mining Dynamical Systems: Automated Symbolic System Identification for Exploratory Analysis},
  booktitle = {9th {{Biennial ASME Conference}} on {{Egnineering Systems Design}} and {{Analysis}}},
  author = {Schmidt, {\relax MD} and Lipson, H},
  year = {2008},
  pages = {1--7},
  file = {/Users/brownsarahm/Zotero/storage/D3FDSRWF/Schmidt, Lipson - 2008 - Data-mining dynamical systems automated symbolic system identification for exploratory analysis(3).pdf}
}

@article{schmidt2009distilling,
  title = {Distilling Free-Form Natural Laws from Experimental Data.},
  author = {Schmidt, Michael and Lipson, Hod},
  year = {2009},
  month = apr,
  journal = {Science (New York, N.Y.)},
  volume = {324},
  number = {5923},
  eprint = {19342586},
  eprinttype = {pubmed},
  pages = {81--5},
  issn = {1095-9203},
  doi = {10.1126/science.1165893},
  abstract = {For centuries, scientists have attempted to identify and document analytical laws that underlie physical phenomena in nature. Despite the prevalence of computing power, the process of finding natural laws and their corresponding equations has resisted automation. A key challenge to finding analytic relations automatically is defining algorithmically what makes a correlation in observed data important and insightful. We propose a principle for the identification of nontriviality. We demonstrated this approach by automatically searching motion-tracking data captured from various physical systems, ranging from simple harmonic oscillators to chaotic double-pendula. Without any prior knowledge about physics, kinematics, or geometry, the algorithm discovered Hamiltonians, Lagrangians, and other laws of geometric and momentum conservation. The discovery rate accelerated as laws found for simpler systems were used to bootstrap explanations for more complex systems, gradually uncovering the "alphabet" used to describe those systems.},
  pmid = {19342586},
  keywords = {Algorithms,Artificial Intelligence,Mathematical Concepts,Nonlinear Dynamics,Physical Processes,Regression Analysis,Software},
  file = {/Users/brownsarahm/Zotero/storage/EVZATDCC/Schmidt, Lipson - 2009 - Distilling free-form natural laws from experimental data(3).pdf}
}

@inproceedings{schmidt2009optimizing,
  title = {Optimizing Costly Functions with Simple Constraints: {{A}} Limited-Memory Projected Quasi-Newton Algorithm},
  booktitle = {Proc. of {{Conf}}. {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Schmidt, Mark and Van Den Berg, Ewout and Friedlander, Michael and Murphy, Kevin},
  year = {2009},
  volume = {5},
  pages = {456--463},
  file = {/Users/brownsarahm/Zotero/storage/ANQN4FV5/Schmidt et al. - 2009 - Optimizing costly functions with simple constraints A limited-memory projected quasi-newton algorithm(3).pdf}
}

@article{schmidt2011optimization,
  title = {Optimization Algorithms for L\_1 Regularization},
  author = {Schmidt, Mark and Fung, Glenn and Rosales, Romer and Carbonetto, Peter},
  year = {2011},
  journal = {IEEE transactions on Pattern Analysis and Machine Intelligence},
  volume = {99},
  number = {1},
  pages = {1--18}
}

@article{schmidt2011projected,
  title = {1 {{Projected Newton-type Methods}} in {{Machine Learning}}},
  author = {Schmidt, Mark and Kim, Dongmin and Sra, S},
  year = {2011},
  journal = {Optimization for Machine Learning},
  file = {/Users/brownsarahm/Zotero/storage/34NWK3JX/Schmidt, Kim, Sra - 2011 - 1 Projected Newton-type Methods in Machine Learning(3).pdf}
}

@article{schneiter2013applet,
  title = {An Applet for the Investigation of {{Simpson}}'s Paradox},
  author = {Schneiter, K and Symanzik, J},
  year = {2013},
  journal = {Journal of Statistics Education},
  volume = {21},
  number = {1},
  pages = {1--20},
  issn = {10691898},
  abstract = {... O'Connell, JW (1975), `` Sex Bias in Graduate Admissions: Data from Berkeley .'' Science, 187 ... Moore, TL (2006), `` Paradoxes in Film Ratings.'' Journal of Statistics Education, 14(1). http ... Morrell, CH (1999), `` Simpson's Paradox : An Example from a Longitudinal Study in South Africa ... \${\textbackslash}backslash\$n},
  keywords = {baker-kramer plot,graphics,s paradox,simpson},
  file = {/Users/brownsarahm/Zotero/storage/RG8IDKHV/Schneiter, Symanzik - 2013 - An applet for the investigation of Simpson's paradox.pdf}
}

@inproceedings{schulam2015framework,
  title = {A {{Framework}} for {{Individualizing Predictions}} of {{Disease Trajectories}} by {{Exploiting Multi-Resolution Structure}}: {{Supplement}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} ({{NIPS}})},
  author = {Schulam, Peter and Saria, Suchi},
  year = {2015},
  pages = {748--756},
  abstract = {For many complex diseases, there is a wide variety of ways in which an individual can manifest the disease. The challenge of personalized medicine is to develop tools that can accurately predict the trajectory of an individual's disease, which can in turn enable clinicians to optimize treatments. We represent an individual's disease trajectory as a continuous-valued continuous-time function describing the severity of the disease over time. We propose a hierarchical latent variable model that individualizes predictions of disease trajectories. This model shares statistical strength across observations at different resolutions--the population, subpopulation and the individual level. We describe an algorithm for learning population and subpopulation parameters offline, and an online procedure for dynamically learning individual-specific parameters. Finally, we validate our model on the task of predicting the course of interstitial lung disease, a leading cause of death among patients with the autoimmune disease scleroderma. We compare our approach against state-of-the-art and demonstrate significant improvements in predictive accuracy.},
  file = {/Users/brownsarahm/Zotero/storage/65MUGTDA/Schulam, Saria - 2015 - A Framework for Individualizing Predictions of Disease Trajectories by Exploiting Multi-Resolution Structure (3).pdf}
}

@article{schuster1979contributions,
  title = {Contributions to the {{Theory}} of {{Nonparametric Regression}}, with {{Application}} to {{System Identification}}},
  author = {Schuster, B Y E and Schuster, E and Yakowitz, S},
  year = {1979},
  journal = {The Annals of Statistics},
  volume = {7},
  number = {1},
  eprint = {2958838},
  eprinttype = {jstor},
  pages = {pp. 139--149},
  issn = {00905364},
  abstract = {The objective in nonparametric regression is to infer a function m(x) on the basis of a finite collection of noisy pairs \{(Xi, m(Xi) + Ni)\}n i=1, where the noise components Ni satisfy certain lenient assumptions and the domain points Xi are selected at random. It is known a priori only that m is a member of a nonparametric class of functions (that is, a class of functions like C[ 0, 1] which, under customary topologies, does not admit a homeomorphic indexing by a subset of a Euclidean space). The main theoretical contribution of this study is to derive uniform convergence bounds and uniform consistency on bounded intervals for the Nadaraya-Watson kernel estimator and its derivatives. Also, we obtain the corresponding convergence results for the Priestly-Chao estimator in the case that the domain points are nonrandom. With these developments we are able to apply nonparametric regression methodology to the problem of identifying noisy time-varying linear systems.},
  file = {/Users/brownsarahm/Zotero/storage/4MHDI6EV/Schuster - 2014 - CONTRIBUTIONS TO THE THEORY OF NONPARAMETRIC(2).pdf}
}

@article{schuster2014contributions,
  title = {{{CONTRIBUTIONS TO THE THEORY OF NONPARAMETRIC}}},
  author = {Schuster, B Y E},
  year = {2014},
  volume = {7},
  number = {1},
  pages = {139--149},
  file = {/Users/brownsarahm/Zotero/storage/QNEESHCE/Schuster - 2014 - CONTRIBUTIONS TO THE THEORY OF NONPARAMETRIC(2).pdf}
}

@article{schwartzmapping,
  title = {Mapping Cognitive Ontologies to and from the Brain},
  author = {Schwartz, Yannick and Thirion, Bertrand and Varoquaux, Gael},
  pages = {1--9},
  file = {/Users/brownsarahm/Zotero/storage/JGK9Y7KV/Schwartz, Thirion, Varoquaux - Unknown - Mapping cognitive ontologies to and from the brain(3).pdf}
}

@article{schwerdtfeger2006verbalautonomic,
  title = {Verbal-Autonomic Response Dissociations as Traits?},
  author = {Schwerdtfeger, Andreas and Schmukle, Stefan C and Egloff, Boris},
  year = {2006},
  month = may,
  journal = {Biological psychology},
  volume = {72},
  number = {2},
  eprint = {16359769},
  eprinttype = {pubmed},
  pages = {213--21},
  issn = {0301-0511},
  doi = {10.1016/j.biopsycho.2005.11.003},
  abstract = {Dissociations between subjective and physiological responses to stress are of central interest in coping research. However, little is known about their stability across situations and time. Two experimental sessions - separated by 1 year - were conducted to examine cross-situational consistency and longterm-stability of HR-derived and SCL-derived dissociation scores. In year 1, a speech stressor, the cold pressor and a video stressor (viewing of the speech video) were applied. In year 2, mental arithmetics, anagrams and a torture video were presented. Thirty-five students participated and HR, SCL and negative affect were recorded. For each stressor, standardized changes in negative affect were subtracted from changes in autonomic reactivity (HR and SCL, respectively). Dissociation scores were relatively consistent across the stressors with HR-derived scores exceeding SCL-derived scores. Longterm-stability proved acceptable (r=.61, P{\textbackslash}textless.001 for HR-derived and r=.40, P{\textbackslash}textless.05 for SCL-derived scores). In sum, verbal-autonomic response dissociations show considerable cross-situational and temporal stability and thus might be considered as traits.},
  pmid = {16359769},
  keywords = {Adaptation,Adult,Affect,Female,Galvanic Skin Response,Galvanic Skin Response: physiology,Heart Rate,Heart Rate: physiology,Humans,Male,Psychological,Psychology,Questionnaires,Repression,Social Desirability,Verbal Behavior,Videotape Recording},
  file = {/Users/brownsarahm/Zotero/storage/8R3DRYXI/Schwerdtfeger, Schmukle, Egloff - 2006 - Verbal-autonomic response dissociations as traits(3).pdf}
}

@article{scientificscientific,
  title = {Scientific {{Models Mechanical Models Analogy Theories Paradigms}} and {{Metaphors}} the {{Semantic View}} and the {{Study}} of {{Scientific Practice Phenomena}} , {{Data}} , and {{Data Models Representation}}},
  author = {Scientific, Take and To, Models},
  pages = {1--20},
  file = {/Users/brownsarahm/Zotero/storage/G4MFVA52/Scientific, To - Unknown - Scientific Models Mechanical Models Analogy Theories Paradigms and Metaphors the Semantic View and the Study.pdf}
}

@article{sculley2010combined,
  title = {Combined Regression and Ranking},
  author = {Sculley, D.},
  year = {2010},
  journal = {Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '10},
  pages = {979},
  doi = {10.1145/1835804.1835928},
  keywords = {large-scale data,ranking,regression},
  file = {/Users/brownsarahm/Zotero/storage/XE8PBMAW/Sculley - 2010 - Combined regression and ranking(3).pdf}
}

@article{searle1998how,
  title = {How to Study Consciousness Scientifically.},
  author = {Searle, J R},
  year = {1998},
  month = nov,
  journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
  volume = {353},
  number = {1377},
  pages = {1935--42},
  issn = {0962-8436},
  doi = {10.1098/rstb.1998.0346},
  abstract = {The neurosciences have advanced to the point that we can now treat consciousness as a scientific problem like any other. The problem is to explain how brain processes cause consciousness and how consciousness is realized in the brain. Progress is impeded by a number of philosophical mistakes, and the aim of this paper is to remove nine of those mistakes: (i) consciousness cannot be defined; (ii) consciousness is subjective but science is objective; (iii) brain processes cannot explain consciousness; (iv) the problem of 'qualia' should be set aside; (v) consciousness is epiphenomenal; (vi) consciousness has no evolutionary function; (vii) a causal account of consciousness is necessarily dualistic; (viii) science is reductionistic, so a scientific account of consciousness would show it reducible to something else; and (ix) an account of consciousness must be an information processing account.},
  pmid = {9854266},
  keywords = {Biological Evolution,Brain,Brain: physiology,Consciousness,Consciousness: physiology,Humans,Models,Neurological,Neurosciences,Philosophy},
  file = {/Users/brownsarahm/Zotero/storage/5JSSAWH4/Searle - 1998 - How to study consciousness scientifically(3).pdf}
}

@article{seeley2007dissociable,
  title = {Dissociable Intrinsic Connectivity Networks for Salience Processing and Executive Control},
  author = {Seeley, William W and Menon, Vinod and Schatzberg, Alan F and Keller, Jennifer and Glover, Gary H and Kenna, Heather and Reiss, Allan L and Greicius, Michael D},
  year = {2007},
  journal = {The Journal of neuroscience},
  volume = {27},
  number = {9},
  pages = {2349--2356}
}

@article{selbst2018intuitive,
  title = {The {{Intuitive Appeal}} of {{Explainable Machines}}},
  author = {Selbst, Andrew D. and Barocas, Solon},
  year = {2018},
  number = {April 2017},
  keywords = {algorithmic accountability,big data,discirmination,explanations,law and technology,machine learning,privacy},
  file = {/Users/brownsarahm/Zotero/storage/96GSFWLV/Selbst, Barocas - 2018 - The Intuitive Appeal of Explainable Machines.pdf}
}

@inproceedings{selbst2019fairness,
  title = {Fairness and Abstraction in Sociotechnical Systems},
  booktitle = {Proceedings of the {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Selbst, Andrew D and Boyd, Danah and Friedler, Sorelle A and Venkatasubramanian, Suresh and Vertesi, Janet},
  year = {2019},
  pages = {59--68},
  publisher = {ACM},
  address = {New York, NY, USA}
}

@article{sell1971completion,
  title = {Completion of a {{Metric Space}}},
  author = {Sell, George R.},
  year = {1971},
  journal = {Mathematics Magazine},
  volume = {44},
  eprint = {10.2307/2689068},
  eprinttype = {jstor},
  pages = {182},
  issn = {0025570X},
  doi = {10.2307/2689068},
  file = {/Users/brownsarahm/Zotero/storage/TZL8MJ4Y/Sell - 1971 - Completion of a Metric Space(3).pdf}
}

@article{selvitella2017ubiquity,
  title = {The Ubiquity of the {{Simpson}}'s {{Paradox}}},
  author = {Selvitella, Alessandro},
  year = {2017},
  journal = {Journal of Statistical Distributions and Applications},
  volume = {4},
  number = {1},
  pages = {2},
  issn = {2195-5832},
  doi = {10.1186/s40488-017-0056-5},
  abstract = {The Simpson's Paradox is the phenomenon that appears in some datasets, where subgroups with a common trend (say, all negative trend) show the reverse trend when they are aggregated (say, positive trend). Even if this issue has an elementary mathematical explanation, it has a deep statistical significance. In this paper, we discuss basic examples in arithmetic, geometry, linear algebra, statistics, game theory, gender bias in university admission and election polls, where we describe the appearance or absence of the Simpson's Paradox. In the final part, we present our results concerning the occurrence of the Simpson's Paradox in Quantum Mechanics with focus on the Quantum Harmonic Oscillator and the Nonlinear Schr{\"o}dinger Equation. We discuss how likely it is to incur in the Simpson's Paradox and give some concrete numerical examples. We conclude with some final comments and possible future directions.},
  keywords = {quantum mechanics,Quantum mechanics,s paradox,Schr{\"o}dinger Eq,schr{\"o}dinger equation,simpson,Simpson's Paradox}
}

@article{seo2005rankbyfeature,
  title = {A Rank-by-Feature Framework for Interactive Exploration of Multidimensional Data},
  author = {Seo, Jinwook and Shneiderman, Ben},
  year = {2005},
  journal = {Information visualization},
  volume = {4},
  number = {2},
  pages = {96--113}
}

@article{sepulcre2010organization,
  title = {The Organization of Local and Distant Functional Connectivity in the Human Brain},
  author = {Sepulcre, Jorge and Liu, Hesheng and Talukdar, Tanveer and Martincorena, I{\~n}igo and Yeo, B T Thomas and Buckner, Randy L},
  year = {2010}
}

@article{sepulcre2012stepwise,
  title = {Stepwise Connectivity of the Modal Cortex Reveals the Multimodal Organization of the Human Brain},
  author = {Sepulcre, Jorge and Sabuncu, Mert R and Yeo, Thomas B and Liu, Hesheng and Johnson, Keith A},
  year = {2012},
  journal = {The Journal of Neuroscience},
  volume = {32},
  number = {31},
  pages = {10649--10661}
}

@article{shalev-shwartz2010learnability,
  title = {Learnability, Stability and Uniform Convergence},
  author = {{Shalev-Shwartz}, Shai and Shamir, O},
  year = {2010},
  journal = {The Journal of Machine Learning Research},
  volume = {11},
  pages = {2635--2670},
  keywords = {learnability,stability,statistical learning theory,stochastic convex opti-,uniform convergence},
  file = {/Users/brownsarahm/Zotero/storage/8ABNY2UR/Shalev-shwartz - 2010 - Learnability , Stability and Uniform Convergence(2).pdf}
}

@inproceedings{shanab2012impact,
  title = {Impact of Noise and Data Sampling on Stability of Feature Ranking Techniques for Biological Datasets},
  booktitle = {Information {{Reuse}} and {{Integration}} ({{IRI}}), 2012 {{IEEE}} 13th {{International Conference}} On},
  author = {Shanab, Ahmad Abu and Khoshgoftaar, Taghi M and Wald, Randall and Napolitano, Amri},
  year = {2012},
  pages = {415--422},
  publisher = {IEEE},
  file = {/Users/brownsarahm/Zotero/storage/G2DBJQ9Q/Shanab et al. - 2012 - Impact of noise and data sampling on stability of feature ranking techniques for biological datasets(3).pdf}
}

@article{shannon1948mathematical,
  title = {A Mathematical Theory of Communication},
  author = {Shannon, {\relax CE}},
  year = {1948},
  journal = {The Bell System Technical Journal},
  volume = {27},
  number = {July, October 1948},
  pages = {379--423, 623--656},
  file = {/Users/brownsarahm/Zotero/storage/HYYLW7H5/Shannon - 1948 - A mathematical theory of communication(3).pdf}
}

@article{sheehan2018crowdsourcing,
  title = {Crowdsourcing Research: Data Collection with Amazon's Mechanical Turk},
  author = {Sheehan, Kim Bartel},
  year = {2018},
  journal = {Communication Monographs},
  volume = {85},
  number = {1},
  pages = {140--156},
  publisher = {Taylor \& Francis}
}

@article{shklovski2022addressing,
  title = {Addressing Ethical Gaps in `{{Technology}} for {{Good}}': {{Foregrounding}} Care and Capabilities},
  author = {Shklovski, Irina and Lehued{\'e}, Sebasti{\'a}n and {Ustek-Spilda}, Funda and Powell, Alison B},
  year = {2022}
}

@inproceedings{shneiderman1996eyes,
  title = {The {{Eyes Have It}}: {{A Task}} by {{Data Type Taxonomy}} for {{Information Visualizations}}},
  booktitle = {Proceedings of the {{IEEE Symposium}} on {{Visual Languages}}},
  author = {Shneiderman, Ben},
  year = {1996},
  month = sep,
  pages = {336--343},
  publisher = {IEEE},
  address = {Boulder, CO}
}

@article{shollerTenSimpleRules2019,
  title = {Ten Simple Rules for Helping Newcomers Become Contributors to Open Projects},
  author = {Sholler, Dan and Steinmacher, Igor and Ford, Denae and Averick, Mara and Hoye, Mike and Wilson, Greg},
  year = {2019},
  journal = {PLoS Computational Biology},
  volume = {15},
  number = {9},
  pages = {e1007296},
  publisher = {Public Library of Science San Francisco, CA USA}
}

@book{sidanius2001social,
  title = {Social Dominance: {{An}} Intergroup Theory of Social Hierarchy and Oppression},
  author = {Sidanius, Jim and Pratto, Felicia},
  year = {2001},
  publisher = {Cambridge University Press}
}

@article{silva2011need,
  title = {The Need for the Emergence of Mathematical Neuroscience: Beyond Computation and Simulation.},
  author = {{\noopsort{silva}}a Silva, Gabriel},
  year = {2011},
  month = jan,
  journal = {Frontiers in computational neuroscience},
  volume = {5},
  number = {November},
  pages = {51},
  issn = {1662-5188},
  doi = {10.3389/fncom.2011.00051},
  pmid = {22131972},
  file = {/Users/brownsarahm/Zotero/storage/EYXLLFZ4/Silva - 2011 - The need for the emergence of mathematical neuroscience beyond computation and simulation(3).pdf}
}

@article{simmons2013categoryspecific,
  title = {Category-Specific Integration of Homeostatic Signals in Caudal but Not Rostral Human Insula.},
  author = {Simmons, W Kyle and Rapuano, Kristina M and Kallman, Seth J and Ingeholm, John E and Miller, Bernard and Gotts, Stephen J and {\noopsort{avery}}a Avery, Jason and Hall, Kevin D and Martin, Alex},
  year = {2013},
  month = nov,
  journal = {Nature neuroscience},
  volume = {16},
  number = {11},
  pages = {1551--2},
  issn = {1546-1726},
  doi = {10.1038/nn.3535},
  abstract = {Prevailing theories hold that the insula is functionally organized along its caudal-to-rostral axis, with posterior regions coding lower-level sensory information and anterior regions coding higher-level stimulus significance relative to the body's homeostatic needs. Contrary to predictions of this model, the response of the taste-sensitive region of the caudal, but not rostral, insula to food images was directly related to the body's homeostatic state as indexed by levels of peripheral glucose.},
  pmid = {24077565},
  keywords = {Adult,Afferent Pathways,Afferent Pathways: blood supply,Afferent Pathways: physiology,Blood Glucose,Blood Glucose: physiology,Brain Mapping,Cerebral Cortex,Cerebral Cortex: blood supply,Cerebral Cortex: physiology,Computer-Assisted,Female,Homeostasis,Homeostasis: physiology,Humans,Image Processing,Magnetic Resonance Imaging,Male,Oxygen,Photic Stimulation,Taste,Taste: physiology,Young Adult},
  file = {/Users/brownsarahm/Zotero/storage/HZAECD78/Simmons et al. - 2013 - Category-specific integration of homeostatic signals in caudal but not rostral human insula(3).pdf}
}

@inproceedings{sklearn_api,
  title = {{{API}} Design for Machine Learning Software: Experiences from the Scikit-Learn Project},
  booktitle = {{{ECML PKDD}} Workshop: {{Languages}} for Data Mining and Machine Learning},
  author = {Buitinck, Lars and Louppe, Gilles and Blondel, Mathieu and Pedregosa, Fabian and Mueller, Andreas and Grisel, Olivier and Niculae, Vlad and Prettenhofer, Peter and Gramfort, Alexandre and Grobler, Jaques and Layton, Robert and VanderPlas, Jake and Joly, Arnaud and Holt, Brian and Varoquaux, Ga{\"e}l},
  year = {2013},
  pages = {108--122}
}

@article{sladky2011slicetiming,
  title = {Slice-Timing Effects and Their Correction in Functional {{MRI}}},
  author = {Sladky, Ronald and Friston, Karl J. and Tr??stl, Jasmin and Cunnington, Ross and Moser, Ewald and Windischberger, Christian},
  year = {2011},
  journal = {NeuroImage},
  volume = {58},
  number = {2},
  pages = {588--594},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2011.06.078},
  abstract = {Exact timing is essential for functional MRI data analysis. Datasets are commonly measured using repeated 2D imaging methods, resulting in a temporal offset between slices. To compensate for this timing difference, slice-timing correction (i.e. temporal data interpolation) has been used as an fMRI pre-processing step for more than fifteen years. However, there has been an ongoing debate about the effectiveness and applicability of this method. This paper presents the first elaborated analysis of the impact of the slice-timing effect on simulated data for different fMRI paradigms and measurement parameters, taking into account data noise and smoothing effects. Here we show, depending on repetition time and paradigm design, slice-timing effects can significantly impair fMRI results and slice-timing correction methods can successfully compensate for these effects and therefore increase the robustness of the data analysis. In addition, our results from simulated data were supported by empirical in vivo datasets. Our findings suggest that slice-timing correction should be included in the fMRI pre-processing pipeline. ?? 2011 Elsevier Inc.},
  pmid = {21757015},
  keywords = {Analysis,Functional MRI,Pre-processing,Slice-timing correction},
  file = {/Users/brownsarahm/Zotero/storage/WLGQF9Z2/Sladky et al. - 2011 - Slice-timing effects and their correction in functional MRI(3).pdf}
}

@article{slovic2000violence,
  title = {Violence Risk Assessment and Risk Communication: {{The}} Effects of Using Actual Cases, Providing Instruction, and Employing Probability versus Frequency Formats},
  author = {Slovic, Paul and Monahan, John and MacGregor, Donald G},
  year = {2000},
  journal = {Law and human behavior},
  volume = {24},
  number = {3},
  pages = {271--296},
  publisher = {Springer}
}

@article{smith1997susan,
  title = {{{SUSAN}}---a New Approach to Low Level Image Processing},
  author = {Smith, Stephen M and Brady, J Michael},
  year = {1997},
  journal = {International journal of computer vision},
  volume = {23},
  number = {1},
  pages = {45--78}
}

@article{smith2002fast,
  title = {Fast Robust Automated Brain Extraction},
  author = {Smith, Stephen M},
  year = {2002},
  journal = {Human brain mapping},
  volume = {17},
  number = {3},
  pages = {143--155}
}

@article{smith2012temporallyindependent,
  title = {Temporally-Independent Functional Modes of Spontaneous Brain Activity},
  author = {Smith, S. M. and Miller, K. L. and Moeller, S. and Xu, J. and Auerbach, E. J. and Woolrich, M. W. and Beckmann, C. F. and Jenkinson, M. and Andersson, J. and Glasser, M. F. and Van Essen, D. C. and {\noopsort{feinberg}}a. Feinberg, D. and Yacoub, E. S. and Ugurbil, K.},
  year = {2012},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {109},
  pages = {3131--3136},
  issn = {0027-8424},
  doi = {10.1073/pnas.1121329109},
  abstract = {Resting-state functional magnetic resonance imaging has become a powerful tool for the study of functional networks in the brain. Even "at rest," the brain's different functional networks spontaneously fluctuate in their activity level; each network's spatial extent can therefore be mapped by finding temporal correlations between its different subregions. Current correlation-based approaches measure the average functional connectivity between regions, but this average is less meaningful for regions that are part of multiple networks; one ideally wants a network model that explicitly allows overlap, for example, allowing a region's activity pattern to reflect one network's activity some of the time, and another network's activity at other times. However, even those approaches that do allow overlap have often maximized mutual spatial independence, which may be suboptimal if distinct networks have significant overlap. In this work, we identify functionally distinct networks by virtue of their temporal independence, taking advantage of the additional temporal richness available via improvements in functional magnetic resonance imaging sampling rate. We identify multiple "temporal functional modes," including several that subdivide the default-mode network (and the regions anticorrelated with it) into several functionally distinct, spatially overlapping, networks, each with its own pattern of correlations and anticorrelations. These functionally distinct modes of spontaneous brain activity are, in general, quite different from resting-state networks previously reported, and may have greater biological interpretability.},
  pmid = {22323591},
  file = {/Users/brownsarahm/Zotero/storage/LTU94EUD/Smith et al. - 2012 - Temporally-independent functional modes of spontaneous brain activity(3).pdf}
}

@article{smith2015ad,
  title = {{{AD}} 3 : {{Alternating Directions Dual Decomposition}} for {{MAP Inference}} in {{Graphical Models}} {$\ast$}},
  author = {Smith, Noah A and Xing, Eric P},
  year = {2015},
  volume = {16},
  pages = {495--545},
  file = {/Users/brownsarahm/Zotero/storage/UUV9P2Y6/Smith, Xing - 2015 - AD 3 Alternating Directions Dual Decomposition for MAP Inference in Graphical Models ∗(3).pdf}
}

@article{snoek2012practical,
  title = {Practical {{Bayesian Optimization}} of {{Machine Learning Algorithms}}},
  author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P. Rp},
  year = {2012},
  journal = {arXiv preprint arXiv:1206.2944},
  eprint = {1206.2944},
  pages = {1--12},
  abstract = {Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a "black art" that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.},
  archiveprefix = {arXiv},
  file = {/Users/brownsarahm/Zotero/storage/W2E3MMT5/Snoek, Larochelle, Adams - 2012 - Practical Bayesian Optimization of Machine Learning Algorithms(3).pdf}
}

@article{sokol2019fat,
  title = {{{FAT}} Forensics: {{A}} Python Toolbox for Algorithmic Fairness, Accountability and Transparency},
  author = {Sokol, Kacper and {Santos-Rodriguez}, Raul and Flach, Peter},
  year = {2019},
  journal = {arXiv preprint arXiv:1909.05167},
  eprint = {1909.05167},
  archiveprefix = {arXiv}
}

@article{somerville2004human,
  title = {Human Amygdala Responses during Presentation of Happy and Neutral Faces: Correlations with State Anxiety.},
  author = {Somerville, Leah H and Kim, Hackjin and Johnstone, Tom and Alexander, Andrew L and Whalen, Paul J},
  year = {2004},
  month = may,
  journal = {Biological psychiatry},
  volume = {55},
  number = {9},
  eprint = {15110733},
  eprinttype = {pubmed},
  pages = {897--903},
  issn = {1873-2402},
  doi = {10.1016/j.biopsych.2004.01.007},
  abstract = {Previous functional imaging studies demonstrating amygdala response to happy facial expressions have all included the presentation of negatively valenced primary comparison expressions within the experimental context. This study assessed amygdala response to happy and neutral facial expressions in an experimental paradigm devoid of primary negatively valenced comparison expressions.},
  pmid = {15110733},
  keywords = {Adult,Affect,Amygdala,Amygdala: physiology,Anxiety Disorders,Anxiety Disorders: diagnosis,Anxiety Disorders: psychology,Facial Expression,Female,Happiness,Humans,Magnetic Resonance Imaging,Male,Severity of Illness Index}
}

@article{somerville2006prior,
  title = {Prior Experience as a Stimulus Category Confound: An Example Using Facial Expressions of Emotion},
  author = {Somerville, Leah H and Whalen, Paul J},
  year = {2006},
  journal = {Social cognitive and affective neuroscience},
  volume = {1},
  number = {3},
  pages = {271--274}
}

@article{song2007supervised,
  title = {Supervised Feature Selection via Dependence Estimation},
  author = {Song, Le and Smola, Alex and Gretton, Arthur and Borgwardt, Karsten M. and Bedo, Justin},
  year = {2007},
  journal = {Proceedings of the 24th international conference on Machine learning - ICML '07},
  pages = {823--830},
  doi = {10.1145/1273496.1273600},
  file = {/Users/brownsarahm/Zotero/storage/NHHQSW3C/Song et al. - 2007 - Supervised feature selection via dependence estimation(3).pdf}
}

@book{song2010hilbert,
  title = {Hilbert Space Embeddings of Hidden {{Markov}} Models},
  author = {Song, L and Boots, Byron and Siddiqi, Sajid M},
  year = {2010},
  file = {/Users/brownsarahm/Zotero/storage/ZUSDM66H/Song, Boots, Siddiqi - 2010 - Hilbert space embeddings of hidden Markov models(3).pdf}
}

@article{sorge2014olfactory,
  title = {Olfactory Exposure to Males, Including Men, Causes Stress and Related Analgesia in Rodents},
  author = {Sorge, R E and Martin, L J and Isbester, K A},
  year = {2014},
  journal = {Nature Methods},
  volume = {11},
  number = {6},
  doi = {10.1038/NMETH.2935}
}

@book{spivey2008continuity,
  title = {The Continuity of Mind},
  author = {Spivey, Michael},
  year = {2008},
  publisher = {Oxford University Press}
}

@article{spoormaker2011largescale,
  title = {Large-Scale Functional Brain Networks in Human Non-Rapid Eye Movement Sleep: Insights from Combined Electroencephalographic/Functional Magnetic Resonance Imaging Studies.},
  author = {Spoormaker, Victor I and Czisch, Michael and Maquet, Pierre and J{\"a}ncke, Lutz},
  year = {2011},
  journal = {Philosophical transactions. Series A, Mathematical, physical, and engineering sciences},
  volume = {369},
  number = {1952},
  pages = {3708--3729},
  issn = {1364-503X},
  abstract = {This paper reviews the existing body of knowledge on the neural correlates of spontaneous oscillations, functional connectivity and brain plasticity in human non-rapid eye movement (NREM) sleep. The first section reviews the evidence that specific sleep events as slow waves and spindles are associated with transient increases in regional brain activity. The second section describes the changes in functional connectivity during NREM sleep, with a particular focus on changes within a low-frequency, large-scale functional brain network. The third section will discuss the possibility that spontaneous oscillations and differential functional connectivity are related to brain plasticity and systems consolidation, with a particular focus on motor skill acquisition. Implications for the mode of information processing per sleep stage and future experimental studies are discussed.},
  pmid = {21893524},
  keywords = {functional connectivity,graph theory,non-rapid eye movement sleep,plasticity,small-world,spindle},
  file = {/Users/brownsarahm/Zotero/storage/WHVGUGR7/Spoormaker et al. - 2011 - Large-scale functional brain networks in human non-rapid eye movement sleep insights from combined electro(3).pdf}
}

@article{sporns2011human,
  title = {The Human Connectome: A Complex Network},
  author = {Sporns, Olaf},
  year = {2011},
  journal = {Annals of the New York Academy of Sciences},
  volume = {1224},
  number = {1},
  pages = {109--125}
}

@article{sporns2014contributions,
  title = {Contributions and Challenges for Network Models in Cognitive Neuroscience},
  author = {Sporns, Olaf},
  year = {2014},
  journal = {Nature Neuroscience},
  volume = {17},
  number = {5},
  pages = {652--660}
}

@article{spreng2010default,
  title = {Default Network Activity, Coupled with the Frontoparietal Control Network, Supports Goal-Directed Cognition},
  author = {Spreng, R Nathan and Stevens, W Dale and Chamberlain, Jon P and Gilmore, Adrian W and Schacter, Daniel L},
  year = {2010},
  journal = {Neuroimage},
  volume = {53},
  number = {1},
  pages = {303--317}
}

@inproceedings{srivastava2019mathematical,
  title = {Mathematical Notions vs. Human Perception of Fairness: {{A}} Descriptive Approach to Fairness for Machine Learning},
  booktitle = {Proceedings of the 25th {{ACM SIGKDD}} International Conference on Knowledge Discovery \& Data Mining},
  author = {Srivastava, Megha and Heidari, Hoda and Krause, Andreas},
  year = {2019},
  pages = {2459--2468}
}

@book{stark2012probability,
  title = {Probability, {{Statistics}}, and {{Random Processes}} for {{Engineers}}},
  author = {Stark, Henry and Woods, John W.},
  year = {2012},
  edition = {4th},
  publisher = {Pearson Education, Inc.},
  isbn = {978-0-13-231123-6}
}

@techreport{states2009ricci,
  title = {Ricci v. {{DeStefano}}. 557 {{U}}.{{S}}. 557, 174},
  author = {States, Supreme Court of the United},
  year = {2009},
  pages = {2658 pages}
}

@article{station2004fast,
  title = {Fast Binary Feature Selection with Conditional Mutual Information},
  author = {Station, Cvlab and Guyon, Isabelle and Fleuret, F},
  year = {2004},
  journal = {The Journal of Machine Learning Research},
  volume = {5},
  pages = {1531--1555},
  keywords = {classification,feature selection,information theory,mutual information,naive bayes},
  file = {/Users/brownsarahm/Zotero/storage/3NQJPAIQ/Fleuret - 2004 - Fast binary feature selection with conditional mutual information(2).pdf}
}

@article{steele1986efronstein,
  title = {An {{Efron-Stein Inequality}} for {{Nonsymmetric Statistics}}},
  author = {Steele, J. Michael},
  year = {1986},
  journal = {The Annals of Statistics},
  volume = {14},
  number = {2},
  pages = {753--758},
  issn = {0090-5364},
  doi = {10.1214/aos/1176349952},
  file = {/Users/brownsarahm/Zotero/storage/ASPNR8FP/Steele - 1986 - An Efron-Stein Inequality for Nonsymmetric Statistics(3).pdf}
}

@article{steinberg2020fast,
  title = {Fast Fair Regression via Efficient Approximations of Mutual Information},
  author = {Steinberg, Daniel and Reid, Alistair and O'Callaghan, Simon and Lattimore, Finnian and McCalman, Lachlan and Caetano, Tiberio},
  year = {2020},
  journal = {arXiv preprint arXiv:2002.06200},
  volume = {abs/2002.06200},
  eprint = {2002.06200},
  archiveprefix = {arXiv}
}

@article{stephan2008nonlinear,
  title = {Nonlinear Dynamic Causal Models for {{fMRI}}.},
  author = {Stephan, Klaas Enno and Kasper, Lars and Harrison, Lee M and Daunizeau, Jean and {\noopsort{ouden}}{den Ouden}, Hanneke E M and Breakspear, Michael and Friston, Karl J},
  year = {2008},
  month = aug,
  journal = {NeuroImage},
  volume = {42},
  number = {2},
  pages = {649--662},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2008.04.262},
  abstract = {Models of effective connectivity characterize the influence that neuronal populations exert over each other. Additionally, some approaches, for example Dynamic Causal Modelling (DCM) and variants of Structural Equation Modelling, describe how effective connectivity is modulated by experimental manipulations. Mathematically, both are based on bilinear equations, where the bilinear term models the effect of experimental manipulations on neuronal interactions. The bilinear framework, however, precludes an important aspect of neuronal interactions that has been established with invasive electrophysiological recording studies; i.e., how the connection between two neuronal units is enabled or gated by activity in other units. These gating processes are critical for controlling the gain of neuronal populations and are mediated through interactions between synaptic inputs (e.g. by means of voltage-sensitive ion channels). They represent a key mechanism for various neurobiological processes, including top-down (e.g. attentional) modulation, learning and neuromodulation. This paper presents a nonlinear extension of DCM that models such processes (to second order) at the neuronal population level. In this way, the modulation of network interactions can be assigned to an explicit neuronal population. We present simulations and empirical results that demonstrate the validity and usefulness of this model. Analyses of synthetic data showed that nonlinear and bilinear mechanisms can be distinguished by our extended DCM. When applying the model to empirical fMRI data from a blocked attention to motion paradigm, we found that attention-induced increases in V5 responses could be best explained as a gating of the V1--{\textbackslash}textgreaterV5 connection by activity in posterior parietal cortex. Furthermore, we analysed fMRI data from an event-related binocular rivalry paradigm and found that interactions amongst percept-selective visual areas were modulated by activity in the middle frontal gyrus. In both practical examples, Bayesian model selection favoured the nonlinear models over corresponding bilinear ones.},
  pmid = {18565765},
  keywords = {Algorithms,Brain Mapping,Brain Mapping: methods,Computer Simulation,Evoked Potentials,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Models,Nerve Net,Nerve Net: physiology,Neurological,Nonlinear Dynamics,Visual,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology,Visual: physiology}
}

@article{sterling2012allostasis,
  title = {Allostasis: {{A}} Model of Predictive Regulation},
  author = {Sterling, Peter},
  year = {2012},
  journal = {Physiology and Behavior},
  volume = {106},
  number = {1},
  pages = {5--15}
}

@book{sterling2015principles,
  title = {Principles of Neural Design},
  author = {Sterling, Peter and Laughlin, Simon},
  year = {2015},
  publisher = {MIT Press}
}

@book{stevens2015bivariate,
  title = {Bivariate {{Choropleth Maps}}: {{A How-to Guide}}},
  author = {Stevens, Joshua},
  year = {2015},
  annotation = {Published: \${\textbackslash}backslash\$url\{http://www.joshuastevens.net/cartography/make-a-bivariate-choropleth-map/\}}
}

@article{street2009dynamic,
  title = {The Dynamic Architecture of Emotion: {{Evidence}} for the Component Process Model},
  author = {Street, Mortimer and Wt, London and Scherer, Klaus R.},
  year = {2009},
  month = nov,
  journal = {Cognition \& Emotion},
  volume = {23},
  number = {916427756},
  pages = {1307--1351},
  issn = {0269-9931},
  doi = {10.1080/02699930902928969},
  file = {/Users/brownsarahm/Zotero/storage/KRVLJC2V/Street, Wt, Scherer - 2009 - The dynamic architecture of emotion Evidence for the component process model(3).pdf}
}

@article{strubell2020Energy,
  title = {Energy and Policy Considerations for Modern Deep Learning Research},
  author = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  year = {2020},
  month = apr,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {34},
  number = {09},
  pages = {13693--13696},
  doi = {10.1609/aaai.v34i09.7123},
  annotation = {Abstract Note: \&lt;p\&gt;The field of artificial intelligence has experienced a dramatic methodological shift towards large neural networks trained on plentiful data. This shift has been fueled by recent advances in hardware and techniques enabling remarkable levels of computation, resulting in impressive advances in AI across many applications. However, the massive computation required to obtain these exciting results is costly both financially, due to the price of specialized hardware and electricity or cloud compute time, and to the environment, as a result of non-renewable energy used to fuel modern tensor processing hardware. In a paper published this year at ACL, we brought this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training and tuning neural network models for NLP (Strubell, Ganesh, and McCallum 2019). In this extended abstract, we briefly summarize our findings in NLP, incorporating updated estimates and broader information from recent related publications, and provide actionable recommendations to reduce costs and improve equity in the machine learning and artificial intelligence community.\&lt;/p\&gt;}
}

@inproceedings{sun2019mithralabel,
  title = {{{MithraLabel}}: {{Flexible Dataset Nutritional Labels}} for {{Responsible Data Science}}},
  shorttitle = {{{MithraLabel}}},
  booktitle = {Proceedings of the 28th {{ACM International Conference}} on {{Information}} and {{Knowledge Management}}},
  author = {Sun, Chenkai and Asudeh, Abolfazl and Jagadish, H. V. and Howe, Bill and Stoyanovich, Julia},
  year = {2019},
  month = nov,
  pages = {2893--2896},
  publisher = {ACM},
  address = {Beijing China},
  doi = {10.1145/3357384.3357853},
  urldate = {2020-05-09},
  abstract = {Using inappropriate datasets for data science tasks can be harmful, especially for applications that impact humans. Targeting data ethics, we demonstrate MithraLabel, a system for generating taskspecific information about a dataset, in the form of a set of visual widgets, as a flexible "nutritional label" that provides a user with information to determine the fitness of the dataset for the task at hand.},
  isbn = {978-1-4503-6976-3},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/8YZ6WQQM/Sun et al. - 2019 - MithraLabel Flexible Dataset Nutritional Labels f.pdf}
}

@article{sunder2008riesz,
  title = {The {{Riesz}} Representation Theorem},
  author = {Sunder, Vs},
  year = {2008},
  journal = {Indian Journal of Pure \& Applied {\textbackslash}ldots},
  issn = {00195588},
  file = {/Users/brownsarahm/Zotero/storage/FQDLEV3U/Sunder - 2008 - The Riesz representation theorem(3).pdf}
}

@incollection{suresh2021Frameworka,
  title = {A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle},
  booktitle = {Equity and Access in Algorithms, Mechanisms, and Optimization},
  author = {Suresh, Harini and Guttag, John},
  year = {2021},
  pages = {1--9}
}

@book{sutton1998introduction,
  title = {Introduction to {{Reinforcement Learning}}},
  author = {Sutton, Richard S and Barto, Andrew G},
  year = {1998},
  publisher = {MIT Press},
  address = {Cambridge, MA}
}

@book{sutton2012principles,
  title = {Principles of {{Research Code}}},
  author = {Sutton, Charles},
  year = {2012},
  doi = {10.1002/sim.5413},
  urldate = {2016-11-03},
  isbn = {978-0-7506-8196-4},
  pmid = {13812029},
  file = {/Users/brownsarahm/Zotero/storage/PNWIWLK4/Sutton - 2012 - Principles of Research Code(3).html}
}

@article{svoboda2006functional,
  title = {The Functional Neuroanatomy of Autobiographical Memory: A Meta-Analysis},
  author = {Svoboda, Eva and McKinnon, Margaret C and Levine, Brian},
  year = {2006},
  journal = {Neuropsychologia},
  volume = {44},
  number = {12},
  pages = {2189--2208}
}

@article{swanson2004brain,
  title = {Brain {{Maps}}: {{Structure}} of the {{Rat Brain}} (2nd Edn)},
  author = {Swanson, L W},
  year = {2004},
  journal = {Nature},
  volume = {363},
  pages = {347--350}
}

@article{tagliazucchi2013breakdown,
  title = {Breakdown of Long-Range Temporal Dependence in Default Mode and Attention Networks during Deep Sleep.},
  author = {Tagliazucchi, Enzo and {\noopsort{wegner}}{von Wegner}, Frederic and Morzelewski, Astrid and Brodbeck, Verena and Jahnke, Kolja and Laufs, Helmut},
  year = {2013},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {110},
  number = {31},
  pages = {15419--24},
  issn = {1091-6490},
  doi = {10.1073/pnas.1312848110},
  abstract = {The integration of segregated brain functional modules is a prerequisite for conscious awareness during wakeful rest. Here, we test the hypothesis that temporal integration, measured as long-term memory in the history of neural activity, is another important quality underlying conscious awareness. For this aim, we study the temporal memory of blood oxygen level-dependent signals across the human nonrapid eye movement sleep cycle. Results reveal that this property gradually decreases from wakefulness to deep nonrapid eye movement sleep and that such decreases affect areas identified with default mode and attention networks. Although blood oxygen level-dependent spontaneous fluctuations exhibit nontrivial spatial organization, even during deep sleep, they also display a decreased temporal complexity in specific brain regions. Conversely, this result suggests that long-range temporal dependence might be an attribute of the spontaneous conscious mentation performed during wakeful rest.},
  pmid = {24003146},
  keywords = {Analysis of Variance,Attention,Attention: physiology,Awareness,Awareness: physiology,Biological,Electroencephalography,Eye Movements,Eye Movements: physiology,Humans,Magnetic Resonance Imaging,Models,Oxygen,Oxygen: blood,Sleep,Sleep: physiology,Time Factors,Wakefulness,Wakefulness: physiology},
  file = {/Users/brownsarahm/Zotero/storage/BMJE5G9F/Tagliazucchi et al. - 2013 - Breakdown of long-range temporal dependence in default mode and attention networks during deep sleep(3).pdf}
}

@article{tagliazucchi2014decoding,
  title = {Decoding {{Wakefulness Levels}} from {{Typical fMRI Resting-State Data Reveals Reliable Drifts}} between {{Wakefulness}} and {{Sleep}}},
  author = {Tagliazucchi, Enzo and Laufs, Helmut},
  year = {2014},
  journal = {Neuron},
  volume = {82},
  number = {3},
  pages = {695--708},
  issn = {10974199},
  doi = {10.1016/j.neuron.2014.03.020},
  abstract = {The mining of huge databases of resting-state brain activity recordings represents state of the art in the assessment of endogenous neuronal activity-and may be a promising tool in the search for functional biomarkers. However, the resting state is an uncontrolled condition and its heterogeneity is neither sufficiently understood nor accounted for. We test the hypothesis that subjects exhibit unstable wakefulness, i.e., drift into sleep during typical resting-state experiments. Analyzing 1,147 resting-state functional magnetic resonance data sets, we revealed a reliable loss of wakefulness in a third of subjects within 3min and demonstrated the dynamic nature of the resting state, with fundamental changes in the associated functional neuroanatomy. Implications include the necessity of wakefulness monitoring and modeling, taking measures to maintain a state of wakefulness, acknowledging the possibility of sleep and exploring its consequences, and especially the critical assessment of possible false-positive or false-negative results. {\copyright} 2014 Elsevier Inc.},
  pmid = {24811386},
  file = {/Users/brownsarahm/Zotero/storage/C4RJI7A2/Tagliazucchi, Laufs - 2014 - Decoding Wakefulness Levels from Typical fMRI Resting-State Data Reveals Reliable Drifts between Wakeful(3).pdf}
}

@article{tagliazucchi2014enhanced,
  title = {Enhanced Repertoire of Brain Dynamical States during the Psychedelic Experience.},
  author = {Tagliazucchi, Enzo and {Carhart-Harris}, Robin and Leech, Robert and Nutt, David and Chialvo, Dante R},
  year = {2014},
  journal = {Human brain mapping},
  volume = {00},
  number = {January},
  eprint = {24989126},
  eprinttype = {pubmed},
  pages = {5442--5456},
  issn = {1097-0193},
  doi = {10.1002/hbm.22562},
  abstract = {The study of rapid changes in brain dynamics and functional connectivity (FC) is of increasing interest in neuroimaging. Brain states departing from normal waking consciousness are expected to be accompanied by alterations in the aforementioned dynamics. In particular, the psychedelic experience produced by psilocybin (a substance found in "magic mushrooms") is characterized by unconstrained cognition and profound alterations in the perception of time, space and selfhood. Considering the spontaneous and subjective manifestation of these effects, we hypothesize that neural correlates of the psychedelic experience can be found in the dynamics and variability of spontaneous brain activity fluctuations and connectivity, measurable with functional Magnetic Resonance Imaging (fMRI). Fifteen healthy subjects were scanned before, during and after intravenous infusion of psilocybin and an inert placebo. Blood-Oxygen Level Dependent (BOLD) temporal variability was assessed computing the variance and total spectral power, resulting in increased signal variability bilaterally in the hippocampi and anterior cingulate cortex. Changes in BOLD signal spectral behavior (including spectral scaling exponents) affected exclusively higher brain systems such as the default mode, executive control, and dorsal attention networks. A novel framework enabled us to track different connectivity states explored by the brain during rest. This approach revealed a wider repertoire of connectivity states post-psilocybin than during control conditions. Together, the present results provide a comprehensive account of the effects of psilocybin on dynamical behavior in the human brain at a macroscopic level and may have implications for our understanding of the unconstrained, hyper-associative quality of consciousness in the psychedelic state. Hum Brain Mapp, 2014. {\copyright} 2014 Wiley Periodicals, Inc.},
  pmid = {24989126},
  keywords = {fmri,functional connectivity,psilocybin,psychedelic state,resting state},
  file = {/Users/brownsarahm/Zotero/storage/GBZBQVEH/Tagliazucchi et al. - 2014 - Enhanced repertoire of brain dynamical states during the psychedelic experience(3).pdf}
}

@article{tajfel1971social,
  title = {Social Categorization and Intergroup Behaviour},
  author = {Tajfel, Henri and Billig, Michael G and Bundy, Robert P and Flament, Claude},
  year = {1971},
  journal = {European journal of social psychology},
  volume = {1},
  number = {2},
  pages = {149--178},
  publisher = {Wiley Online Library}
}

@article{tam2007emotioni,
  title = {{{EMOTION-I Model}}: {{A Biologically-Based Theoretical Framework}} for {{Deriving Emotional Context}} of {{Sensation}} in {{Autonomous Control Systems}}},
  author = {Tam, David},
  year = {2007},
  month = dec,
  journal = {The Open Cybernetics \& Systemics Journal},
  volume = {1},
  number = {1},
  pages = {28--46},
  issn = {1874110X},
  doi = {10.2174/1874110X00701010028},
  keywords = {autonomous control system,contextual representation,model of emotion,neural processing,origin of emotions},
  file = {/Users/brownsarahm/Zotero/storage/XQQSJTBT/Tam - 2007 - EMOTION-I Model A Biologically-Based Theoretical Framework for Deriving Emotional Context of Sensation in Autonomous Con(3).pdf}
}

@article{teh2006hierarchical,
  title = {Hierarchical {{Dirichlet Processes}}},
  author = {Teh, Yee Whye and Jordan, Michael I and Beal, Matthew J and Blei, David M},
  year = {2006},
  month = dec,
  journal = {Journal of the American Statistical Association},
  volume = {101},
  number = {476},
  pages = {1566--1581},
  issn = {0162-1459},
  doi = {10.1198/016214506000000302},
  file = {/Users/brownsarahm/Zotero/storage/RDZVQDLS/Teh et al. - 2006 - Hierarchical Dirichlet Processes(3).pdf}
}

@article{teh2010dirichlet,
  title = {Dirichlet {{Process}}},
  author = {Teh, Yee Whye},
  year = {2010},
  journal = {Encyclopedia of Machine Learning},
  pages = {280--287},
  issn = {1941-7330},
  doi = {10.1007/978-0-387-30164-8_219},
  abstract = {Sammut, C and Webb, GI, (eds.) . (280 - 287). Springer},
  pmid = {21031154},
  file = {/Users/brownsarahm/Zotero/storage/9PBHJCCA/Teh - 2010 - Dirichlet Process(3).pdf}
}

@article{teshima2020coupling,
  title = {Coupling-Based Invertible Neural Networks Are Universal Diffeomorphism Approximators},
  author = {Teshima, Takeshi and Ishikawa, Isao and Tojo, Koichi and Oono, Kenta and Ikeda, Masahiro and Sugiyama, Masashi},
  year = {2020},
  journal = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {3362--3373}
}

@article{thacker2008performance,
  title = {Performance Characterization in Computer Vision: {{A}} Guide to Best Practices},
  author = {{\noopsort{thacker}}a. Thacker, Neil and Clark, Adrian F. and Barron, John L. and Ross Beveridge, J. and Courtney, Patrick and Crum, William R. and Ramesh, Visvanathan and Clark, Christine},
  year = {2008},
  month = mar,
  journal = {Computer Vision and Image Understanding},
  volume = {109},
  number = {3},
  pages = {305--334},
  issn = {10773142},
  doi = {10.1016/j.cviu.2007.04.006},
  keywords = {performance assessment,performance evaluation,vision system design},
  file = {/Users/brownsarahm/Zotero/storage/PRLK4HEF/Thacker et al. - 2008 - Performance characterization in computer vision A guide to best practices(3).pdf}
}

@article{thalmann2019how,
  title = {How Does Chunking Help Working Memory?},
  author = {Thalmann, Mirko and Souza, Alessandra S. and Oberauer, Klaus},
  year = {2019},
  journal = {Journal of Experimental Psychology: Learning Memory and Cognition},
  volume = {45},
  number = {1},
  pages = {37--55},
  issn = {02787393},
  doi = {10.1037/xlm0000578},
  abstract = {Chunking is the recoding of smaller units of information into larger, familiar units. Chunking is often assumed to help bypassing the limited capacity of working memory (WM). We investigate how chunks are used in WM tasks, addressing three questions: (a) Does chunking reduce the load on WM? Across four experiments chunking benefits were found not only for recall of the chunked but also of other not-chunked information concurrently held in WM, supporting the assumption that chunking reduces load. (b) Is the chunking benefit independent of chunk size? The chunking benefit was independent of chunk size only if the chunks were composed of unique elements, so that each chunk could be replaced by its first element (Experiment 1), but not when several chunks consisted of overlapping sets of elements, disabling this replacement strategy (Experiments 2 and 3). The chunk-size effect is not due to differences in rehearsal duration as it persisted when participants were required to perform articulatory suppression (Experiment 3). Hence, WM capacity is not limited to a fixed number of chunks regardless of their size. (c) Does the chunking benefit depend on the serial position of the chunk? Chunks in early list positions improved recall of other, not-chunked material, but chunks at the end of the list did not. We conclude that a chunk reduces the load on WM via retrieval of a compact chunk representation from long-term memory that replaces the representations of individual elements of the chunk. This frees up capacity for subsequently encoded material. (PsycINFO Database Record (c) 2018 APA, all rights reserved)},
  keywords = {Chunk,Long-term memory,Short-term memory,Working memory}
}

@book{themendeleysupportteam2011getting,
  title = {Getting {{Started}} with {{Mendeley}}},
  author = {{The Mendeley Support Team}},
  year = {2011},
  publisher = {Mendeley Ltd.},
  address = {London},
  abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
  keywords = {how-to,Mendeley,user manual},
  file = {/Users/brownsarahm/Zotero/storage/TY6RYRCB/The Mendeley Support Team - 2011 - Getting Started with Mendeley(3).pdf}
}

@book{thomas2005illuminating,
  title = {Illuminating the {{Path}}: {{The Research}} and {{Development Agenda}} for {{Visual Analytics}}},
  editor = {Thomas, James J and Cook, Kristin A},
  year = {2005},
  month = aug,
  publisher = {IEEE Computer Society}
}

@inproceedings{thomas2010technical,
  title = {Technical {{Outreach Community Help}} : {{An Engineering Outreach-Mentoring Program For Minorities}}},
  booktitle = {American {{Society}} for {{Engineering Education}}},
  author = {Thomas, Lauren D (Virginia Tech) and Smith, Michael (National Society of Black Engineers) and Brown, Sarah},
  year = {2010},
  volume = {7},
  abstract = {Providing exposure, stimulating enthusiasm, training, promoting the value of engineering, and mentoring minority K-12 students, as a means to increasing STEM participation is the primary goal of the National Society of Black Engineers (NSBE) Technical Outreach Community Help (TORCH) program. The program has taken advantage of its unique opportunity to increase the number of minority students that are exposed to engineering through an outreach and mentorship model using the face of NSBE's collegiate and alumni members. Utilization of formal and informal environments, with African American mentors in engineering provides a unique experience for participants to discover the field and explore the disciplines. The combination of mentors who share ethnic background, similar experiences, and the actual content of the program help to diminish the barrier between minority K-12 students and engineering. This paper will cover the design, content, and assessment of the TORCH program, as well as discuss the program's progress and future. {\copyright} American Society for Engineering Education, 2010.},
  copyright = {All rights reserved},
  file = {/Users/brownsarahm/Zotero/storage/GIT3P98I/Thomas, Smith, Brown - 2010 - Technical Outreach Community Help An Engineering Outreach-Mentoring Program For Minorities(4).pdf}
}

@article{thompson1987sample,
  title = {Sample Size for Estimating Multinomial Proportions},
  author = {Thompson, SK S.K.},
  year = {1987},
  journal = {The American Statistician},
  volume = {41},
  number = {1},
  pages = {42--46},
  issn = {00031305},
  doi = {10.2307/2684318},
  abstract = {This article presents a procedure and a table for selecting sample size for simultaneously estimating the parameters of a multinomial distribution. The results are obtained by ex- amining the "worst" possible value of a multinomial pa- rameter vector, analogous to the case in which a binomial parameter equals one-half.},
  keywords = {multinomial distribution,simultaneous in-},
  file = {/Users/brownsarahm/Zotero/storage/UQN3B4FH/Thompson - 1987 - Sample size for estimating multinomial proportions(3).pdf}
}

@article{thompsonaudio,
  title = {Audio Stimulus Reconstruction from Brain Activity Using Multi-Source Semantic Embedding},
  author = {Thompson, Jessica and Casey, Michael and Torresani, Lorenzo},
  keywords = {audio,bedding,eeg,fmri,multi-source learning,music,semantic em-,stimulus reconstruction,tags},
  file = {/Users/brownsarahm/Zotero/storage/NNAEJQWB/Thompson, Casey, Torresani - Unknown - Audio stimulus reconstruction from brain activity using multi-source semantic embedding(3).pdf}
}

@article{thura2014deliberation,
  title = {Deliberation and Commitment in the Premotor and Primary Motor Cortex during Dynamic Decision Making},
  author = {Thura, David and Cisek, Paul},
  year = {2014},
  journal = {Neuron},
  volume = {6},
  number = {81},
  pages = {1401--1416}
}

@article{tibshirani1996regression,
  title = {Regression Shrinkage and Selection via the Lasso},
  author = {Tibshirani, R},
  year = {1996},
  journal = {Journal of the Royal Statistical Society. Series B ( Methodological)},
  volume = {58},
  number = {1},
  eprint = {2346178},
  eprinttype = {jstor},
  pages = {266--288},
  file = {/Users/brownsarahm/Zotero/storage/TWXKPUK3/Tibshirani - 1996 - Regression shrinkage and selection via the lasso(3).pdf}
}

@book{titanic,
  title = {Titanic {{Data}}},
  annotation = {Published: \${\textbackslash}backslash\$url\{http://www.public.iastate.edu/{$\sim$}hofmann/datasets.html\}}
}

@article{titsias2010bayesian,
  title = {Bayesian {{Gaussian Process Latent Variable Model}}},
  author = {Titsias, Michalis and Lawrence, Neil},
  year = {2010},
  journal = {Artificial Intelligence},
  volume = {9},
  pages = {844--851},
  issn = {0899-7667},
  doi = {10.1162/089976699300016331},
  abstract = {We introduce a variational inference framework for training the Gaussian process latent variable model and thus performing Bayesian nonlinear dimensionality reduction. This method allows us to variationally integrate out the input variables of the Gaussian process and compute a lower bound on the exact marginal likelihood of the nonlinear latent variable model. The maximization of the variational lower bound provides a Bayesian training procedure that is robust to overfitting and can automatically select the dimensionality of the nonlinear latent space. We demonstrate our method on real world datasets. The focus in this paper is on dimensionality reduction problems, but the methodology is more general. For example, our algorithm is immediately applicable for training Gaussian process models in the presence of missing or uncertain inputs.},
  pmid = {80990000001},
  keywords = {learning,statistics \& optimisation,theory \& algorithms},
  file = {/Users/brownsarahm/Zotero/storage/4JIWIBJM/Titsias, Lawrence - 2010 - Bayesian Gaussian Process Latent Variable Model(3).pdf}
}

@article{tognoli2014metastable,
  title = {The {{Metastable Brain}}},
  author = {Tognoli, Emmanuelle and Kelso, J. a Scott},
  year = {2014},
  journal = {Neuron},
  volume = {81},
  number = {1},
  pages = {35--48},
  issn = {08966273},
  doi = {10.1016/j.neuron.2013.12.022},
  abstract = {Neural ensembles oscillate across a broad range of frequencies and are transiently coupled or "bound" together when people attend to a stimulus, perceive, think, and act. This is a dynamic, self-assembling process, with parts of the brain engaging and disengaging in time. But how is it done? The theory of Coordination Dynamics proposes a mechanism called metastability, a subtle blend of integration and segregation. Tendencies for brain regions to express their individual autonomy and specialized functions (segregation, modularity) coexist with tendencies to couple and coordinate globally for multiple functions (integration). Although metastability has garnered increasing attention, it has yet to be demonstrated and treated within a fully spatiotemporal perspective. Here, we illustrate metastability in continuous neural and behavioral recordings, and we discuss theory and experiments at multiple scales, suggesting that metastable dynamics underlie the real-time coordination necessary for the brain's dynamic cognitive, behavioral, and social functions. How does the transient coupling of neural ensembles that supports cognitive function occur? Tognoli and Kelso consider a mechanism known as metastability, discussing theory and data at multiple scales that suggest that metastable dynamics underlies the coordination necessary for the brain's dynamic functions. ?? 2014 Elsevier Inc.},
  pmid = {24411730},
  file = {/Users/brownsarahm/Zotero/storage/W37A83LE/Tognoli, Kelso - 2014 - The Metastable Brain(3).pdf}
}

@article{tomasi2012resting,
  title = {Resting Functional Connectivity of Language Networks: Characterization and Reproducibility},
  author = {Tomasi, Dardo and Volkow, Nora D},
  year = {2012},
  journal = {Molecular psychiatry},
  volume = {17},
  number = {8},
  pages = {841--854}
}

@article{tomkins1964what,
  title = {What and Where Are the Primary Affects? {{Some}} Evidence for a Theory},
  author = {Tomkins, Silvan S and McCarter, Robert},
  year = {1964},
  journal = {Perceptual and motor skills},
  volume = {18},
  number = {1},
  pages = {119--158}
}

@article{tononi1998complexity,
  title = {Complexity and Coherency: {{Integrating}} Information in the Brain},
  author = {Tononi, Giulio and Edelman, Gerald M and Sporns, Olaf},
  year = {1998},
  journal = {Trends in Cognitive Sciences},
  volume = {2},
  number = {12},
  pages = {474--484}
}

@article{tononi1999measures,
  title = {Measures of Degeneracy and Redundancy in Biological Networks.},
  author = {Tononi, G and Sporns, O and Edelman, G M},
  year = {1999},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {96},
  number = {March},
  pages = {3257--3262},
  issn = {0027-8424},
  doi = {10.1073/pnas.96.6.3257},
  abstract = {Degeneracy, the ability of elements that are structurally different to perform the same function, is a prominent property of many biological systems ranging from genes to neural networks to evolution itself. Because structurally different elements may produce different outputs in different contexts, degeneracy should be distinguished from redundancy, which occurs when the same function is performed by identical elements. However, because of ambiguities in the distinction between structure and function and because of the lack of a theoretical treatment, these two notions often are conflated. By using information theoretical concepts, we develop here functional measures of the degeneracy and redundancy of a system with respect to a set of outputs. These measures help to distinguish the concept of degeneracy from that of redundancy and make it operationally useful. Through computer simulations of neural systems differing in connectivity, we show that degeneracy is low both for systems in which each element affects the output independently and for redundant systems in which many elements can affect the output in a similar way but do not have independent effects. By contrast, degeneracy is high for systems in which many different elements can affect the output in a similar way and at the same time can have independent effects. We demonstrate that networks that have been selected for degeneracy have high values of complexity, a measure of the average mutual information between the subsets of a system. These measures promise to be useful in characterizing and understanding the functional robustness and adaptability of biological networks.},
  pmid = {10077671},
  file = {/Users/brownsarahm/Zotero/storage/EWZQQ4T7/Tononi, Sporns, Edelman - 1999 - Measures of degeneracy and redundancy in biological networks(3).pdf}
}

@article{touroutoglou2012dissociable,
  title = {Dissociable Large-Scale Networks Anchored in the Right Anterior Insula Subserve Affective Experience and Attention},
  author = {Touroutoglou, Alexandra and Hollenbeck, Mark and Dickerson, Bradford C and Barrett, Lisa Feldman},
  year = {2012},
  journal = {Neuroimage},
  volume = {60},
  number = {4},
  pages = {1947--1958}
}

@article{tovote2015neuronal,
  title = {Neuronal Circuits for Fear and Anxiety},
  author = {Tovote, P and Fadok, J P and Luthi, A},
  year = {2015},
  journal = {Nature Reviews Neuroscience},
  volume = {16},
  number = {6},
  pages = {317--331}
}

@inproceedings{tramer2017fairtest,
  title = {{{FairTest}}: {{Discovering}} Unwarranted Associations in Data-Driven Applications},
  booktitle = {2017 {{IEEE}} European Symposium on Security and Privacy ({{EuroS}}\&{{P}})},
  author = {Tramer, Florian and Atlidakis, Vaggelis and Geambasu, Roxana and Hsu, Daniel and Hubaux, Jean-Pierre and Humbert, Mathias and Juels, Ari and Lin, Huang},
  year = {2017},
  pages = {401--416},
  organization = {IEEE}
}

@article{tremblay2019determinantal,
  title = {Determinantal Point Processes for Coresets},
  author = {Tremblay, Nicolas and Barthelm{\'e}, Simon and Amblard, Pierre-Olivier},
  year = {2019},
  journal = {Journal of Machine Learning Research},
  volume = {20},
  number = {168},
  pages = {1--70}
}

@article{trope2010construal,
  title = {Construal-Level Theory of Psychological Distance.},
  author = {Trope, Yaacov and Liberman, Nira},
  year = {2010},
  journal = {Psychological review},
  volume = {117},
  number = {2},
  pages = {440},
  publisher = {American Psychological Association}
}

@article{trumbo1981theory,
  title = {A Theory for Coloring Bivariate Statistical Maps},
  author = {Trumbo, Bruce E},
  year = {1981},
  journal = {The American Statistician},
  volume = {35},
  number = {4},
  pages = {220--226}
}

@inproceedings{tsamardinos2003principled,
  title = {Towards Principled Feature Selection: Relevancy, Filters, and Wrappers},
  booktitle = {Proceedings of the {{Ninth International Workshop}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Tsamardinos, Ioannis and Aliferis, Constantin F.},
  year = {2003},
  file = {/Users/brownsarahm/Zotero/storage/Z3336ARW/Unknown - Unknown - No Title(17).pdf}
}

@inproceedings{tur2011learning,
  title = {Learning Mixed Graphical Models from Data with p Larger than n},
  booktitle = {Proceedings 27th {{Conference}} on {{Uncertainty}} in {{Artificial Intelligence}}},
  author = {Tur, Inma and Castelo, Robert},
  year = {2011},
  isbn = {978-0-9749039-7-2},
  file = {/Users/brownsarahm/Zotero/storage/BCU26R6D/Tur, Castelo - 2011 - Learning mixed graphical models from data with p larger than n(3).pdf}
}

@article{turkheimer2014phenotypic,
  title = {A Phenotypic Null Hypothesis for the Genetics of Personality},
  author = {Turkheimer, Eric and Pettersson, Erik and Horn, Erin E},
  year = {2014},
  journal = {Annual review of psychology},
  volume = {65},
  pages = {515--540}
}

@article{tversky1973availability,
  title = {Availability: {{A}} Heuristic for Judging Frequency and Probability},
  author = {Tversky, Amos and Kahneman, Daniel},
  year = {1973},
  journal = {Cognitive psychology},
  volume = {5},
  number = {2},
  pages = {207--232},
  publisher = {Elsevier}
}

@article{tversky1981framing,
  title = {The Framing of Decisions and the Psychology of Choice},
  author = {Tversky, Amos and Kahneman, Daniel},
  year = {1981},
  journal = {science},
  volume = {211},
  number = {4481},
  pages = {453--458},
  publisher = {American Association for the Advancement of Science}
}

@article{tversky1986urational,
  title = {{{uRational}} Choice and the Framing of Decisions. {{vJournal}} of Business, 59 (4), Part 2},
  author = {Tversky, Amos and Kahneman, Daniel},
  year = {1986},
  journal = {S251) S275}
}

@article{tversky1991loss,
  title = {Loss Aversion in Riskless Choice: {{A}} Reference-Dependent Model},
  author = {Tversky, Amos and Kahneman, Daniel},
  year = {1991},
  journal = {The quarterly journal of economics},
  volume = {106},
  number = {4},
  pages = {1039--1061},
  publisher = {MIT Press}
}

@article{uddin2015salience,
  title = {Salience Processing and Insular Cortical Function and Dysfunction},
  author = {Uddin, Lucina Q},
  year = {2015},
  journal = {Nature Reviews Neuroscience},
  volume = {16},
  number = {1},
  pages = {55--61}
}

@article{ullsperger2014neurophysiology,
  title = {Neurophysiology of Performance Monitoring and Adaptive Behavior},
  author = {Ullsperger, Markus and Danielmeier, Claudia and Jocham, Gerhard},
  year = {2014},
  journal = {Physiological reviews},
  volume = {94},
  number = {1},
  pages = {35--79}
}

@article{upadhyay2021towards,
  ids = {upadhyay2021Robust,upadhyay2021Robusta},
  title = {Towards Robust and Reliable Algorithmic Recourse},
  author = {Upadhyay, Sohini and Joshi, Shalmali and Lakkaraju, Himabindu},
  year = {2021},
  journal = {Advances in Neural Information Processing Systems},
  volume = {34},
  pages = {16926--16937}
}

@inproceedings{ustun2019Actionable,
  title = {Actionable Recourse in Linear Classification},
  booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
  author = {Ustun, Berk and Spangher, Alexander and Liu, Yang},
  year = {2019},
  pages = {10--19}
}

@book{uttal2001new,
  title = {The New Phrenology: {{The}} Limits of Localizing Cognitive Processes in the Brain.},
  author = {Uttal, William R},
  year = {2001},
  publisher = {The MIT press}
}

@article{vaccaro2024combinations,
  title = {When Combinations of Humans and {{AI}} Are Useful: {{A}} Systematic Review and Meta-Analysis},
  author = {Vaccaro, Michelle and Almaatouq, Abdullah and Malone, Thomas},
  year = {2024},
  journal = {Nature Human Behaviour},
  pages = {1--11},
  publisher = {Nature Publishing Group UK London}
}

@article{valverde2011unscented,
  title = {Unscented {{Kalman}} Filter for Power System Dynamic State Estimation},
  author = {Valverde, G. and Terzija, V.},
  year = {2011},
  journal = {IET Generation, Transmission \& Distribution},
  volume = {5},
  number = {1},
  pages = {29},
  issn = {17518687},
  doi = {10.1049/iet-gtd.2010.0210}
}

@article{vandenheuvel2009functionally,
  title = {Functionally Linked Resting-State Networks Reflect the Underlying Structural Connectivity Architecture of the Human Brain},
  author = {Van Den Heuvel, Martijn P and Mandl, Rene and Kahn, Rene and Pol, Hulshoff and Hilleke, E},
  year = {2009},
  journal = {Human Brain Mapping},
  volume = {30},
  number = {10},
  pages = {3127--3141}
}

@article{vandenheuvel2010exploring,
  title = {Exploring the Brain Network: {{A}} Review on Resting-State {{fMRI}} Functional Connectivity},
  author = {Van Den Heuvel, Martijn P and Pol, Hilleke E},
  year = {2010},
  journal = {European Neuropsychopharmacology},
  volume = {20},
  number = {8},
  pages = {519--534}
}

@article{vandenheuvel2011richclub,
  title = {Rich-Club Organization of the Human Connectome},
  author = {{\noopsort{heuvel}}{van den Heuvel}, Martijn P and Sporns, Olaf},
  year = {2011},
  journal = {The Journal of neuroscience},
  volume = {31},
  number = {44},
  pages = {15775--15786}
}

@article{vandenheuvel2012highcost,
  title = {High-Cost, High-Capacity Backbone for Global Brain Communication},
  author = {VanDenHeuvel, Martijn P and Kahn, Rene S and Goni, Joaquin and Sporns, Olaf},
  year = {2012},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {109},
  number = {28},
  pages = {11372--11377}
}

@article{vandenheuvel2013abnormal,
  ids = {vandenheuvel2013Abnormal,vandenheuvel2013Abnormala,vandenheuvel2013Abnormalb},
  title = {Abnormal Rich Club Organization and Functional Brain Dynamics in Schizophrenia},
  author = {{\noopsort{heuvel}}{van den Heuvel}, Martijn P and Sporns, Olaf and Collin, Guusje and Scheewe, Thomas and Mandl, Ren{\'e} C W and Cahn, Wiepke and Go{\~n}i, Joaqu{\'i}n and Pol, Hilleke E Hulshoff and Kahn, Ren{\'e} S},
  year = {2013},
  journal = {JAMA psychiatry},
  volume = {70},
  number = {8},
  pages = {783--792},
  publisher = {American Medical Association}
}

@article{vandenheuvel2013network,
  title = {Network Hubs in the Human Brain},
  author = {{\noopsort{heuvel}}{van den Heuvel}, Martijn P and Sporns, Olaf},
  year = {2013},
  journal = {Trends in cognitive sciences},
  volume = {17},
  number = {12},
  pages = {683--696}
}

@article{vanoudenhove2014relevance,
  title = {The Relevance of the Philosophical 'mind-Body Problem' for the Status of Psychosomatic Medicine: {{A}} Conceptual Analysis of the Biopsychosocial Model},
  author = {Van Oudenhove, Lukas and Cuypers, Stefaan},
  year = {2014},
  journal = {Medicine, Health Care and Philosophy},
  volume = {17},
  number = {2},
  pages = {201--213},
  issn = {15728633},
  doi = {10.1007/s11019-013-9521-1},
  abstract = {Psychosomatic medicine, with its prevailing biopsychosocial model, aims to integrate human and exact sciences with their divergent conceptual models. Therefore, its own conceptual foundations, which often remain implicit and unknown, may be critically relevant. We defend the thesis that choosing between different metaphysical views on the 'mind-body problem' may have important implications for the conceptual foundations of psychosomatic medicine, and therefore potentially also for its methods, scientific status and relationship with the scientific disciplines it aims to integrate: biomedical sciences (including neuroscience), psychology and social sciences. To make this point, we introduce three key positions in the philosophical 'mind-body' debate (emergentism, reductionism, and supervenience physicalism) and investigate their consequences for the conceptual basis of the biopsychosocial model in general and its 'psycho-biological' part ('mental causation') in particular. Despite the clinical merits of the biopsychosocial model, we submit that it is conceptually underdeveloped or even flawed, which may hamper its use as a proper scientific model.},
  pmid = {24443097},
  keywords = {Biopsychosocial model,Dualism,Neuroscience,Philosophy of mind,Physicalism,Psychosomatic medicine},
  file = {/Users/brownsarahm/Zotero/storage/CH8XSY3S/Van Oudenhove, Cuypers - 2014 - The relevance of the philosophical 'mind-body problem' for the status of psychosomatic medicine A con(3).pdf}
}

@article{vanoverwalle2009social,
  title = {Social Cognition and the Brain: A Meta-Analysis},
  author = {Van Overwalle, Frank},
  year = {2009},
  journal = {Human brain mapping},
  volume = {30},
  number = {3},
  pages = {829--858}
}

@article{vasterling2009mild,
  title = {Mild Traumatic Brain Injury and Posttraumatic Stress Disorder in Returning Veterans: Perspectives from Cognitive Neuroscience.},
  author = {Vasterling, Jennifer J and Verfaellie, Mieke and Sullivan, Karen D},
  year = {2009},
  month = dec,
  journal = {Clinical psychology review},
  volume = {29},
  number = {8},
  eprint = {19744760},
  eprinttype = {pubmed},
  pages = {674--84},
  issn = {1873-7811},
  doi = {10.1016/j.cpr.2009.08.004},
  abstract = {A significant proportion of military personnel deployed in support of Operation Enduring Freedom (OEF) and Operation Iraqi Freedom (OIF) has been exposed to war-zone events potentially associated with traumatic brain injury (TBI) and posttraumatic stress disorder (PTSD). There has been significant controversy regarding healthcare policy for those service members and military veterans who returned from OEF/OIF deployments with both mild TBI and PTSD. There is currently little empirical evidence available to address these controversies. This review uses a cognitive neuroscience framework to address the potential impact of mild TBI on the development, course, and clinical management of PTSD. The field would benefit from research efforts that take into consideration the potential differential impact of mild TBI with versus without persistent cognitive deficits, longitudinal work examining the trajectory of PTSD symptoms when index trauma events involve TBI, randomized clinical trials designed to examine the impact of mild TBI on response to existing PTSD treatment interventions, and development and examination of potential treatment augmentation strategies.},
  pmid = {19744760},
  keywords = {Blast Injuries,Blast Injuries: complications,Blast Injuries: therapy,Brain Injuries,Brain Injuries: complications,Brain Injuries: therapy,Combat Disorders,Combat Disorders: complications,Combat Disorders: therapy,Humans,Military Personnel,Military Personnel: psychology,Post-Traumatic,Post-Traumatic: complications,Post-Traumatic: therapy,Stress Disorders,United States,Veterans,Veterans: psychology,War},
  file = {/Users/brownsarahm/Zotero/storage/JGHRBIZP/Vasterling, Verfaellie, Sullivan - 2009 - Mild traumatic brain injury and posttraumatic stress disorder in returning veterans perspec(3).pdf}
}

@inproceedings{vasudevan2020Lift,
  title = {Lift: {{A}} Scalable Framework for Measuring Fairness in Ml Applications},
  booktitle = {Proceedings of the 29th {{ACM}} International Conference on Information \& Knowledge Management},
  author = {Vasudevan, Sriram and Kenthapadi, Krishnaram},
  year = {2020},
  pages = {2773--2780}
}

@book{verschelden2017Bandwidth,
  title = {Bandwidth Recovery: Helping Students Reclaim Cognitive Resources Lost to Poverty, Racism, and Social Marginalization},
  shorttitle = {Bandwidth Recovery},
  author = {Verschelden, Cia},
  year = {2017},
  edition = {First edition},
  publisher = {Stylus Publishing},
  address = {Sterling, Virginia},
  isbn = {978-1-62036-604-2 978-1-62036-605-9},
  lccn = {LC4091 .V47 2017},
  keywords = {Children with social disabilities,Cognition in children,Education,Social aspects,Students with social disabilities,United States}
}

@book{verschelden2017Bandwidtha,
  title = {Bandwidth Recovery: {{Helping}} Students Reclaim Cognitive Resources Lost to Poverty, Racism, and Social Marginalization},
  author = {Verschelden, Cia},
  year = {2017},
  publisher = {Stylus Publishing, LLC}
}

@article{verschelden2017Bandwidthb,
  title = {Bandwidth Recovery: {{Helping}} Students Reclaim Cognitive Resources Lost to Poverty, Racism, and Social Marginalization},
  author = {Verschelden, Cia and Pasquerella, Lynn},
  year = {2017},
  publisher = {Routledge}
}

@article{vetter2014report,
  title = {Report {{Decoding Sound}} and {{Imagery Content}} in {{Early Visual Cortex}}},
  author = {Vetter, Petra and Smith, Fraser W and Muckli, Lars},
  year = {2014},
  journal = {Current Biology},
  volume = {24},
  number = {11},
  pages = {1256--1262},
  issn = {0960-9822},
  doi = {10.1016/j.cub.2014.04.020}
}

@article{viskontas2009human,
  title = {Human Medial Temporal Lobe Neurons Respond Preferentially to Personally Relevant Images},
  author = {Viskontas, Indre V and Quiroga, Rodrigo Quian and Fried, Itzhak},
  year = {2009},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {106},
  number = {50},
  pages = {21329--21334}
}

@article{visscher2003mixed,
  title = {Mixed Blocked/Event-Related Designs Separate Transient and Sustained Activity in {{fMRI}}},
  author = {Visscher, Kristina M and Miezin, Francis M and Kelly, James E and Buckner, Randy L and Donaldson, David I and McAvoy, Mark P and Bhalodia, Vidya M and Petersen, Steven E},
  year = {2003},
  month = aug,
  journal = {NeuroImage},
  volume = {19},
  number = {4},
  pages = {1694--1708},
  issn = {10538119},
  doi = {10.1016 S1053-8119(03)00178-2},
  file = {/Users/brownsarahm/Zotero/storage/TQH4BBIE/Visscher et al. - 2003 - Mixed blockedevent-related designs separate transient and sustained activity in fMRI(3).pdf}
}

@article{vogelstein2011are,
  title = {Are Mental Properties Supervenient on Brain Properties?},
  author = {Vogelstein, Joshua T and Vogelstein, R Jacob and Priebe, Carey E},
  year = {2011},
  month = jan,
  journal = {Scientific reports},
  volume = {1},
  pages = {100},
  issn = {2045-2322},
  doi = {10.1038/srep00100},
  abstract = {The "mind-brain supervenience" conjecture suggests that all mental properties are derived from the physical properties of the brain. To address the question of whether the mind supervenes on the brain, we frame a supervenience hypothesis in rigorous statistical terms. Specifically, we propose a modified version of supervenience (called {$\epsilon$}-supervenience) that is amenable to experimental investigation and statistical analysis. To illustrate this approach, we perform a thought experiment that illustrates how the probabilistic theory of pattern recognition can be used to make a one-sided determination of {$\epsilon$}-supervenience. The physical property of the brain employed in this analysis is the graph describing brain connectivity (i.e., the brain-graph or connectome). {$\epsilon$}-supervenience allows us to determine whether a particular mental property can be inferred from one's connectome to within any given positive misclassification rate, regardless of the relationship between the two. This may provide further motivation for cross-disciplinary research between neuroscientists and statisticians.},
  pmid = {22355618},
  keywords = {Brain,Brain: physiology,Humans,Mental Processes,Probability},
  file = {/Users/brownsarahm/Zotero/storage/HEQYQ7Q7/Vogelstein, Vogelstein, Priebe - 2011 - Are mental properties supervenient on brain properties(3).pdf}
}

@inproceedings{vonluxburg2005statistical,
  title = {Towards a Statistical Theory of Clustering},
  booktitle = {Pascal Workshop on Statistics and Optimization of Clustering},
  author = {Von Luxburg, Ulrike and {Ben-david}, Shai and Luxburg, Ulrike Von},
  year = {2005},
  pages = {20--26},
  doi = {10.1209/epl/i2004-10507-8},
  abstract = {The goal of this paper is to discuss statistical aspects of clus- tering in a framework where the data to be clustered has been sampled from some unknown probability distribution. Firstly, the clustering of the data set should reveal some structure of the underlying data rather than model artifacts due to the random sampling process. Secondly, the more sample points we have, the more reliable the clustering should be. We discuss which methods can and cannot be used to tackle those prob- lems. In particular we argue that generalization bounds as they are used in statistical learning theory of classification are unsuitable in a general clustering framework.We suggest that the main replacements of general- ization bounds should be convergence proofs and stability considerations. This paper should be considered as a roadmap paper which identifies im- portant questions and potentially fruitful directions for future research about statistical clustering. We do not attempt to present a complete statistical theory of clustering.},
  file = {/Users/brownsarahm/Zotero/storage/HLGEY6U2/von Luxburg, Ben-David - 2005 - Towards a statistical theory of clustering(2).pdf}
}

@article{vreeken2002spiking,
  title = {Spiking Neural Networks , an Introduction},
  author = {Vreeken, Jilles},
  year = {2002},
  journal = {Computing},
  volume = {7},
  number = {3},
  pages = {1--5},
  abstract = {Biological neurons use short and sudden increases in voltage to send information. These signals are more commonly known as action potentials, spikes or pulses. Recent neurological research has shown that neurons encode information in the timing of single spikes, and not only just in their average firing frequency. This paper gives an introduction to spiking neural networks, some biological background, and will present two models of spiking neurons that employ pulse coding. Networks of spiking neurons are more powerful than their non-spiking predecessors as they can encode temporal information in their signals, but therefore do also need different and biologically more plausible rules for synaptic plasticity.},
  file = {/Users/brownsarahm/Zotero/storage/9J5PEB9P/Vreeken - 2002 - Spiking neural networks , an introduction(3).pdf}
}

@article{wachter2017transparent,
  title = {Transparent, Explainable, and Accountable {{AI}} for Robotics},
  author = {Wachter, Sandra and Mittelstadt, Brent and Floridi, Luciano},
  year = {2017},
  journal = {Science Robotics},
  volume = {2},
  number = {6},
  eprint = {https://robotics.sciencemag.org/content/2/6/eaan6080.full.pdf},
  publisher = {Science Robotics},
  doi = {10.1126/scirobotics.aan6080},
  abstract = {To create fair and accountable AI and robotics, we need precise regulation and better methods to certify, explain, and audit inscrutable systems.},
  elocation-id = {eaan6080}
}

@article{wager2013fmribased,
  title = {An {{fMRI-based}} Neurologic Signature of Physical Pain.},
  author = {Wager, Tor D and Atlas, Lauren Y and {\noopsort{lindquist}}a Lindquist, Martin and Roy, Mathieu and Woo, Choong-Wan and Kross, Ethan},
  year = {2013},
  journal = {The New England journal of medicine},
  volume = {368},
  pages = {1388--97},
  issn = {1533-4406},
  doi = {10.1056/NEJMoa1204471},
  abstract = {BACKGROUND: Persistent pain is measured by means of self-report, the sole reliance on which hampers diagnosis and treatment. Functional magnetic resonance imaging (fMRI) holds promise for identifying objective measures of pain, but brain measures that are sensitive and specific to physical pain have not yet been identified.\${\textbackslash}backslash\$n\${\textbackslash}backslash\$nMETHODS: In four studies involving a total of 114 participants, we developed an fMRI-based measure that predicts pain intensity at the level of the individual person. In study 1, we used machine-learning analyses to identify a pattern of fMRI activity across brain regions--a neurologic signature--that was associated with heat-induced pain. The pattern included the thalamus, the posterior and anterior insulae, the secondary somatosensory cortex, the anterior cingulate cortex, the periaqueductal gray matter, and other regions. In study 2, we tested the sensitivity and specificity of the signature to pain versus warmth in a new sample. In study 3, we assessed specificity relative to social pain, which activates many of the same brain regions as physical pain. In study 4, we assessed the responsiveness of the measure to the analgesic agent remifentanil.\${\textbackslash}backslash\$n\${\textbackslash}backslash\$nRESULTS: In study 1, the neurologic signature showed sensitivity and specificity of 94\% or more (95\% confidence interval [CI], 89 to 98) in discriminating painful heat from nonpainful warmth, pain anticipation, and pain recall. In study 2, the signature discriminated between painful heat and nonpainful warmth with 93\% sensitivity and specificity (95\% CI, 84 to 100). In study 3, it discriminated between physical pain and social pain with 85\% sensitivity (95\% CI, 76 to 94) and 73\% specificity (95\% CI, 61 to 84) and with 95\% sensitivity and specificity in a forced-choice test of which of two conditions was more painful. In study 4, the strength of the signature response was substantially reduced when remifentanil was administered.\${\textbackslash}backslash\$n\${\textbackslash}backslash\$nCONCLUSIONS: It is possible to use fMRI to assess pain elicited by noxious heat in healthy persons. Future studies are needed to assess whether the signature predicts clinical pain. (Funded by the National Institute on Drug Abuse and others.).},
  pmid = {23574118},
  keywords = {Adult,Analgesics,Artificial Intelligence,Brain,Brain Mapping,Brain Mapping: methods,Brain: physiopathology,Female,Hot Temperature,Hot Temperature: adverse effects,Humans,Magnetic Resonance Imaging,Male,Opioid,Opioid: pharmacology,Opioid: therapeutic use,Pain,Pain Measurement,Pain Measurement: methods,Pain: etiology,Pain: physiopathology,Pain: psychology,Piperidines,Piperidines: pharmacology,Piperidines: therapeutic use,ROC Curve,Sensitivity and Specificity,Young Adult},
  file = {/Users/brownsarahm/Zotero/storage/7KYBKPLA/Wager et al. - 2013 - An fMRI-based neurologic signature of physical pain(6).pdf;/Users/brownsarahm/Zotero/storage/MLMN5QWF/Wager et al. - 2013 - An fMRI-based neurologic signature of physical pain(5).pdf}
}

@article{wagner2021Measuring,
  title = {Measuring Algorithmically Infused Societies},
  author = {Wagner, Claudia and Strohmaier, Markus and Olteanu, Alexandra and K{\i}c{\i}man, Emre and Contractor, Noshir and {Eliassi-Rad}, Tina},
  year = {2021},
  month = jul,
  journal = {Nature},
  volume = {595},
  number = {7866},
  pages = {197--204},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-021-03666-1},
  urldate = {2024-09-28},
  langid = {english},
  file = {/Users/brownsarahm/Zotero/storage/8HGM2FPB/Wagner et al. - 2021 - Measuring algorithmically infused societies.pdf}
}

@inproceedings{wagstaff2012machine,
  title = {Machine Learning That Matters},
  booktitle = {Proceedings of the 29th {{International Coference}} on {{International Conference}} on {{Machine Learning}}},
  author = {Wagstaff, Kiri L},
  year = {2012},
  pages = {1851--1856},
  file = {/Users/brownsarahm/Zotero/storage/MSRJ4379/Wagstaff - 2012 - Machine Learning that Matters(3).pdf}
}

@misc{wagstaff2012Machinea,
  title = {Machine {{Learning}} That {{Matters}}},
  author = {Wagstaff, Kiri},
  year = {2012},
  month = jun,
  number = {arXiv:1206.4656},
  eprint = {1206.4656},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2024-04-19},
  abstract = {Much of current machine learning (ML) research has lost its connection to problems of import to the larger world of science and society. From this perspective, there exist glaring limitations in the data sets we investigate, the metrics we employ for evaluation, and the degree to which results are communicated back to their originating domains. What changes are needed to how we conduct research to increase the impact that ML has? We present six Impact Challenges to explicitly focus the field?s energy and attention, and we discuss existing obstacles that must be addressed. We aim to inspire ongoing discussion and focus on ML that matters.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/brownsarahm/Zotero/storage/CWTYLLYR/Wagstaff - 2012 - Machine Learning that Matters.pdf;/Users/brownsarahm/Zotero/storage/FYUEFHPL/1206.html}
}

@article{wakslak2009effect,
  title = {The Effect of Construal Level on Subjective Probability Estimates},
  author = {Wakslak, Cheryl and Trope, Yaacov},
  year = {2009},
  journal = {Psychological Science},
  volume = {20},
  number = {1},
  pages = {52--58},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA}
}

@article{wald1945sequential,
  title = {Sequential Tests of Statistical Hypotheses},
  author = {Wald, Abraham and {Others}},
  year = {1945},
  journal = {Annals of Mathematical Statistics},
  volume = {16},
  number = {2},
  pages = {117--186},
  file = {/Users/brownsarahm/Zotero/storage/9XFHW5N5/Wald - 1945 - Sequential tests of statistical hypotheses(2).pdf}
}

@article{wald1948optimum,
  title = {Optimum Character of the Sequential Probability Ratio Test},
  author = {Wald, Abraham and Wolfowitz, Jacob and {Others}},
  year = {1948},
  journal = {The Annals of Mathematical Statistics},
  volume = {19},
  number = {3},
  pages = {326--339},
  file = {/Users/brownsarahm/Zotero/storage/BC565SVL/Wald, Wolfowitz - 1948 - Optimum character of the sequential probability ratio test(2).pdf}
}

@article{wallach2004conditional,
  title = {Conditional Random Fields: {{An}} Introduction},
  author = {Wallach, Hanna M},
  year = {2004},
  pages = {1--9},
  file = {/Users/brownsarahm/Zotero/storage/VWTMLEVC/Wallach - 2004 - Conditional random fields An introduction(3).pdf}
}

@article{wang2002simulationbased,
  title = {A Simulation-Based Approach to {{Bayesian}} Sample Size Determination for Performance under a given Model and for Separating Models},
  author = {Wang, Fei and Gelfand, Alan E.},
  year = {2002},
  month = may,
  journal = {Statistical Science},
  volume = {17},
  number = {2},
  pages = {193--208},
  doi = {10.1214/ss/1030550861},
  keywords = {and phrases,average posterior variance criterion,bayes factor,fitting and,likelihood and penalized likelihood,linear and generalized linear,models,random effects models,sampling priors,screening criterion},
  file = {/Users/brownsarahm/Zotero/storage/T8FA94S3/Wang, Gelfand - 2002 - A simulation-based approach to Bayesian sample size determination for performance under a given model and for (3).pdf}
}

@inproceedings{wang2006gaussian,
  title = {Gaussian Process Dynamical Models},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Wang, Jack and Fleet, David and Hertzmann, Aaron},
  year = {2006},
  doi = {10.1109/TPAMI.2007.1167},
  isbn = {978-1-4577-1102-2},
  pmid = {18084059},
  file = {/Users/brownsarahm/Zotero/storage/KBLM2MZS/Wang, Fleet, Hertzmann - 2006 - Gaussian process dynamical models(3).pdf}
}

@article{wang2009effective,
  title = {Effective {{Feature Selection}} on {{Data}} with {{Uncertain Labels}}},
  author = {Wang, Bo and Jia, Yan and Han, Yi and Han, Weihong},
  year = {2009},
  month = mar,
  journal = {2009 IEEE 25th International Conference on Data Engineering},
  pages = {1657--1662},
  issn = {1084-4627},
  doi = {10.1109/ICDE.2009.170},
  file = {/Users/brownsarahm/Zotero/storage/WZ3U3R9T/Wang et al. - 2009 - Effective Feature Selection on Data with Uncertain Labels(3).pdf}
}

@article{wang2009Human,
  ids = {wang2009Humana,wang2009Humanb},
  title = {Human Action Recognition by Semilatent Topic Models},
  author = {Wang, Yang and Mori, Greg},
  year = {2009},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  volume = {31},
  number = {10},
  pages = {1762--1774},
  publisher = {IEEE}
}

@article{wang2012empirical,
  title = {An {{Empirical Study}} on the {{Stability}} of {{Feature Selection}} for {{Imbalanced Software Engineering Data}}},
  author = {Wang, Huanjing and Khoshgoftaar, Taghi M. and Napolitano, Amri},
  year = {2012},
  journal = {2012 11th International Conference on Machine Learning and Applications},
  pages = {317--323},
  doi = {10.1109/ICMLA.2012.60},
  keywords = {feature ranking,imbal-,stability,subsample},
  file = {/Users/brownsarahm/Zotero/storage/3A647Z3Z/Wang, Khoshgoftaar, Napolitano - 2012 - An Empirical Study on the Stability of Feature Selection for Imbalanced Software Engineering (3).pdf}
}

@article{wang2013relationship,
  title = {The Relationship of Anatomical and Functional Connectivity to Resting-State Connectivity in Primate Somatosensory Cortex},
  author = {Wang, Zheng and Chen, Li Min and Negyessy, Laszlo and Friedman, Robert M and Mishra, Arabinda and Gore, John C and Roe, Anna W},
  year = {2013},
  journal = {Neuron},
  volume = {78},
  number = {6},
  pages = {1116--1126}
}

@article{wang2014finding,
  title = {Finding {{Patterns}} with a {{Rotten Core}} : {{Data Mining}} for {{Crime Series}} with {{Core Sets}}},
  author = {Wang, Tong and Rudin, Cynthia and Wagner, Daniel and Sevieri, Rich},
  year = {2014},
  journal = {Big Data},
  issn = {2167-6461},
  doi = {10.1089/big.2014.0021},
  abstract = {One of the most challenging problems facing crime analysts is that of identifying crime series, which are sets of crimes committed by the same individual or group. Detecting crime series can be an important step in predictive policing, as knowledge of a pattern can be of paramount importance toward finding the offenders or stopping the pattern. Currently, crime analysts detect crime series manually; our goal is to assist them by providing automated tools for discovering crime series from within a database of crimes. Our approach relies on a key hypothesis that each crime series possesses at least one core of crimes that are very similar to each other, which can be used to characterize the modus operandi (M.O.) of the criminal. Based on this assumption, as long as we find all of the cores in the database, we have found a piece of each crime series. We propose a subspace clustering method, where the subspace is the M.O. of the series. The method has three steps: We first construct a similarity graph to link crimes that are generally similar, second we find cores of crime using an integer linear programming approach, and third we construct the rest of the crime series by merging cores to form the full crime series. To judge whether a set of crimes is indeed a core, we consider both pattern-general similarity, which can be learned from past crime series, and pattern-specific similarity, which is specific to the M.O. of the series and cannot be learned. Our method can be used for general pattern detection beyond crime series detection, as cores exist for patterns in many domains.},
  keywords = {core sets,crime series detection,dense,pattern mining,similarity graph,subspace clustering},
  file = {/Users/brownsarahm/Zotero/storage/DB7SX65D/Wang et al. - 2014 - Finding Patterns with a Rotten Core Data Mining for Crime Series with Core Sets(3).pdf}
}

@article{wang2020interpret,
  ids = {wang2020Interpret},
  title = {Interpret Neural Networks by Extracting Critical Subnetworks},
  author = {Wang, Yulong and Su, Hang and Zhang, Bo and Hu, Xiaolin},
  year = {2020},
  journal = {IEEE Transactions on Image Processing},
  volume = {29},
  pages = {6707--6720},
  publisher = {IEEE}
}

@inproceedings{wang2021local,
  title = {A Local Similarity-Preserving Framework for Nonlinear Dimensionality Reduction with Neural Networks},
  booktitle = {Database Systems for Advanced Applications: 26th International Conference, {{DASFAA}} 2021, Taipei, Taiwan, April 11--14, 2021, Proceedings, Part {{II}} 26},
  author = {Wang, Xiang and Li, Xiaoyong and Zhu, Junxing and Xu, Zichen and Ren, Kaijun and Zhang, Weiming and Liu, Xinwang and Yu, Kui},
  year = {2021},
  pages = {376--391},
  publisher = {Springer}
}

@article{wangpreliminary,
  title = {A Preliminary, Large-Scale Evaluation of the Collaborative Potential of Human and Machine Creativity},
  author = {Wang, Dawei and Huang, Difang and Shen, Haipeng and Uzzi, Brian},
  publisher = {Center for Open Science},
  doi = {10.31234/osf.io/xeh64}
}

@article{watanabemultisite,
  title = {Multisite {{Disease Classification}} with {{Functional Connectomes}} via {{Multitask Structured Sparse SVM}}},
  author = {Watanabe, Takanori and Kessler, Daniel and Scott, Clayton and Sripada, Chandra},
  pages = {1--9},
  keywords = {alternating direction method,chine,multitask learning,resting-state fmri,structured sparsity,support vector ma-},
  file = {/Users/brownsarahm/Zotero/storage/RMBSRDTF/Watanabe et al. - Unknown - Multisite Disease Classification with Functional Connectomes via Multitask Structured Sparse SVM(3).pdf}
}

@article{weathers1999psychometric,
  title = {Psychometric Properties of Nine Scoring Rules for the {{Clinician-Administered Posttraumatic Stress Disorder Scale}}.},
  author = {Weathers, Frank W. and Ruscio, Ayelet Meron and Keane, Terence M.},
  year = {1999},
  journal = {Psychological Assessment},
  volume = {11},
  number = {2},
  pages = {124--133},
  issn = {1040-3590},
  doi = {10.1037//1040-3590.11.2.124},
  file = {/Users/brownsarahm/Zotero/storage/PMCLVWRW/Weathers, Ruscio, Keane - 1999 - Psychometric properties of nine scoring rules for the Clinician-Administered Posttraumatic Stress Di(3).pdf}
}

@article{weathers2001clinicianadministered,
  title = {Clinician-{{Administered PTSD Scale}}: {{A}} Review of the First Ten Years of Research},
  author = {Weathers, Frank W and Keane, Terence M and Davidson, Jonathan R T},
  year = {2001},
  journal = {Depression and anxiety},
  volume = {13},
  number = {3},
  pages = {132--156},
  keywords = {assessment,diagnosis,in 1990 at the,national center,posttraumatic stress disorder,reliability,s ince its development,structured interview,validity},
  file = {/Users/brownsarahm/Zotero/storage/FL8FTHNV/First, Years - 2001 - Review Article(2).pdf}
}

@inproceedings{webb2011physiological,
  title = {Physiological {{Correlates}} of {{Emotional State}}},
  booktitle = {{{HCI International}} 2011--{{Posters}}' {{Extended Abstracts}}},
  author = {Webb, {\relax AK} and Cunha, {\relax MG} and Prakash, {\relax SR} and Irvine, {\relax JM}},
  year = {2011},
  pages = {332--336},
  keywords = {affect,emotion,psychophysiology},
  file = {/Users/brownsarahm/Zotero/storage/358B9L3S/Webb et al. - 2011 - Physiological Correlates of Emotional State(3).pdf}
}

@article{webb2013wearable,
  title = {Wearable Sensors Can Assist in {{PTSD}} Diagnosis},
  author = {Webb, Andrea K and Vincent, Ashley L. and Jin, Alvin and Pollack, Mark H.},
  year = {2013},
  month = may,
  journal = {2013 IEEE International Conference on Body Sensor Networks},
  pages = {1--6},
  doi = {10.1109/BSN.2013.6575525},
  keywords = {classification accuracy,feature extraction,physiological sensors,ptsd},
  file = {/Users/brownsarahm/Zotero/storage/FL7TKMG4/Webb et al. - 2013 - Wearable sensors can assist in PTSD diagnosis(5).pdf;/Users/brownsarahm/Zotero/storage/VGPNVNCM/Webb et al. - 2013 - Wearable sensors can assist in PTSD diagnosis(6).pdf}
}

@article{webb2015physiological,
  title = {Physiological Reactivity to Nonideographic Virtual Reality Stimuli in Veterans with and without {{PTSD}}.},
  author = {Webb, Andrea K and Vincent, Ashley L and Jin, Alvin B and Pollack, Mark H},
  year = {2015},
  month = feb,
  journal = {Brain and behavior},
  volume = {5},
  number = {2},
  pages = {e00304},
  issn = {2162-3279},
  doi = {10.1002/brb3.304},
  abstract = {BACKGROUND: Post-traumatic stress disorder (PTSD) currently is diagnosed via clinical interview in which subjective self reports of traumatic events and associated experiences are discussed with a mental health professional. The reliability and validity of diagnoses can be improved with the use of objective physiological measures. METHODS: In this study, physiological activity was recorded from 58 male veterans (PTSD Diagnosis n = 16; Trauma Exposed/No PTSD Diagnosis: n = 23; No Trauma/No PTSD Diagnosis: n = 19) with and without PTSD and combat trauma exposure in response to emotionally evocative non-idiographic virtual reality stimuli. RESULTS: Statistically significant differences among the Control, Trauma, and PTSD groups were present during the viewing of two virtual reality videos. Skin conductance and interbeat interval features were extracted for each of ten video events (five events of increasing severity per video). These features were submitted to three stepwise discriminant function analyses to assess classification accuracy for Control versus Trauma, Control versus PTSD, and Trauma versus PTSD pairings of participant groups. Leave-one-out cross-validation classification accuracy was between 71 and 94\%. CONCLUSIONS: These results are promising and suggest the utility of objective physiological measures in assisting with PTSD diagnosis.},
  pmid = {25642387},
  keywords = {classification,conductance,diagnosis,interbeat interval,post-traumatic stress disorder,skin},
  file = {/Users/brownsarahm/Zotero/storage/FQ5HZEFY/Webb et al. - 2015 - Physiological reactivity to nonideographic virtual reality stimuli in veterans with and without PTSD(3).pdf}
}

@article{weierich2010novelty,
  title = {Novelty as a Dimension in the Affective Brain},
  author = {Weierich, Mariann R. and Wright, Christopher I. and Negreira, Alyson and Dickerson, Brad C. and Barrett, Lisa Feldman},
  year = {2010},
  journal = {Neuroimage},
  volume = {49},
  number = {3},
  pages = {2871--2878},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2009.09.047},
  abstract = {Many neuroscience studies have demonstrated that the human amygdala is a central element in the neural workspace that computes affective value. Emerging evidence suggests that novelty is an affective dimension that engages the amygdala independently of other affective properties. This current study is the first in which novelty, valence, and arousal were systematically examined for their relative contributions to amygdala activation during affective processing. Healthy young adults viewed International Affective Picture System (IAPS) images that varied along the dimensions of valence (positive, negative, neutral), arousal (high, mid, low), and novelty (novel, familiar). The results demonstrate that, in comparison to negative (vs. positive) and high (vs. low) arousal stimuli, the amygdala has higher peak responses and a selectively longer time course of activation to novel (vs. familiar) stimuli. In addition, novelty differentially engaged other affective brain areas including those involved in controlling and regulating amygdala responses (e.g., orbitofrontal cortex), as well as those transmitting sensory signals that the amygdala modulates (e.g., occipitotemporal visual cortex). Taken together with other findings, these results support the idea that an essential amygdala function is signaling stimulus importance or salience. The results also suggest that novelty is a critical stimulus dimension for amygdala engagement (in addition to valence and arousal). ?? 2009 Elsevier Inc. All rights reserved.},
  pmid = {19796697},
  keywords = {Affect,Amygdala,Emotion,fMRI,Neuroimaging,Novelty},
  file = {/Users/brownsarahm/Zotero/storage/WAB4IMNR/Weierich et al. - 2010 - Novelty as a dimension in the affective brain(3).pdf}
}

@article{weiss2000correctness,
  title = {Correctness of Local Probability in Graphical Models with Loops.},
  author = {Weiss, Y},
  year = {2000},
  journal = {Neural computation},
  volume = {12},
  pages = {1--41},
  issn = {0899-7667},
  doi = {10.1162/089976600300015880},
  abstract = {Graphical models, such as Bayesian networks and Markov networks, represent joint distributions over a set of variables by means of a graph. When the graph is singly connected, local propagation rules of the sort proposed by Pearl (1988) are guaranteed to converge to the correct posterior probabilities. Recently a number of researchers have empirically demonstrated good performance of these same local propagation schemes on graphs with loops, but a theoretical understanding of this performance has yet to be achieved. For graphical models with a single loop, we derive an analytical relationship between the probabilities computed using local propagation and the correct marginals. Using this relationship we show a category of graphical models with loops for which local propagation gives rise to provably optimal maximum a posteriori assignments (although the computed marginals will be incorrect). We also show how nodes can use local information in the messages they receive in order to correct their computed marginals. We discuss how these results can be extended to graphical models with multiple loops and show simulation results suggesting that some properties of propagation on single-loop graphs may hold for a larger class of graphs. Specifically we discuss the implication of our results for understanding a class of recently proposed error-correcting codes known as turbo codes.},
  pmid = {10636932},
  file = {/Users/brownsarahm/Zotero/storage/WFK6UR2F/Weiss - 2000 - Correctness of local probability in graphical models with loops(3).pdf}
}

@article{werker1984crosslanguage,
  title = {Cross-Language Speech-Perception - Evidence for Perceptual Reorganization during the 1st Year of Life},
  author = {Werker, Janet F and Tees, Richard C and {Anonymous}},
  year = {1984},
  journal = {Infant Behav Dev Infant Behav Dev},
  volume = {7},
  number = {1},
  pages = {49--63},
  issn = {0163-6383},
  doi = {Doi 10.1016/S0163-6383(84)80022-3},
  abstract = {Previous work in which we compared English infants, English adults, and Hindi adults on their ability to discriminate two pairs of Hindi (non-English) speech contrasts has indicated that infants discriminate speech sounds according to phonetic category without prior specific language experience (Werker, Gilbert, Humphrey, \& Tees, 1981), whereas adults and children as young as age 4 (Werker \& Tees, in press) may lose this ability as a function of age and or linguistic experience. The present work was designed to (a) determine the generalisability of such a decline by comparing adult English adult Salish, and English infant subjects on their perception of a new non-English (Salish) speech contrast, and (b) delineate the time course of the developmental decline in this ability. The results of these experiments replicate our original finding by showing that infants can discriminate nonnative speech contrasts without relevant experience, and that there is a decline in that ability during ontogeny. Furthermore, data from both cross-sectional and longitudinal studies shows that this decline occurs within the first year of life, and that it is a function of specific language experience.},
  pmid = {341},
  keywords = {infancy,Language,phonemes,speech sounds},
  file = {/Users/brownsarahm/Zotero/storage/DJC8F8VW/Werker, Tees, Anonymous - 1984 - Cross-language speech-perception - evidence for perceptual reorganization during the 1st year of lif(3).pdf}
}

@incollection{werner2009emotion,
  title = {Emotion Regulation and Psychopathology: {{A}} Conceptual Framework.},
  booktitle = {Emotion {{Regulation}} and {{Psychopathology}}: A Transdiagnostic Approach to Etiology and Treatment},
  author = {Werner, K and Gross, {\relax JJ}},
  editor = {Kring, Ann M and Sloan, Denise M.},
  year = {2009},
  pages = {13--37},
  publisher = {The Guilford Press},
  isbn = {1-60623-450-1},
  file = {/Users/brownsarahm/Zotero/storage/A4TPAEXU/Werner, Gross - 2009 - Emotion regulation and psychopathology A conceptual framework(3).pdf}
}

@article{wexler2019if,
  title = {The What-If Tool: {{Interactive}} Probing of Machine Learning Models},
  author = {Wexler, James and Pushkarna, Mahima and Bolukbasi, Tolga and Wattenberg, Martin and Vi{\'e}gas, Fernanda and Wilson, Jimbo},
  year = {2019},
  journal = {IEEE transactions on visualization and computer graphics},
  volume = {26},
  number = {1},
  pages = {56--65},
  publisher = {IEEE}
}

@article{whalen1998masked,
  title = {Masked Presentations of Emotional Facial Expressions Modulate Amygdala Activity without Explicit Knowledge},
  author = {Whalen, Paul J and Rauch, Scott L and Etcoff, Nancy L and McInerney, Sean C and Lee, Michael B and Jenike, Michael A},
  year = {1998},
  journal = {The Journal of neuroscience},
  volume = {18},
  number = {1},
  pages = {411--418},
  file = {/Users/brownsarahm/Zotero/storage/VS5GZC54/Whalen et al. - 1998 - Masked presentations of emotional facial expressions modulate amygdala activity without explicit knowledge(3).pdf}
}

@article{whitacre2010degeneracy,
  title = {Degeneracy: A Design Principle for Achieving Robustness and Evolvability},
  author = {Whitacre, J and Bender, A},
  year = {2010},
  journal = {Journal of Theoretical Biology},
  volume = {263},
  number = {1},
  pages = {143--153}
}

@article{white2020fairness,
  title = {Fairness of {{AI}} for People with Disabilities: Problem Analysis and Interdisciplinary Collaboration},
  author = {White, Jason JG},
  year = {2020},
  month = mar,
  journal = {ACM SIGACCESS Accessibility and Computing},
  number = {125},
  pages = {1--1},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {1558-2337},
  doi = {10.1145/3386296.3386299},
  articleno = {3},
  issue_date = {October 2019}
}

@article{whitney1971direct,
  title = {A Direct Method of Nonparametric Measurement Selection},
  author = {Whitney, {\relax AW}},
  year = {1971},
  journal = {Computers, IEEE Transactions on},
  volume = {6},
  number = {September},
  pages = {1100--1103},
  file = {/Users/brownsarahm/Zotero/storage/44X3ABFY/Whitney - 1971 - A direct method of nonparametric measurement selection(3).pdf}
}

@inproceedings{wick2019unlocking,
  title = {Unlocking Fairness: A Trade-off Revisited},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Wick, Michael and Tristan, Jean-Baptiste and others},
  year = {2019},
  volume = {32},
  pages = {8780--8789},
  publisher = {Curran Associates, Inc.},
  address = {Vancouver, Canada}
}

@article{wiggins2019replication,
  title = {The Replication Crisis in Psychology: {{An}} Overview for Theoretical and Philosophical Psychology.},
  author = {Wiggins, Bradford J and Chrisopherson, Cody D},
  year = {2019},
  journal = {Journal of Theoretical and Philosophical Psychology},
  volume = {39},
  number = {4},
  pages = {202},
  publisher = {Educational Publishing Foundation}
}

@article{williamson2004dynamic,
  title = {A Dynamic Interaction between Machine Learning and the Philosophy of Science},
  author = {Williamson, J.},
  year = {2004},
  pages = {539--549},
  issn = {0924-6495},
  doi = {10.1023/B:MIND.0000045990.57744.2b},
  abstract = {The relationship between machine learning and the philosophy of science can be classed as a dynamic interaction: a mutually beneficial connection between two autonomous fields that changes direction over time. I discuss the nature of this interaction and give a case study highlighting interactions between research on Bayesian networks in machine learning and research on causality and probability in the philosophy of science.},
  keywords = {B Philosophy (General)},
  file = {/Users/brownsarahm/Zotero/storage/C33WKJ53/Williamson - 2004 - A dynamic interaction between machine learning and the philosophy of science(3).pdf}
}

@article{williamson2010philosophy,
  title = {The Philosophy of Science and Its Relation to Machine Learning},
  author = {Williamson, Jon},
  year = {2010},
  journal = {Scientific Data Mining and Knowledge Discovery},
  pages = {1--14},
  file = {/Users/brownsarahm/Zotero/storage/BRHGRYXZ/Williamson - 2010 - The philosophy of science and its relation to machine learning(3).pdf}
}

@article{wilson-mendenhall2011grounding,
  title = {Grounding Emotion in Situated Conceptualization},
  author = {{Wilson-Mendenhall}, C.D. and Barrett, Lisa Feldman and Simmons, Kyle W. and Barsalou, Lawrence W.},
  year = {2011},
  journal = {Neuropsychologia},
  volume = {49},
  number = {5},
  pages = {1105--1127}
}

@article{wilson-mendenhall2014variety,
  title = {Variety in Emotional Life: {{Within-category}} Typicality of Emotional Experiences Is Associated with Neural Activity in Large-Scale Brain Networks},
  author = {{Wilson-Mendenhall}, Christine D. and Barrett, Lisa Feldman and Barsalou, Lawrence W.},
  year = {2014},
  journal = {Social cognitive and affective neuroscience},
  volume = {nsu037}
}

@article{wilson2010functional,
  title = {Functional Localization within the Prefrontal Cortex: Missing the Forest for the Trees?},
  author = {Wilson, Charles R E and Gaffan, David and Browning, Philip G F and Baxter, Mark G},
  year = {2010},
  journal = {Trends in neurosciences},
  volume = {33},
  number = {12},
  pages = {533--540}
}

@book{wilson2019Teaching,
  ids = {wilson2019Teachinga},
  title = {Teaching {{Tech Together}}: {{How}} to {{Make}} Your Lessons Work and Build a Teaching Community around Them},
  author = {Wilson, Greg},
  year = {2019},
  publisher = {CRC Press}
}

@article{winsberg2009computer,
  title = {Computer {{Simulation}} and the {{Philosophy}} of {{Science}}},
  author = {Winsberg, Eric},
  year = {2009},
  journal = {Philosophy Compass},
  volume = {4},
  number = {5},
  pages = {835--845},
  issn = {17479991},
  doi = {10.1111/j.1747-9991.2009.00236.x},
  abstract = {There are a variety of topics in the philosophy of science that need to be rethought, in varying degrees, after one pays careful attention to the ways in which computer simulations are used in the sciences. There are a number of conceptual issues internal to the practice of computer simula- tion that can benefit from the attention of philosophers. This essay surveys some of the recent lit- erature on simulation from the perspective of the philosophy of science and argues that philosophers have a lot to learn by paying closer attention to the practice of simulation.},
  file = {/Users/brownsarahm/Zotero/storage/VJ7HQVR2/Winsberg - 2009 - Computer Simulation and the Philosophy of Science.pdf}
}

@article{winzeler1998direct,
  title = {Direct Allelic Variation Scanning of the Yeast Genome.},
  author = {{\noopsort{winzeler}}a Winzeler, E and Richards, D R and Conway, a R and Goldstein, a L and Kalman, S and McCullough, M J and McCusker, J H and {\noopsort{stevens}}a Stevens, D and Wodicka, L and Lockhart, D J and Davis, R W},
  year = {1998},
  journal = {Science (New York, N.Y.)},
  volume = {281},
  number = {August},
  pages = {1194--1197},
  issn = {0036-8075},
  doi = {10.1126/science.281.5380.1194},
  abstract = {As more genomes are sequenced, the identification and characterization of the causes of heritable variation within a species will be increasingly important. It is demonstrated that allelic variation in any two isolates of a species can be scanned, mapped, and scored directly and efficiently without allele-specific polymerase chain reaction, without creating new strains or constructs, and without knowing the specific nature of the variation. A total of 3714 biallelic markers, spaced about every 3.5 kilobases, were identified by analyzing the patterns obtained when total genomic DNA from two different strains of yeast was hybridized to high-density oligonucleotide arrays. The markers were then used to simultaneously map a multidrug-resistance locus and four other loci with high resolution (11 to 64 kilobases).},
  pmid = {9712584},
  file = {/Users/brownsarahm/Zotero/storage/P63I8HLE/Winzeler et al. - 1998 - Direct allelic variation scanning of the yeast genome(3).pdf}
}

@article{woo2014separate,
  title = {Separate Neural Representations for Physical Pain and Social Rejection},
  author = {Woo, Choong-Wan and Koban, Leonie and Kross, Ethan and Lindquist, Martin A and Banich, Marie T and Ruzic, Luka and {Andrews-Hanna}, Jessica R and Wager, Tor D},
  year = {2014},
  journal = {Nature communications},
  volume = {5}
}

@book{word2021Carpentries,
  title = {The {{Carpentries}}: {{Instructor Training}}},
  editor = {Word, Karen and Brown, Sarah and Dennis, Tim and Barnes, Kelly Anne},
  year = {2021},
  month = jun,
  isbn = {https://doi.org/10.5281/zenodo.5709383}
}

@misc{word2022Carpentries,
  title = {The {{Carpentries Instructor Training}}},
  author = {Word,, Karen},
  year = {2022}
}

@article{wright2008neural,
  title = {Neural Correlates of Novelty and Face--Age Effects in Young and Elderly Adults},
  author = {Wright, Christopher I and Negreira, Alyson and Gold, Andrea L and Britton, Jennifer C and Williams, Danielle and Barrett, Lisa Feldman},
  year = {2008},
  journal = {Neuroimage},
  volume = {42},
  number = {2},
  pages = {956--968}
}

@inproceedings{wu2017towards,
  title = {Towards a Bayesian Model of Data Visualization Cognition},
  booktitle = {{{DECISIVe}}: {{Workshop}} on Dealing with Cognitive Biases in Visualizations. {{IEEE VIS}}},
  author = {Wu, Yifan and Xu, Larry and Chang, Remco and Wu, Eugene},
  year = {2017}
}

@article{xing2010brief,
  title = {A Brief Survey on Sequence Classification},
  author = {Xing, Zhengzheng and Pei, Jian and Keogh, Eamonn},
  year = {2010},
  month = nov,
  journal = {ACM SIGKDD Explorations Newsletter},
  volume = {12},
  number = {1},
  pages = {40},
  issn = {19310145},
  doi = {10.1145/1882471.1882478},
  file = {/Users/brownsarahm/Zotero/storage/LFMVRHR7/Xing, Pei, Keogh - 2010 - A brief survey on sequence classification(3).pdf}
}

@article{xu2002language,
  title = {Language and Conceptual Development: {{Words}} as Essence Placeholders},
  author = {Xu, Fei},
  year = {2002},
  journal = {Behavioral and Brain Sciences},
  volume = {25},
  number = {06},
  pages = {704--705}
}

@article{xu2012role,
  title = {The Role of Language in Acquiring Object Kind Concepts in Infancy},
  author = {Xu, Fei},
  year = {2012},
  journal = {Cognition},
  pages = {223--250}
}

@article{xu2017deep,
  ids = {xu2017Deep},
  title = {Deep Learning Based Regression and Multiclass Models for Acute Oral Toxicity Prediction with Automatic Chemical Feature Extraction},
  author = {Xu, Youjun and Pei, Jianfeng and Lai, Luhua},
  year = {2017},
  journal = {Journal of chemical information and modeling},
  volume = {57},
  number = {11},
  pages = {2672--2685},
  publisher = {ACS Publications}
}

@article{xu2018detecting,
  title = {Detecting {{Simpson}}'s {{Paradox}}},
  author = {Xu, Chenguang and Brown, Sarah M and Grant, Christan},
  year = {2018},
  journal = {AAAI},
  copyright = {All rights reserved}
}

@inproceedings{yan2020silva,
  title = {Silva: {{Interactively}} Assessing Machine Learning Fairness Using Causality},
  booktitle = {Proceedings of the 2020 {{CHI}} Conference on Human Factors in Computing Systems},
  author = {Yan, Jing Nathan and Gu, Ziwei and Lin, Hubert and Rzeszotarski, Jeffrey M},
  year = {2020},
  pages = {1--13}
}

@inproceedings{yang1999data,
  title = {Data {{Visualization}} and {{Feature Selection}}: {{New Algorithms}} for {{Nongaussian Data}}},
  booktitle = {{{NIPS}}},
  author = {Yang, {\relax HH} and Moody, {\relax JE}},
  year = {1999},
  pages = {687--702},
  keywords = {classi cation,feature selection,ica,joint mutual information,sualization,vi-},
  file = {/Users/brownsarahm/Zotero/storage/VU5X9FDL/Yang, Moody - 1999 - Data Visualization and Feature Selection New Algorithms for Nongaussian Data(3).pdf}
}

@article{yang2018grounding,
  title = {Grounding {{Interactive Machine Learning Tool Design}} in {{How Non}} - {{Experts Actually Build Models}}},
  author = {Yang, Qian and Suh, Jina and Chen, Nan-Chen and Ramos, Gonzalo},
  year = {2018},
  number = {March},
  doi = {10.1145/3196709.3196729},
  abstract = {See, stats, and : https : / / www . researchgate . net / publication / 324069323 Grounding Design - Experts Models Conference DOI : 10 . 1145 / 3196709 . 3196729 CITATIONS 0 READS 78 4 , including : Some : CORA : Cardiac UW - TextVis Qian Carnegie 14 SEE Jina University 9 SEE All . The . ABSTRACT Machine learning (ML) promises data - driven insights and solutions for people from all walks of life , but the skill of crafting these solutions is possessed by only a few . Emerging research addresses this issue by creating ML tools that are easy and accessible to people who are not formally trained in ML (" non - experts ") . This work investigated how non - experts build ML solutions for themselves in real life . Our interviews and surveys revealed unique potentials of non - expert ML , as well several pitfalls that non - experts are susceptible to . For example , many perceived percentage accuracy as a sole measure of performance , thus problematic models proceeded to deployment . These observations suggested that , while challenging , making ML easy and robust should both be important goals of designing novice - facing ML tools . To advance on this insight , we discuss design implications and created a sensitizing concept to demonstrate how designers might guide non - experts to easily build robust solutions .},
  keywords = {Empirical Study,End - user Machine Learning,Machine Teaching,Sensitizing Concept,User - Centered Design},
  file = {/Users/brownsarahm/Zotero/storage/G67NTKJP/Yang et al. - 2018 - Grounding Interactive Machine Learning Tool Design in How Non - Experts Actually Build Models.pdf}
}

@inproceedings{yang2018nutritional,
  title = {A Nutritional Label for Rankings},
  booktitle = {Proceedings of the 2018 International Conference on Management of Data},
  author = {Yang, Ke and Stoyanovich, Julia and Asudeh, Abolfazl and Howe, Bill and Jagadish, {\relax HV} and Miklau, Gerome},
  year = {2018},
  pages = {1773--1776}
}

@article{yarkoni2009big,
  title = {Big Correlations in Little Studies: {{Inflated fMRI}} Correlations Reflect Low Statistical Power---{{Commentary}} on {{Vul}} et al.(2009)},
  author = {Yarkoni, Tal},
  year = {2009},
  journal = {Perspectives on Psychological Science},
  volume = {4},
  number = {3},
  pages = {294--298}
}

@article{yeh2020completeness,
  ids = {yeh2020Completenessaware},
  title = {On Completeness-Aware Concept-Based Explanations in Deep Neural Networks},
  author = {Yeh, Chih-Kuan and Kim, Been and Arik, Sercan and Li, Chun-Liang and Pfister, Tomas and Ravikumar, Pradeep},
  year = {2020},
  journal = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {20554--20565}
}

@article{yeo2011organization,
  title = {The Organization of the Human Cerebral Cortex Estimated by Intrinsic Functional Connectivity},
  author = {Yeo, Btt T Thomas and Krienen, Fenna M Fm and Sepulcre, Jorge and Sabuncu, Mert R and Lashkari, Danial and Hollinshead, Marisa and Roffman, Joshua L and Smoller, Jordan W and Z{\"o}llei, Lilla and Polimeni, Jonathan R and {Others}},
  year = {2011},
  journal = {Journal of neurophysiology},
  volume = {106},
  number = {3},
  pages = {1125--1165},
  doi = {10.1152/jn.00338.2011.},
  file = {/Users/brownsarahm/Zotero/storage/7DN893K4/Yeo, Krienen - 2011 - The organization of the human cerebral cortex estimated by intrinsic functional connectivity(2).pdf}
}

@article{yetime,
  title = {Time {{Series Shapelets}} : {{A New Primitive}} for {{Data Mining}}},
  author = {Ye, Lexiang},
  file = {/Users/brownsarahm/Zotero/storage/UC63AF9Z/Ye - Unknown - Time Series Shapelets A New Primitive for Data Mining(3).pdf}
}

@article{yoshino2010sadness,
  title = {Sadness Enhances the Experience of Pain via Neural Activation in the Anterior Cingulate Cortex and Amygdala: {{An fMRI}} Study},
  author = {Yoshino, Atsuo and Okamoto, Yasumasa and Onoda, Keiichi and Yoshimura, Shinpei and Kunisato, Yoshihiko and Demoto, Yoshihiko and Okada, Go and Yamawaki, Shigeto},
  year = {2010},
  journal = {NeuroImage},
  volume = {50},
  number = {3},
  pages = {1194--1201},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2009.11.079},
  abstract = {Pain is a multidimensional experience. Human pain perception can be modulated by subjective emotional responses. We examined this association within the context of a neuroimaging study, using functional MRI to examine neural responses to electrical pain-inducing stimuli in 15 healthy subjects (6 females; age range = 20-30??years). Pain-inducing stimuli were presented during different emotional contexts, which were induced via the continuous presentation (5??s) of sad, happy, or neutral pictures of faces. We found that subjective pain ratings were higher in the sad emotional context than in the happy and neutral contexts, and that pain-related activation in the ACC was more pronounced in the sad context relative to the happy and neutral contexts. Psychophysiological interaction (PPI) and dynamic causal modeling (DCM) analyses demonstrated amygdala to ACC connections during the experience of pain in the sad context. These findings serve to highlight the neural mechanisms that may be relevant to understanding the broader relationship between somatic complaints and negative emotion. ?? 2009 Elsevier Inc. All rights reserved.},
  pmid = {19969094},
  file = {/Users/brownsarahm/Zotero/storage/X4J7MTTJ/Yoshino et al. - 2010 - Sadness enhances the experience of pain via neural activation in the anterior cingulate cortex and amygdala A(3).pdf}
}

@article{young2021call,
  title = {A Call for Scholar Activism},
  author = {Young, Meg and Krafft, {\relax PM} and Katell, Michael A},
  year = {2021},
  journal = {AI Activism},
  volume = {28},
  pages = {43}
}

@inproceedings{yu2008stable,
  title = {Stable Feature Selection via Dense Feature Groups},
  booktitle = {Proceeding of the 14th {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining - {{KDD}} 08},
  author = {Yu, Lei and Ding, Chris and Loscalzo, Steven and Yu, Lei and Ding, Chris and Ding, Chris and Loscalzo, Steven and Loscalzo, Steven},
  year = {2008},
  pages = {803},
  publisher = {ACM Press},
  address = {New York, New York, USA},
  doi = {10.1145/1401890.1401986},
  abstract = {Many feature selection algorithms have been proposed in the past focusing on improving classification accuracy. In this work, we point out the importance of stable feature selection for knowledge discovery from high-dimensional data, and identify two causes of instability of feature selection algorithms: selection of a minimum subset without redundant features and small sample size. We propose a general framework for stable feature selection which emphasizes both good generalization and stability of feature selection results. The framework identifies dense feature groups based on kernel density estimation and treats features in each dense group as a coherent entity for feature selection. An efficient algorithm DRAGS (Dense Relevant Attribute Group Selector) is developed under this framework. We also introduce a general measure for assessing the stability of feature selection algorithms. Our empirical study based on microarray data verifies that dense feature groups remain stable under random sample hold out, and the DRAGS algorithm is effective in identifying a set of feature groups which exhibit both high classification accuracy and stability.},
  isbn = {978-1-60558-193-4},
  keywords = {classification,density estimation,feature selection,high-dimensional data,kernel,stability},
  file = {/Users/brownsarahm/Zotero/storage/7SQAQY69/Yu, Ding, Loscalzo - 2008 - Stable feature selection via dense feature groups(2).pdf}
}

@inproceedings{yu2020keeping,
  title = {Keeping Designers in the Loop: {{Communicating}} Inherent Algorithmic Trade-Offs across Multiple Objectives},
  booktitle = {Proceedings of the 2020 {{ACM}} Designing Interactive Systems Conference},
  author = {Yu, Bowen and Yuan, Ye and Terveen, Loren and Wu, Zhiwei Steven and Forlizzi, Jodi and Zhu, Haiyi},
  year = {2020},
  pages = {1245--1257}
}

@inproceedings{zafar2017fairness,
  title = {Fairness {{Constraints}}: {{Mechanisms}} for {{Fair Classification}}},
  booktitle = {Proceedings of the 20th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Zafar, Muhammad Bilal and Valera, Isabel and Rogriguez, Manuel Gomez and Gummadi, Krishna P},
  editor = {Singh, Aarti and Zhu, Jerry},
  year = {2017},
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {54},
  pages = {962--970},
  publisher = {PMLR},
  address = {Fort Lauderdale, FL, USA},
  abstract = {Algorithmic decision making systems are ubiquitous across a wide variety of online as well as offline services. These systems rely on complex learning methods and vast amounts of data to optimize the service functionality, satisfaction of the end user and profitability. However, there is a growing concern that these automated decisions can lead, even in the absence of intent, to a lack of fairness, i.e., their outcomes can disproportionately hurt (or, benefit) particular groups of people sharing one or more sensitive attributes (e.g., race, sex). In this paper, we introduce a flexible mechanism to design fair classifiers by leveraging a novel intuitive measure of decision boundary (un)fairness. We instantiate this mechanism with two well-known classifiers, logistic regression and support vector machines, and show on real-world data that our mechanism allows for a fine-grained control on the degree of fairness, often at a small cost in terms of accuracy.}
}

@article{zafar2019fairness,
  title = {Fairness Constraints: {{A}} Flexible Approach for Fair Classification.},
  author = {Zafar, Muhammad Bilal and Valera, Isabel and {Gomez-Rodriguez}, Manuel and Gummadi, Krishna P},
  year = {2019},
  journal = {Journal of Machine Learning Research},
  volume = {20},
  number = {75},
  pages = {1--42}
}

@article{zakharov2011ensemble,
  title = {Ensemble Logistic Regression for Feature Selection},
  author = {Zakharov, Roman and Dupont, Pierre},
  year = {2011},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {7036 LNBI},
  pages = {133--144},
  issn = {03029743},
  doi = {10.1007/978-3-642-24855-9_12},
  abstract = {This paper describes a novel feature selection algorithm embedded into logistic regression. It specifically addresses high dimensional data with few observations, which are commonly found in the biomedical domain such as microarray data. The overall objective is to optimize the predictive performance of a classifier while favoring also sparse and stable models. Feature relevance is first estimated according to a simple t-test ranking. This initial feature relevance is treated as a feature sampling probability and a multivariate logistic regression is iteratively reestimated on subsets of randomly and non-uniformly sampled features. At each iteration, the feature sampling probability is adapted according to the predictive performance and the weights of the logistic regression. Globally,the proposed selection method can be seen as an ensemble of logistic regression models voting jointly for the final relevance of features. Practical experiments reported on several microarray datasets show that the proposed method offers a comparable or better stability and significantly better predictive performances than logistic regression regularized with Elastic Net. It also outperforms a selection based on Random Forests, another popular embedded feature selection from an ensemble of classifiers.},
  keywords = {logistic regression,microarray data classification,stability of gene selection},
  file = {/Users/brownsarahm/Zotero/storage/6STE59UP/Zakharov, Dupont - 2011 - Ensemble logistic regression for feature selection(3).pdf}
}

@article{zanninogiandaniele2010visual,
  title = {Visual and Semantic Processing of Living Things and Artifacts: An {{fMRI}} Study},
  author = {{Zannino Gian Daniele} and Buccione, Ivana and Perri, Roberta and Macaluso, Emanuele Lo Gerfo and Caltagirone, Carlo and Carlesimo, Giovanni A},
  year = {2010},
  journal = {Journal of Cognitive Neuroscience},
  volume = {13},
  number = {1},
  pages = {1}
}

@article{zeng2014removal,
  title = {Removal of {{EOG}} Artifacts from {{EEG}} Recordings Using Stationary Subspace Analysis.},
  author = {Zeng, Hong and Song, Aiguo},
  year = {2014},
  month = jan,
  journal = {TheScientificWorldJournal},
  volume = {2014},
  pages = {259121},
  issn = {1537-744X},
  doi = {10.1155/2014/259121},
  abstract = {An effective approach is proposed in this paper to remove ocular artifacts from the raw EEG recording. The proposed approach first conducts the blind source separation on the raw EEG recording by the stationary subspace analysis (SSA) algorithm. Unlike the classic blind source separation algorithms, SSA is explicitly tailored to the understanding of distribution changes, where both the mean and the covariance matrix are taken into account. In addition, neither independency nor uncorrelation is required among the sources by SSA. Thereby, it can concentrate artifacts in fewer components than the representative blind source separation methods. Next, the components that are determined to be related to the ocular artifacts are projected back to be subtracted from EEG signals, producing the clean EEG data eventually. The experimental results on both the artificially contaminated EEG data and real EEG data have demonstrated the effectiveness of the proposed method, in particular for the cases where limited number of electrodes are used for the recording, as well as when the artifact contaminated signal is highly nonstationary and the underlying sources cannot be assumed to be independent or uncorrelated.},
  pmid = {24550696},
  file = {/Users/brownsarahm/Zotero/storage/Z99U5PKR/Zeng, Song - 2014 - Removal of EOG artifacts from EEG recordings using stationary subspace analysis(3).pdf}
}

@article{zeng2015interpretable,
  title = {Interpretable {{Classification Models}} for {{Recidivism Prediction}}},
  author = {Zeng, Jiaming and Ustun, Berk and Rudin, Cynthia},
  year = {2015},
  journal = {arXiv preprint arXiv:1503.07810},
  number = {2014},
  eprint = {1503.07810},
  archiveprefix = {arXiv},
  keywords = {interpretability,machine learning,recidivism,scoring systems},
  file = {/Users/brownsarahm/Zotero/storage/5ZJ923V6/Zeng, Ustun, Rudin - 2015 - Interpretable Classification Models for Recidivism Prediction(4).pdf;/Users/brownsarahm/Zotero/storage/VUK7HANL/Zeng, Ustun, Rudin - 2015 - Interpretable Classification Models for Recidivism Prediction(4).pdf}
}

@article{zhang2004wavelet,
  title = {Wavelet Support Vector Machine.},
  author = {Zhang, Li and Zhou, Weida and Jiao, Licheng},
  year = {2004},
  month = feb,
  journal = {IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society},
  volume = {34},
  number = {1},
  eprint = {15369048},
  eprinttype = {pubmed},
  pages = {34--9},
  issn = {1083-4419},
  abstract = {An admissible support vector (SV) kernel (the wavelet kernel), by which we can construct a wavelet support vector machine (SVM), is presented. The wavelet kernel is a kind of multidimensional wavelet function that can approximate arbitrary nonlinear functions. The existence of wavelet kernels is proven by results of theoretic analysis. Computer simulations show the feasibility and validity of wavelet support vector machines (WSVMs) in regression and pattern recognition.},
  pmid = {15369048},
  file = {/Users/brownsarahm/Zotero/storage/U45GTDPE/Zhang, Zhou, Jiao - 2004 - Wavelet support vector machine(3).pdf}
}

@article{zhang2016achieving,
  title = {Achieving Non-Discrimination in Data Release},
  author = {Zhang, Lu and Wu, Yongkai and Wu, Xintao},
  year = {2016},
  pages = {1335--1344},
  doi = {10.1145/3097983.3098167},
  abstract = {Discrimination discovery and prevention/removal are increasingly important tasks in data mining. Discrimination discovery aims to unveil discriminatory practices on the protected attribute (e.g., gender) by analyzing the dataset of historical decision records, and discrimination prevention aims to remove discrimination by modifying the biased data before conducting predictive analysis. In this paper, we show that the key to discrimination discovery and prevention is to find the meaningful partitions that can be used to provide quantitative evidences for the judgment of discrimination. With the support of the causal graph, we present a graphical condition for identifying a meaningful partition. Based on that, we develop a simple criterion for the claim of non-discrimination, and propose discrimination removal algorithms which accurately remove discrimination while retaining good data utility. Experiments using real datasets show the effectiveness of our approaches.},
  keywords = {- Applied computing -{\textbackslash}textgreater Law,- Information systems -{\textbackslash}textgreater Data mining,- Mathematics of computing -{\textbackslash}textgreater Causal networks,social and behavior},
  file = {/Users/brownsarahm/Zotero/storage/Y648G8PL/Zhang, Wu, Wu - 2016 - Achieving non-discrimination in data release.pdf}
}

@inproceedings{zhang2018mitigating,
  title = {Mitigating Unwanted Biases with Adversarial Learning},
  booktitle = {Proceedings of the 2018 {{AAAI}}/{{ACM}} Conference on {{AI}}, Ethics, and Society},
  author = {Zhang, Brian Hu and Lemoine, Blake and Mitchell, Margaret},
  year = {2018},
  pages = {335--340},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA}
}

@inproceedings{zhang2019active,
  title = {Active Mini-Batch Sampling Using Repulsive Point Processes},
  booktitle = {Proceedings of the {{AAAI}} Conference on Artificial Intelligence},
  author = {Zhang, Cheng and {\"O}ztireli, Cengiz and Mandt, Stephan and Salvi, Giampiero},
  year = {2019},
  volume = {33},
  pages = {5741--5748}
}

@inproceedings{zhang2021Invertible,
  ids = {zhang2021Invertiblea},
  title = {Invertible Concept-Based Explanations for Cnn Models with Non-Negative Concept Activation Vectors},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Zhang, Ruihan and Madumal, Prashan and Miller, Tim and Ehinger, Krista A and Rubinstein, Benjamin IP},
  year = {2021},
  volume = {35},
  pages = {11682--11690}
}

@article{zhao2017men,
  title = {Men {{Also Like Shopping}}: {{Reducing Gender Bias Amplification}} Using {{Corpus-level Constraints}}},
  author = {Zhao, Jieyu and Wang, Tianlu and Yatskar, Mark and Ordonez, Vicente and Chang, Kai-Wei},
  year = {2017},
  journal = {CoRR},
  volume = {abs/1707.09457}
}

@inproceedings{zhou2022mutual,
  ids = {zhou2022Mutual},
  title = {Mutual Information-Driven Pan-Sharpening},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF}} Conference on Computer Vision and Pattern Recognition},
  author = {Zhou, Man and Yan, Keyu and Huang, Jie and Yang, Zihe and Fu, Xueyang and Zhao, Feng},
  year = {2022},
  pages = {1798--1808}
}

@article{zhuang2021enjoy,
  title = {Enjoy Your Editing: {{Controllable GANs}} for Image Editing via Latent Space Navigation},
  author = {Zhuang, Peiye and Koyejo, Oluwasanmi and Schwing, Alexander G},
  year = {2021},
  journal = {arXiv preprint arXiv:2102.01187},
  eprint = {2102.01187},
  archiveprefix = {arXiv}
}

@article{zoladz2013current,
  title = {Current Status on Behavioral and Biological Markers of {{PTSD}}: A Search for Clarity in a Conflicting Literature.},
  author = {Zoladz, Phillip R and Diamond, David M},
  year = {2013},
  month = jun,
  journal = {Neuroscience and biobehavioral reviews},
  volume = {37},
  number = {5},
  eprint = {23567521},
  eprinttype = {pubmed},
  pages = {860--95},
  issn = {1873-7528},
  doi = {10.1016/j.neubiorev.2013.03.024},
  abstract = {Extensive research has identified stereotypic behavioral and biological abnormalities in post-traumatic stress disorder (PTSD), such as heightened autonomic activity, an exaggerated startle response, reduced basal cortisol levels and cognitive impairments. We have reviewed primary research in this area, noting that factors involved in the susceptibility and expression of PTSD symptoms are more complex and heterogeneous than is commonly stated, with extensive findings which are inconsistent with the stereotypic behavioral and biological profile of the PTSD patient. A thorough assessment of the literature indicates that interactions among myriad susceptibility factors, including social support, early life stress, sex, age, peri- and post-traumatic dissociation, cognitive appraisal of trauma, neuroendocrine abnormalities and gene polymorphisms, in conjunction with the inconsistent expression of the disorder across studies, confounds attempts to characterize PTSD as a monolithic disorder. Overall, our assessment of the literature addresses the great challenge in developing a behavioral and biomarker-based diagnosis of PTSD.},
  pmid = {23567521},
  keywords = {Biological Markers,Endocrine System Diseases,Endocrine System Diseases: etiology,Female,Humans,Male,Peripheral Nervous System Diseases,Peripheral Nervous System Diseases: etiology,Post-Traumatic,Post-Traumatic: complications,Post-Traumatic: genetics,Post-Traumatic: psychology,Sex Factors,Stereotyped Behavior,Stereotyped Behavior: physiology,Stress Disorders},
  file = {/Users/brownsarahm/Zotero/storage/25LCKFBW/Zoladz, Diamond - 2013 - Current status on behavioral and biological markers of PTSD a search for clarity in a conflicting literature(3).pdf}
}

@article{zook2017ten,
  title = {Ten Simple Rules for Responsible Big Data Research},
  author = {Zook, Matthew and Barocas, Solon and Boyd, danah and Crawford, Kate and Keller, Emily and Gangadharan, Seeta Pe{\~n}a and Goodman, Alyssa and Hollander, Rachelle and Koenig, Barbara A. and Metcalf, Jacob and Narayanan, Arvind and Nelson, Alondra and Pasquale, Frank},
  year = {2017},
  journal = {PLOS Computational Biology},
  volume = {13},
  number = {3},
  pages = {e1005399},
  doi = {10.1371/journal.pcbi.1005399},
  abstract = {The use of big data research methods has grown tremendously over the past five years in both academia and industry. As the size and complexity of available datasets has grown, so too have the ethical questions raised by big data research. These questions become increasingly urgent as data and research agendas move well beyond those typical of the computational and natural sciences, to more directly address sensitive aspects of human behavior, interaction, and health. The tools of big data research are increasingly woven into our daily lives, including mining digital medical records for scientific and economic insights, mapping relationships via social media, capturing individuals' speech and action via sensors, tracking movement across space, shaping police and security policy via ªpredictive policing,º and much more.}
}

@article{zotero-566,
  abstract = {Machine learning is often characterized as a scienti c discipline, and this suggests we incorporate knowledge of science and its methods into the goals and techniques of the eld. Research in AI and cognitive science further suggests that one can view science as a search through a space of theories that requires two active components \{a generator and a test. The generator produces new theories or variants on existing theories, whereas the test yields information concerning the quality of theories. Science incorporates a variety of tests that\vphantom\}}
}

@article{zou2005regularization,
  title = {Regularization and Variable Selection via the Elastic Net},
  author = {Zou, Hui and Hastie, Trevor},
  year = {2005},
  month = apr,
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {67},
  number = {2},
  pages = {301--320},
  issn = {1369-7412},
  doi = {10.1111/j.1467-9868.2005.00503.x},
  keywords = {grouping effect,lars algorithm,lasso,penalization},
  file = {/Users/brownsarahm/Zotero/storage/GBPM48K9/Zou, Hastie - 2005 - Regularization and variable selection via the elastic net(3).pdf}
}

@article{zou2012priors,
  title = {Priors for {{Diversity}} in {{Generative Latent Variable Models}}.},
  author = {Zou, Jy and Adams, Rp},
  year = {2012},
  journal = {Nips},
  pages = {1--9},
  issn = {10495258},
  file = {/Users/brownsarahm/Zotero/storage/BX468JEU/Zou, Adams - 2012 - Priors for Diversity in Generative Latent Variable Models(3).pdf}
}

@preamble{ "\providecommand{\noopsort}[1]{} " }
