# What is AI *not*? 


## AI is not magic

> Biology is much more magical than anything in a computer. 

There is still a lot about biology that we do not know and biological systems are a part of the *natural* world, that we study through science formally and that we learn informally about through senses during our lived experiences.
AI is a part of a computer, it is *designed* so, at some level every bit of it is known, if not all well understood at all possible levels of abstraction.   

## Generative AI is not automation

Machines can automate things. In general, people expect automated processes to be highly reliable. 
Generative AI is designed to *generate* text based on a pattern that starts with a prompt. 

Automation can save a lot of time, but inserting a generative model in the middle may insert randomness into processes that do not need any. There are a lot of problems that, with a little bit of care, could be *reliably automated* but a Generative AI tool is probably not the best way.  

## Generative AI is not an authoritative source for factual knowledge

It will not give the same response to a given prompt every time. 

LLMs will [make mistakes](#errorproof). 

They meet the philosophical definion of Bullshit @hicks2024chatgpt

## Generative AI is not good at math

Fundamentally, an LLM cannot do any actual calculations, unless it is an agent than can operate a tool (like a calculator). They sometimes provide and can be strategically prompted to give the right answer and special training procedures have shown progress in this. 


## Generative AI is not search

Traditional, strict search {term}`algorithms <algorithm>`, a type of algorithm for finding an item in a set.  Modern, large scale search engines, like Google, have been machine learning- based since their inception.  They were learning what page the person was most likely to choose to read[^click] given the query. 

Generative AI, at base is more like a compressed copy of the internet that is then expanded to produce an answer, randomly because it is lossy compression[^tokenparam].

[^tokenparam]: they are trained on millions or hundreds of millions of tokens and have 